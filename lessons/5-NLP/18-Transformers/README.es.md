# Mecanismos de Atenci贸n y Transformadores

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/118)

Uno de los problemas m谩s importantes en el 谩mbito de la PNL es la **traducci贸n autom谩tica**, una tarea esencial en la que se basan herramientas como Google Translate. En esta secci贸n, nos centraremos en la traducci贸n autom谩tica o, m谩s generalmente, en cualquier tarea de *secuencia a secuencia* (que tambi茅n se denomina **transducci贸n de oraciones**).

Con los RNN, la secuencia a secuencia se implementa mediante dos redes recurrentes, donde una red, el **codificador**, colapsa una secuencia de entrada en un estado oculto, mientras que otra red, el **decodificador**, desenrolla este estado oculto. en un resultado traducido. Hay un par de problemas con este enfoque:

* El estado final de la red del codificador tiene dificultades para recordar el comienzo de una oraci贸n, lo que provoca una mala calidad del modelo para oraciones largas.
* Todas las palabras de una secuencia tienen el mismo impacto en el resultado. En realidad, sin embargo, palabras espec铆ficas en la secuencia de entrada a menudo tienen m谩s impacto que otras en las salidas secuenciales.

Los **Mecanismos de atenci贸n** proporcionan un medio para ponderar el impacto contextual de cada vector de entrada en cada predicci贸n de salida del RNN. La forma en que se implementa es creando accesos directos entre los estados intermedios del RNN de entrada y el RNN de salida. De esta manera, al generar el s铆mbolo de salida y<sub>t</sub>, tendremos en cuenta todos los estados ocultos de entrada h<sub>i</sub>, con diferentes coeficientes de peso 伪<sub>t,i< /sub>.

![Image showing an encoder/decoder model with an additive attention layer](./images/encoder-decoder-attention.png)

> El modelo codificador-decodificador con mecanismo de atenci贸n aditiva en [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf), citado de [this blog post](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

La matriz de atenci贸n {&alpha;<sub>i,j</sub>} representar铆a el grado que ciertas palabras de entrada juegan en la generaci贸n de una palabra determinada en la secuencia de salida. A continuaci贸n se muestra un ejemplo de dicha matriz:

![Image showing a sample alignment found by RNNsearch-50, taken from Bahdanau - arviz.org](./images/bahdanau-fig3.png)

> Figura de [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf) (Fig.3)

Los mecanismos de atenci贸n son responsables de gran parte del estado actual o casi actual de la PNL. Sin embargo, agregar atenci贸n aumenta en gran medida la cantidad de par谩metros del modelo, lo que gener贸 problemas de escala con los RNN. Una limitaci贸n clave del escalamiento de RNN es que la naturaleza recurrente de los modelos dificulta el entrenamiento por lotes y paralelizado. En un RNN, cada elemento de una secuencia debe procesarse en orden secuencial, lo que significa que no se puede paralelizar f谩cilmente.

![Encoder Decoder with Attention](images/EncDecAttention.gif)

> Figura de [Google's Blog](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)

La adopci贸n de mecanismos de atenci贸n combinada con esta restricci贸n llev贸 a la creaci贸n de los modelos de transformadores de 煤ltima generaci贸n que conocemos y utilizamos hoy, como BERT para Open-GPT3.

## Modelos de transformadores

Una de las ideas principales detr谩s de los transformadores es evitar la naturaleza secuencial de los RNN y crear un modelo que sea paralelizable durante el entrenamiento. Esto se logra implementando dos ideas:

* codificaci贸n posicional
* usar un mecanismo de autoatenci贸n para capturar patrones en lugar de RNN (o CNN) (por eso el art铆culo que presenta los transformadores se llama *[La atenci贸n es todo lo que necesitas](https://arxiv.org/abs/1706.03762)*

### Codificaci贸n/incrustaci贸n posicional

La idea de codificaci贸n posicional es la siguiente.
1. Cuando se utilizan RNN, la posici贸n relativa de los tokens est谩 representada por el n煤mero de pasos y, por lo tanto, no es necesario representarla expl铆citamente.
2. Sin embargo, una vez que pasamos a prestar atenci贸n, necesitamos conocer las posiciones relativas de las fichas dentro de una secuencia.
3. Para obtener codificaci贸n posicional, aumentamos nuestra secuencia de tokens con una secuencia de posiciones de tokens en la secuencia (es decir, una secuencia de n煤meros 0,1,...).
4. Luego mezclamos la posici贸n del token con un vector de incrustaci贸n del token. Para transformar la posici贸n (entero) en un vector, podemos utilizar diferentes enfoques:

* Incrustaci贸n entrenable, similar a la incrustaci贸n de tokens. Este es el enfoque que consideramos aqu铆. Aplicamos capas de incrustaci贸n sobre ambos tokens y sus posiciones, lo que da como resultado vectores de incrustaci贸n de las mismas dimensiones, que luego sumamos.
* Funci贸n de codificaci贸n de posici贸n fija, como se propone en el art铆culo original.

<img src="images/pos-embedding.png" width="50%"/>

> Imagen del autor

El resultado que obtenemos con la incrustaci贸n posicional incrusta tanto el token original como su posici贸n dentro de una secuencia.

### Autoatenci贸n de m煤ltiples cabezas

A continuaci贸n, necesitamos capturar algunos patrones dentro de nuestra secuencia. Para hacer esto, los transformadores utilizan un mecanismo de **autoatenci贸n**, que es esencialmente atenci贸n aplicada a la misma secuencia que la entrada y la salida. Aplicar la atenci贸n personal nos permite tener en cuenta el **contexto** dentro de la oraci贸n y ver qu茅 palabras est谩n interrelacionadas. Por ejemplo, nos permite ver a qu茅 palabras se hace referencia mediante correferencias, como *it*, y tambi茅n tener en cuenta el contexto:

![](images/CoreferenceResolution.png)

> Imagen de [Google Blog](https://research.googleblog.com/2017/08/transformer-novel-neural-network.html)

En los transformadores, utilizamos **Atenci贸n de m煤ltiples cabezales** para darle a la red el poder de capturar varios tipos diferentes de dependencias, por ejemplo. relaciones de palabras a largo plazo versus a corto plazo, correferencia versus otra cosa, etc.

[TensorFlow Notebook](TransformersTF.ipynb) contiene m谩s detalles sobre la implementaci贸n de capas transformadoras.

### Atenci贸n codificador-decodificador

En los transformadores, la atenci贸n se utiliza en dos lugares:

* Para capturar patrones dentro del texto ingresado usando la atenci贸n propia
* Para realizar la traducci贸n de secuencias: es la capa de atenci贸n entre el codificador y el decodificador.

La atenci贸n del codificador-decodificador es muy similar al mecanismo de atenci贸n utilizado en los RNN, como se describe al principio de esta secci贸n. Este diagrama animado explica el papel de la atenci贸n del codificador-decodificador.

![Animated GIF showing how the evaluations are performed in transformer models.](./images/transformer-animated-explanation.gif)

Dado que cada posici贸n de entrada se asigna de forma independiente a cada posici贸n de salida, los transformadores pueden paralelizarse mejor que los RNN, lo que permite modelos de lenguaje mucho m谩s grandes y expresivos. Cada cabeza de atenci贸n se puede utilizar para aprender diferentes relaciones entre palabras, lo que mejora las tareas posteriores de procesamiento del lenguaje natural.

##BERTO

**BERT** (Representaciones de codificador bidireccional de transformadores) es una red de transformadores multicapa muy grande con 12 capas para *BERT-base* y 24 para *BERT-large*. Primero, el modelo se entrena previamente en un gran corpus de datos de texto (WikiPedia + libros) mediante entrenamiento no supervisado (predicci贸n de palabras enmascaradas en una oraci贸n). Durante el entrenamiento previo, el modelo absorbe niveles significativos de comprensi贸n del lenguaje que luego se pueden aprovechar con otros conjuntos de datos mediante un ajuste fino. Este proceso se llama **transferencia de aprendizaje**.

![picture from http://jalammar.github.io/illustrated-bert/](images/jalammarBERT-language-modeling-masked-lm.png)

> Imagen [source](http://jalammar.github.io/illustrated-bert/)

## 锔 Ejercicios: Transformadores

Contin煤a tu aprendizaje en los siguientes cuadernos:

* [Transformers in PyTorch](TransformersPyTorch.ipynb)
* [Transformers in TensorFlow](TransformersTF.ipynb)

## Conclusi贸n

En esta lecci贸n aprendiste sobre los transformadores y los mecanismos de atenci贸n, todas herramientas esenciales en la caja de herramientas de la PNL. Existen muchas variaciones de arquitecturas Transformer, incluidas BERT, DistilBERT. BigBird, OpenGPT3 y m谩s que se pueden ajustar. El [paquete HuggingFace](https://github.com/huggingface/) proporciona un repositorio para entrenar muchas de estas arquitecturas con PyTorch y TensorFlow.

##  Desaf铆o

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/218)

# Revisi贸n y autoestudio

* [Blog post](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/), explaining the classical [Attention is all you need](https://arxiv.org/abs/1706.03762) paper on transformers.
* [A series of blog posts](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452) on transformers, explaining the architecture in detail.

## [Assignment](assignment.md)


