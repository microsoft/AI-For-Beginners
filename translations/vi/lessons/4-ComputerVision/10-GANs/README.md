# Máº¡ng Generative Adversarial (GAN)

Trong pháº§n trÆ°á»›c, chÃºng ta Ä‘Ã£ tÃ¬m hiá»ƒu vá» **mÃ´ hÃ¬nh sinh**: cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ táº¡o ra hÃ¬nh áº£nh má»›i tÆ°Æ¡ng tá»± nhÆ° nhá»¯ng hÃ¬nh áº£nh trong táº­p dá»¯ liá»‡u huáº¥n luyá»‡n. VAE lÃ  má»™t vÃ­ dá»¥ Ä‘iá»ƒn hÃ¬nh cá»§a mÃ´ hÃ¬nh sinh.

## [CÃ¢u há»i trÆ°á»›c bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/19)

Tuy nhiÃªn, náº¿u chÃºng ta cá»‘ gáº¯ng táº¡o ra thá»© gÃ¬ Ä‘Ã³ thá»±c sá»± Ã½ nghÄ©a, nhÆ° má»™t bá»©c tranh vá»›i Ä‘á»™ phÃ¢n giáº£i há»£p lÃ½, báº±ng VAE, chÃºng ta sáº½ tháº¥y ráº±ng viá»‡c huáº¥n luyá»‡n khÃ´ng há»™i tá»¥ tá»‘t. Äá»‘i vá»›i trÆ°á»ng há»£p nÃ y, chÃºng ta nÃªn tÃ¬m hiá»ƒu vá» má»™t kiáº¿n trÃºc khÃ¡c Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº·c biá»‡t cho cÃ¡c mÃ´ hÃ¬nh sinh - **Máº¡ng Generative Adversarial**, hay GAN.

Ã tÆ°á»Ÿng chÃ­nh cá»§a GAN lÃ  cÃ³ hai máº¡ng nÆ¡-ron Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»‘i khÃ¡ng láº«n nhau:

<img src="../../../../../translated_images/vi/gan_architecture.8f3a5ab62b8d5d69.webp" width="70%"/>

> HÃ¬nh áº£nh bá»Ÿi [Dmitry Soshnikov](http://soshnikov.com)

> âœ… Má»™t chÃºt tá»« vá»±ng:
> * **Generator** lÃ  má»™t máº¡ng nháº­n má»™t vector ngáº«u nhiÃªn vÃ  táº¡o ra hÃ¬nh áº£nh nhÆ° káº¿t quáº£
> * **Discriminator** lÃ  má»™t máº¡ng nháº­n má»™t hÃ¬nh áº£nh vÃ  pháº£i xÃ¡c Ä‘á»‹nh xem Ä‘Ã³ lÃ  hÃ¬nh áº£nh tháº­t (tá»« táº­p dá»¯ liá»‡u huáº¥n luyá»‡n) hay lÃ  hÃ¬nh áº£nh Ä‘Æ°á»£c táº¡o bá»Ÿi generator. NÃ³ vá» cÆ¡ báº£n lÃ  má»™t bá»™ phÃ¢n loáº¡i hÃ¬nh áº£nh.

### Discriminator

Kiáº¿n trÃºc cá»§a discriminator khÃ´ng khÃ¡c gÃ¬ so vá»›i má»™t máº¡ng phÃ¢n loáº¡i hÃ¬nh áº£nh thÃ´ng thÆ°á»ng. Trong trÆ°á»ng há»£p Ä‘Æ¡n giáº£n nháº¥t, nÃ³ cÃ³ thá»ƒ lÃ  má»™t bá»™ phÃ¢n loáº¡i fully-connected, nhÆ°ng thÆ°á»ng sáº½ lÃ  má»™t [máº¡ng tÃ­ch cháº­p](../07-ConvNets/README.md).

> âœ… Má»™t GAN dá»±a trÃªn máº¡ng tÃ­ch cháº­p Ä‘Æ°á»£c gá»i lÃ  [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Má»™t CNN discriminator bao gá»“m cÃ¡c lá»›p sau: má»™t sá»‘ lá»›p tÃ­ch cháº­p+káº¿t há»£p (vá»›i kÃ­ch thÆ°á»›c khÃ´ng gian giáº£m dáº§n) vÃ  má»™t hoáº·c nhiá»u lá»›p fully-connected Ä‘á»ƒ táº¡o "vector Ä‘áº·c trÆ°ng", cuá»‘i cÃ¹ng lÃ  bá»™ phÃ¢n loáº¡i nhá»‹ phÃ¢n.

> âœ… 'Pooling' trong ngá»¯ cáº£nh nÃ y lÃ  má»™t ká»¹ thuáº­t giáº£m kÃ­ch thÆ°á»›c hÃ¬nh áº£nh. "CÃ¡c lá»›p pooling giáº£m kÃ­ch thÆ°á»›c dá»¯ liá»‡u báº±ng cÃ¡ch káº¿t há»£p Ä‘áº§u ra cá»§a cÃ¡c cá»¥m neuron táº¡i má»™t lá»›p thÃ nh má»™t neuron duy nháº¥t á»Ÿ lá»›p tiáº¿p theo." - [nguá»“n](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

Generator hÆ¡i phá»©c táº¡p hÆ¡n má»™t chÃºt. Báº¡n cÃ³ thá»ƒ coi nÃ³ nhÆ° lÃ  má»™t discriminator Ä‘áº£o ngÆ°á»£c. Báº¯t Ä‘áº§u tá»« má»™t vector tiá»m áº©n (thay vÃ¬ vector Ä‘áº·c trÆ°ng), nÃ³ cÃ³ má»™t lá»›p fully-connected Ä‘á»ƒ chuyá»ƒn Ä‘á»•i thÃ nh kÃ­ch thÆ°á»›c/hÃ¬nh dáº¡ng yÃªu cáº§u, sau Ä‘Ã³ lÃ  cÃ¡c lá»›p deconvolution+káº¿t há»£p. Äiá»u nÃ y tÆ°Æ¡ng tá»± nhÆ° pháº§n *decoder* cá»§a [autoencoder](../09-Autoencoders/README.md).

> âœ… VÃ¬ lá»›p tÃ­ch cháº­p Ä‘Æ°á»£c triá»ƒn khai nhÆ° má»™t bá»™ lá»c tuyáº¿n tÃ­nh quÃ©t qua hÃ¬nh áº£nh, deconvolution vá» cÆ¡ báº£n tÆ°Æ¡ng tá»± nhÆ° tÃ­ch cháº­p vÃ  cÃ³ thá»ƒ Ä‘Æ°á»£c triá»ƒn khai báº±ng cÃ¹ng logic lá»›p.

<img src="../../../../../translated_images/vi/gan_arch_detail.46b95fd366f8e543.webp" width="70%"/>

> HÃ¬nh áº£nh bá»Ÿi [Dmitry Soshnikov](http://soshnikov.com)

### Huáº¥n luyá»‡n GAN

GAN Ä‘Æ°á»£c gá»i lÃ  **Ä‘á»‘i khÃ¡ng** vÃ¬ cÃ³ sá»± cáº¡nh tranh liÃªn tá»¥c giá»¯a generator vÃ  discriminator. Trong quÃ¡ trÃ¬nh cáº¡nh tranh nÃ y, cáº£ generator vÃ  discriminator Ä‘á»u cáº£i thiá»‡n, do Ä‘Ã³ máº¡ng há»c cÃ¡ch táº¡o ra hÃ¬nh áº£nh ngÃ y cÃ ng tá»‘t hÆ¡n.

QuÃ¡ trÃ¬nh huáº¥n luyá»‡n diá»…n ra trong hai giai Ä‘oáº¡n:

* **Huáº¥n luyá»‡n discriminator**. Nhiá»‡m vá»¥ nÃ y khÃ¡ Ä‘Æ¡n giáº£n: chÃºng ta táº¡o má»™t batch hÃ¬nh áº£nh báº±ng generator, gÃ¡n nhÃ£n 0, tá»©c lÃ  hÃ¬nh áº£nh giáº£, vÃ  láº¥y má»™t batch hÃ¬nh áº£nh tá»« táº­p dá»¯ liá»‡u Ä‘áº§u vÃ o (vá»›i nhÃ£n 1, hÃ¬nh áº£nh tháº­t). ChÃºng ta thu Ä‘Æ°á»£c má»™t *discriminator loss* vÃ  thá»±c hiá»‡n backprop.
* **Huáº¥n luyá»‡n generator**. Äiá»u nÃ y hÆ¡i phá»©c táº¡p hÆ¡n má»™t chÃºt, vÃ¬ chÃºng ta khÃ´ng biáº¿t Ä‘áº§u ra mong Ä‘á»£i cho generator trá»±c tiáº¿p. ChÃºng ta láº¥y toÃ n bá»™ máº¡ng GAN bao gá»“m generator ná»‘i tiáº¿p vá»›i discriminator, cung cáº¥p cho nÃ³ má»™t sá»‘ vector ngáº«u nhiÃªn vÃ  mong Ä‘á»£i káº¿t quáº£ lÃ  1 (tÆ°Æ¡ng á»©ng vá»›i hÃ¬nh áº£nh tháº­t). Sau Ä‘Ã³, chÃºng ta Ä‘Ã³ng bÄƒng cÃ¡c tham sá»‘ cá»§a discriminator (khÃ´ng muá»‘n nÃ³ Ä‘Æ°á»£c huáº¥n luyá»‡n á»Ÿ bÆ°á»›c nÃ y) vÃ  thá»±c hiá»‡n backprop.

Trong quÃ¡ trÃ¬nh nÃ y, cáº£ generator vÃ  discriminator loss Ä‘á»u khÃ´ng giáº£m Ä‘Ã¡ng ká»ƒ. Trong tÃ¬nh huá»‘ng lÃ½ tÆ°á»Ÿng, chÃºng nÃªn dao Ä‘á»™ng, tÆ°Æ¡ng á»©ng vá»›i viá»‡c cáº£ hai máº¡ng cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a mÃ¬nh.

## âœï¸ BÃ i táº­p: GANs

* [Notebook GAN trong TensorFlow/Keras](GANTF.ipynb)
* [Notebook GAN trong PyTorch](GANPyTorch.ipynb)

### CÃ¡c váº¥n Ä‘á» khi huáº¥n luyá»‡n GAN

GAN Ä‘Æ°á»£c biáº¿t Ä‘áº¿n lÃ  Ä‘áº·c biá»‡t khÃ³ huáº¥n luyá»‡n. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ váº¥n Ä‘á»:

* **Mode Collapse**. Thuáº­t ngá»¯ nÃ y Ã¡m chá»‰ viá»‡c generator há»c cÃ¡ch táº¡o ra má»™t hÃ¬nh áº£nh thÃ nh cÃ´ng duy nháº¥t Ä‘á»ƒ Ä‘Ã¡nh lá»«a discriminator, thay vÃ¬ táº¡o ra nhiá»u hÃ¬nh áº£nh khÃ¡c nhau.
* **Nháº¡y cáº£m vá»›i siÃªu tham sá»‘**. ThÆ°á»ng báº¡n cÃ³ thá»ƒ tháº¥y ráº±ng GAN khÃ´ng há»™i tá»¥ chÃºt nÃ o, vÃ  sau Ä‘Ã³ Ä‘á»™t ngá»™t giáº£m tá»‘c Ä‘á»™ há»c dáº«n Ä‘áº¿n há»™i tá»¥.
* Giá»¯ **cÃ¢n báº±ng** giá»¯a generator vÃ  discriminator. Trong nhiá»u trÆ°á»ng há»£p, discriminator loss cÃ³ thá»ƒ giáº£m xuá»‘ng 0 tÆ°Æ¡ng Ä‘á»‘i nhanh, dáº«n Ä‘áº¿n generator khÃ´ng thá»ƒ tiáº¿p tá»¥c huáº¥n luyá»‡n. Äá»ƒ kháº¯c phá»¥c Ä‘iá»u nÃ y, chÃºng ta cÃ³ thá»ƒ thá»­ Ä‘áº·t cÃ¡c tá»‘c Ä‘á»™ há»c khÃ¡c nhau cho generator vÃ  discriminator, hoáº·c bá» qua viá»‡c huáº¥n luyá»‡n discriminator náº¿u loss Ä‘Ã£ quÃ¡ tháº¥p.
* Huáº¥n luyá»‡n cho **Ä‘á»™ phÃ¢n giáº£i cao**. Pháº£n Ã¡nh cÃ¹ng váº¥n Ä‘á» nhÆ° vá»›i autoencoders, váº¥n Ä‘á» nÃ y xáº£y ra vÃ¬ viá»‡c tÃ¡i táº¡o quÃ¡ nhiá»u lá»›p cá»§a máº¡ng tÃ­ch cháº­p dáº«n Ä‘áº¿n cÃ¡c lá»—i. Váº¥n Ä‘á» nÃ y thÆ°á»ng Ä‘Æ°á»£c giáº£i quyáº¿t báº±ng cÃ¡ch **phÃ¡t triá»ƒn dáº§n**, khi Ä‘áº§u tiÃªn má»™t vÃ i lá»›p Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn hÃ¬nh áº£nh Ä‘á»™ phÃ¢n giáº£i tháº¥p, sau Ä‘Ã³ cÃ¡c lá»›p Ä‘Æ°á»£c "má»Ÿ khÃ³a" hoáº·c thÃªm vÃ o. Má»™t giáº£i phÃ¡p khÃ¡c lÃ  thÃªm cÃ¡c káº¿t ná»‘i bá»• sung giá»¯a cÃ¡c lá»›p vÃ  huáº¥n luyá»‡n nhiá»u Ä‘á»™ phÃ¢n giáº£i cÃ¹ng lÃºc - xem bÃ i bÃ¡o [Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) Ä‘á»ƒ biáº¿t chi tiáº¿t.

## Style Transfer

GAN lÃ  má»™t cÃ¡ch tuyá»‡t vá»i Ä‘á»ƒ táº¡o ra hÃ¬nh áº£nh nghá»‡ thuáº­t. Má»™t ká»¹ thuáº­t thÃº vá»‹ khÃ¡c lÃ  **style transfer**, ká»¹ thuáº­t nÃ y láº¥y má»™t **hÃ¬nh áº£nh ná»™i dung** vÃ  váº½ láº¡i nÃ³ theo má»™t phong cÃ¡ch khÃ¡c, Ã¡p dá»¥ng cÃ¡c bá»™ lá»c tá»« **hÃ¬nh áº£nh phong cÃ¡ch**.

CÃ¡ch hoáº¡t Ä‘á»™ng nhÆ° sau:
* ChÃºng ta báº¯t Ä‘áº§u vá»›i má»™t hÃ¬nh áº£nh nhiá»…u ngáº«u nhiÃªn (hoáº·c vá»›i hÃ¬nh áº£nh ná»™i dung, nhÆ°ng Ä‘á»ƒ dá»… hiá»ƒu hÆ¡n thÃ¬ báº¯t Ä‘áº§u tá»« nhiá»…u ngáº«u nhiÃªn)
* Má»¥c tiÃªu cá»§a chÃºng ta lÃ  táº¡o ra má»™t hÃ¬nh áº£nh gáº§n vá»›i cáº£ hÃ¬nh áº£nh ná»™i dung vÃ  hÃ¬nh áº£nh phong cÃ¡ch. Äiá»u nÃ y Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi hai hÃ m loss:
   - **Content loss** Ä‘Æ°á»£c tÃ­nh dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng Ä‘Æ°á»£c trÃ­ch xuáº¥t bá»Ÿi CNN táº¡i má»™t sá»‘ lá»›p tá»« hÃ¬nh áº£nh hiá»‡n táº¡i vÃ  hÃ¬nh áº£nh ná»™i dung
   - **Style loss** Ä‘Æ°á»£c tÃ­nh giá»¯a hÃ¬nh áº£nh hiá»‡n táº¡i vÃ  hÃ¬nh áº£nh phong cÃ¡ch theo cÃ¡ch thÃ´ng minh sá»­ dá»¥ng ma tráº­n Gram (chi tiáº¿t hÆ¡n trong [notebook vÃ­ dá»¥](StyleTransfer.ipynb))
* Äá»ƒ lÃ m hÃ¬nh áº£nh mÆ°á»£t hÆ¡n vÃ  loáº¡i bá» nhiá»…u, chÃºng ta cÅ©ng giá»›i thiá»‡u **Variation loss**, tÃ­nh khoáº£ng cÃ¡ch trung bÃ¬nh giá»¯a cÃ¡c pixel lÃ¢n cáº­n
* VÃ²ng láº·p tá»‘i Æ°u chÃ­nh Ä‘iá»u chá»‰nh hÃ¬nh áº£nh hiá»‡n táº¡i báº±ng cÃ¡ch sá»­ dá»¥ng gradient descent (hoáº·c má»™t thuáº­t toÃ¡n tá»‘i Æ°u khÃ¡c) Ä‘á»ƒ giáº£m thiá»ƒu tá»•ng loss, lÃ  tá»•ng cÃ³ trá»ng sá»‘ cá»§a cáº£ ba loáº¡i loss.

## âœï¸ VÃ­ dá»¥: [Style Transfer](StyleTransfer.ipynb)

## [CÃ¢u há»i sau bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## Káº¿t luáº­n

Trong bÃ i há»c nÃ y, báº¡n Ä‘Ã£ tÃ¬m hiá»ƒu vá» GANs vÃ  cÃ¡ch huáº¥n luyá»‡n chÃºng. Báº¡n cÅ©ng Ä‘Ã£ tÃ¬m hiá»ƒu vá» nhá»¯ng thÃ¡ch thá»©c Ä‘áº·c biá»‡t mÃ  loáº¡i máº¡ng nÆ¡-ron nÃ y cÃ³ thá»ƒ gáº·p pháº£i vÃ  má»™t sá»‘ chiáº¿n lÆ°á»£c Ä‘á»ƒ vÆ°á»£t qua chÃºng.

## ğŸš€ Thá»­ thÃ¡ch

Cháº¡y qua [notebook Style Transfer](StyleTransfer.ipynb) sá»­ dá»¥ng hÃ¬nh áº£nh cá»§a riÃªng báº¡n.

## Ã”n táº­p & Tá»± há»c

Äá»ƒ tham kháº£o, hÃ£y Ä‘á»c thÃªm vá» GANs trong cÃ¡c tÃ i liá»‡u sau:

* Marco Pasini, [10 BÃ i há»c tÃ´i há»c Ä‘Æ°á»£c khi huáº¥n luyá»‡n GANs trong má»™t nÄƒm](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), má»™t kiáº¿n trÃºc GAN *de facto* Ä‘Ã¡ng xem xÃ©t
* [Táº¡o nghá»‡ thuáº­t sinh báº±ng GANs trÃªn Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## BÃ i táº­p

Xem láº¡i má»™t trong hai notebook liÃªn quan Ä‘áº¿n bÃ i há»c nÃ y vÃ  huáº¥n luyá»‡n láº¡i GAN vá»›i hÃ¬nh áº£nh cá»§a riÃªng báº¡n. Báº¡n cÃ³ thá»ƒ táº¡o ra gÃ¬?

---

