# Autoencoders

Khi huáº¥n luyá»‡n CNN, má»™t trong nhá»¯ng váº¥n Ä‘á» lÃ  chÃºng ta cáº§n ráº¥t nhiá»u dá»¯ liá»‡u Ä‘Æ°á»£c gáº¯n nhÃ£n. Trong trÆ°á»ng há»£p phÃ¢n loáº¡i hÃ¬nh áº£nh, chÃºng ta cáº§n phÃ¢n chia hÃ¬nh áº£nh thÃ nh cÃ¡c lá»›p khÃ¡c nhau, Ä‘iá»u nÃ y Ä‘Ã²i há»i sá»± ná»— lá»±c thá»§ cÃ´ng.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/17)

Tuy nhiÃªn, chÃºng ta cÃ³ thá»ƒ muá»‘n sá»­ dá»¥ng dá»¯ liá»‡u thÃ´ (khÃ´ng Ä‘Æ°á»£c gáº¯n nhÃ£n) Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c bá»™ trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng cá»§a CNN, Ä‘iá»u nÃ y Ä‘Æ°á»£c gá»i lÃ  **há»c tá»± giÃ¡m sÃ¡t**. Thay vÃ¬ sá»­ dá»¥ng nhÃ£n, chÃºng ta sáº½ sá»­ dá»¥ng hÃ¬nh áº£nh huáº¥n luyá»‡n lÃ m cáº£ Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra cá»§a máº¡ng. Ã tÆ°á»Ÿng chÃ­nh cá»§a **autoencoder** lÃ  chÃºng ta sáº½ cÃ³ má»™t **máº¡ng mÃ£ hÃ³a** chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh Ä‘áº§u vÃ o thÃ nh má»™t **khÃ´ng gian tiá»m áº©n** nÃ o Ä‘Ã³ (thÆ°á»ng chá»‰ lÃ  má»™t vector cÃ³ kÃ­ch thÆ°á»›c nhá» hÆ¡n), sau Ä‘Ã³ lÃ  **máº¡ng giáº£i mÃ£**, vá»›i má»¥c tiÃªu tÃ¡i táº¡o láº¡i hÃ¬nh áº£nh gá»‘c.

> âœ… Má»™t [autoencoder](https://wikipedia.org/wiki/Autoencoder) lÃ  "má»™t loáº¡i máº¡ng nÆ¡-ron nhÃ¢n táº¡o Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ há»c cÃ¡ch mÃ£ hÃ³a hiá»‡u quáº£ dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c gáº¯n nhÃ£n."

VÃ¬ chÃºng ta Ä‘ang huáº¥n luyá»‡n autoencoder Ä‘á»ƒ náº¯m báº¯t cÃ ng nhiá»u thÃ´ng tin tá»« hÃ¬nh áº£nh gá»‘c cÃ ng tá»‘t nháº±m tÃ¡i táº¡o chÃ­nh xÃ¡c, máº¡ng cá»‘ gáº¯ng tÃ¬m **embedding** tá»‘t nháº¥t cá»§a hÃ¬nh áº£nh Ä‘áº§u vÃ o Ä‘á»ƒ náº¯m báº¯t Ã½ nghÄ©a.

![SÆ¡ Ä‘á»“ AutoEncoder](../../../../../translated_images/vi/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> HÃ¬nh áº£nh tá»« [blog Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## CÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng Autoencoders

Máº·c dÃ¹ viá»‡c tÃ¡i táº¡o hÃ¬nh áº£nh gá»‘c cÃ³ váº» khÃ´ng há»¯u Ã­ch tá»± thÃ¢n, nhÆ°ng cÃ³ má»™t sá»‘ trÆ°á»ng há»£p autoencoders Ä‘áº·c biá»‡t há»¯u Ã­ch:

* **Giáº£m chiá»u cá»§a hÃ¬nh áº£nh Ä‘á»ƒ trá»±c quan hÃ³a** hoáº·c **huáº¥n luyá»‡n embedding hÃ¬nh áº£nh**. ThÃ´ng thÆ°á»ng autoencoders cho káº¿t quáº£ tá»‘t hÆ¡n PCA, vÃ¬ nÃ³ tÃ­nh Ä‘áº¿n tÃ­nh cháº¥t khÃ´ng gian cá»§a hÃ¬nh áº£nh vÃ  cÃ¡c Ä‘áº·c trÆ°ng phÃ¢n cáº¥p.
* **Khá»­ nhiá»…u**, tá»©c lÃ  loáº¡i bá» nhiá»…u khá»i hÃ¬nh áº£nh. VÃ¬ nhiá»…u mang theo ráº¥t nhiá»u thÃ´ng tin khÃ´ng cáº§n thiáº¿t, autoencoder khÃ´ng thá»ƒ Ä‘Æ°a táº¥t cáº£ vÃ o khÃ´ng gian tiá»m áº©n tÆ°Æ¡ng Ä‘á»‘i nhá», do Ä‘Ã³ nÃ³ chá»‰ náº¯m báº¯t pháº§n quan trá»ng cá»§a hÃ¬nh áº£nh. Khi huáº¥n luyá»‡n bá»™ khá»­ nhiá»…u, chÃºng ta báº¯t Ä‘áº§u vá»›i hÃ¬nh áº£nh gá»‘c vÃ  sá»­ dá»¥ng hÃ¬nh áº£nh cÃ³ nhiá»…u Ä‘Æ°á»£c thÃªm vÃ o má»™t cÃ¡ch nhÃ¢n táº¡o lÃ m Ä‘áº§u vÃ o cho autoencoder.
* **SiÃªu phÃ¢n giáº£i**, tÄƒng Ä‘á»™ phÃ¢n giáº£i hÃ¬nh áº£nh. ChÃºng ta báº¯t Ä‘áº§u vá»›i hÃ¬nh áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i cao vÃ  sá»­ dá»¥ng hÃ¬nh áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i tháº¥p hÆ¡n lÃ m Ä‘áº§u vÃ o cho autoencoder.
* **MÃ´ hÃ¬nh sinh**. Sau khi huáº¥n luyá»‡n autoencoder, pháº§n giáº£i mÃ£ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra cÃ¡c Ä‘á»‘i tÆ°á»£ng má»›i báº¯t Ä‘áº§u tá»« cÃ¡c vector tiá»m áº©n ngáº«u nhiÃªn.

## Autoencoders Biáº¿n thá»ƒ (VAE)

Autoencoders truyá»n thá»‘ng giáº£m chiá»u cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o báº±ng cÃ¡ch nÃ o Ä‘Ã³, tÃ¬m ra cÃ¡c Ä‘áº·c trÆ°ng quan trá»ng cá»§a hÃ¬nh áº£nh Ä‘áº§u vÃ o. Tuy nhiÃªn, cÃ¡c vector tiá»m áº©n thÆ°á»ng khÃ´ng cÃ³ Ã½ nghÄ©a nhiá»u. NÃ³i cÃ¡ch khÃ¡c, láº¥y vÃ­ dá»¥ bá»™ dá»¯ liá»‡u MNIST, viá»‡c xÃ¡c Ä‘á»‹nh cÃ¡c chá»¯ sá»‘ tÆ°Æ¡ng á»©ng vá»›i cÃ¡c vector tiá»m áº©n khÃ¡c nhau khÃ´ng pháº£i lÃ  nhiá»‡m vá»¥ dá»… dÃ ng, vÃ¬ cÃ¡c vector tiá»m áº©n gáº§n nhau khÃ´ng nháº¥t thiáº¿t pháº£i tÆ°Æ¡ng á»©ng vá»›i cÃ¹ng má»™t chá»¯ sá»‘.

Máº·t khÃ¡c, Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh *sinh*, tá»‘t hÆ¡n lÃ  cÃ³ má»™t sá»± hiá»ƒu biáº¿t vá» khÃ´ng gian tiá»m áº©n. Ã tÆ°á»Ÿng nÃ y dáº«n chÃºng ta Ä‘áº¿n **autoencoder biáº¿n thá»ƒ** (VAE).

VAE lÃ  autoencoder há»c cÃ¡ch dá»± Ä‘oÃ¡n *phÃ¢n phá»‘i thá»‘ng kÃª* cá»§a cÃ¡c tham sá»‘ tiá»m áº©n, Ä‘Æ°á»£c gá»i lÃ  **phÃ¢n phá»‘i tiá»m áº©n**. VÃ­ dá»¥, chÃºng ta cÃ³ thá»ƒ muá»‘n cÃ¡c vector tiá»m áº©n Ä‘Æ°á»£c phÃ¢n phá»‘i theo chuáº©n vá»›i má»™t sá»‘ giÃ¡ trá»‹ trung bÃ¬nh z<sub>mean</sub> vÃ  Ä‘á»™ lá»‡ch chuáº©n z<sub>sigma</sub> (cáº£ giÃ¡ trá»‹ trung bÃ¬nh vÃ  Ä‘á»™ lá»‡ch chuáº©n Ä‘á»u lÃ  cÃ¡c vector cÃ³ má»™t sá»‘ chiá»u d). Bá»™ mÃ£ hÃ³a trong VAE há»c cÃ¡ch dá»± Ä‘oÃ¡n cÃ¡c tham sá»‘ nÃ y, sau Ä‘Ã³ bá»™ giáº£i mÃ£ láº¥y má»™t vector ngáº«u nhiÃªn tá»« phÃ¢n phá»‘i nÃ y Ä‘á»ƒ tÃ¡i táº¡o Ä‘á»‘i tÆ°á»£ng.

TÃ³m láº¡i:

 * Tá»« vector Ä‘áº§u vÃ o, chÃºng ta dá»± Ä‘oÃ¡n `z_mean` vÃ  `z_log_sigma` (thay vÃ¬ dá»± Ä‘oÃ¡n Ä‘á»™ lá»‡ch chuáº©n, chÃºng ta dá»± Ä‘oÃ¡n logarit cá»§a nÃ³)
 * ChÃºng ta láº¥y máº«u má»™t vector `sample` tá»« phÃ¢n phá»‘i N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Bá»™ giáº£i mÃ£ cá»‘ gáº¯ng giáº£i mÃ£ hÃ¬nh áº£nh gá»‘c báº±ng cÃ¡ch sá»­ dá»¥ng `sample` lÃ m vector Ä‘áº§u vÃ o

 <img src="../../../../../translated_images/vi/vae.464c465a5b6a9e25.webp" width="50%">

> HÃ¬nh áº£nh tá»« [bÃ i viáº¿t blog nÃ y](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) cá»§a Isaak Dykeman

Autoencoders biáº¿n thá»ƒ sá»­ dá»¥ng má»™t hÃ m máº¥t mÃ¡t phá»©c táº¡p bao gá»“m hai pháº§n:

* **Máº¥t mÃ¡t tÃ¡i táº¡o** lÃ  hÃ m máº¥t mÃ¡t cho tháº¥y má»©c Ä‘á»™ gáº§n gÅ©i cá»§a hÃ¬nh áº£nh tÃ¡i táº¡o vá»›i má»¥c tiÃªu (nÃ³ cÃ³ thá»ƒ lÃ  Mean Squared Error, hoáº·c MSE). ÄÃ¢y lÃ  hÃ m máº¥t mÃ¡t giá»‘ng nhÆ° trong autoencoders thÃ´ng thÆ°á»ng.
* **Máº¥t mÃ¡t KL**, Ä‘áº£m báº£o ráº±ng phÃ¢n phá»‘i biáº¿n tiá»m áº©n gáº§n vá»›i phÃ¢n phá»‘i chuáº©n. NÃ³ dá»±a trÃªn khÃ¡i niá»‡m [Kullback-Leibler divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - má»™t thÆ°á»›c Ä‘o Ä‘á»ƒ Æ°á»›c tÃ­nh má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a hai phÃ¢n phá»‘i thá»‘ng kÃª.

Má»™t lá»£i tháº¿ quan trá»ng cá»§a VAEs lÃ  chÃºng cho phÃ©p chÃºng ta táº¡o ra hÃ¬nh áº£nh má»›i má»™t cÃ¡ch tÆ°Æ¡ng Ä‘á»‘i dá»… dÃ ng, vÃ¬ chÃºng ta biáº¿t phÃ¢n phá»‘i nÃ o Ä‘á»ƒ láº¥y máº«u cÃ¡c vector tiá»m áº©n. VÃ­ dá»¥, náº¿u chÃºng ta huáº¥n luyá»‡n VAE vá»›i vector tiá»m áº©n 2D trÃªn MNIST, chÃºng ta cÃ³ thá»ƒ thay Ä‘á»•i cÃ¡c thÃ nh pháº§n cá»§a vector tiá»m áº©n Ä‘á»ƒ táº¡o ra cÃ¡c chá»¯ sá»‘ khÃ¡c nhau:

<img alt="vaemnist" src="../../../../../translated_images/vi/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> HÃ¬nh áº£nh bá»Ÿi [Dmitry Soshnikov](http://soshnikov.com)

Quan sÃ¡t cÃ¡ch cÃ¡c hÃ¬nh áº£nh hÃ²a trá»™n vÃ o nhau, khi chÃºng ta báº¯t Ä‘áº§u láº¥y cÃ¡c vector tiá»m áº©n tá»« cÃ¡c pháº§n khÃ¡c nhau cá»§a khÃ´ng gian tham sá»‘ tiá»m áº©n. ChÃºng ta cÅ©ng cÃ³ thá»ƒ trá»±c quan hÃ³a khÃ´ng gian nÃ y trong 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/vi/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> HÃ¬nh áº£nh bá»Ÿi [Dmitry Soshnikov](http://soshnikov.com)

## âœï¸ BÃ i táº­p: Autoencoders

TÃ¬m hiá»ƒu thÃªm vá» autoencoders trong cÃ¡c notebook tÆ°Æ¡ng á»©ng sau:

* [Autoencoders trong TensorFlow](AutoencodersTF.ipynb)
* [Autoencoders trong PyTorch](AutoEncodersPyTorch.ipynb)

## CÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a Autoencoders

* **Dá»¯ liá»‡u cá»¥ thá»ƒ** - chÃºng chá»‰ hoáº¡t Ä‘á»™ng tá»‘t vá»›i loáº¡i hÃ¬nh áº£nh mÃ  chÃºng Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n. VÃ­ dá»¥, náº¿u chÃºng ta huáº¥n luyá»‡n má»™t máº¡ng siÃªu phÃ¢n giáº£i trÃªn hÃ¬nh áº£nh hoa, nÃ³ sáº½ khÃ´ng hoáº¡t Ä‘á»™ng tá»‘t trÃªn chÃ¢n dung. Äiá»u nÃ y lÃ  do máº¡ng cÃ³ thá»ƒ táº¡o ra hÃ¬nh áº£nh cÃ³ Ä‘á»™ phÃ¢n giáº£i cao hÆ¡n báº±ng cÃ¡ch láº¥y cÃ¡c chi tiáº¿t tinh táº¿ tá»« cÃ¡c Ä‘áº·c trÆ°ng há»c Ä‘Æ°á»£c tá»« táº­p dá»¯ liá»‡u huáº¥n luyá»‡n.
* **Máº¥t mÃ¡t** - hÃ¬nh áº£nh tÃ¡i táº¡o khÃ´ng giá»‘ng vá»›i hÃ¬nh áº£nh gá»‘c. Báº£n cháº¥t cá»§a máº¥t mÃ¡t Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh bá»Ÿi *hÃ m máº¥t mÃ¡t* Ä‘Æ°á»£c sá»­ dá»¥ng trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.
* Hoáº¡t Ä‘á»™ng trÃªn **dá»¯ liá»‡u khÃ´ng Ä‘Æ°á»£c gáº¯n nhÃ£n**

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Káº¿t luáº­n

Trong bÃ i há»c nÃ y, báº¡n Ä‘Ã£ tÃ¬m hiá»ƒu vá» cÃ¡c loáº¡i autoencoders khÃ¡c nhau dÃ nh cho nhÃ  khoa há»c AI. Báº¡n Ä‘Ã£ há»c cÃ¡ch xÃ¢y dá»±ng chÃºng vÃ  cÃ¡ch sá»­ dá»¥ng chÃºng Ä‘á»ƒ tÃ¡i táº¡o hÃ¬nh áº£nh. Báº¡n cÅ©ng Ä‘Ã£ tÃ¬m hiá»ƒu vá» VAE vÃ  cÃ¡ch sá»­ dá»¥ng nÃ³ Ä‘á»ƒ táº¡o ra hÃ¬nh áº£nh má»›i.

## ğŸš€ Thá»­ thÃ¡ch

Trong bÃ i há»c nÃ y, báº¡n Ä‘Ã£ tÃ¬m hiá»ƒu vá» viá»‡c sá»­ dá»¥ng autoencoders cho hÃ¬nh áº£nh. NhÆ°ng chÃºng cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho Ã¢m nháº¡c! HÃ£y xem dá»± Ã¡n [MusicVAE](https://magenta.tensorflow.org/music-vae) cá»§a Magenta, dá»± Ã¡n sá»­ dá»¥ng autoencoders Ä‘á»ƒ há»c cÃ¡ch tÃ¡i táº¡o Ã¢m nháº¡c. Thá»±c hiá»‡n má»™t sá»‘ [thÃ­ nghiá»‡m](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) vá»›i thÆ° viá»‡n nÃ y Ä‘á»ƒ xem báº¡n cÃ³ thá»ƒ táº¡o ra gÃ¬.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Ã”n táº­p & Tá»± há»c

Äá»ƒ tham kháº£o, hÃ£y Ä‘á»c thÃªm vá» autoencoders trong cÃ¡c tÃ i liá»‡u sau:

* [XÃ¢y dá»±ng Autoencoders trong Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [BÃ i viáº¿t blog trÃªn NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Giáº£i thÃ­ch vá» Autoencoders Biáº¿n thá»ƒ](https://kvfrans.com/variational-autoencoders-explained/)
* [Autoencoders Biáº¿n thá»ƒ CÃ³ Ä‘iá»u kiá»‡n](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## BÃ i táº­p

á» cuá»‘i [notebook nÃ y sá»­ dá»¥ng TensorFlow](AutoencodersTF.ipynb), báº¡n sáº½ tÃ¬m tháº¥y má»™t 'nhiá»‡m vá»¥' - hÃ£y sá»­ dá»¥ng nÃ³ lÃ m bÃ i táº­p cá»§a báº¡n.

---

