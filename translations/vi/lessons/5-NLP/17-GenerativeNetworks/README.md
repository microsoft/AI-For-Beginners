# Máº¡ng táº¡o sinh

## [CÃ¢u há»i trÆ°á»›c bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/33)

Máº¡ng nÆ¡-ron há»“i quy (RNN) vÃ  cÃ¡c biáº¿n thá»ƒ táº¿ bÃ o cÃ³ cá»•ng cá»§a nÃ³ nhÆ° Táº¿ bÃ o Bá»™ nhá»› Ngáº¯n DÃ i (LSTM) vÃ  ÄÆ¡n vá»‹ Há»“i quy CÃ³ cá»•ng (GRU) cung cáº¥p má»™t cÆ¡ cháº¿ Ä‘á»ƒ mÃ´ hÃ¬nh hÃ³a ngÃ´n ngá»¯, vÃ¬ chÃºng cÃ³ thá»ƒ há»c cÃ¡ch sáº¯p xáº¿p tá»« vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n cho tá»« tiáº¿p theo trong má»™t chuá»—i. Äiá»u nÃ y cho phÃ©p chÃºng ta sá»­ dá»¥ng RNN cho cÃ¡c **nhiá»‡m vá»¥ táº¡o sinh**, cháº³ng háº¡n nhÆ° táº¡o vÄƒn báº£n thÃ´ng thÆ°á»ng, dá»‹ch mÃ¡y, vÃ  tháº­m chÃ­ lÃ  chÃº thÃ­ch hÃ¬nh áº£nh.

> âœ… HÃ£y nghÄ© vá» táº¥t cáº£ nhá»¯ng láº§n báº¡n Ä‘Ã£ hÆ°á»Ÿng lá»£i tá»« cÃ¡c nhiá»‡m vá»¥ táº¡o sinh nhÆ° hoÃ n thÃ nh vÄƒn báº£n khi báº¡n gÃµ. TÃ¬m hiá»ƒu vá» cÃ¡c á»©ng dá»¥ng yÃªu thÃ­ch cá»§a báº¡n Ä‘á»ƒ xem liá»‡u chÃºng cÃ³ sá»­ dá»¥ng RNN hay khÃ´ng.

Trong kiáº¿n trÃºc RNN mÃ  chÃºng ta Ä‘Ã£ tháº£o luáº­n trong bÃ i trÆ°á»›c, má»—i Ä‘Æ¡n vá»‹ RNN táº¡o ra tráº¡ng thÃ¡i áº©n tiáº¿p theo nhÆ° má»™t Ä‘áº§u ra. Tuy nhiÃªn, chÃºng ta cÅ©ng cÃ³ thá»ƒ thÃªm má»™t Ä‘áº§u ra khÃ¡c vÃ o má»—i Ä‘Æ¡n vá»‹ há»“i quy, Ä‘iá»u nÃ y cho phÃ©p chÃºng ta xuáº¥t ra má»™t **chuá»—i** (cÃ³ Ä‘á»™ dÃ i báº±ng vá»›i chuá»—i ban Ä‘áº§u). HÆ¡n ná»¯a, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c Ä‘Æ¡n vá»‹ RNN khÃ´ng nháº­n Ä‘áº§u vÃ o á»Ÿ má»—i bÆ°á»›c, chá»‰ cáº§n má»™t vector tráº¡ng thÃ¡i ban Ä‘áº§u, vÃ  sau Ä‘Ã³ táº¡o ra má»™t chuá»—i Ä‘áº§u ra.

Äiá»u nÃ y cho phÃ©p cÃ¡c kiáº¿n trÃºc nÆ¡-ron khÃ¡c nhau nhÆ° Ä‘Æ°á»£c hiá»ƒn thá»‹ trong hÃ¬nh dÆ°á»›i Ä‘Ã¢y:

![HÃ¬nh áº£nh hiá»ƒn thá»‹ cÃ¡c máº«u máº¡ng nÆ¡-ron há»“i quy phá»• biáº¿n.](../../../../../translated_images/vi/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> HÃ¬nh áº£nh tá»« bÃ i viáº¿t blog [Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) cá»§a [Andrej Karpaty](http://karpathy.github.io/)

* **Má»™t-Ä‘áº¿n-má»™t** lÃ  máº¡ng nÆ¡-ron truyá»n thá»‘ng vá»›i má»™t Ä‘áº§u vÃ o vÃ  má»™t Ä‘áº§u ra
* **Má»™t-Ä‘áº¿n-nhiá»u** lÃ  má»™t kiáº¿n trÃºc táº¡o sinh nháº­n má»™t giÃ¡ trá»‹ Ä‘áº§u vÃ o vÃ  táº¡o ra má»™t chuá»—i giÃ¡ trá»‹ Ä‘áº§u ra. VÃ­ dá»¥, náº¿u chÃºng ta muá»‘n huáº¥n luyá»‡n má»™t máº¡ng **chÃº thÃ­ch hÃ¬nh áº£nh** Ä‘á»ƒ táº¡o ra mÃ´ táº£ vÄƒn báº£n cho má»™t bá»©c áº£nh, chÃºng ta cÃ³ thá»ƒ Ä‘Æ°a bá»©c áº£nh lÃ m Ä‘áº§u vÃ o, truyá»n qua CNN Ä‘á»ƒ láº¥y tráº¡ng thÃ¡i áº©n cá»§a nÃ³, vÃ  sau Ä‘Ã³ cÃ³ má»™t chuá»—i há»“i quy táº¡o chÃº thÃ­ch tá»«ng tá»« má»™t.
* **Nhiá»u-Ä‘áº¿n-má»™t** tÆ°Æ¡ng á»©ng vá»›i cÃ¡c kiáº¿n trÃºc RNN mÃ  chÃºng ta Ä‘Ã£ mÃ´ táº£ trong bÃ i trÆ°á»›c, cháº³ng háº¡n nhÆ° phÃ¢n loáº¡i vÄƒn báº£n.
* **Nhiá»u-Ä‘áº¿n-nhiá»u**, hoáº·c **chuá»—i-Ä‘áº¿n-chuá»—i** tÆ°Æ¡ng á»©ng vá»›i cÃ¡c nhiá»‡m vá»¥ nhÆ° **dá»‹ch mÃ¡y**, nÆ¡i chÃºng ta cÃ³ RNN Ä‘áº§u tiÃªn thu tháº­p táº¥t cáº£ thÃ´ng tin tá»« chuá»—i Ä‘áº§u vÃ o vÃ o tráº¡ng thÃ¡i áº©n, vÃ  má»™t chuá»—i RNN khÃ¡c giáº£i mÃ£ tráº¡ng thÃ¡i nÃ y thÃ nh chuá»—i Ä‘áº§u ra.

Trong bÃ i nÃ y, chÃºng ta sáº½ táº­p trung vÃ o cÃ¡c mÃ´ hÃ¬nh táº¡o sinh Ä‘Æ¡n giáº£n giÃºp chÃºng ta táº¡o vÄƒn báº£n. Äá»ƒ Ä‘Æ¡n giáº£n, chÃºng ta sáº½ sá»­ dá»¥ng mÃ£ hÃ³a cáº¥p kÃ½ tá»±.

ChÃºng ta sáº½ huáº¥n luyá»‡n RNN nÃ y Ä‘á»ƒ táº¡o vÄƒn báº£n tá»«ng bÆ°á»›c. á» má»—i bÆ°á»›c, chÃºng ta sáº½ láº¥y má»™t chuá»—i kÃ½ tá»± cÃ³ Ä‘á»™ dÃ i `nchars`, vÃ  yÃªu cáº§u máº¡ng táº¡o ra kÃ½ tá»± Ä‘áº§u ra tiáº¿p theo cho má»—i kÃ½ tá»± Ä‘áº§u vÃ o:

![HÃ¬nh áº£nh minh há»a RNN táº¡o ra tá»« 'HELLO'.](../../../../../translated_images/vi/rnn-generate.56c54afb52f9781d.webp)

Khi táº¡o vÄƒn báº£n (trong quÃ¡ trÃ¬nh suy luáº­n), chÃºng ta báº¯t Ä‘áº§u vá»›i má»™t **gá»£i Ã½**, Ä‘Æ°á»£c truyá»n qua cÃ¡c táº¿ bÃ o RNN Ä‘á»ƒ táº¡o tráº¡ng thÃ¡i trung gian cá»§a nÃ³, vÃ  sau Ä‘Ã³ tá»« tráº¡ng thÃ¡i nÃ y báº¯t Ä‘áº§u quÃ¡ trÃ¬nh táº¡o. ChÃºng ta táº¡o tá»«ng kÃ½ tá»± má»™t, vÃ  truyá»n tráº¡ng thÃ¡i cÃ¹ng kÃ½ tá»± vá»«a táº¡o vÃ o má»™t táº¿ bÃ o RNN khÃ¡c Ä‘á»ƒ táº¡o kÃ½ tá»± tiáº¿p theo, cho Ä‘áº¿n khi táº¡o Ä‘á»§ sá»‘ kÃ½ tá»±.

<img src="../../../../../translated_images/vi/rnn-generate-inf.5168dc65e0370eea.webp" width="60%"/>

> HÃ¬nh áº£nh cá»§a tÃ¡c giáº£

## âœï¸ BÃ i táº­p: Máº¡ng táº¡o sinh

Tiáº¿p tá»¥c há»c trong cÃ¡c notebook sau:

* [Máº¡ng táº¡o sinh vá»›i PyTorch](GenerativePyTorch.ipynb)
* [Máº¡ng táº¡o sinh vá»›i TensorFlow](GenerativeTF.ipynb)

## Táº¡o vÄƒn báº£n má»m vÃ  nhiá»‡t Ä‘á»™

Äáº§u ra cá»§a má»—i táº¿ bÃ o RNN lÃ  má»™t phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a cÃ¡c kÃ½ tá»±. Náº¿u chÃºng ta luÃ´n chá»n kÃ½ tá»± cÃ³ xÃ¡c suáº¥t cao nháº¥t lÃ m kÃ½ tá»± tiáº¿p theo trong vÄƒn báº£n Ä‘Æ°á»£c táº¡o, vÄƒn báº£n thÆ°á»ng cÃ³ thá»ƒ trá»Ÿ nÃªn "láº·p láº¡i" giá»¯a cÃ¡c chuá»—i kÃ½ tá»± giá»‘ng nhau, nhÆ° trong vÃ­ dá»¥ nÃ y:

```
today of the second the company and a second the company ...
```

Tuy nhiÃªn, náº¿u chÃºng ta nhÃ¬n vÃ o phÃ¢n phá»‘i xÃ¡c suáº¥t cho kÃ½ tá»± tiáº¿p theo, cÃ³ thá»ƒ sá»± khÃ¡c biá»‡t giá»¯a má»™t vÃ i xÃ¡c suáº¥t cao nháº¥t khÃ´ng lá»›n, vÃ­ dá»¥ má»™t kÃ½ tá»± cÃ³ xÃ¡c suáº¥t 0.2, kÃ½ tá»± khÃ¡c - 0.19, v.v. Cháº³ng háº¡n, khi tÃ¬m kÃ½ tá»± tiáº¿p theo trong chuá»—i '*play*', kÃ½ tá»± tiáº¿p theo cÃ³ thá»ƒ lÃ  khoáº£ng tráº¯ng hoáº·c **e** (nhÆ° trong tá»« *player*).

Äiá»u nÃ y dáº«n Ä‘áº¿n káº¿t luáº­n ráº±ng khÃ´ng pháº£i lÃºc nÃ o cÅ©ng "cÃ´ng báº±ng" Ä‘á»ƒ chá»n kÃ½ tá»± cÃ³ xÃ¡c suáº¥t cao nháº¥t, vÃ¬ chá»n kÃ½ tá»± cÃ³ xÃ¡c suáº¥t cao thá»© hai váº«n cÃ³ thá»ƒ dáº«n Ä‘áº¿n vÄƒn báº£n cÃ³ Ã½ nghÄ©a. Sáº½ khÃ´n ngoan hÆ¡n náº¿u **láº¥y máº«u** kÃ½ tá»± tá»« phÃ¢n phá»‘i xÃ¡c suáº¥t do máº¡ng xuáº¥t ra. ChÃºng ta cÅ©ng cÃ³ thá»ƒ sá»­ dá»¥ng má»™t tham sá»‘, **nhiá»‡t Ä‘á»™**, Ä‘á»ƒ lÃ m pháº³ng phÃ¢n phá»‘i xÃ¡c suáº¥t, trong trÆ°á»ng há»£p chÃºng ta muá»‘n thÃªm sá»± ngáº«u nhiÃªn, hoáº·c lÃ m nÃ³ dá»‘c hÆ¡n, náº¿u chÃºng ta muá»‘n bÃ¡m sÃ¡t cÃ¡c kÃ½ tá»± cÃ³ xÃ¡c suáº¥t cao nháº¥t.

KhÃ¡m phÃ¡ cÃ¡ch táº¡o vÄƒn báº£n má»m Ä‘Æ°á»£c triá»ƒn khai trong cÃ¡c notebook Ä‘Æ°á»£c liÃªn káº¿t á»Ÿ trÃªn.

## Káº¿t luáº­n

Máº·c dÃ¹ viá»‡c táº¡o vÄƒn báº£n cÃ³ thá»ƒ há»¯u Ã­ch tá»± thÃ¢n, lá»£i Ã­ch lá»›n hÆ¡n Ä‘áº¿n tá»« kháº£ nÄƒng táº¡o vÄƒn báº£n báº±ng RNN tá»« má»™t vector Ä‘áº·c trÆ°ng ban Ä‘áº§u. VÃ­ dá»¥, táº¡o vÄƒn báº£n Ä‘Æ°á»£c sá»­ dá»¥ng nhÆ° má»™t pháº§n cá»§a dá»‹ch mÃ¡y (chuá»—i-Ä‘áº¿n-chuá»—i, trong trÆ°á»ng há»£p nÃ y vector tráº¡ng thÃ¡i tá»« *encoder* Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o hoáº·c *giáº£i mÃ£* thÃ´ng Ä‘iá»‡p Ä‘Ã£ dá»‹ch), hoáº·c táº¡o mÃ´ táº£ vÄƒn báº£n cho má»™t hÃ¬nh áº£nh (trong trÆ°á»ng há»£p nÃ y vector Ä‘áº·c trÆ°ng sáº½ Ä‘áº¿n tá»« bá»™ trÃ­ch xuáº¥t CNN).

## ğŸš€ Thá»­ thÃ¡ch

Há»c má»™t sá»‘ bÃ i há»c trÃªn Microsoft Learn vá» chá»§ Ä‘á» nÃ y

* Táº¡o vÄƒn báº£n vá»›i [PyTorch](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/6-generative-networks/?WT.mc_id=academic-77998-cacaste)/[TensorFlow](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-tensorflow/5-generative-networks/?WT.mc_id=academic-77998-cacaste)

## [CÃ¢u há»i sau bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/34)

## Ã”n táº­p & Tá»± há»c

DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ bÃ i viáº¿t Ä‘á»ƒ má»Ÿ rá»™ng kiáº¿n thá»©c cá»§a báº¡n

* CÃ¡c cÃ¡ch tiáº¿p cáº­n khÃ¡c nhau Ä‘á»ƒ táº¡o vÄƒn báº£n vá»›i Markov Chain, LSTM vÃ  GPT-2: [bÃ i viáº¿t blog](https://towardsdatascience.com/text-generation-gpt-2-lstm-markov-chain-9ea371820e1e)
* VÃ­ dá»¥ táº¡o vÄƒn báº£n trong [tÃ i liá»‡u Keras](https://keras.io/examples/generative/lstm_character_level_text_generation/)

## [BÃ i táº­p](lab/README.md)

ChÃºng ta Ä‘Ã£ tháº¥y cÃ¡ch táº¡o vÄƒn báº£n tá»«ng kÃ½ tá»± má»™t. Trong bÃ i thá»±c hÃ nh, báº¡n sáº½ khÃ¡m phÃ¡ viá»‡c táº¡o vÄƒn báº£n á»Ÿ cáº¥p Ä‘á»™ tá»«.

---

