# Nháº­n diá»‡n Thá»±c thá»ƒ ÄÆ°á»£c Ä‘áº·t tÃªn

Cho Ä‘áº¿n nay, chÃºng ta chá»§ yáº¿u táº­p trung vÃ o má»™t nhiá»‡m vá»¥ NLP - phÃ¢n loáº¡i. Tuy nhiÃªn, cÃ²n cÃ³ nhiá»u nhiá»‡m vá»¥ NLP khÃ¡c cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng máº¡ng nÆ¡-ron. Má»™t trong nhá»¯ng nhiá»‡m vá»¥ Ä‘Ã³ lÃ  **[Nháº­n diá»‡n Thá»±c thá»ƒ ÄÆ°á»£c Ä‘áº·t tÃªn](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), nhiá»‡m vá»¥ nÃ y liÃªn quan Ä‘áº¿n viá»‡c nháº­n diá»‡n cÃ¡c thá»±c thá»ƒ cá»¥ thá»ƒ trong vÄƒn báº£n, cháº³ng háº¡n nhÆ° Ä‘á»‹a Ä‘iá»ƒm, tÃªn ngÆ°á»i, khoáº£ng thá»i gian, cÃ´ng thá»©c hÃ³a há»c, vÃ  nhiá»u hÆ¡n ná»¯a.

## [CÃ¢u há»i trÆ°á»›c bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## VÃ­ dá»¥ vá» viá»‡c sá»­ dá»¥ng NER

Giáº£ sá»­ báº¡n muá»‘n phÃ¡t triá»ƒn má»™t chatbot ngÃ´n ngá»¯ tá»± nhiÃªn, tÆ°Æ¡ng tá»± nhÆ° Amazon Alexa hoáº·c Google Assistant. CÃ¡ch cÃ¡c chatbot thÃ´ng minh hoáº¡t Ä‘á»™ng lÃ  *hiá»ƒu* ngÆ°á»i dÃ¹ng muá»‘n gÃ¬ báº±ng cÃ¡ch thá»±c hiá»‡n phÃ¢n loáº¡i vÄƒn báº£n trÃªn cÃ¢u Ä‘áº§u vÃ o. Káº¿t quáº£ cá»§a viá»‡c phÃ¢n loáº¡i nÃ y lÃ  cÃ¡i gá»i lÃ  **Ã½ Ä‘á»‹nh**, xÃ¡c Ä‘á»‹nh chatbot nÃªn lÃ m gÃ¬.

<img alt="Bot NER" src="../../../../../translated_images/vi/bot-ner.4b09235dbb0ad275.webp" width="50%"/>

> HÃ¬nh áº£nh cá»§a tÃ¡c giáº£

Tuy nhiÃªn, ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ cung cáº¥p má»™t sá»‘ tham sá»‘ nhÆ° má»™t pháº§n cá»§a cÃ¢u nÃ³i. VÃ­ dá»¥, khi há»i vá» thá»i tiáº¿t, há» cÃ³ thá»ƒ chá»‰ Ä‘á»‹nh Ä‘á»‹a Ä‘iá»ƒm hoáº·c ngÃ y. Má»™t chatbot cáº§n cÃ³ kháº£ nÄƒng hiá»ƒu cÃ¡c thá»±c thá»ƒ Ä‘Ã³ vÃ  Ä‘iá»n vÃ o cÃ¡c Ã´ tham sá»‘ tÆ°Æ¡ng á»©ng trÆ°á»›c khi thá»±c hiá»‡n hÃ nh Ä‘á»™ng. ÄÃ¢y chÃ­nh lÃ  nÆ¡i NER phÃ¡t huy tÃ¡c dá»¥ng.

> âœ… Má»™t vÃ­ dá»¥ khÃ¡c lÃ  [phÃ¢n tÃ­ch cÃ¡c bÃ i bÃ¡o khoa há»c y táº¿](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Má»™t trong nhá»¯ng Ä‘iá»u chÃ­nh cáº§n tÃ¬m kiáº¿m lÃ  cÃ¡c thuáº­t ngá»¯ y táº¿ cá»¥ thá»ƒ, cháº³ng háº¡n nhÆ° bá»‡nh vÃ  cÃ¡c cháº¥t y táº¿. Trong khi má»™t sá»‘ lÆ°á»£ng nhá» cÃ¡c bá»‡nh cÃ³ thá»ƒ Ä‘Æ°á»£c trÃ­ch xuáº¥t báº±ng cÃ¡ch tÃ¬m kiáº¿m chuá»—i con, cÃ¡c thá»±c thá»ƒ phá»©c táº¡p hÆ¡n nhÆ° há»£p cháº¥t hÃ³a há»c vÃ  tÃªn thuá»‘c cáº§n má»™t phÆ°Æ¡ng phÃ¡p phá»©c táº¡p hÆ¡n.

## NER dÆ°á»›i dáº¡ng PhÃ¢n loáº¡i Token

CÃ¡c mÃ´ hÃ¬nh NER vá» cÆ¡ báº£n lÃ  **mÃ´ hÃ¬nh phÃ¢n loáº¡i token**, bá»Ÿi vÃ¬ Ä‘á»‘i vá»›i má»—i token Ä‘áº§u vÃ o, chÃºng ta cáº§n quyáº¿t Ä‘á»‹nh liá»‡u nÃ³ cÃ³ thuá»™c vá» má»™t thá»±c thá»ƒ hay khÃ´ng, vÃ  náº¿u cÃ³ - thuá»™c vá» lá»›p thá»±c thá»ƒ nÃ o.

HÃ£y xem xÃ©t tiÃªu Ä‘á» bÃ i bÃ¡o sau:

**Tricuspid valve regurgitation** vÃ  **lithium carbonate** **toxicity** á»Ÿ tráº» sÆ¡ sinh.

CÃ¡c thá»±c thá»ƒ á»Ÿ Ä‘Ã¢y lÃ :

* Tricuspid valve regurgitation lÃ  má»™t bá»‡nh (`DIS`)
* Lithium carbonate lÃ  má»™t cháº¥t hÃ³a há»c (`CHEM`)
* Toxicity cÅ©ng lÃ  má»™t bá»‡nh (`DIS`)

LÆ°u Ã½ ráº±ng má»™t thá»±c thá»ƒ cÃ³ thá»ƒ bao gá»“m nhiá»u token. VÃ , nhÆ° trong trÆ°á»ng há»£p nÃ y, chÃºng ta cáº§n phÃ¢n biá»‡t giá»¯a hai thá»±c thá»ƒ liÃªn tiáº¿p. Do Ä‘Ã³, thÆ°á»ng sá»­ dá»¥ng hai lá»›p cho má»—i thá»±c thá»ƒ - má»™t lá»›p chá»‰ Ä‘á»‹nh token Ä‘áº§u tiÃªn cá»§a thá»±c thá»ƒ (thÆ°á»ng sá»­ dá»¥ng tiá»n tá»‘ `B-`, cho **b**áº¯t Ä‘áº§u), vÃ  lá»›p khÃ¡c - pháº§n tiáº¿p theo cá»§a thá»±c thá»ƒ (`I-`, cho **i**nner token). ChÃºng ta cÅ©ng sá»­ dá»¥ng `O` lÃ m lá»›p Ä‘á»ƒ Ä‘áº¡i diá»‡n cho táº¥t cáº£ cÃ¡c token **k**hÃ¡c. Viá»‡c gáº¯n tháº» token nhÆ° váº­y Ä‘Æ°á»£c gá»i lÃ  [gáº¯n tháº» BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (hoáº·c IOB). Khi Ä‘Æ°á»£c gáº¯n tháº», tiÃªu Ä‘á» cá»§a chÃºng ta sáº½ trÃ´ng nhÆ° sau:

Token | Tag
------|-----
Tricuspid | B-DIS
valve | I-DIS
regurgitation | I-DIS
and | O
lithium | B-CHEM
carbonate | I-CHEM
toxicity | B-DIS
in | O
a | O
newborn | O
infant | O
. | O

VÃ¬ chÃºng ta cáº§n xÃ¢y dá»±ng má»™t sá»± tÆ°Æ¡ng á»©ng má»™t-má»™t giá»¯a cÃ¡c token vÃ  cÃ¡c lá»›p, chÃºng ta cÃ³ thá»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡-ron **nhiá»u-Ä‘áº¿n-nhiá»u** tá»« hÃ¬nh áº£nh nÃ y:

![HÃ¬nh áº£nh hiá»ƒn thá»‹ cÃ¡c máº«u máº¡ng nÆ¡-ron há»“i quy phá»• biáº¿n.](../../../../../translated_images/vi/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> *HÃ¬nh áº£nh tá»« [bÃ i viáº¿t blog nÃ y](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) cá»§a [Andrej Karpathy](http://karpathy.github.io/). CÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i token NER tÆ°Æ¡ng á»©ng vá»›i kiáº¿n trÃºc máº¡ng á»Ÿ phÃ­a bÃªn pháº£i cá»§a hÃ¬nh áº£nh nÃ y.*

## Huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh NER

VÃ¬ má»™t mÃ´ hÃ¬nh NER vá» cÆ¡ báº£n lÃ  má»™t mÃ´ hÃ¬nh phÃ¢n loáº¡i token, chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng RNN mÃ  chÃºng ta Ä‘Ã£ quen thuá»™c Ä‘á»ƒ thá»±c hiá»‡n nhiá»‡m vá»¥ nÃ y. Trong trÆ°á»ng há»£p nÃ y, má»—i khá»‘i cá»§a máº¡ng há»“i quy sáº½ tráº£ vá» ID token. Notebook vÃ­ dá»¥ sau Ä‘Ã¢y cho tháº¥y cÃ¡ch huáº¥n luyá»‡n LSTM Ä‘á»ƒ phÃ¢n loáº¡i token.

## âœï¸ Notebook VÃ­ dá»¥: NER

Tiáº¿p tá»¥c há»c táº­p cá»§a báº¡n trong notebook sau:

* [NER vá»›i TensorFlow](NER-TF.ipynb)

## Káº¿t luáº­n

Má»™t mÃ´ hÃ¬nh NER lÃ  má»™t **mÃ´ hÃ¬nh phÃ¢n loáº¡i token**, nghÄ©a lÃ  nÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ thá»±c hiá»‡n phÃ¢n loáº¡i token. ÄÃ¢y lÃ  má»™t nhiá»‡m vá»¥ ráº¥t phá»• biáº¿n trong NLP, giÃºp nháº­n diá»‡n cÃ¡c thá»±c thá»ƒ cá»¥ thá»ƒ trong vÄƒn báº£n bao gá»“m Ä‘á»‹a Ä‘iá»ƒm, tÃªn, ngÃ y thÃ¡ng, vÃ  nhiá»u hÆ¡n ná»¯a.

## ğŸš€ Thá»­ thÃ¡ch

HoÃ n thÃ nh bÃ i táº­p Ä‘Æ°á»£c liÃªn káº¿t dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh nháº­n diá»‡n thá»±c thá»ƒ Ä‘Æ°á»£c Ä‘áº·t tÃªn cho cÃ¡c thuáº­t ngá»¯ y táº¿, sau Ä‘Ã³ thá»­ nghiá»‡m nÃ³ trÃªn má»™t táº­p dá»¯ liá»‡u khÃ¡c.

## [CÃ¢u há»i sau bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Ã”n táº­p & Tá»± há»c

Äá»c qua blog [Hiá»‡u quáº£ phi thÆ°á»ng cá»§a Máº¡ng NÆ¡-ron Há»“i quy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) vÃ  theo dÃµi pháº§n Äá»c thÃªm trong bÃ i viáº¿t Ä‘Ã³ Ä‘á»ƒ nÃ¢ng cao kiáº¿n thá»©c cá»§a báº¡n.

## [BÃ i táº­p](lab/README.md)

Trong bÃ i táº­p cá»§a bÃ i há»c nÃ y, báº¡n sáº½ pháº£i huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh nháº­n diá»‡n thá»±c thá»ƒ y táº¿. Báº¡n cÃ³ thá»ƒ báº¯t Ä‘áº§u báº±ng cÃ¡ch huáº¥n luyá»‡n mÃ´ hÃ¬nh LSTM nhÆ° Ä‘Ã£ mÃ´ táº£ trong bÃ i há»c nÃ y, vÃ  tiáº¿p tá»¥c sá»­ dá»¥ng mÃ´ hÃ¬nh BERT transformer. Äá»c [hÆ°á»›ng dáº«n](lab/README.md) Ä‘á»ƒ biáº¿t táº¥t cáº£ chi tiáº¿t.

---

