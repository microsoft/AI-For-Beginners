# NhÃºng

## [CÃ¢u há»i trÆ°á»›c bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/27)

Khi huáº¥n luyá»‡n cÃ¡c bá»™ phÃ¢n loáº¡i dá»±a trÃªn BoW hoáº·c TF/IDF, chÃºng ta Ä‘Ã£ lÃ m viá»‡c vá»›i cÃ¡c vector tÃºi tá»« cÃ³ chiá»u cao vá»›i Ä‘á»™ dÃ i `vocab_size`, vÃ  chÃºng ta Ä‘Ã£ chuyá»ƒn Ä‘á»•i rÃµ rÃ ng tá»« cÃ¡c vector biá»ƒu diá»…n vá»‹ trÃ­ cÃ³ chiá»u tháº¥p sang biá»ƒu diá»…n thÆ°a thá»›t má»™t-hot. Tuy nhiÃªn, biá»ƒu diá»…n má»™t-hot nÃ y khÃ´ng hiá»‡u quáº£ vá» máº·t bá»™ nhá»›. NgoÃ i ra, má»—i tá»« Ä‘Æ°á»£c xá»­ lÃ½ Ä‘á»™c láº­p vá»›i nhau, tá»©c lÃ  cÃ¡c vector mÃ£ hÃ³a má»™t-hot khÃ´ng thá»ƒ hiá»‡n báº¥t ká»³ sá»± tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a nÃ o giá»¯a cÃ¡c tá»«.

Ã tÆ°á»Ÿng cá»§a **nhÃºng** lÃ  biá»ƒu diá»…n cÃ¡c tá»« báº±ng cÃ¡c vector dÃ y Ä‘áº·c cÃ³ chiá»u tháº¥p hÆ¡n, pháº£n Ã¡nh pháº§n nÃ o Ã½ nghÄ©a ngá»¯ nghÄ©a cá»§a má»™t tá»«. ChÃºng ta sáº½ tháº£o luáº­n sau vá» cÃ¡ch xÃ¢y dá»±ng cÃ¡c nhÃºng tá»« cÃ³ Ã½ nghÄ©a, nhÆ°ng hiá»‡n táº¡i hÃ£y chá»‰ nghÄ© vá» nhÃºng nhÆ° má»™t cÃ¡ch Ä‘á»ƒ giáº£m chiá»u cá»§a vector tá»«.

VÃ¬ váº­y, lá»›p nhÃºng sáº½ nháº­n má»™t tá»« lÃ m Ä‘áº§u vÃ o vÃ  táº¡o ra má»™t vector Ä‘áº§u ra vá»›i kÃ­ch thÆ°á»›c `embedding_size` Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh. Theo má»™t cÃ¡ch nÃ o Ä‘Ã³, nÃ³ ráº¥t giá»‘ng vá»›i lá»›p `Linear`, nhÆ°ng thay vÃ¬ nháº­n má»™t vector mÃ£ hÃ³a má»™t-hot, nÃ³ sáº½ cÃ³ thá»ƒ nháº­n má»™t sá»‘ tá»« lÃ m Ä‘áº§u vÃ o, cho phÃ©p chÃºng ta trÃ¡nh táº¡o ra cÃ¡c vector mÃ£ hÃ³a má»™t-hot lá»›n.

Báº±ng cÃ¡ch sá»­ dá»¥ng lá»›p nhÃºng lÃ m lá»›p Ä‘áº§u tiÃªn trong máº¡ng phÃ¢n loáº¡i cá»§a chÃºng ta, chÃºng ta cÃ³ thá»ƒ chuyá»ƒn tá»« mÃ´ hÃ¬nh tÃºi tá»« sang mÃ´ hÃ¬nh **tÃºi nhÃºng**, nÆ¡i chÃºng ta Ä‘áº§u tiÃªn chuyá»ƒn Ä‘á»•i má»—i tá»« trong vÄƒn báº£n cá»§a mÃ¬nh thÃ nh nhÃºng tÆ°Æ¡ng á»©ng, vÃ  sau Ä‘Ã³ tÃ­nh toÃ¡n má»™t sá»‘ hÃ m tá»•ng há»£p trÃªn táº¥t cáº£ cÃ¡c nhÃºng Ä‘Ã³, cháº³ng háº¡n nhÆ° `sum`, `average` hoáº·c `max`.

![HÃ¬nh áº£nh minh há»a má»™t bá»™ phÃ¢n loáº¡i nhÃºng cho nÄƒm tá»« trong chuá»—i.](../../../../../translated_images/vi/embedding-classifier-example.b77f021a7ee67eee.webp)

> HÃ¬nh áº£nh cá»§a tÃ¡c giáº£

## âœï¸ BÃ i táº­p: NhÃºng

Tiáº¿p tá»¥c há»c trong cÃ¡c notebook sau:
* [NhÃºng vá»›i PyTorch](EmbeddingsPyTorch.ipynb)
* [NhÃºng TensorFlow](EmbeddingsTF.ipynb)

## NhÃºng ngá»¯ nghÄ©a: Word2Vec

Máº·c dÃ¹ lá»›p nhÃºng Ä‘Ã£ há»c cÃ¡ch Ã¡nh xáº¡ cÃ¡c tá»« sang biá»ƒu diá»…n vector, nhÆ°ng biá»ƒu diá»…n nÃ y khÃ´ng nháº¥t thiáº¿t pháº£i cÃ³ nhiá»u Ã½ nghÄ©a ngá»¯ nghÄ©a. Sáº½ ráº¥t tá»‘t náº¿u há»c Ä‘Æ°á»£c má»™t biá»ƒu diá»…n vector sao cho cÃ¡c tá»« tÆ°Æ¡ng tá»± hoáº·c tá»« Ä‘á»“ng nghÄ©a tÆ°Æ¡ng á»©ng vá»›i cÃ¡c vector gáº§n nhau theo má»™t sá»‘ khoáº£ng cÃ¡ch vector (vÃ­ dá»¥: khoáº£ng cÃ¡ch Euclid).

Äá»ƒ lÃ m Ä‘iá»u Ä‘Ã³, chÃºng ta cáº§n tiá»n huáº¥n luyá»‡n mÃ´ hÃ¬nh nhÃºng cá»§a mÃ¬nh trÃªn má»™t táº­p há»£p lá»›n vÄƒn báº£n theo má»™t cÃ¡ch cá»¥ thá»ƒ. Má»™t cÃ¡ch Ä‘á»ƒ huáº¥n luyá»‡n nhÃºng ngá»¯ nghÄ©a Ä‘Æ°á»£c gá»i lÃ  [Word2Vec](https://en.wikipedia.org/wiki/Word2vec). NÃ³ dá»±a trÃªn hai kiáº¿n trÃºc chÃ­nh Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ táº¡o ra biá»ƒu diá»…n phÃ¢n tÃ¡n cá»§a cÃ¡c tá»«:

 - **TÃºi tá»« liÃªn tá»¥c** (CBoW) â€” trong kiáº¿n trÃºc nÃ y, chÃºng ta huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n má»™t tá»« tá»« ngá»¯ cáº£nh xung quanh. Vá»›i ngram $(W_{-2},W_{-1},W_0,W_1,W_2)$, má»¥c tiÃªu cá»§a mÃ´ hÃ¬nh lÃ  dá»± Ä‘oÃ¡n $W_0$ tá»« $(W_{-2},W_{-1},W_1,W_2)$.
 - **Skip-gram liÃªn tá»¥c** thÃ¬ ngÆ°á»£c láº¡i vá»›i CBoW. MÃ´ hÃ¬nh sá»­ dá»¥ng cá»­a sá»• ngá»¯ cáº£nh xung quanh Ä‘á»ƒ dá»± Ä‘oÃ¡n tá»« hiá»‡n táº¡i.

CBoW nhanh hÆ¡n, trong khi skip-gram cháº­m hÆ¡n nhÆ°ng lÃ m tá»‘t hÆ¡n trong viá»‡c biá»ƒu diá»…n cÃ¡c tá»« Ã­t xuáº¥t hiá»‡n.

![HÃ¬nh áº£nh minh há»a cáº£ hai thuáº­t toÃ¡n CBoW vÃ  Skip-Gram Ä‘á»ƒ chuyá»ƒn Ä‘á»•i tá»« thÃ nh vector.](../../../../../translated_images/vi/example-algorithms-for-converting-words-to-vectors.fbe9207a726922f6.webp)

> HÃ¬nh áº£nh tá»« [bÃ i bÃ¡o nÃ y](https://arxiv.org/pdf/1301.3781.pdf)

CÃ¡c nhÃºng Word2Vec Ä‘Ã£ tiá»n huáº¥n luyá»‡n (cÅ©ng nhÆ° cÃ¡c mÃ´ hÃ¬nh tÆ°Æ¡ng tá»± khÃ¡c nhÆ° GloVe) cÅ©ng cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng thay cho lá»›p nhÃºng trong máº¡ng nÆ¡-ron. Tuy nhiÃªn, chÃºng ta cáº§n xá»­ lÃ½ cÃ¡c tá»« vá»±ng, vÃ¬ tá»« vá»±ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tiá»n huáº¥n luyá»‡n Word2Vec/GloVe cÃ³ kháº£ nÄƒng khÃ¡c vá»›i tá»« vá»±ng trong táº­p vÄƒn báº£n cá»§a chÃºng ta. HÃ£y xem cÃ¡c Notebook á»Ÿ trÃªn Ä‘á»ƒ biáº¿t cÃ¡ch giáº£i quyáº¿t váº¥n Ä‘á» nÃ y.

## NhÃºng theo ngá»¯ cáº£nh

Má»™t háº¡n cháº¿ chÃ­nh cá»§a cÃ¡c biá»ƒu diá»…n nhÃºng tiá»n huáº¥n luyá»‡n truyá»n thá»‘ng nhÆ° Word2Vec lÃ  váº¥n Ä‘á» phÃ¢n biá»‡t nghÄ©a cá»§a tá»«. Máº·c dÃ¹ cÃ¡c nhÃºng tiá»n huáº¥n luyá»‡n cÃ³ thá»ƒ náº¯m báº¯t má»™t pháº§n Ã½ nghÄ©a cá»§a tá»« trong ngá»¯ cáº£nh, nhÆ°ng má»i nghÄ©a cÃ³ thá»ƒ cÃ³ cá»§a má»™t tá»« Ä‘á»u Ä‘Æ°á»£c mÃ£ hÃ³a vÃ o cÃ¹ng má»™t nhÃºng. Äiá»u nÃ y cÃ³ thá»ƒ gÃ¢y ra váº¥n Ä‘á» trong cÃ¡c mÃ´ hÃ¬nh háº¡ nguá»“n, vÃ¬ nhiá»u tá»« nhÆ° tá»« 'play' cÃ³ cÃ¡c nghÄ©a khÃ¡c nhau tÃ¹y thuá»™c vÃ o ngá»¯ cáº£nh mÃ  chÃºng Ä‘Æ°á»£c sá»­ dá»¥ng.

VÃ­ dá»¥, tá»« 'play' trong hai cÃ¢u sau cÃ³ Ã½ nghÄ©a khÃ¡ khÃ¡c nhau:

- TÃ´i Ä‘Ã£ Ä‘i xem má»™t **vá»Ÿ ká»‹ch** táº¡i nhÃ  hÃ¡t.
- John muá»‘n **chÆ¡i** vá»›i báº¡n bÃ¨ cá»§a mÃ¬nh.

CÃ¡c nhÃºng tiá»n huáº¥n luyá»‡n á»Ÿ trÃªn biá»ƒu diá»…n cáº£ hai nghÄ©a cá»§a tá»« 'play' trong cÃ¹ng má»™t nhÃºng. Äá»ƒ vÆ°á»£t qua háº¡n cháº¿ nÃ y, chÃºng ta cáº§n xÃ¢y dá»±ng cÃ¡c nhÃºng dá»±a trÃªn **mÃ´ hÃ¬nh ngÃ´n ngá»¯**, Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t táº­p há»£p lá»›n vÄƒn báº£n vÃ  *hiá»ƒu* cÃ¡ch cÃ¡c tá»« cÃ³ thá»ƒ Ä‘Æ°á»£c ghÃ©p láº¡i vá»›i nhau trong cÃ¡c ngá»¯ cáº£nh khÃ¡c nhau. Viá»‡c tháº£o luáº­n vá» nhÃºng theo ngá»¯ cáº£nh náº±m ngoÃ i pháº¡m vi cá»§a bÃ i hÆ°á»›ng dáº«n nÃ y, nhÆ°ng chÃºng ta sáº½ quay láº¡i chÃºng khi nÃ³i vá» cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ sau trong khÃ³a há»c.

## Káº¿t luáº­n

Trong bÃ i há»c nÃ y, báº¡n Ä‘Ã£ khÃ¡m phÃ¡ cÃ¡ch xÃ¢y dá»±ng vÃ  sá»­ dá»¥ng cÃ¡c lá»›p nhÃºng trong TensorFlow vÃ  Pytorch Ä‘á»ƒ pháº£n Ã¡nh tá»‘t hÆ¡n Ã½ nghÄ©a ngá»¯ nghÄ©a cá»§a cÃ¡c tá»«.

## ğŸš€ Thá»­ thÃ¡ch

Word2Vec Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng cho má»™t sá»‘ á»©ng dá»¥ng thÃº vá»‹, bao gá»“m táº¡o lá»i bÃ i hÃ¡t vÃ  thÆ¡. HÃ£y xem [bÃ i viáº¿t nÃ y](https://www.politetype.com/blog/word2vec-color-poems) Ä‘á»ƒ tÃ¬m hiá»ƒu cÃ¡ch tÃ¡c giáº£ sá»­ dá»¥ng Word2Vec Ä‘á»ƒ táº¡o thÆ¡. Xem [video nÃ y cá»§a Dan Shiffmann](https://www.youtube.com/watch?v=LSS_bos_TPI&ab_channel=TheCodingTrain) Ä‘á»ƒ khÃ¡m phÃ¡ má»™t cÃ¡ch giáº£i thÃ­ch khÃ¡c vá» ká»¹ thuáº­t nÃ y. Sau Ä‘Ã³, thá»­ Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t nÃ y vÃ o táº­p vÄƒn báº£n cá»§a riÃªng báº¡n, cÃ³ thá»ƒ láº¥y tá»« Kaggle.

## [CÃ¢u há»i sau bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ai/quiz/28)

## Ã”n táº­p & Tá»± há»c

Äá»c bÃ i bÃ¡o nÃ y vá» Word2Vec: [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)

## [BÃ i táº­p: Notebook](assignment.md)

---

