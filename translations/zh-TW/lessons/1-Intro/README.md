# 人工智慧簡介

![人工智慧內容摘要的手繪圖](../../../../translated_images/zh-TW/ai-intro.bf28d1ac4235881c.webp)

> 手繪筆記由 [Tomomi Imura](https://twitter.com/girlie_mac) 提供

## [課前測驗](https://ff-quizzes.netlify.app/en/ai/quiz/1)

**人工智慧**是一門令人興奮的科學領域，研究如何讓電腦展現出智能行為，例如執行人類擅長的事情。

最初，電腦由 [Charles Babbage](https://en.wikipedia.org/wiki/Charles_Babbage) 發明，用來根據明確定義的程序（演算法）操作數字。現代電腦雖然比19世紀提出的原型複雜得多，但仍然遵循受控計算的理念。因此，只要我們知道達成目標所需的精確步驟，就可以編程讓電腦完成某些事情。

![一個人的照片](../../../../translated_images/zh-TW/dsh_age.d212a30d4e54fb5f.webp)

> 照片由 [Vickie Soshnikova](http://twitter.com/vickievalerie) 提供

> ✅ 從一張照片中判斷一個人的年齡是一項無法明確編程的任務，因為我們不知道自己在腦海中得出數字的具體過程。

---

然而，有些任務我們並不明確知道如何解決。比如從一張照片中判斷一個人的年齡。我們能夠做到這件事，是因為我們看過許多不同年齡的人的例子，但我們無法明確解釋自己是如何做到的，也無法編程讓電腦完成這件事。這正是**人工智慧**（簡稱 AI）感興趣的任務類型。

✅ 想一想有哪些任務可以交給電腦處理，並且能從 AI 中受益。考慮金融、醫療和藝術領域——這些領域今天如何從 AI 中受益？

## 弱人工智慧 vs. 強人工智慧

弱人工智慧 | 強人工智慧
---------------------------------------|-------------------------------------
弱人工智慧指的是設計和訓練用於特定任務或狹窄任務集的 AI 系統。|強人工智慧，或稱人工通用智慧（AGI），指的是具有人類水平智能和理解能力的 AI 系統。
這些 AI 系統並不具備一般智能；它們擅長執行預定義的任務，但缺乏真正的理解或意識。|這些 AI 系統能夠執行人類可以完成的任何智力任務，適應不同領域，並擁有某種形式的意識或自我認知。
弱人工智慧的例子包括虛擬助理如 Siri 或 Alexa、流媒體服務使用的推薦算法，以及專門設計用於客戶服務的聊天機器人。|實現強人工智慧是 AI 研究的長期目標，需要開發能夠在廣泛任務和情境中進行推理、學習、理解和適應的 AI 系統。
弱人工智慧高度專業化，並不具備人類般的認知能力或超出其狹窄領域的一般問題解決能力。|強人工智慧目前仍是一個理論概念，尚無 AI 系統達到這種通用智能的水平。

更多資訊請參考 **[人工通用智慧](https://en.wikipedia.org/wiki/Artificial_general_intelligence)** (AGI)。

## 智能的定義與圖靈測試

在討論**[智能](https://en.wikipedia.org/wiki/Intelligence)**這個術語時，其中一個問題是我們對此並沒有明確的定義。有人可能認為智能與**抽象思維**或**自我意識**相關，但我們無法準確定義它。

![貓的照片](../../../../translated_images/zh-TW/photo-cat.8c8e8fb760ffe457.webp)

> [照片](https://unsplash.com/photos/75715CVEJhI)由 [Amber Kipp](https://unsplash.com/@sadmax) 提供，來自 Unsplash

為了看出“智能”這個術語的模糊性，試著回答這個問題：“貓是智能的嗎？”不同的人往往會給出不同的答案，因為沒有普遍接受的測試來證明這個說法是對還是錯。如果你認為有——試著讓你的貓參加智商測試吧……

✅ 花點時間思考你如何定義智能。一隻能解迷宮並獲得食物的烏鴉是智能的嗎？一個小孩是智能的嗎？

---

在討論 AGI 時，我們需要某種方法來判斷是否創造了一個真正智能的系統。[Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing) 提出了一種方法，稱為**[圖靈測試](https://en.wikipedia.org/wiki/Turing_test)**，它也可以作為智能的定義。該測試將給定系統與某些本質上智能的事物（如真人）進行比較，並且因為任何自動化比較都可能被電腦程序繞過，我們使用人類審問者。如果人類無法在基於文字的對話中區分真人和電腦系統，那麼該系統就被認為是智能的。

> 一個名為 [Eugene Goostman](https://en.wikipedia.org/wiki/Eugene_Goostman) 的聊天機器人於2014年在聖彼得堡接近通過圖靈測試，使用了一個巧妙的個性技巧。它事先聲明自己是一個13歲的烏克蘭男孩，這解釋了知識的缺乏和文本中的一些不一致之處。該機器人在5分鐘的對話中說服了30%的評審員相信它是人類，這是一個圖靈認為機器能在2000年之前通過的指標。然而，應該理解的是，這並不表示我們已經創造了一個智能系統，或者電腦系統欺騙了人類審問者——系統並沒有欺騙人類，而是機器人創造者欺騙了人類！

✅ 你是否曾被聊天機器人欺騙，認為自己在與人類交談？它是如何說服你的？

## 人工智慧的不同方法

如果我們希望電腦像人類一樣行事，我們需要以某種方式在電腦內部模擬我們的思維方式。因此，我們需要嘗試理解什麼使人類具有智能。

> 為了能夠將智能編程到機器中，我們需要理解自己做決策的過程是如何運作的。如果你進行一些自我反思，你會意識到有些過程是潛意識進行的——例如，我們可以在不思考的情況下區分貓和狗——而另一些則涉及推理。

解決這個問題有兩種可能的方法：

自上而下方法（符號推理） | 自下而上方法（神經網路）
---------------------------------------|-------------------------------------
自上而下方法模擬人類解決問題的推理方式。它涉及從人類中提取**知識**，並以電腦可讀的形式表示。我們還需要開發一種在電腦內部模擬**推理**的方法。|自下而上方法模擬人類大腦的結構，由大量簡單單元組成，稱為**神經元**。每個神經元的作用類似於其輸入的加權平均值，我們可以通過提供**訓練數據**來訓練神經元網路以解決有用的問題。

此外，還有一些其他可能的智能方法：

* **湧現式**、**協同式**或**多代理方法**基於這樣的事實，即通過大量簡單代理的交互可以獲得複雜的智能行為。根據[進化控制論](https://en.wikipedia.org/wiki/Global_brain#Evolutionary_cybernetics)，智能可以在*系統轉變*過程中從更簡單的反應行為中*湧現*。

* **進化方法**或**遺傳算法**是一種基於進化原則的優化過程。

我們將在課程後續考慮這些方法，但現在我們將重點放在兩個主要方向：自上而下和自下而上。

### 自上而下方法

在**自上而下方法**中，我們嘗試模擬我們的推理。因為我們可以在推理時跟隨自己的思維，我們可以嘗試將這個過程形式化並編程到電腦中。這被稱為**符號推理**。

人們往往在腦海中有一些指導其決策過程的規則。例如，當醫生診斷病人時，他或她可能意識到病人有發燒症狀，因此可能身體內部有炎症。通過將大量規則應用於特定問題，醫生可能能夠得出最終診斷。

這種方法高度依賴於**知識表示**和**推理**。從人類專家中提取知識可能是最困難的部分，因為醫生在許多情況下可能不知道自己為什麼得出特定診斷。有時解決方案只是自然而然地出現在他的腦海中，沒有明確的思考。有些任務，例如從照片中判斷一個人的年齡，根本無法簡化為知識操作。

### 自下而上方法

或者，我們可以嘗試模擬我們大腦中的最簡單元素——神經元。我們可以在電腦中構建所謂的**人工神經網路**，然後通過提供例子來教它解決問題。這個過程類似於新生兒通過觀察學習周圍環境的方式。

✅ 研究一下嬰兒是如何學習的。嬰兒大腦的基本元素是什麼？

> | 那機器學習呢？         |      |
> |--------------|-----------|
> | 基於電腦通過某些數據學習解決問題的人工智慧部分稱為**機器學習**。我們不會在本課程中考慮傳統機器學習——我們推薦您參考單獨的 [機器學習初學者課程](http://aka.ms/ml-beginners)。 |   ![機器學習初學者課程](../../../../translated_images/zh-TW/ml-for-beginners.9e4fed176fd5817d.webp)    |

## 人工智慧的簡史

人工智慧作為一個領域始於20世紀中期。最初，符號推理是主要方法，並取得了一些重要成功，例如專家系統——能夠在某些有限問題領域中充當專家的電腦程序。然而，很快就發現這種方法的可擴展性不佳。從專家中提取知識、在電腦中表示知識並保持知識庫的準確性，事實證明是一項非常複雜且在許多情況下成本過高的任務。這導致了1970年代的所謂[人工智慧寒冬](https://en.wikipedia.org/wiki/AI_winter)。

<img alt="人工智慧簡史" src="../../../../translated_images/zh-TW/history-of-ai.7e83efa70b537f5a.webp" width="70%"/>

> 圖片由 [Dmitry Soshnikov](http://soshnikov.com) 提供

隨著時間的推移，計算資源變得更便宜，更多數據可用，神經網路方法開始在許多領域（如計算機視覺或語音理解）中展現出色的表現。在過去十年中，“人工智慧”這個術語大多被用作神經網路的同義詞，因為我們聽到的大多數人工智慧成功案例都基於神經網路。

我們可以觀察到方法的變化，例如在創建下棋電腦程序方面：

* 早期的下棋程序基於搜索——程序明確嘗試估算對手在一定步數內的可能走法，並根據幾步內可以達到的最佳位置選擇最佳走法。這導致了所謂的[alpha-beta剪枝](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning)搜索算法的發展。
* 搜索策略在遊戲結束時效果很好，因為搜索空間受到少量可能走法的限制。然而，在遊戲開始時，搜索空間巨大，算法可以通過學習人類玩家之間的現有比賽來改進。隨後的實驗採用了所謂的[基於案例推理](https://en.wikipedia.org/wiki/Case-based_reasoning)，程序在知識庫中尋找與當前棋局非常相似的案例。
* 現代能夠擊敗人類玩家的程序基於神經網路和[強化學習](https://en.wikipedia.org/wiki/Reinforcement_learning)，程序通過長時間與自己對弈並從自己的錯誤中學習來學會下棋——就像人類學習下棋一樣。然而，電腦程序可以在更短的時間內玩更多的棋局，因此可以學得更快。

✅ 研究一下其他由人工智慧玩過的遊戲。

同樣，我們可以看到創建“會說話的程序”（可能通過圖靈測試）的方法如何改變：

* 早期的此類程序，例如 [Eliza](https://en.wikipedia.org/wiki/ELIZA)，基於非常簡單的語法規則和將輸入句子重新表述為問題。
* 現代助理，例如 Cortana、Siri 或 Google Assistant，都是混合系統，使用神經網路將語音轉換為文本並識別我們的意圖，然後採用一些推理或明確算法執行所需操作。
* 未來，我們可能期待一個完全基於神經網路的模型能夠自行處理對話。最近的 GPT 和 [Turing-NLG](https://www.microsoft.com/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft) 神經網路系列顯示了巨大的成功。

<img alt="圖靈測試的演變" src="../../../../translated_images/zh-TW/turing-test-evol.4184696701293ead.webp" width="70%"/>
> 圖片由 Dmitry Soshnikov 提供，[照片](https://unsplash.com/photos/r8LmVbUKgns) 由 [Marina Abrosimova](https://unsplash.com/@abrosimova_marina_foto) 提供，Unsplash

## 最近的人工智慧研究

神經網路研究的快速增長始於 2010 年左右，當時大型公共數據集開始變得可用。一個名為 [ImageNet](https://en.wikipedia.org/wiki/ImageNet) 的龐大圖像集合，包含約 1400 萬張帶有註解的圖像，催生了 [ImageNet 大規模視覺識別挑戰賽](https://image-net.org/challenges/LSVRC/)。

![ILSVRC 準確率](../../../../lessons/1-Intro/images/ilsvrc.gif)

> 圖片由 [Dmitry Soshnikov](http://soshnikov.com) 提供

2012 年，[卷積神經網路](../4-ComputerVision/07-ConvNets/README.md) 首次被用於圖像分類，這導致分類錯誤率顯著下降（從接近 30% 降至 16.4%）。2015 年，微軟研究院的 ResNet 架構[達到了人類水準的準確率](https://doi.org/10.1109/ICCV.2015.123)。

自那時起，神經網路在許多任務中展現了非常成功的表現：

---

年份 | 達到人類水準的領域
-----|--------
2015 | [圖像分類](https://doi.org/10.1109/ICCV.2015.123)
2016 | [對話式語音識別](https://arxiv.org/abs/1610.05256)
2018 | [自動機器翻譯](https://arxiv.org/abs/1803.05567)（中翻英）
2020 | [圖像標註](https://arxiv.org/abs/2009.13682)

在過去幾年中，我們見證了大型語言模型的巨大成功，例如 BERT 和 GPT-3。這主要是因為有大量的通用文本數據可用，這使我們能夠訓練模型來捕捉文本的結構和意義，先在通用文本集合上進行預訓練，然後再將這些模型專門化用於更具體的任務。我們將在本課程稍後的[自然語言處理](../5-NLP/README.md)部分中學到更多。

## 🚀 挑戰

在網路上進行探索，判斷您認為人工智慧在哪些領域最有效地被使用。是地圖應用程式、語音轉文字服務，還是某款電子遊戲？研究該系統是如何構建的。

## [課後測驗](https://ff-quizzes.netlify.app/en/ai/quiz/2)

## 回顧與自學

透過閱讀[這一課程](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/2-history-of-ML)來回顧人工智慧和機器學習的歷史。從該課程或本課程頂部的手繪筆記中選擇一個元素，深入研究其文化背景，以了解其演變過程。

**作業**：[遊戲開發馬拉松](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**免責聲明**：  
本文件使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵資訊，建議使用專業人工翻譯。我們對因使用此翻譯而產生的任何誤解或誤釋不承擔責任。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->