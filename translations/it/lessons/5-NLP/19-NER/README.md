# Reconocimiento de Entidades Nombradas

Hasta ahora, hemos estado concentr√°ndonos principalmente en una tarea de NLP: la clasificaci√≥n. Sin embargo, tambi√©n existen otras tareas de NLP que se pueden llevar a cabo con redes neuronales. Una de esas tareas es el **[Reconocimiento de Entidades Nombradas](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), que se ocupa de reconocer entidades espec√≠ficas dentro del texto, como lugares, nombres de personas, intervalos de fecha y hora, f√≥rmulas qu√≠micas, entre otros.

## [Cuestionario previo a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/119)

## Ejemplo de Uso de NER

Supongamos que deseas desarrollar un chatbot de lenguaje natural, similar a Amazon Alexa o Google Assistant. La forma en que funcionan los chatbots inteligentes es *entendiendo* lo que el usuario quiere al realizar una clasificaci√≥n de texto en la frase de entrada. El resultado de esta clasificaci√≥n es lo que se llama **intenci√≥n**, que determina lo que debe hacer un chatbot.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> Imagen del autor

Sin embargo, un usuario puede proporcionar algunos par√°metros como parte de la frase. Por ejemplo, al preguntar por el clima, puede especificar una ubicaci√≥n o una fecha. Un bot deber√≠a ser capaz de entender esas entidades y llenar los espacios de par√°metros correspondientes antes de realizar la acci√≥n. Aqu√≠ es exactamente donde entra en juego el NER.

> ‚úÖ Otro ejemplo ser√≠a [analizar art√≠culos cient√≠ficos m√©dicos](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Una de las principales cosas que necesitamos buscar son t√©rminos m√©dicos espec√≠ficos, como enfermedades y sustancias m√©dicas. Si bien un peque√±o n√∫mero de enfermedades probablemente se puede extraer utilizando b√∫squeda de subcadenas, entidades m√°s complejas, como compuestos qu√≠micos y nombres de medicamentos, requieren un enfoque m√°s complicado.

## NER como Clasificaci√≥n de Tokens

Los modelos de NER son esencialmente **modelos de clasificaci√≥n de tokens**, porque para cada uno de los tokens de entrada necesitamos decidir si pertenece a una entidad o no, y si lo hace, a qu√© clase de entidad.

Considera el siguiente t√≠tulo de un art√≠culo:

**Regurgitaci√≥n de la v√°lvula tric√∫spide** y **toxicidad de carbonato de litio** en un reci√©n nacido.

Las entidades aqu√≠ son:

* Regurgitaci√≥n de la v√°lvula tric√∫spide es una enfermedad (`DIS`)
* Carbonato de litio es una sustancia qu√≠mica (`CHEM`)
* Toxicidad tambi√©n es una enfermedad (`DIS`)

Observa que una entidad puede abarcar varios tokens. Y, como en este caso, necesitamos distinguir entre dos entidades consecutivas. Por lo tanto, es com√∫n usar dos clases para cada entidad: una que especifica el primer token de la entidad (a menudo se utiliza el prefijo `B-`, para **b**eginning), y otra - la continuaci√≥n de una entidad (`I-`, para **i**nner token). Tambi√©n usamos `O` como una clase para representar todos los **o**tros tokens. Este etiquetado de tokens se llama [etiquetado BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (o IOB). Cuando se etiqueta, nuestro t√≠tulo se ver√° as√≠:

Token | Etiqueta
------|-----
Tricuspid | B-DIS
valve | I-DIS
regurgitation | I-DIS
and | O
lithium | B-CHEM
carbonate | I-CHEM
toxicity | B-DIS
in | O
a | O
newborn | O
infant | O
. | O

Dado que necesitamos construir una correspondencia uno a uno entre tokens y clases, podemos entrenar un modelo de red neuronal **muchos a muchos** a partir de esta imagen:

![Imagen que muestra patrones comunes de redes neuronales recurrentes.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.it.jpg)

> *Imagen de [esta entrada de blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) de [Andrej Karpathy](http://karpathy.github.io/). Los modelos de clasificaci√≥n de tokens NER corresponden a la arquitectura de red m√°s a la derecha en esta imagen.*

## Entrenamiento de Modelos NER

Dado que un modelo de NER es esencialmente un modelo de clasificaci√≥n de tokens, podemos utilizar RNNs con los que ya estamos familiarizados para esta tarea. En este caso, cada bloque de la red recurrente devolver√° el ID del token. El siguiente cuaderno de ejemplo muestra c√≥mo entrenar un LSTM para la clasificaci√≥n de tokens.

## ‚úçÔ∏è Cuadernos de Ejemplo: NER

Contin√∫a tu aprendizaje en el siguiente cuaderno:

* [NER con TensorFlow](../../../../../lessons/5-NLP/19-NER/NER-TF.ipynb)

## Conclusi√≥n

Un modelo de NER es un **modelo de clasificaci√≥n de tokens**, lo que significa que puede ser utilizado para realizar clasificaci√≥n de tokens. Esta es una tarea muy com√∫n en NLP, ayudando a reconocer entidades espec√≠ficas dentro del texto, incluyendo lugares, nombres, fechas y m√°s.

## üöÄ Desaf√≠o

Completa la tarea vinculada a continuaci√≥n para entrenar un modelo de reconocimiento de entidades nombradas para t√©rminos m√©dicos, y luego pru√©balo en un conjunto de datos diferente.

## [Cuestionario posterior a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/219)

## Revisi√≥n y Autoestudio

Lee el blog [La Efectividad Irrazonable de las Redes Neuronales Recurrentes](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) y sigue la secci√≥n de Lectura Adicional en ese art√≠culo para profundizar tu conocimiento.

## [Tarea](lab/README.md)

En la tarea para esta lecci√≥n, tendr√°s que entrenar un modelo de reconocimiento de entidades m√©dicas. Puedes comenzar entrenando un modelo LSTM como se describe en esta lecci√≥n y luego proceder a utilizar el modelo transformador BERT. Lee [las instrucciones](lab/README.md) para obtener todos los detalles.

**Disclaimer**:  
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en IA. Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o malas interpretaciones que surjan del uso de esta traducci√≥n.