# အကျင့်သင့် AI နှင့် တာဝန်ရှိမှုရှိသော AI

ဒီသင်တန်းကို အဆုံးသတ်လိုက်ဖို့နီးပါပြီ၊ အခုအချိန်မှာတော့ AI ဟာ ဒေတာထဲက ဆက်စပ်မှုတွေကို ရှာဖွေပြီး လူသားအပြုအမူတချို့ကို ပြန်လည်တူညီအောင် သင်ကြားပေးနိုင်တဲ့ သင်္ချာနည်းလမ်းတွေကို အခြေခံထားတဲ့ အရာတစ်ခုဖြစ်တယ်ဆိုတာ ရှင်းလင်းစွာနားလည်နိုင်ပြီလို့ မျှော်လင့်ပါတယ်။ ယနေ့ခေတ်မှာ AI ကို ဒေတာထဲက ပုံစံတွေကို ရှာဖွေပြီး ပြဿနာအသစ်တွေကို ဖြေရှင်းဖို့ အသုံးချနိုင်တဲ့ အလွန်အစွမ်းထက်တဲ့ ကိရိယာတစ်ခုအဖြစ် သတ်မှတ်ထားပါတယ်။

## [Pre-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

သို့သော်၊ သိပ္ပံစိတ်ကူးယဉ်ဇာတ်လမ်းတွေမှာတော့ AI ဟာ လူသားမျိုးနွယ်အတွက် အန္တရာယ်တစ်ခုအဖြစ် ပေါ်လာတတ်တဲ့ ဇာတ်လမ်းတွေကို မကြာခဏတွေ့ရပါတယ်။ အများအားဖြင့် ဒီဇာတ်လမ်းတွေဟာ AI က လူသားတွေနဲ့ ရင်ဆိုင်ဖို့ ဆုံးဖြတ်တဲ့ အချိန်မှာ ဖြစ်တတ်ပါတယ်။ ဒါက AI ဟာ စိတ်ခံစားမှုတစ်ခုခုရှိတယ်၊ ဒါမှမဟုတ် ဖွံ့ဖြိုးသူတွေ မမျှော်လင့်ထားတဲ့ ဆုံးဖြတ်ချက်တွေကို ချမှတ်နိုင်တယ်ဆိုတာကို အဓိပ္ပာယ်ဖွင့်ဆိုပါတယ်။

ဒီသင်တန်းမှာ သင်ယူခဲ့တဲ့ AI ဟာ အကြီးမားတဲ့ မက်ထရစ် သင်္ချာဆိုင်ရာ လုပ်ငန်းစဉ်တွေထက် မပိုပါဘူး။ ဒါဟာ ကျွန်တော်တို့ရဲ့ ပြဿနာတွေကို ဖြေရှင်းဖို့ အထောက်အကူဖြစ်စေတဲ့ အလွန်အစွမ်းထက်တဲ့ ကိရိယာတစ်ခုဖြစ်ပြီး၊ အခြားသော အစွမ်းထက်တဲ့ ကိရိယာတစ်ခုလိုပဲ - ကောင်းစွာအသုံးချနိုင်သလို၊ မကောင်းစွာအသုံးချနိုင်ပါတယ်။ အရေးကြီးတာကတော့ ဒါကို *မတော်တဆ* သို့မဟုတ် *ရည်ရွယ်ချက်ရှိရှိ* မတော်တဆအသုံးချမိနိုင်တာပါ။

## တာဝန်ရှိမှုရှိသော AI ရဲ့ မူဝါဒများ

AI ကို မတော်တဆ သို့မဟုတ် ရည်ရွယ်ချက်ရှိရှိ မတော်တဆအသုံးမပြုမိစေရန် Microsoft က အရေးကြီးတဲ့ [တာဝန်ရှိမှုရှိသော AI ရဲ့ မူဝါဒများ](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste) ကို ဖော်ပြထားပါတယ်။ ဒီမူဝါဒတွေကို အောက်ပါ အယူအဆတွေက အခြေခံထားပါတယ် -

* **တရားမျှတမှု** ဟာ *မော်ဒယ်အရိပ်အမြွက်* (model biases) ဆိုတဲ့ အရေးကြီးတဲ့ ပြဿနာနဲ့ ဆက်စပ်ပါတယ်။ ဒါဟာ သင်ကြားမှုအတွက် အရိပ်အမြွက်ပါဝင်တဲ့ ဒေတာကို အသုံးပြုခြင်းကြောင့် ဖြစ်တတ်ပါတယ်။ ဥပမာအားဖြင့်၊ လူတစ်ဦးအတွက် ဆော့ဖ်ဝဲဒီဗလော့ပါအလုပ်ရရှိနိုင်မှု အလားအလာကို ခန့်မှန်းတဲ့အခါ၊ သင်ကြားမှုဒေတာဟာ အမျိုးသားတွေကို ပိုမိုအားထားထားတဲ့ ဒေတာဖြစ်နိုင်တဲ့အတွက် မော်ဒယ်ဟာ အမျိုးသားတွေကို ပိုမိုနှစ်သက်တတ်ပါတယ်။ ဒေတာသင်ကြားမှုကို သေချာစွာ ချိန်ခွင့်ညှိပြီး မော်ဒယ်ကို စစ်ဆေးကာ အရိပ်အမြွက်တွေကို ရှောင်ရှားဖို့ လိုအပ်ပါတယ်၊ မော်ဒယ်ဟာ ပိုမိုသက်ဆိုင်တဲ့ အချက်အလက်တွေကို ထည့်သွင်းစဉ်းစားထားတာကို သေချာစေဖို့ လိုအပ်ပါတယ်။
* **ယုံကြည်စိတ်ချမှုနှင့် လုံခြုံမှု**။ AI မော်ဒယ်တွေဟာ သဘာဝအရ အမှားတွေကို ပြုလုပ်နိုင်ပါတယ်။ နယူးရယ်နက်ဝက်က အလားအလာတွေကို ပြန်ပေးတတ်ပြီး၊ ဆုံးဖြတ်ချက်ချတဲ့အခါမှာ ဒီအချက်ကို ထည့်သွင်းစဉ်းစားဖို့ လိုအပ်ပါတယ်။ မော်ဒယ်တိုင်းမှာ တိကျမှုနဲ့ ပြန်လည်ခေါ်ဆောင်မှုရှိပြီး၊ အမှားအကြံပေးမှုကြောင့် ဖြစ်နိုင်တဲ့ နစ်နာမှုကို ကာကွယ်ဖို့ ဒီအချက်တွေကို နားလည်ဖို့ လိုအပ်ပါတယ်။
* **ကိုယ်ရေးကိုယ်တာနှင့် လုံခြုံရေး** ဟာ AI-ဆိုင်ရာ အထူးသက်ဆိုင်မှုတွေ ရှိပါတယ်။ ဥပမာအားဖြင့်၊ မော်ဒယ်တစ်ခုကို သင်ကြားဖို့ ဒေတာတစ်ခုခုကို အသုံးပြုတဲ့အခါ၊ ဒီဒေတာဟာ မော်ဒယ်ထဲမှာ တစ်နည်းနည်းနဲ့ "ပေါင်းစည်း" သွားပါတယ်။ တစ်ဖက်မှာတော့ ဒါဟာ လုံခြုံရေးနဲ့ ကိုယ်ရေးကိုယ်တာကို တိုးတက်စေပါတယ်၊ ဒါပေမယ့် မော်ဒယ်ကို သင်ကြားခဲ့တဲ့ ဒေတာကို မှတ်ထားဖို့ လိုအပ်ပါတယ်။
* **ပါဝင်မှု** ဆိုတာ AI ကို လူတွေကို အစားထိုးဖို့ မလုပ်ဘဲ၊ လူတွေကို ပိုမိုဖန်တီးနိုင်စေဖို့ အထောက်အကူဖြစ်စေဖို့ တည်ဆောက်တာကို ဆိုလိုပါတယ်။ ဒါဟာ တရားမျှတမှုနဲ့လည်း ဆက်စပ်ပါတယ်၊ အထူးသဖြင့် လူနည်းစုအဖွဲ့အစည်းတွေနဲ့ ဆက်စပ်တဲ့အခါ၊ ကျွန်တော်တို့ စုဆောင်းတဲ့ ဒေတာအများစုဟာ အရိပ်အမြွက်ပါဝင်နိုင်ပါတယ်၊ ဒီအဖွဲ့အစည်းတွေကို ထည့်သွင်းပြီး AI ကောင်းစွာကိုင်တွယ်နိုင်ဖို့ သေချာစေဖို့ လိုအပ်ပါတယ်။
* **ပွင့်လင်းမြင်သာမှု**။ AI ကို အသုံးပြုနေတယ်ဆိုတာကို အမြဲရှင်းလင်းစွာ ဖော်ပြထားတာကို သေချာစေဖို့ လိုအပ်ပါတယ်။ ထို့အပြင်၊ အလားအလာရှိသလောက် AI စနစ်တွေဟာ *ဖွင့်ဟနိုင်* ဖြစ်စေရန် ကြိုးစားလိုက်စားရမယ်။
* **တာဝန်ယူမှု**။ AI မော်ဒယ်တွေက ဆုံးဖြတ်ချက်တစ်ခုခုကို ထုတ်ပေးတဲ့အခါ၊ ဒီဆုံးဖြတ်ချက်တွေအပေါ် တာဝန်ယူမှုဟာ ဘယ်သူ့မှာရှိတယ်ဆိုတာ အမြဲရှင်းလင်းမဖြစ်နိုင်ပါဘူး။ AI ဆုံးဖြတ်ချက်တွေရဲ့ တာဝန်ယူမှုဟာ ဘယ်မှာရှိတယ်ဆိုတာ နားလည်နိုင်ဖို့ လိုအပ်ပါတယ်။ အရေးကြီးတဲ့ ဆုံးဖြတ်ချက်တွေကို ချမှတ်တဲ့အခါ လူသားတွေကို ထည့်သွင်းဖို့လိုအပ်ပါတယ်၊ ဒါကြောင့် တာဝန်ယူမှုဟာ လူသားတွေအပေါ်မှာရှိနေစေဖို့ လိုအပ်ပါတယ်။

## တာဝန်ရှိမှုရှိသော AI အတွက် ကိရိယာများ

Microsoft က [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox) ကို ဖန်တီးထားပြီး၊ အောက်ပါ ကိရိယာတွေပါဝင်ပါတယ် -

* Interpretability Dashboard (InterpretML)
* Fairness Dashboard (FairLearn)
* Error Analysis Dashboard
* Responsible AI Dashboard, အောက်ပါအရာတွေပါဝင်ပါတယ် -

   - EconML - Causal Analysis အတွက် ကိရိယာ၊ which focuses on what-if questions
   - DiCE - Counterfactual Analysis အတွက် ကိရိယာ၊ မော်ဒယ်ရဲ့ ဆုံးဖြတ်ချက်ကို အကျိုးသက်ရောက်စေဖို့ ဘယ်လိုအချက်တွေကို ပြောင်းလဲဖို့ လိုအပ်တယ်ဆိုတာကို ကြည့်နိုင်စေပါတယ်

AI Ethics အကြောင်း ပိုမိုသိရှိလိုပါက၊ [ဒီသင်ခန်းစာ](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) ကို သွားရောက်လေ့လာပါ၊ Machine Learning Curriculum ထဲမှာ လုပ်ငန်းတာဝန်တွေပါဝင်ပါတယ်။

## ပြန်လည်သုံးသပ်ခြင်းနှင့် ကိုယ်တိုင်လေ့လာခြင်း

တာဝန်ရှိမှုရှိသော AI အကြောင်း ပိုမိုလေ့လာရန် ဒီ [Learn Path](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) ကို လိုက်နာပါ။

## [Post-lecture quiz](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**အကြောင်းကြားချက်**:  
ဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှုအတွက် ကြိုးစားနေသော်လည်း၊ အလိုအလျောက် ဘာသာပြန်ခြင်းတွင် အမှားများ သို့မဟုတ် မမှန်ကန်မှုများ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူရင်းစာရွက်စာတမ်းကို ၎င်း၏ မူရင်းဘာသာစကားဖြင့် အာဏာတရားရှိသော အရင်းအမြစ်အဖြစ် သတ်မှတ်သင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူ့ဘာသာပြန်ပညာရှင်များမှ ပရော်ဖက်ရှင်နယ် ဘာသာပြန်ခြင်းကို အကြံပြုပါသည်။ ဤဘာသာပြန်ကို အသုံးပြုခြင်းမှ ဖြစ်ပေါ်လာသော အလွဲအလွတ်များ သို့မဟုတ် အနားလွဲမှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။