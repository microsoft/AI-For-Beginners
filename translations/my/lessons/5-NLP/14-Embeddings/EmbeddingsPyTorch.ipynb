{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "ယခင်ဥပမာတွင် ကျွန်ုပ်တို့သည် `vocab_size` အရှည်ရှိ အမြင့်မားသော dimension bag-of-words vectors များကို အသုံးပြုခဲ့ပြီး၊ အနိမ့် dimension positional representation vectors များမှ sparse one-hot representation သို့ တိတိကျကျ ပြောင်းလဲခဲ့ပါသည်။ သို့သော်၊ one-hot representation သည် memory ကို ထိရောက်စွာ အသုံးမပြုနိုင်သလို၊ စကားလုံးတစ်လုံးချင်းစီကိုလည်း အချင်းချင်း သီးခြားစီ ဆက်စပ်မှုမရှိဘဲ ဆက်ဆံထားသည်။ အဆိုပါ one-hot encoded vectors များသည် စကားလုံးများအကြား အဓိပ္ပါယ်ဆိုင်ရာ ဆင်တူမှုများကို မဖော်ပြနိုင်ပါ။\n",
    "\n",
    "ဤယူနစ်တွင် ကျွန်ုပ်တို့သည် **News AG** dataset ကို ဆက်လက်လေ့လာသွားမည်ဖြစ်သည်။ စတင်ရန်အတွက် ဒေတာများကို load ပြုလုပ်ပြီး ယခင် notebook မှ အဓိပ္ပါယ်ဖွင့်ဆိုချက်များကို ရယူကြပါစို့။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\WORK\\ai-for-beginners\\5-NLP\\14-Embeddings\\data\\train.csv: 29.5MB [00:01, 18.8MB/s]                            \n",
      "d:\\WORK\\ai-for-beginners\\5-NLP\\14-Embeddings\\data\\test.csv: 1.86MB [00:00, 11.2MB/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocab...\n",
      "Vocab size =  95812\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import numpy as np\n",
    "from torchnlp import *\n",
    "train_dataset, test_dataset, classes, vocab = load_dataset()\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size = \",vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding ဆိုတာဘာလဲ?\n",
    "\n",
    "**Embedding** ဆိုတာက စကားလုံးတွေကို အနည်းဆုံး dimension ရှိတဲ့ dense vector တွေဖြင့် ကိုယ်စားပြုဖော်ပြတာဖြစ်ပြီး၊ စကားလုံးတစ်လုံးရဲ့ အဓိပ္ပါယ်ဆိုင်ရာ အနက်ကို တစ်နည်းနည်းနဲ့ ပြသပေးတာဖြစ်ပါတယ်။ စကားလုံး embedding တွေကို ဘယ်လို အဓိပ္ပါယ်ရှိအောင် ဖန်တီးမလဲဆိုတာကို နောက်ပိုင်းမှာ ဆွေးနွေးပေးပါမယ်၊ ဒါပေမယ့် အခုအချိန်မှာတော့ embedding ကို စကားလုံး vector ရဲ့ dimension ကို လျှော့ချတဲ့ နည်းလမ်းတစ်ခုအနေနဲ့ သာ စဉ်းစားကြည့်ပါ။\n",
    "\n",
    "ဒါကြောင့် embedding layer က စကားလုံးတစ်လုံးကို input အနေနဲ့ ယူပြီး၊ သတ်မှတ်ထားတဲ့ `embedding_size` ရဲ့ output vector ကို ထုတ်ပေးပါမယ်။ တစ်နည်းအားဖြင့်၊ ဒါဟာ `Linear` layer နဲ့ ဆင်တူပါတယ်၊ ဒါပေမယ့် one-hot encoded vector ကို ယူမယ့်အစား၊ စကားလုံးနံပါတ်ကို input အနေနဲ့ ယူနိုင်မှာ ဖြစ်ပါတယ်။\n",
    "\n",
    "ကျွန်တော်တို့ network ရဲ့ ပထမဆုံး layer အနေနဲ့ embedding layer ကို သုံးခြင်းအားဖြင့်၊ bag-of-words မှ **embedding bag** မော်ဒယ်ဆီကို ပြောင်းနိုင်ပါတယ်။ ဒီမှာ ကျွန်တော်တို့ရဲ့ စာသားထဲက စကားလုံးတစ်လုံးစီကို သက်ဆိုင်ရာ embedding ကို ပြောင်းပြီး၊ ထို embedding တွေကို `sum`၊ `average` သို့မဟုတ် `max` ကဲ့သို့သော aggregate function တစ်ခုခုကို တွက်ချက်ပေးပါမယ်။\n",
    "\n",
    "![Image showing an embedding classifier for five sequence words.](../../../../../translated_images/my/embedding-classifier-example.b77f021a7ee67eee.webp)\n",
    "\n",
    "ကျွန်တော်တို့ရဲ့ classifier neural network က embedding layer နဲ့ စပြီး၊ aggregation layer နဲ့ linear classifier ကို အပေါ်မှာ ထည့်သွင်းထားပါမယ်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.mean(x,dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အရွယ်အစား မတူညီသော variable sequence ကို ကိုင်တွယ်ခြင်း\n",
    "\n",
    "ဒီ architecture ရဲ့ ရလဒ်အနေနဲ့, network အတွက် minibatches တွေကို တစ်သတ်မှတ်နည်းလမ်းနဲ့ ဖန်တီးဖို့ လိုအပ်လာမယ်။ ယခင်ယူနစ်မှာ bag-of-words ကို အသုံးပြုတဲ့အခါ, minibatch ထဲမှာရှိတဲ့ BoW tensors အားလုံးဟာ `vocab_size` အရွယ်အစားတူညီနေခဲ့တယ်၊ ကျွန်တော်တို့ရဲ့ text sequence ရဲ့ အရှည်ကိုမထည့်သွင်းစဉ်းစားဘဲ။ ဒါပေမယ့် word embeddings ကို အသုံးပြုတဲ့အခါ, တစ်ခုချင်းစီ text sample မှာ စကားလုံးအရေအတွက် မတူညီလာနိုင်ပြီး, အဲ့ဒီ samples တွေကို minibatches အဖြစ် ပေါင်းစည်းတဲ့အခါ padding တစ်ခုခုကို အသုံးပြုဖို့ လိုအပ်လာမယ်။\n",
    "\n",
    "ဒါကို datasource ကို `collate_fn` function ပေးခြင်းနဲ့ တူညီတဲ့နည်းလမ်းကို အသုံးပြုပြီး လုပ်ဆောင်နိုင်ပါတယ်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padify(b):\n",
    "    # b is the list of tuples of length batch_size\n",
    "    #   - first element of a tuple = label, \n",
    "    #   - second = feature (text sequence)\n",
    "    # build vectorized sequence\n",
    "    v = [encode(x[1]) for x in b]\n",
    "    # first, compute max length of a sequence in this minibatch\n",
    "    l = max(map(len,v))\n",
    "    return ( # tuple of two tensors - labels and features\n",
    "        torch.LongTensor([t[0]-1 for t in b]),\n",
    "        torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v])\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=padify, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အထွေထွေ Embedding Classifier ကိုလေ့ကျင့်ခြင်း\n",
    "\n",
    "အခုတော့ သင့်တော်သော dataloader ကိုသတ်မှတ်ပြီးသားဖြစ်သောကြောင့် ယခင်ယူနစ်တွင်သတ်မှတ်ထားသောလေ့ကျင့်မှု function ကိုအသုံးပြု၍ မော်ဒယ်ကိုလေ့ကျင့်နိုင်ပါပြီ။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.6415625\n",
      "6400: acc=0.6865625\n",
      "9600: acc=0.7103125\n",
      "12800: acc=0.726953125\n",
      "16000: acc=0.739375\n",
      "19200: acc=0.75046875\n",
      "22400: acc=0.7572321428571429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.889799795315499, 0.7623160588611644)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = EmbedClassifier(vocab_size,32,len(classes)).to(device)\n",
    "train_epoch(net,train_loader, lr=1, epoch_size=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **မှတ်ချက်**: အချိန်သက်သာစေရန်အတွက် ဒီမှာ ၂၅,၀၀၀ မှတ်တမ်းပမာဏ (တစ်ခုလုံးသော epoch ထက်နည်း) ကိုသာလေ့ကျင့်နေပါသည်၊ သို့သော် သင်သည် လေ့ကျင့်မှုကို ဆက်လက်လုပ်ဆောင်နိုင်ပြီး၊ အတော်များများသော epoch များအတွက် လေ့ကျင့်ရန် function တစ်ခုရေးနိုင်ပြီး၊ သင့်တိုးတက်မှုနှုန်း parameter ကို စမ်းသပ်ခြင်းဖြင့် ပိုမိုမြင့်မားသော တိကျမှုရရှိရန် ကြိုးစားနိုင်ပါသည်။ သင်သည် ၉၀% အနီးအတောင်တိကျမှုကို ရောက်ရှိနိုင်သင့်သည်။\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmbeddingBag Layer နှင့် အရှည်မတူညီသော အစီအစဉ်ကို ကိုယ်စားပြုခြင်း\n",
    "\n",
    "ယခင် အဆောက်အအုံတွင်၊ minibatch ထဲသို့ ထည့်သွင်းနိုင်ရန် အစီအစဉ်အားလုံးကို အရှည်တူအောင် pad လုပ်ရန် လိုအပ်ခဲ့သည်။ သို့သော်၊ အရှည်မတူညီသော အစီအစဉ်များကို ကိုယ်စားပြုရန်အတွက် ဤနည်းလမ်းသည် အကျိုးရှိဆုံးမဟုတ်ပါ။ အခြားနည်းလမ်းတစ်ခုမှာ **offset** vector ကို အသုံးပြုခြင်းဖြစ်ပြီး၊ ၎င်းသည် အစီအစဉ်အားလုံး၏ offsets ကို တစ်ခုတည်းသော vector အကြီးထဲတွင် သိမ်းဆည်းထားမည်ဖြစ်သည်။\n",
    "\n",
    "![Offset sequence ကို ကိုယ်စားပြုထားသော ပုံ](../../../../../translated_images/my/offset-sequence-representation.eb73fcefb29b46ee.webp)\n",
    "\n",
    "> **Note**: အထက်ပါ ပုံတွင် အက္ခရာများ၏ အစီအစဉ်ကို ပြထားသော်လည်း၊ ကျွန်ုပ်တို့၏ ဥပမာတွင် စကားလုံးများ၏ အစီအစဉ်များနှင့် အလုပ်လုပ်နေပါသည်။ သို့သော်၊ offset vector ဖြင့် အစီအစဉ်များကို ကိုယ်စားပြုခြင်း၏ အခြေခံသဘောတရားမှာ မပြောင်းလဲပါ။\n",
    "\n",
    "Offset ကိုယ်စားပြုမှုနှင့် အလုပ်လုပ်ရန်၊ [`EmbeddingBag`](https://pytorch.org/docs/stable/generated/torch.nn.EmbeddingBag.html) layer ကို အသုံးပြုပါသည်။ ၎င်းသည် `Embedding` နှင့် ဆင်တူသော်လည်း၊ content vector နှင့် offset vector ကို input အဖြစ် လက်ခံပြီး၊ `mean`, `sum` သို့မဟုတ် `max` ဖြစ်နိုင်သော averaging layer ကိုလည်း ပါဝင်စေသည်။\n",
    "\n",
    "ဤနေရာတွင် `EmbeddingBag` ကို အသုံးပြုထားသော ပြင်ဆင်ထားသော network ကို ဖော်ပြထားသည်-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.EmbeddingBag(vocab_size, embed_dim)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, text, off):\n",
    "        x = self.embedding(text, off)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ဒေတာစနစ်ကိုလေ့ကျင့်ရန်အတွက် ပြင်ဆင်ရန် offset vector ကိုပြင်ဆင်ပေးမည့် conversion function ကိုပေးရန်လိုအပ်သည်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsetify(b):\n",
    "    # first, compute data tensor from all sequences\n",
    "    x = [torch.tensor(encode(t[1])) for t in b]\n",
    "    # now, compute the offsets by accumulating the tensor of sequence lengths\n",
    "    o = [0] + [len(t) for t in x]\n",
    "    o = torch.tensor(o[:-1]).cumsum(dim=0)\n",
    "    return ( \n",
    "        torch.LongTensor([t[0]-1 for t in b]), # labels\n",
    "        torch.cat(x), # text \n",
    "        o\n",
    "    )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=offsetify, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ယခင် ဥပမာများနှင့် မတူကွဲပြားစွာ၊ ယခုအခါ ကျွန်ုပ်တို့၏ network သည် parameter နှစ်ခုကို လက်ခံပါသည် - data vector နှင့် offset vector၊ အရွယ်အစားကွဲပြားမှုရှိသည်။ ထို့အပြင် ကျွန်ုပ်တို့၏ data loader သည် 2 ခုအစား 3 ခုသောတန်ဖိုးများကိုပေးသည် - text နှင့် offset vector နှစ်ခုစလုံးကို feature အဖြစ်ပေးသည်။ ထို့ကြောင့် ကျွန်ုပ်တို့၏ training function ကို အနည်းငယ်ပြင်ဆင်ရန်လိုအပ်သည်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.6153125\n",
      "6400: acc=0.6615625\n",
      "9600: acc=0.6932291666666667\n",
      "12800: acc=0.715078125\n",
      "16000: acc=0.7270625\n",
      "19200: acc=0.7382291666666667\n",
      "22400: acc=0.7486160714285715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22.771553103007037, 0.7551983365323096)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = EmbedClassifier(vocab_size,32,len(classes)).to(device)\n",
    "\n",
    "def train_epoch_emb(net,dataloader,lr=0.01,optimizer=None,loss_fn = torch.nn.CrossEntropyLoss(),epoch_size=None, report_freq=200):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    loss_fn = loss_fn.to(device)\n",
    "    net.train()\n",
    "    total_loss,acc,count,i = 0,0,0,0\n",
    "    for labels,text,off in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        labels,text,off = labels.to(device), text.to(device), off.to(device)\n",
    "        out = net(text, off)\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "        i+=1\n",
    "        if i%report_freq==0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "        if epoch_size and count>epoch_size:\n",
    "            break\n",
    "    return total_loss.item()/count, acc.item()/count\n",
    "\n",
    "\n",
    "train_epoch_emb(net,train_loader, lr=4, epoch_size=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Embeddings: Word2Vec\n",
    "\n",
    "ယခင်ဥပမာတွင် မော်ဒယ်၏ embedding layer သည် စကားလုံးများကို ဗက်တာအနေနဲ့ ဖော်ပြဖို့ သင်ယူခဲ့ပေမယ့်၊ အဲဒီဖော်ပြမှုမှာ အဓိပ္ပါယ်ဆိုင်ရာ အနက်အဓိပ္ပါယ်များ မပါရှိသလောက်ပါ။ စကားလုံးများကို ဗက်တာအနေနဲ့ ဖော်ပြရာမှာ၊ အဓိပ္ပါယ်တူသော စကားလုံးများ (သို့) အနီးစပ်ဆုံးသော စကားလုံးများသည် ဗက်တာအကွာအဝေး (ဥပမာ euclidian distance) အရ နီးစပ်နေမယ့် representation ကို သင်ယူနိုင်ရင် ပိုကောင်းမယ်လို့ ထင်ရပါတယ်။\n",
    "\n",
    "ဒါကို ပြုလုပ်ဖို့အတွက်၊ ကျွန်တော်တို့ရဲ့ embedding မော်ဒယ်ကို စာသားအစုကြီးတစ်ခုအပေါ်မှာ အထူးနည်းလမ်းတစ်ခုနဲ့ ကြိုတင်သင်ယူစေဖို့ လိုအပ်ပါတယ်။ အဓိပ္ပါယ်ဆိုင်ရာ embedding များကို သင်ယူစေဖို့ ပထမဆုံးနည်းလမ်းများထဲက တစ်ခုကို [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) လို့ ခေါ်ပါတယ်။ ဒါဟာ စကားလုံးများကို ဖြန့်ဖြူးထားသော representation အဖြစ် ဖန်တီးဖို့ အသုံးပြုတဲ့ အဓိက architecture နှစ်ခုအပေါ်မှာ အခြေခံထားပါတယ်-\n",
    "\n",
    " - **Continuous bag-of-words** (CBoW) — ဒီ architecture မှာ မော်ဒယ်ကို ပတ်ဝန်းကျင်အကြောင်းအရာကနေ စကားလုံးတစ်လုံးကို ခန့်မှန်းဖို့ သင်ကြားပေးပါတယ်။ ngram $(W_{-2},W_{-1},W_0,W_1,W_2)$ ကို ပေးထားတဲ့အခါ၊ မော်ဒယ်ရဲ့ ရည်မှန်းချက်က $(W_{-2},W_{-1},W_1,W_2)$ ကနေ $W_0$ ကို ခန့်မှန်းဖို့ ဖြစ်ပါတယ်။\n",
    " - **Continuous skip-gram** — CBoW ရဲ့ ဆန့်ကျင်ဘက်ဖြစ်ပါတယ်။ ဒီမော်ဒယ်က ပတ်ဝန်းကျင်အကြောင်းအရာ စကားလုံးများကို အသုံးပြုပြီး လက်ရှိစကားလုံးကို ခန့်မှန်းပါတယ်။\n",
    "\n",
    "CBoW က ပိုမြန်ပါတယ်၊ skip-gram က ပိုနှေးပေမယ့် မကြာခဏ မတွေ့ရတဲ့ စကားလုံးများကို ပိုကောင်းစွာ ဖော်ပြနိုင်ပါတယ်။\n",
    "\n",
    "![CBoW နဲ့ Skip-Gram algorithm နှစ်ခုစလုံးကို စကားလုံးများကို ဗက်တာအဖြစ် ပြောင်းလဲဖို့ အသုံးပြုနေတဲ့ ပုံ။](../../../../../translated_images/my/example-algorithms-for-converting-words-to-vectors.fbe9207a726922f6.webp)\n",
    "\n",
    "Google News dataset ပေါ်မှာ ကြိုတင်သင်ယူထားတဲ့ word2vec embedding ကို စမ်းသပ်ဖို့၊ **gensim** library ကို အသုံးပြုနိုင်ပါတယ်။ အောက်မှာ 'neural' နဲ့ အနီးဆုံးသော စကားလုံးများကို ရှာဖွေထားပါတယ်-\n",
    "\n",
    "> **Note:** စကားလုံးဗက်တာများကို ပထမဆုံး ဖန်တီးတဲ့အခါ၊ အဲဒီဗက်တာများကို ဒေါင်းလုပ်လုပ်ရတာ အချိန်အတော်ကြာနိုင်ပါတယ်!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "w2v = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuronal -> 0.7804799675941467\n",
      "neurons -> 0.7326500415802002\n",
      "neural_circuits -> 0.7252851724624634\n",
      "neuron -> 0.7174385190010071\n",
      "cortical -> 0.6941086649894714\n",
      "brain_circuitry -> 0.6923246383666992\n",
      "synaptic -> 0.6699118614196777\n",
      "neural_circuitry -> 0.6638563275337219\n",
      "neurochemical -> 0.6555314064025879\n",
      "neuronal_activity -> 0.6531826257705688\n"
     ]
    }
   ],
   "source": [
    "for w,p in w2v.most_similar('neural'):\n",
    "    print(f\"{w} -> {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ကျွန်ုပ်တို့သည် စကားလုံးမှ ဗက်တာအင်ဘက်ဒ်များကိုလည်းတွက်ချက်နိုင်ပြီး အမျိုးအစားခွဲခြားမှုမော်ဒယ်ကိုလေ့ကျင့်ရန်အသုံးပြုနိုင်ပါသည် (ရှင်းလင်းမှုအတွက် ဗက်တာ၏ပထမ ၂၀ ခုအစိတ်အပိုင်းများကိုသာပြသပါသည်)။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01226807,  0.06225586,  0.10693359,  0.05810547,  0.23828125,\n",
       "        0.03686523,  0.05151367, -0.20703125,  0.01989746,  0.10058594,\n",
       "       -0.03759766, -0.1015625 , -0.15820312, -0.08105469, -0.0390625 ,\n",
       "       -0.05053711,  0.16015625,  0.2578125 ,  0.10058594, -0.25976562],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.word_vec('play')[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('queen', 0.7118192911148071)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=['king','woman'],negative=['man'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CBoW နဲ့ Skip-Grams နှစ်ခုလုံးဟာ “predictive” embeddings ဖြစ်ပြီး၊ ဒါတွေက အနီးအနားက context တွေကိုပဲ အဓိကထားပါတယ်။ Word2Vec က global context ကို အသုံးမပြုပါဘူး။\n",
    "\n",
    "**FastText** က Word2Vec အပေါ်မှာ တိုးတက်မှုတစ်ခုဖြစ်ပြီး၊ စကားလုံးတစ်လုံးစီအတွက် vector ကို သင်ယူရုံမက၊ စကားလုံးတစ်လုံးအတွင်းရှိ character n-grams တွေကိုပါ သင်ယူပါတယ်။ ဒီ representation တွေကို training တစ်ကြိမ်စီမှာ vector တစ်ခုအဖြစ် ပျမ်းမျှတွက်ချက်ပေးပါတယ်။ ဒါက pre-training အတွက် အချိန်ပိုကုန်စေသော်လည်း၊ word embeddings တွေမှာ sub-word information ကို encode လုပ်နိုင်စေပါတယ်။\n",
    "\n",
    "အခြားနည်းလမ်းတစ်ခုဖြစ်တဲ့ **GloVe** က co-occurrence matrix ရဲ့ အယူအဆကို အသုံးပြုပြီး၊ co-occurrence matrix ကို neural methods တွေသုံးပြီး ပိုမိုဖော်ပြနိုင်တဲ့၊ nonlinear word vectors တွေအဖြစ် ခွဲထုတ်ပါတယ်။\n",
    "\n",
    "သင် gensim က support လုပ်ပေးတဲ့ word embedding models အမျိုးမျိုးကို အသုံးပြုပြီး၊ embeddings ကို FastText နဲ့ GloVe အဖြစ် ပြောင်းလဲပြီး စမ်းသပ်ကြည့်နိုင်ပါတယ်။\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch တွင် Pre-Trained Embeddings ကို အသုံးပြုခြင်း\n",
    "\n",
    "အထက်ပါ ဥပမာကို ပြောင်းလဲပြီး၊ Word2Vec ကဲ့သို့သော အဓိပ္ပါယ်ဆိုင်ရာ embeddings များဖြင့် ကျွန်ုပ်တို့၏ embedding layer တွင် matrix ကို ကြိုတင်ဖြည့်စွက်နိုင်ပါသည်။ Pre-trained embedding ၏ vocabulary နှင့် ကျွန်ုပ်တို့၏ text corpus ၏ vocabulary များသည် မျှမတူနိုင်ကြောင်းကို သတိပြုရမည်ဖြစ်ပြီး၊ မပါဝင်သော စကားလုံးများအတွက် weight များကို အလွတ်တစ်ဆင့်ဖြင့် initialize လုပ်မည်ဖြစ်သည်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 300\n",
      "Populating matrix, this will take some time...Done, found 41080 words, 54732 words missing\n"
     ]
    }
   ],
   "source": [
    "embed_size = len(w2v.get_vector('hello'))\n",
    "print(f'Embedding size: {embed_size}')\n",
    "\n",
    "net = EmbedClassifier(vocab_size,embed_size,len(classes))\n",
    "\n",
    "print('Populating matrix, this will take some time...',end='')\n",
    "found, not_found = 0,0\n",
    "for i,w in enumerate(vocab.get_itos()):\n",
    "    try:\n",
    "        net.embedding.weight[i].data = torch.tensor(w2v.get_vector(w))\n",
    "        found+=1\n",
    "    except:\n",
    "        net.embedding.weight[i].data = torch.normal(0.0,1.0,(embed_size,))\n",
    "        not_found+=1\n",
    "\n",
    "print(f\"Done, found {found} words, {not_found} words missing\")\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.6359375\n",
      "6400: acc=0.68109375\n",
      "9600: acc=0.7067708333333333\n",
      "12800: acc=0.723671875\n",
      "16000: acc=0.73625\n",
      "19200: acc=0.7463541666666667\n",
      "22400: acc=0.7560714285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(214.1013875559821, 0.7626759436980166)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch_emb(net,train_loader, lr=4, epoch_size=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ကျွန်တော်တို့အနေဖြင့် တိကျမှုမှာ အလွန်များပြားသော တိုးတက်မှုကို မတွေ့ရပါဘူး၊ ဒါဟာ အလွန်ကွဲပြားတဲ့ ဝေါဟာရများကြောင့် ဖြစ်နိုင်ပါတယ်။  \n",
    "ကွဲပြားတဲ့ ဝေါဟာရများကြောင့် ဖြစ်ပေါ်လာတဲ့ ပြဿနာကို ဖြေရှင်းရန် အောက်ပါနည်းလမ်းများကို အသုံးပြုနိုင်ပါတယ်-  \n",
    "* word2vec မော်ဒယ်ကို ကျွန်တော်တို့ရဲ့ ဝေါဟာရပေါ်မှာ ပြန်လည်လေ့ကျင့်ပါ  \n",
    "* word2vec မော်ဒယ်ကို ကြိုတင်လေ့ကျင့်ထားတဲ့ ဝေါဟာရနဲ့ dataset ကို load လုပ်ပါ။ Dataset ကို load လုပ်တဲ့အခါ အသုံးပြုမယ့် ဝေါဟာရကို သတ်မှတ်နိုင်ပါတယ်။\n",
    "\n",
    "နောက်ဆုံးနည်းလမ်းက ပိုမိုလွယ်ကူသလို PyTorch `torchtext` framework မှာ embedding တွေအတွက် built-in support ပါဝင်တာကြောင့် ပိုမိုအဆင်ပြေပါတယ်။  \n",
    "ဥပမာအားဖြင့် GloVe-based vocabulary ကို အောက်ပါနည်းလမ်းဖြင့် instantiate လုပ်နိုင်ပါတယ်-  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 399999/400000 [00:15<00:00, 25411.14it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = torchtext.vocab.GloVe(name='6B', dim=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "အသုံးပြုနိုင်သော ဝေါဟာရတွင် အခြေခံ လုပ်ဆောင်ချက်များ ရှိပါသည်။\n",
    "* `vocab.stoi` dictionary သည် စကားလုံးကို ၎င်း၏ အညွှန်းနံပါတ်သို့ ပြောင်းလဲရန် အကူအညီပေးသည်။\n",
    "* `vocab.itos` သည် ဆန့်ကျင်ဘက်လုပ်ဆောင်ချက်ကို ပြုလုပ်သည် - နံပါတ်ကို စကားလုံးသို့ ပြောင်းလဲသည်။\n",
    "* `vocab.vectors` သည် embedding vectors များပါဝင်သော array ဖြစ်ပြီး၊ စကားလုံး `s` ၏ embedding ကို ရယူရန် `vocab.vectors[vocab.stoi[s]]` ကို အသုံးပြုရမည်။\n",
    "\n",
    "ဤသည်မှာ **kind-man+woman = queen** ဆိုသော သင်္ချာကို ပြသရန် embedding များကို ပြောင်းလဲအသုံးပြုသည့် ဥပမာတစ်ခုဖြစ်သည် (အလုပ်ဖြစ်စေရန် coefficient ကို အနည်းငယ် ပြင်ဆင်ခဲ့ရသည်)။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the vector corresponding to kind-man+woman\n",
    "qvec = vocab.vectors[vocab.stoi['king']]-vocab.vectors[vocab.stoi['man']]+1.3*vocab.vectors[vocab.stoi['woman']]\n",
    "# find the index of the closest embedding vector \n",
    "d = torch.sum((vocab.vectors-qvec)**2,dim=1)\n",
    "min_idx = torch.argmin(d)\n",
    "# find the corresponding word\n",
    "vocab.itos[min_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ဒေါင်းလုပ်များကို အသုံးပြု၍ classifier ကို လေ့ကျင့်ရန်အတွက်၊ ကျွန်ုပ်တို့၏ dataset ကို GloVe vocabulary ကို အသုံးပြု၍ encode လုပ်ရန်အရင်လိုအပ်သည်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsetify(b):\n",
    "    # first, compute data tensor from all sequences\n",
    "    x = [torch.tensor(encode(t[1],voc=vocab)) for t in b] # pass the instance of vocab to encode function!\n",
    "    # now, compute the offsets by accumulating the tensor of sequence lengths\n",
    "    o = [0] + [len(t) for t in x]\n",
    "    o = torch.tensor(o[:-1]).cumsum(dim=0)\n",
    "    return ( \n",
    "        torch.LongTensor([t[0]-1 for t in b]), # labels\n",
    "        torch.cat(x), # text \n",
    "        o\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "အပေါ်တွင်မြင်တွေ့ခဲ့သည့်အတိုင်း၊ vector embedding အားလုံးကို `vocab.vectors` matrix တွင်သိမ်းဆည်းထားသည်။ ၎င်းကို embedding layer ၏ weight များထဲသို့ရိုးရှင်းသောကူးယူမှုကိုအသုံးပြု၍ weight များထည့်သွင်းရန်အလွန်လွယ်ကူစေသည်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EmbedClassifier(len(vocab),len(vocab.vectors[0]),len(classes))\n",
    "net.embedding.weight.data = vocab.vectors\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.6271875\n",
      "6400: acc=0.68078125\n",
      "9600: acc=0.7030208333333333\n",
      "12800: acc=0.71984375\n",
      "16000: acc=0.7346875\n",
      "19200: acc=0.7455729166666667\n",
      "22400: acc=0.7529464285714286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35.53972978646833, 0.7575175943698017)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=offsetify, shuffle=True)\n",
    "train_epoch_emb(net,train_loader, lr=4, epoch_size=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ကျွန်ုပ်တို့ အချက်အလက်များတွင် ပါဝင်သော စကားလုံးများအနက် အချို့သည် ကြိုတင်လေ့ကျင့်ထားသော GloVe ဝေါဟာရတွင် မပါဝင်သောကြောင့် တိကျမှုမှာ အရေးပါသော တိုးတက်မှု မရှိခြင်း၏ အကြောင်းအရင်းများထဲမှ တစ်ခုဖြစ်သည်။ ထို့ကြောင့် အဆိုပါ စကားလုံးများကို အဓိကအားဖြင့် မထည့်သွင်းထားပါ။ ဤအချက်ကို ကျော်လွှားရန် ကျွန်ုပ်တို့၏ အချက်အလက်များပေါ်တွင် ကိုယ်ပိုင် embedding များကို လေ့ကျင့်နိုင်ပါသည်။\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## အကြောင်းအရာအခြေခံ Embeddings\n",
    "\n",
    "Word2Vec ကဲ့သို့သော ရိုးရာ pretrained embedding ကိုယ်စားပြုမှုများ၏ အဓိက ကန့်သတ်ချက်တစ်ခုမှာ စကားလုံးအဓိပ္ပါယ်ရှင်းလင်းမှု၏ ပြဿနာဖြစ်သည်။ Pretrained embeddings များသည် စကားလုံးများ၏ အချို့သော အဓိပ္ပါယ်များကို အကြောင်းအရာအတွင်းမှ ဖမ်းဆီးနိုင်သော်လည်း၊ စကားလုံးတစ်လုံး၏ အားလုံးဖြစ်နိုင်သော အဓိပ္ပါယ်များကို တစ်ခုတည်းသော embedding အတွင်းတွင် encode လုပ်ထားသည်။ ဒါက Downstream မော်ဒယ်များတွင် ပြဿနာများ ဖြစ်ပေါ်စေတတ်သည်၊ အကြောင်းမူကား 'play' ကဲ့သို့သော စကားလုံးများသည် အသုံးပြုသည့် အကြောင်းအရာပေါ်မူတည်၍ အဓိပ္ပါယ်များကွဲပြားနိုင်သည်။\n",
    "\n",
    "ဥပမာအားဖြင့် 'play' စကားလုံးသည် အောက်ပါ စာကြောင်းနှစ်ခုတွင် အဓိပ္ပါယ်ကွဲပြားမှုများ ရှိသည်။\n",
    "- ကျွန်တော် **play** တစ်ခုကို ရုံတော်မှာ သွားကြည့်ခဲ့တယ်။\n",
    "- John က သူ့သူငယ်ချင်းတွေနဲ့ **play** လုပ်ချင်တယ်။\n",
    "\n",
    "အထက်ပါ pretrained embeddings များသည် 'play' စကားလုံး၏ အဓိပ္ပါယ်နှစ်ခုလုံးကို တစ်ခုတည်းသော embedding အတွင်းတွင် ကိုယ်စားပြုထားသည်။ ဒီကန့်သတ်ချက်ကို ကျော်လွှားရန် **ဘာသာစကားမော်ဒယ်** အပေါ် အခြေခံထားသော embeddings များကို တည်ဆောက်ရန် လိုအပ်သည်။ ဘာသာစကားမော်ဒယ်သည် စာသားများ၏ အကြီးမားသော corpus အပေါ်တွင် လေ့ကျင့်ထားပြီး စကားလုံးများကို အကြောင်းအရာကွဲပြားမှုများအတွင်းတွင် ဘယ်လိုပေါင်းစည်းနိုင်သည်ကို *သိ* နိုင်သည်။ Contextual embeddings ကို ဆွေးနွေးခြင်းသည် ဒီသင်ခန်းစာ၏ အကျိုးကျေးဇူးအတွင်း မပါဝင်သော်လည်း၊ ဘာသာစကားမော်ဒယ်များကို နောက်ထပ် unit တွင် ပြန်လည်ဆွေးနွေးမည်ဖြစ်သည်။\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**အကြောင်းကြားချက်**:  \nဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှုအတွက် ကြိုးစားနေသော်လည်း၊ အလိုအလျောက် ဘာသာပြန်မှုများတွင် အမှားများ သို့မဟုတ် မမှန်ကန်မှုများ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူရင်းစာရွက်စာတမ်းကို ၎င်း၏ မူရင်းဘာသာစကားဖြင့် အာဏာတရ အရင်းအမြစ်အဖြစ် ရှုလေ့လာသင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူ့ဘာသာပြန်ပညာရှင်များမှ ပရော်ဖက်ရှင်နယ် ဘာသာပြန်မှုကို အကြံပြုပါသည်။ ဤဘာသာပြန်မှုကို အသုံးပြုခြင်းမှ ဖြစ်ပေါ်လာသော အလွဲအလွတ်များ သို့မဟုတ် အနားလွဲမှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cb620c6d4b9f7a635928804c26cf22403d89d98d79684e4529119355ee6d5a5"
  },
  "kernelspec": {
   "display_name": "py37_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "coopTranslator": {
   "original_hash": "f50b026abce5cf36783a560ea72cb9b1",
   "translation_date": "2025-08-30T10:39:43+00:00",
   "source_file": "lessons/5-NLP/14-Embeddings/EmbeddingsPyTorch.ipynb",
   "language_code": "my"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}