{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# పునరావృత న్యూరల్ నెట్‌వర్క్స్\n",
    "\n",
    "మునుపటి మాడ్యూల్‌లో, మేము టెక్స్ట్ యొక్క సమృద్ధి సారాంశ ప్రతినిధులను కవర్ చేసాము. మనం ఉపయోగిస్తున్న ఆర్కిటెక్చర్ వాక్యంలో ఉన్న పదాల సమగ్ర అర్థాన్ని పట్టుకుంటుంది, కానీ పదాల **క్రమం**ని పరిగణలోకి తీసుకోదు, ఎందుకంటే ఎంబెడ్డింగ్స్ తరువాత జరిగే సమీకరణ ఆ సమాచారాన్ని మూల టెక్స్ట్ నుండి తీసివేస్తుంది. ఈ మోడల్స్ పదాల క్రమాన్ని ప్రతినిధ్యం చేయలేకపోవడం వలన, అవి టెక్స్ట్ జనరేషన్ లేదా ప్రశ్నోత్తరాల వంటి క్లిష్టమైన లేదా అనిశ్చిత పనులను పరిష్కరించలేవు.\n",
    "\n",
    "ఒక టెక్స్ట్ సీక్వెన్స్ అర్థాన్ని పట్టుకోవడానికి, మనం **పునరావృత న్యూరల్ నెట్‌వర్క్** లేదా RNN అనే న్యూరల్ నెట్‌వర్క్ ఆర్కిటెక్చర్‌ను ఉపయోగిస్తాము. RNN ఉపయోగించినప్పుడు, మన వాక్యాన్ని ఒక్కో టోకెన్‌గా నెట్‌వర్క్ ద్వారా పంపిస్తాము, మరియు నెట్‌వర్క్ కొన్ని **స్థితి**ని ఉత్పత్తి చేస్తుంది, ఆ స్థితిని తరువాత వచ్చే టోకెన్‌తో మళ్లీ నెట్‌వర్క్‌కు ఇస్తాము.\n",
    "\n",
    "![పునరావృత న్యూరల్ నెట్‌వర్క్ జనరేషన్ ఉదాహరణ చూపిస్తున్న చిత్రం.](../../../../../translated_images/te/rnn.27f5c29c53d727b5.webp)\n",
    "\n",
    "ఇన్‌పుట్ సీక్వెన్స్ టోకెన్లు $X_0,\\dots,X_n$ ఇచ్చినప్పుడు, RNN న్యూరల్ నెట్‌వర్క్ బ్లాక్స్ సీక్వెన్స్‌ను సృష్టిస్తుంది, మరియు ఈ సీక్వెన్స్‌ను బ్యాక్‌ప్రొపగేషన్ ద్వారా ఎండ్-టు-ఎండ్ శిక్షణ ఇస్తుంది. ప్రతి నెట్‌వర్క్ బ్లాక్ జంట $(X_i,S_i)$ని ఇన్‌పుట్‌గా తీసుకుని, $S_{i+1}$ని ఫలితంగా ఉత్పత్తి చేస్తుంది. చివరి స్థితి $S_n$ లేదా అవుట్‌పుట్ $Y_n$ లీనియర్ క్లాసిఫైయర్‌లోకి వెళ్లి ఫలితాన్ని ఉత్పత్తి చేస్తుంది. అన్ని నెట్‌వర్క్ బ్లాక్స్ ఒకే బరువులను పంచుకుంటాయి, మరియు ఒకే బ్యాక్‌ప్రొపగేషన్ పాస్‌తో ఎండ్-టు-ఎండ్ శిక్షణ పొందుతాయి.\n",
    "\n",
    "> పై చిత్రంలో పునరావృత న్యూరల్ నెట్‌వర్క్‌ను విస్తరించిన రూపంలో (ఎడమవైపు) మరియు మరింత సంక్షిప్త పునరావృత ప్రాతినిధ్యంలో (కుడివైపు) చూపించారు. అన్ని RNN సెల్స్ ఒకే **పంచుకునే బరువులు** కలిగి ఉంటాయని గ్రహించడం ముఖ్యం.\n",
    "\n",
    "స్థితి వెక్టార్లు $S_0,\\dots,S_n$ నెట్‌వర్క్ ద్వారా పంపబడినందున, RNN పదాల మధ్య క్రమబద్ధమైన ఆధారితత్వాలను నేర్చుకోగలదు. ఉదాహరణకు, వాక్యంలో *not* అనే పదం ఎక్కడైనా వస్తే, అది స్థితి వెక్టర్‌లోని కొన్ని అంశాలను నిరాకరించడాన్ని నేర్చుకోవచ్చు.\n",
    "\n",
    "ప్రతి RNN సెల్‌లో రెండు బరువు మ్యాట్రిక్సులు ఉంటాయి: $W_H$ మరియు $W_I$, మరియు బైయాస్ $b$. ప్రతి RNN దశలో, ఇన్‌పుట్ $X_i$ మరియు ఇన్‌పుట్ స్థితి $S_i$ ఇచ్చినప్పుడు, అవుట్‌పుట్ స్థితి $S_{i+1} = f(W_H\\times S_i + W_I\\times X_i+b)$గా లెక్కించబడుతుంది, ఇక్కడ $f$ ఒక యాక్టివేషన్ ఫంక్షన్ (సాధారణంగా $\\tanh$).\n",
    "\n",
    "> టెక్స్ట్ జనరేషన్ (మనం తదుపరి యూనిట్‌లో కవర్ చేయబోతున్నది) లేదా మెషీన్ అనువాదం వంటి సమస్యల కోసం, ప్రతి RNN దశలో కొంత అవుట్‌పుట్ విలువ కూడా కావాలి. ఈ సందర్భంలో, మరో మ్యాట్రిక్స్ $W_O$ ఉంటుంది, మరియు అవుట్‌పుట్ $Y_i=f(W_O\\times S_i+b_O)$గా లెక్కించబడుతుంది.\n",
    "\n",
    "పునరావృత న్యూరల్ నెట్‌వర్క్స్ మన న్యూస్ డేటాసెట్‌ను వర్గీకరించడంలో ఎలా సహాయపడతాయో చూద్దాం.\n",
    "\n",
    "> సాండ్‌బాక్స్ వాతావరణం కోసం, అవసరమైన లైబ్రరీ ఇన్‌స్టాల్ అయి, డేటా ముందుగా లోడ్ అయ్యిందని నిర్ధారించుకోవడానికి క్రింది సెల్‌ను నడపాలి. మీరు లోకల్‌గా నడుపుతున్నట్లయితే, ఈ సెల్‌ను దాటవేయవచ్చు.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --quiet tensorflow_datasets==4.4.0\n",
    "!cd ~ && wget -q -O - https://mslearntensorflowlp.blob.core.windows.net/data/tfds-ag-news.tgz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "# We are going to be training pretty large models. In order not to face errors, we need\n",
    "# to set tensorflow option to grow GPU memory allocation when required\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "if len(physical_devices)>0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "ds_train, ds_test = tfds.load('ag_news_subset').values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "పెద్ద మోడల్స్‌ను ట్రెయిన్ చేస్తున్నప్పుడు, GPU మెమరీ కేటాయింపు సమస్యగా మారవచ్చు. మేము వివిధ మినీబ్యాచ్ సైజులతో ప్రయోగాలు చేయవలసి ఉండవచ్చు, తద్వారా డేటా మా GPU మెమరీలో సరిపోతుంది, కానీ ట్రెయినింగ్ వేగంగా జరుగుతుంది. మీరు మీ స్వంత GPU యంత్రంలో ఈ కోడ్‌ను నడుపుతున్నట్లయితే, ట్రెయినింగ్ వేగాన్ని పెంచేందుకు మినీబ్యాచ్ సైజ్‌ను సర్దుబాటు చేయడం ద్వారా ప్రయోగాలు చేయవచ్చు.\n",
    "\n",
    "> **Note**: కొన్ని NVidia డ్రైవర్ వెర్షన్లు మోడల్ ట్రెయినింగ్ తర్వాత మెమరీని విడుదల చేయకపోవడం తెలిసింది. ఈ నోట్‌బుక్‌లో మేము అనేక ఉదాహరణలను నడుపుతున్నాము, మరియు ఇది కొన్ని సెటప్‌లలో మెమరీ పూర్తిగా ఖాళీ కావడానికి కారణమవుతుంది, ముఖ్యంగా మీరు అదే నోట్‌బుక్‌లో మీ స్వంత ప్రయోగాలు చేస్తున్నట్లయితే. మోడల్ ట్రెయినింగ్ ప్రారంభించినప్పుడు కొన్ని విచిత్రమైన లోపాలు ఎదురైతే, మీరు నోట్‌బుక్ కర్నెల్‌ను రీస్టార్ట్ చేయవచ్చు.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "embed_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## సింపుల్ RNN వర్గీకరణ\n",
    "\n",
    "సింపుల్ RNN సందర్భంలో, ప్రతి రికరెంట్ యూనిట్ ఒక సింపుల్ లీనియర్ నెట్‌వర్క్, ఇది ఒక ఇన్‌పుట్ వెక్టర్ మరియు స్టేట్ వెక్టర్‌ను తీసుకుని, కొత్త స్టేట్ వెక్టర్‌ను ఉత్పత్తి చేస్తుంది. Kerasలో, దీన్ని `SimpleRNN` లేయర్ ద్వారా ప్రాతినిధ్యం వహించవచ్చు.\n",
    "\n",
    "మనం ఒక-హాట్ ఎన్‌కోడ్ చేసిన టోకెన్లను నేరుగా RNN లేయర్‌కు పంపవచ్చు, కానీ వాటి అధిక డైమెన్షనాలిటీ కారణంగా ఇది మంచి ఆలోచన కాదు. అందువల్ల, మేము పద వెక్టర్ల డైమెన్షనాలిటీని తగ్గించడానికి ఒక ఎంబెడ్డింగ్ లేయర్ ఉపయోగిస్తాము, ఆ తర్వాత RNN లేయర్, చివరగా `Dense` వర్గీకరణ లేయర్ ఉంటుంది.\n",
    "\n",
    "> **Note**: డైమెన్షనాలిటీ అంత ఎక్కువగా లేని సందర్భాల్లో, ఉదాహరణకు క్యారెక్టర్-స్థాయి టోకనైజేషన్ ఉపయోగించినప్పుడు, ఒక-హాట్ ఎన్‌కోడ్ చేసిన టోకెన్లను నేరుగా RNN సెల్‌లో పంపడం అర్థం కావచ్చు.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 64)          1280000   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 16)                1296      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 1,281,364\n",
      "Trainable params: 1,281,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "\n",
    "vectorizer = keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    input_shape=(1,))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    vectorizer,\n",
    "    keras.layers.Embedding(vocab_size, embed_size),\n",
    "    keras.layers.SimpleRNN(16),\n",
    "    keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **గమనిక:** సౌలభ్యానికి మేము ఇక్కడ శిక్షణ పొందని embedding లేయర్‌ను ఉపయోగిస్తున్నాము, కానీ మెరుగైన ఫలితాల కోసం మునుపటి యూనిట్‌లో వివరించినట్లుగా Word2Vec ఉపయోగించి pretrained embedding లేయర్‌ను ఉపయోగించవచ్చు. pretrained embeddings తో పని చేయడానికి ఈ కోడ్‌ను అనుకూలపరచడం మీకు మంచి వ్యాయామం అవుతుంది.\n",
    "\n",
    "ఇప్పుడు మనం మన RNN ను శిక్షణ ఇస్తాము. సాధారణంగా RNN లను శిక్షణ ఇవ్వడం చాలా కష్టం, ఎందుకంటే RNN సెల్స్ సీక్వెన్స్ పొడవు మేరకు అనుసంధానించినప్పుడు, బ్యాక్‌ప్రొపగేషన్‌లో పాల్గొనే లేయర్ల సంఖ్య చాలా ఎక్కువగా ఉంటుంది. అందువల్ల మనం తక్కువ లెర్నింగ్ రేట్‌ను ఎంచుకోవాలి, మరియు మంచి ఫలితాలు పొందడానికి పెద్ద డేటాసెట్‌పై నెట్‌వర్క్‌ను శిక్షణ ఇవ్వాలి. ఇది చాలా సమయం తీసుకోవచ్చు, కాబట్టి GPU ఉపయోగించడం మంచిది.\n",
    "\n",
    "వేగవంతం చేయడానికి, మేము RNN మోడల్‌ను కేవలం వార్తా శీర్షికలపై మాత్రమే శిక్షణ ఇస్తాము, వివరణను వదిలేస్తాము. మీరు వివరణతో శిక్షణ ఇస్తూ చూడవచ్చు, మోడల్ శిక్షణ పొందగలదా అని పరీక్షించండి.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vectorizer\n"
     ]
    }
   ],
   "source": [
    "def extract_title(x):\n",
    "    return x['title']\n",
    "\n",
    "def tupelize_title(x):\n",
    "    return (extract_title(x),x['label'])\n",
    "\n",
    "print('Training vectorizer')\n",
    "vectorizer.adapt(ds_train.take(2000).map(extract_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 82s 11ms/step - loss: 0.6629 - acc: 0.7623 - val_loss: 0.5559 - val_acc: 0.7995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3e0030d350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['acc'], optimizer='adam')\n",
    "model.fit(ds_train.map(tupelize_title).batch(batch_size),validation_data=ds_test.map(tupelize_title).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "> **గమనిక** ఇక్కడ ఖచ్చితత్వం తక్కువగా ఉండవచ్చు, ఎందుకంటే మేము కేవలం వార్తా శీర్షికలపై మాత్రమే శిక్షణ ఇస్తున్నాము.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## వేరియబుల్ సీక్వెన్సులను మళ్లీ పరిశీలించడం\n",
    "\n",
    "`TextVectorization` లేయర్ ఆటోమేటిక్‌గా మినీబ్యాచ్‌లో వేరియబుల్ పొడవు ఉన్న సీక్వెన్సులను ప్యాడ్ టోకెన్లతో ప్యాడ్ చేస్తుంది. ఆ టోకెన్లు కూడా ట్రైనింగ్‌లో భాగంగా ఉంటాయి, మరియు అవి మోడల్ కన్వర్జెన్స్‌ను క్లిష్టతరం చేయవచ్చు.\n",
    "\n",
    "ప్యాడింగ్ పరిమాణాన్ని తగ్గించడానికి మనం అనేక విధానాలు అనుసరించవచ్చు. వాటిలో ఒకటి డేటాసెట్‌ను సీక్వెన్స్ పొడవు ఆధారంగా పునఃక్రమబద్ధీకరించి, అన్ని సీక్వెన్సులను పరిమాణం ప్రకారం గ్రూప్ చేయడం. ఇది `tf.data.experimental.bucket_by_sequence_length` ఫంక్షన్ ఉపయోగించి చేయవచ్చు (చూడండి [డాక్యుమెంటేషన్](https://www.tensorflow.org/api_docs/python/tf/data/experimental/bucket_by_sequence_length)).\n",
    "\n",
    "మరొక విధానం **మాస్కింగ్** ఉపయోగించడం. కేరాస్‌లో, కొన్ని లేయర్లు ట్రైనింగ్ సమయంలో ఏ టోకెన్లు పరిగణించాలో చూపించే అదనపు ఇన్‌పుట్‌ను మద్దతు ఇస్తాయి. మాస్కింగ్‌ను మోడల్‌లో చేర్చడానికి, మనం ప్రత్యేకమైన `Masking` లేయర్ ([డాక్స్](https://keras.io/api/layers/core_layers/masking/))ను చేర్చవచ్చు, లేదా మన `Embedding` లేయర్‌లో `mask_zero=True` పారామీటర్‌ను పేర్కొనవచ్చు.\n",
    "\n",
    "> **గమనిక**: ఈ ట్రైనింగ్ మొత్తం డేటాసెట్‌పై ఒక ఎపోచ్ పూర్తి చేయడానికి సుమారు 5 నిమిషాలు పడుతుంది. మీరు సహనం లేకపోతే ఎప్పుడైనా ట్రైనింగ్‌ను నిలిపివేయవచ్చు. మీరు చేయగలిగేది ట్రైనింగ్ కోసం ఉపయోగించే డేటా పరిమాణాన్ని `.take(...)` క్లాజ్‌ను `ds_train` మరియు `ds_test` డేటాసెట్‌ల తర్వాత చేర్చడం ద్వారా పరిమితం చేయడం.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 371s 49ms/step - loss: 0.5401 - acc: 0.8079 - val_loss: 0.3780 - val_acc: 0.8822\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3dec118850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text(x):\n",
    "    return x['title']+' '+x['description']\n",
    "\n",
    "def tupelize(x):\n",
    "    return (extract_text(x),x['label'])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    vectorizer,\n",
    "    keras.layers.Embedding(vocab_size,embed_size,mask_zero=True),\n",
    "    keras.layers.SimpleRNN(16),\n",
    "    keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['acc'], optimizer='adam')\n",
    "model.fit(ds_train.map(tupelize).batch(batch_size),validation_data=ds_test.map(tupelize).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు మేము మాస్కింగ్ ఉపయోగిస్తున్నందున, మేము శీర్షికలు మరియు వివరణల మొత్తం డేటాసెట్‌పై మోడల్‌ను శిక్షణ ఇవ్వవచ్చు.\n",
    "\n",
    "> **Note**: మీరు గమనించారా, మేము వార్తా శీర్షికలపై శిక్షణ పొందిన వెక్టరైజర్‌ను ఉపయోగిస్తున్నాము, ఆర్టికల్ మొత్తం శరీరం మీద కాదు? ఇది కొంత టోకెన్లను నిర్లక్ష్యం చేయవచ్చు, కాబట్టి వెక్టరైజర్‌ను మళ్లీ శిక్షణ ఇవ్వడం మంచిది. అయితే, దీని ప్రభావం చాలా తక్కువగా ఉండవచ్చు, అందువల్ల సరళత కోసం మేము మునుపటి ప్రీ-ట్రెయిన్డ్ వెక్టరైజర్‌ను కొనసాగిస్తాము.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM: దీర్ఘ స్వల్పకాలిక జ్ఞాపకం\n",
    "\n",
    "RNNల ప్రధాన సమస్యలలో ఒకటి **వెనుకబడే గ్రాడియెంట్లు తగ్గిపోవడం**. RNNలు చాలా పొడవుగా ఉండవచ్చు, మరియు బ్యాక్‌ప్రొపగేషన్ సమయంలో గ్రాడియెంట్లను నెట్‌వర్క్ మొదటి లేయర్ వరకు వెనుకకు పంపడం కష్టంగా ఉండవచ్చు. ఇది జరిగితే, నెట్‌వర్క్ దూరంలోని టోకెన్ల మధ్య సంబంధాలను నేర్చుకోలేకపోతుంది. ఈ సమస్యను నివారించడానికి ఒక మార్గం **గేట్ల** ద్వారా **స్పష్టమైన స్థితి నిర్వహణ**ను ప్రవేశపెట్టడం. గేట్లను ప్రవేశపెట్టే రెండు సాధారణ ఆర్కిటెక్చర్లు **లాంగ్ షార్ట్-టర్మ్ మెమరీ** (LSTM) మరియు **గేటెడ్ రీలే యూనిట్** (GRU). ఇక్కడ మనం LSTMలను చర్చిస్తాము.\n",
    "\n",
    "![Image showing an example long short term memory cell](../../../../../lessons/5-NLP/16-RNN/images/long-short-term-memory-cell.svg)\n",
    "\n",
    "LSTM నెట్‌వర్క్ RNNకు సమానంగా ఏర్పాటు చేయబడింది, కానీ రెండు స్థితులు లేయర్ నుండి లేయర్‌కు పంపబడతాయి: అసలు స్థితి $c$, మరియు దాచిన వెక్టర్ $h$. ప్రతి యూనిట్ వద్ద, దాచిన వెక్టర్ $h_{t-1}$ను ఇన్‌పుట్ $x_t$తో కలిపి, అవి కలిసి **గేట్ల** ద్వారా స్థితి $c_t$ మరియు అవుట్‌పుట్ $h_t$పై నియంత్రణ వహిస్తాయి. ప్రతి గేట్ సిగ్మాయిడ్ యాక్టివేషన్ కలిగి ఉంటుంది (ఫలితం $[0,1]$ పరిధిలో ఉంటుంది), ఇది స్థితి వెక్టర్‌తో గుణించబడినప్పుడు బిట్‌వైజ్ మాస్క్‌లాగా భావించవచ్చు. LSTMలకు క్రింది గేట్లు ఉంటాయి (పై చిత్రంలో ఎడమ నుండి కుడికి):\n",
    "* **మర్చిపో గేట్** ఇది వెక్టర్ $c_{t-1}$లోని ఏ భాగాలను మర్చిపోవాలో, ఏ భాగాలను కొనసాగించాలో నిర్ణయిస్తుంది.\n",
    "* **ఇన్‌పుట్ గేట్** ఇది ఇన్‌పుట్ వెక్టర్ మరియు గత దాచిన వెక్టర్ నుండి ఎంత సమాచారం స్థితి వెక్టర్‌లో చేర్చాలో నిర్ణయిస్తుంది.\n",
    "* **అవుట్‌పుట్ గేట్** ఇది కొత్త స్థితి వెక్టర్ తీసుకుని దాని ఏ భాగాలు కొత్త దాచిన వెక్టర్ $h_t$ను ఉత్పత్తి చేయడానికి ఉపయోగించాలో నిర్ణయిస్తుంది.\n",
    "\n",
    "స్థితి $c$ యొక్క భాగాలను ఆన్/ఆఫ్ చేయగల ఫ్లాగులుగా భావించవచ్చు. ఉదాహరణకు, సీక్వెన్స్‌లో *Alice* అనే పేరు వస్తే, అది ఒక మహిళను సూచిస్తుందని ఊహించి, వాక్యంలో మహిళా నామవాచకం ఉన్నట్లు సూచించే ఫ్లాగ్‌ను స్థితిలో పెంచుతాము. తరువాత *and Tom* అనే పదాలు వస్తే, బహువచన నామవాచకం ఉన్నట్లు సూచించే ఫ్లాగ్‌ను పెంచుతాము. ఈ విధంగా స్థితిని నిర్వహించడం ద్వారా వాక్యంలోని వ్యాకరణ లక్షణాలను ట్రాక్ చేయవచ్చు.\n",
    "\n",
    "> **గమనిక**: LSTMల అంతర్గత నిర్మాణాన్ని అర్థం చేసుకోవడానికి ఇది ఒక అద్భుతమైన వనరు: [Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) క్రిస్టోఫర్ ఒలాహ్ రాసినది.\n",
    "\n",
    "LSTM సెల్ అంతర్గత నిర్మాణం క్లిష్టంగా కనిపించినప్పటికీ, Keras ఈ అమలును `LSTM` లేయర్ లో దాచివేస్తుంది, కాబట్టి పై ఉదాహరణలో మనం చేయవలసింది రికరెంట్ లేయర్‌ను మార్చడం మాత్రమే:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 188s 13ms/step - loss: 0.5692 - acc: 0.7916 - val_loss: 0.3441 - val_acc: 0.8870\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3d6af5c350>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    vectorizer,\n",
    "    keras.layers.Embedding(vocab_size, embed_size),\n",
    "    keras.layers.LSTM(8),\n",
    "    keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['acc'], optimizer='adam')\n",
    "model.fit(ds_train.map(tupelize).batch(8),validation_data=ds_test.map(tupelize).batch(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **గమనిక** LSTM లను శిక్షణ ఇవ్వడం కూడా చాలా మందగిస్తుంది, మరియు శిక్షణ ప్రారంభంలో మీరు ఎక్కువగా ఖచ్చితత్వం పెరుగుదల చూడకపోవచ్చు. మంచి ఖచ్చితత్వం సాధించడానికి మీరు కొంత కాలం శిక్షణ కొనసాగించవలసి ఉంటుంది.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ద్విముఖి మరియు బహుళస్థాయి RNNలు\n",
    "\n",
    "ఇప్పటి వరకు మన ఉదాహరణల్లో, రికరెంట్ నెట్‌వర్క్లు సీక్వెన్స్ ప్రారంభం నుండి చివరి వరకు పనిచేస్తాయి. ఇది మనకు సహజంగా అనిపిస్తుంది ఎందుకంటే మనం చదవడం లేదా మాట్లాడే మాట వినడం చేసే దిశలో ఇది జరుగుతుంది. అయితే, ఇన్‌పుట్ సీక్వెన్స్‌ను యాదృచ్ఛికంగా యాక్సెస్ చేయాల్సిన సందర్భాల్లో, రికరెంట్ గణనను రెండు దిశలలోనూ నడపడం బాగుంటుంది. రెండు దిశలలో గణనలను అనుమతించే RNNలను **ద్విముఖి** RNNలు అంటారు, ఇవి రికరెంట్ లేయర్‌ను ప్రత్యేకమైన `Bidirectional` లేయర్‌తో చుట్టడం ద్వారా సృష్టించవచ్చు.\n",
    "\n",
    "> **Note**: `Bidirectional` లేయర్ లోపల లేయర్ యొక్క రెండు కాపీలు తయారుచేస్తుంది, వాటిలో ఒక కాపీకి `go_backwards` ప్రాపర్టీని `True` గా సెట్ చేస్తుంది, తద్వారా అది సీక్వెన్స్‌లో వ్యతిరేక దిశలో నడుస్తుంది.\n",
    "\n",
    "రికరెంట్ నెట్‌వర్క్లు, ఏదైనా ఒక దిశలోనైనా లేదా ద్విముఖి అయినా, సీక్వెన్స్‌లోని నమూనాలను పట్టుకుని వాటిని స్టేట్ వెక్టర్లుగా నిల్వ చేస్తాయి లేదా అవి అవుట్‌పుట్‌గా ఇస్తాయి. కాంవల్యూషనల్ నెట్‌వర్క్ల లాగా, మొదటి లేయర్ ద్వారా తీసుకున్న తక్కువ స్థాయి నమూనాల నుండి నిర్మించిన ఉన్నత స్థాయి నమూనాలను పట్టుకోవడానికి మరొక రికరెంట్ లేయర్‌ను మొదటి లేయర్ తర్వాత నిర్మించవచ్చు. దీని ద్వారా మనకు **బహుళస్థాయి RNN** అనే భావన వస్తుంది, ఇది రెండు లేదా అంతకంటే ఎక్కువ రికరెంట్ నెట్‌వర్క్లతో కూడి ఉంటుంది, ఇక్కడ మునుపటి లేయర్ అవుట్‌పుట్‌ను తదుపరి లేయర్ ఇన్‌పుట్‌గా పంపిస్తారు.\n",
    "\n",
    "![బహుళస్థాయి లాంగ్-షార్ట్-టర్మ్-మెమరీ RNNని చూపించే చిత్రం](../../../../../translated_images/te/multi-layer-lstm.dd975e29bb2a59fe.webp)\n",
    "\n",
    "*ఫెర్నాండో లోపెజ్ రాసిన [ఈ అద్భుతమైన పోస్ట్](https://towardsdatascience.com/from-a-lstm-cell-to-a-multilayer-lstm-network-with-pytorch-2899eb5696f3) నుండి చిత్రం.*\n",
    "\n",
    "కేరాస్ ఈ నెట్‌వర్క్లను సృష్టించడం సులభం చేస్తుంది, ఎందుకంటే మీరు కేవలం మోడల్‌కు మరిన్ని రికరెంట్ లేయర్లను జోడించాలి. చివరి లేయర్ తప్ప అన్ని లేయర్లకు `return_sequences=True` పారామీటర్‌ను ఇవ్వాలి, ఎందుకంటే మాకు లేయర్ అన్ని మధ్యస్థితులను తిరిగి ఇవ్వాలి, కేవలం రికరెంట్ గణన చివరి స్థితి మాత్రమే కాదు.\n",
    "\n",
    "మన క్లాసిఫికేషన్ సమస్య కోసం రెండు-లేయర్ ద్విముఖి LSTMను నిర్మిద్దాం.\n",
    "\n",
    "> **Note** ఈ కోడ్ కూడా పూర్తయ్యేందుకు కొంత సమయం పడుతుంది, కానీ ఇప్పటివరకు మనం చూసిన అత్యధిక ఖచ్చితత్వాన్ని ఇస్తుంది. కాబట్టి ఫలితాన్ని చూడటానికి వేచి ఉండటం మంచిది.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5044/7500 [===================>..........] - ETA: 2:33 - loss: 0.3709 - acc: 0.8706\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5045/7500 [===================>..........] - ETA: 2:33 - loss: 0.3709 - acc: 0.8706"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    vectorizer,\n",
    "    keras.layers.Embedding(vocab_size, 128, mask_zero=True),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64,return_sequences=True)),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(64)),    \n",
    "    keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',metrics=['acc'], optimizer='adam')\n",
    "model.fit(ds_train.map(tupelize).batch(batch_size),\n",
    "          validation_data=ds_test.map(tupelize).batch(batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ఇతర పనుల కోసం RNNలు\n",
    "\n",
    "ఇప్పటి వరకు, మేము RNNలను టెక్స్ట్ సీక్వెన్స్‌లను వర్గీకరించడానికి ఉపయోగించడంపై దృష్టి పెట్టాము. కానీ అవి టెక్స్ట్ ఉత్పత్తి మరియు యంత్ర అనువాదం వంటి మరెన్నో పనులను నిర్వహించగలవు — ఆ పనులను మేము తదుపరి యూనిట్‌లో పరిశీలిస్తాము.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**అస్పష్టత**:  \nఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ఉపయోగించి అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో పొరపాట్లు లేదా తప్పిదాలు ఉండవచ్చు. మూల పత్రం దాని స్వదేశీ భాషలో అధికారిక మూలంగా పరిగణించాలి. ముఖ్యమైన సమాచారానికి, ప్రొఫెషనల్ మానవ అనువాదం సిఫార్సు చేయబడుతుంది. ఈ అనువాదం వాడకం వల్ల కలిగే ఏవైనా అపార్థాలు లేదా తప్పుదారుల బాధ్యత మేము తీసుకోము.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "conda-env-py37_tensorflow-py"
  },
  "kernelspec": {
   "display_name": "py37_tensorflow",
   "language": "python",
   "name": "conda-env-py37_tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "81351e61f619b432ff51010a4f993194",
   "translation_date": "2025-11-26T02:05:22+00:00",
   "source_file": "lessons/5-NLP/16-RNN/RNNTF.ipynb",
   "language_code": "te"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}