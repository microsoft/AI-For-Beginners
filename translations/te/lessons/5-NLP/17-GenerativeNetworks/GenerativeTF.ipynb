{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# జనరేటివ్ నెట్‌వర్క్స్\n",
    "\n",
    "రీకరెంట్ న్యూరల్ నెట్‌వర్క్స్ (RNNs) మరియు వాటి గేటెడ్ సెల్ వేరియంట్లు, ఉదాహరణకు లాంగ్ షార్ట్ టర్మ్ మెమరీ సెల్స్ (LSTMs) మరియు గేటెడ్ రీకరెంట్ యూనిట్స్ (GRUs), భాషా మోడలింగ్ కోసం ఒక యంత్రాంగాన్ని అందించాయి, అంటే అవి పదాల క్రమాన్ని నేర్చుకుని, ఒక సీక్వెన్స్‌లో తదుపరి పదం కోసం అంచనాలు ఇవ్వగలవు. ఇది RNNలను **జనరేటివ్ పనుల** కోసం ఉపయోగించడానికి వీలు కల్పిస్తుంది, ఉదాహరణకు సాధారణ టెక్స్ట్ జనరేషన్, మెషీన్ అనువాదం, మరియు ఇమేజ్ క్యాప్షనింగ్ కూడా.\n",
    "\n",
    "మునుపటి యూనిట్‌లో చర్చించిన RNN నిర్మాణంలో, ప్రతి RNN యూనిట్ తదుపరి హిడెన్ స్టేట్‌ను అవుట్‌పుట్‌గా ఉత్పత్తి చేసింది. అయితే, ప్రతి రీకరెంట్ యూనిట్‌కు మరో అవుట్‌పుట్‌ను కూడా జోడించవచ్చు, ఇది మాకు ఒక **సీక్వెన్స్** (మూల సీక్వెన్స్ పొడవుతో సమానం) అవుట్‌పుట్ ఇవ్వడానికి అనుమతిస్తుంది. అంతేకాకుండా, ప్రతి దశలో ఇన్‌పుట్‌ను స్వీకరించని RNN యూనిట్లను ఉపయోగించవచ్చు, అవి కొంత ప్రారంభ స్థితి వెక్టర్‌ను తీసుకుని, ఆ తర్వాత అవుట్‌పుట్‌ల సీక్వెన్స్‌ను ఉత్పత్తి చేస్తాయి.\n",
    "\n",
    "ఈ నోట్‌బుక్‌లో, మనం సులభమైన జనరేటివ్ మోడల్స్‌పై దృష్టి సారించబోతున్నాము, ఇవి మనకు టెక్స్ట్‌ను ఉత్పత్తి చేయడంలో సహాయపడతాయి. సౌలభ్యం కోసం, మనం **అక్షర స్థాయి నెట్‌వర్క్**ను నిర్మిద్దాం, ఇది అక్షరాలవారీగా టెక్స్ట్‌ను ఉత్పత్తి చేస్తుంది. శిక్షణ సమయంలో, మనం కొంత టెక్స్ట్ కార్పస్ తీసుకుని, దాన్ని అక్షరాల సీక్వెన్స్‌లుగా విభజించాలి.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "ds_train, ds_test = tfds.load('ag_news_subset').values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## అక్షర పదకోశం నిర్మాణం\n",
    "\n",
    "అక్షర స్థాయి జనరేటివ్ నెట్‌వర్క్‌ను నిర్మించడానికి, మేము టెక్స్ట్‌ను పదాల స్థానంలో వ్యక్తిగత అక్షరాలుగా విభజించాలి. మునుపటి `TextVectorization` లేయర్ ఇది చేయలేకపోతుంది, కాబట్టి మాకు రెండు ఎంపికలు ఉన్నాయి:\n",
    "\n",
    "* టెక్స్ట్‌ను మానవీయంగా లోడ్ చేసి 'చేతితో' టోకనైజేషన్ చేయడం, [ఈ అధికారిక Keras ఉదాహరణ](https://keras.io/examples/generative/lstm_character_level_text_generation/)లో చూపినట్లుగా\n",
    "* అక్షర స్థాయి టోకనైజేషన్ కోసం `Tokenizer` క్లాస్ ఉపయోగించడం.\n",
    "\n",
    "మేము రెండవ ఎంపికను ఎంచుకుంటాము. `Tokenizer` ను పదాలుగా కూడా టోకనైజ్ చేయడానికి ఉపయోగించవచ్చు, కాబట్టి అక్షర స్థాయి నుండి పద స్థాయి టోకనైజేషన్‌కు సులభంగా మారవచ్చు.\n",
    "\n",
    "అక్షర స్థాయి టోకనైజేషన్ చేయడానికి, `char_level=True` పారామీటర్‌ను ఇవ్వాలి:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(x):\n",
    "    return x['title']+' '+x['description']\n",
    "\n",
    "def tupelize(x):\n",
    "    return (extract_text(x),x['label'])\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True,lower=False)\n",
    "tokenizer.fit_on_texts([x['title'].numpy().decode('utf-8') for x in ds_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మేము కూడా ఒక ప్రత్యేక టోకెన్‌ను **సీక్వెన్స్ ముగింపు** సూచించడానికి ఉపయోగించాలనుకుంటున్నాము, దీన్ని మేము `<eos>` అని పిలుస్తాము. దీన్ని మనం చేతితో వాక్యకోశంలో చేర్చుదాం:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = len(tokenizer.word_index)+1\n",
    "tokenizer.word_index['<eos>'] = eos_token\n",
    "\n",
    "vocab_size = eos_token + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు, టెక్స్ట్‌ను సంఖ్యల సీక్వెన్స్‌లుగా ఎన్‌కోడ్ చేయడానికి, మనం ఉపయోగించవచ్చు:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[48, 2, 10, 10, 5, 44, 1, 25, 5, 8, 10, 13, 78]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['Hello, world!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## శీర్షికలు సృష్టించడానికి జనరేటివ్ RNN శిక్షణ\n",
    "\n",
    "మేము వార్తా శీర్షికలను సృష్టించడానికి RNN ను శిక్షణ ఇవ్వడానికి విధానం ఈ విధంగా ఉంటుంది. ప్రతి దశలో, ఒక శీర్షిక తీసుకుని దాన్ని RNN లో ఇన్పుట్ గా ఇస్తాము, మరియు ప్రతి ఇన్పుట్ అక్షరానికి తర్వాతి అవుట్పుట్ అక్షరాన్ని నెట్‌వర్క్ సృష్టించాలని అడుగుతాము:\n",
    "\n",
    "!['HELLO' అనే పదం RNN ద్వారా సృష్టించబడుతున్న ఉదాహరణను చూపించే చిత్రం.](../../../../../translated_images/te/rnn-generate.56c54afb52f9781d.webp)\n",
    "\n",
    "మన సీక్వెన్స్ చివరి అక్షరానికి, నెట్‌వర్క్ `<eos>` టోకెన్ సృష్టించాలని అడుగుతాము.\n",
    "\n",
    "ఇక్కడ ఉపయోగిస్తున్న జనరేటివ్ RNN ప్రధాన తేడా ఏమిటంటే, మేము RNN యొక్క ప్రతి దశ నుండి అవుట్పుట్ తీసుకుంటాము, కేవలం చివరి సెల్ నుండి మాత్రమే కాదు. ఇది RNN సెల్ కు `return_sequences` పారామీటర్ ను సెట్ చేయడం ద్వారా సాధ్యమవుతుంది.\n",
    "\n",
    "కాబట్టి, శిక్షణ సమయంలో, నెట్‌వర్క్ కు ఇన్పుట్ ఒక నిర్దిష్ట పొడవు గల ఎన్‌కోడ్ చేసిన అక్షరాల సీక్వెన్స్ ఉంటుంది, అవుట్పుట్ అదే పొడవు గల సీక్వెన్స్ కానీ ఒక ఎలిమెంట్ ముందుకు షిఫ్ట్ చేయబడినది మరియు `<eos>` తో ముగిసినది. మినీబ్యాచ్ అనేది ఇలాంటి అనేక సీక్వెన్స్‌లతో ఉంటుంది, అందువల్ల అన్ని సీక్వెన్స్‌లను సరిపోల్చడానికి **padding** అవసరం.\n",
    "\n",
    "మనం డేటాసెట్ ను మార్చే ఫంక్షన్లు సృష్టిద్దాం. మినీబ్యాచ్ స్థాయిలో సీక్వెన్స్‌లను ప్యాడ్ చేయాలనుకుంటున్నందున, ముందుగా `.batch()` పిలిచి డేటాసెట్ ను బ్యాచ్ చేస్తాము, ఆపై `map` ద్వారా ట్రాన్స్‌ఫర్మేషన్ చేస్తాము. కాబట్టి, ట్రాన్స్‌ఫర్మేషన్ ఫంక్షన్ మొత్తం మినీబ్యాచ్ ను పారామీటర్ గా తీసుకుంటుంది:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_batch(x):\n",
    "    x = [t.numpy().decode('utf-8') for t in x]\n",
    "    z = tokenizer.texts_to_sequences(x)\n",
    "    z = tf.keras.preprocessing.sequence.pad_sequences(z)\n",
    "    return tf.one_hot(z,vocab_size), tf.one_hot(tf.concat([z[:,1:],tf.constant(eos_token,shape=(len(z),1))],axis=1),vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మేము ఇక్కడ చేసే కొన్ని ముఖ్యమైన విషయాలు:\n",
    "* మొదట స్ట్రింగ్ టెన్సర్ నుండి అసలు టెక్స్ట్‌ను తీసుకుంటాము\n",
    "* `text_to_sequences` స్ట్రింగుల జాబితాను ఇంటిజర్ టెన్సర్ల జాబితాగా మార్చుతుంది\n",
    "* `pad_sequences` ఆ టెన్సర్లను వారి గరిష్ట పొడవుకు ప్యాడ్ చేస్తుంది\n",
    "* చివరగా, మేము అన్ని అక్షరాలను వన్-హాట్ ఎన్‌కోడ్ చేస్తాము, అలాగే షిఫ్టింగ్ మరియు `<eos>` జోడింపును కూడా చేస్తాము. వన్-హాట్ ఎన్‌కోడ్ చేసిన అక్షరాలు ఎందుకు అవసరమో త్వరలో చూద్దాం\n",
    "\n",
    "కానీ, ఈ ఫంక్షన్ **Pythonic** గా ఉంటుంది, అంటే దీన్ని ఆటోమేటిక్‌గా Tensorflow కంప్యూటేషనల్ గ్రాఫ్‌గా మార్చలేము. ఈ ఫంక్షన్‌ను నేరుగా `Dataset.map` ఫంక్షన్‌లో ఉపయోగిస్తే ఎర్రర్లు వస్తాయి. అందుకే ఈ Pythonic కాల్‌ను `py_function` రాపర్ ఉపయోగించి చుట్టుకోవాలి:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_batch_fn(x):\n",
    "    x = x['title']\n",
    "    a,b = tf.py_function(title_batch,inp=[x],Tout=(tf.float32,tf.float32))\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **గమనిక**: Pythonic మరియు Tensorflow ట్రాన్స్‌ఫర్మేషన్ ఫంక్షన్ల మధ్య తేడా కొంచెం క్లిష్టంగా అనిపించవచ్చు, మరియు మీరు dataset ను `fit` కు పంపించే ముందు సాధారణ Python ఫంక్షన్లతో ట్రాన్స్‌ఫర్మ్ చేయకపోవడం ఎందుకు అనుకుంటున్నారో ఉండవచ్చు. ఇది ఖచ్చితంగా చేయవచ్చు, కానీ `Dataset.map` ఉపయోగించడం పెద్ద లాభం కలిగిస్తుంది, ఎందుకంటే డేటా ట్రాన్స్‌ఫర్మేషన్ పైప్‌లైన్ Tensorflow కంప్యూటేషనల్ గ్రాఫ్ ఉపయోగించి అమలు చేయబడుతుంది, ఇది GPU కంప్యూటేషన్లను ఉపయోగించి CPU/GPU మధ్య డేటా మార్పిడి అవసరాన్ని తగ్గిస్తుంది.\n",
    "\n",
    "ఇప్పుడు మనం మన జనరేటర్ నెట్‌వర్క్‌ను నిర్మించి శిక్షణ ప్రారంభించవచ్చు. ఇది మునుపటి యూనిట్‌లో చర్చించిన ఏదైనా రికరెంట్ సెల్ (సింపుల్, LSTM లేదా GRU) ఆధారంగా ఉండవచ్చు. మన ఉదాహరణలో మనం LSTM ఉపయోగిస్తాము.\n",
    "\n",
    "నెట్‌వర్క్ అక్షరాలను ఇన్‌పుట్‌గా తీసుకుంటుంది, మరియు వోకాబ్యులరీ పరిమాణం చాలా చిన్నది కాబట్టి, embedding లేయర్ అవసరం లేదు, one-hot-encoded ఇన్‌పుట్ నేరుగా LSTM సెల్‌లోకి పోవచ్చు. అవుట్‌పుట్ లేయర్ `Dense` క్లాసిఫైయర్ అవుతుంది, ఇది LSTM అవుట్‌పుట్‌ను one-hot-encoded టోకెన్ నంబర్లుగా మార్చుతుంది.\n",
    "\n",
    "అదనంగా, మనం వేరియబుల్-లెంగ్త్ సీక్వెన్సులతో పని చేస్తున్నందున, `Masking` లేయర్ ఉపయోగించి స్ట్రింగ్‌లో ప్యాడ్ చేసిన భాగాన్ని నిర్లక్ష్యం చేసే మాస్క్ సృష్టించవచ్చు. ఇది తప్పనిసరి కాదు, ఎందుకంటే మనం `<eos>` టోకెన్ తర్వాతి అన్ని విషయాలలో ఎక్కువగా ఆసక్తి చూపడం లేదు, కానీ ఈ లేయర్ రకం గురించి కొంత అనుభవం పొందడానికి దీన్ని ఉపయోగిస్తాము. `input_shape` `(None, vocab_size)` ఉంటుంది, ఇక్కడ `None` వేరియబుల్ లెంగ్త్ సీక్వెన్స్‌ను సూచిస్తుంది, మరియు అవుట్‌పుట్ ఆకారం కూడా `(None, vocab_size)` ఉంటుంది, మీరు `summary` నుండి చూడవచ్చు:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, None, 84)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         109056    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 84)          10836     \n",
      "=================================================================\n",
      "Total params: 119,892\n",
      "Trainable params: 119,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "15000/15000 [==============================] - 229s 15ms/step - loss: 1.5385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa40c1245e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Masking(input_shape=(None,vocab_size)),\n",
    "    keras.layers.LSTM(128,return_sequences=True),\n",
    "    keras.layers.Dense(vocab_size,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(ds_train.batch(8).map(title_batch_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## అవుట్పుట్ ఉత్పత్తి\n",
    "\n",
    "మనం మోడల్‌ను శిక్షణ ఇచ్చిన తర్వాత, దాన్ని ఉపయోగించి కొంత అవుట్పుట్ ఉత్పత్తి చేయాలనుకుంటున్నాము. ముందుగా, టోకెన్ సంఖ్యల శ్రేణి ద్వారా ప్రాతినిధ్యం వహించిన టెక్స్ట్‌ను డీకోడ్ చేయడానికి ఒక మార్గం అవసరం. దీని కోసం, మనం `tokenizer.sequences_to_texts` ఫంక్షన్‌ను ఉపయోగించవచ్చు; అయితే, ఇది క్యారెక్టర్-స్థాయి టోకనైజేషన్‌తో బాగా పనిచేయదు. అందుకే, మనం tokenizer నుండి టోకెన్ల డిక్షనరీ (దాన్ని `word_index` అంటారు) తీసుకుని, ఒక రివర్స్ మ్యాప్ తయారు చేసి, మన స్వంత డీకోడింగ్ ఫంక్షన్ రాస్తాము:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_map = {val:key for key, val in tokenizer.word_index.items()}\n",
    "\n",
    "def decode(x):\n",
    "    return ''.join([reverse_map[t] for t in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు, జనరేషన్ చేద్దాం. మనం కొన్ని స్ట్రింగ్ `start` తో ప్రారంభించి, దాన్ని సీక్వెన్స్ `inp` గా ఎన్‌కోడ్ చేస్తాము, ఆపై ప్రతి దశలో మన నెట్‌వర్క్‌ను పిలిచి తదుపరి అక్షరాన్ని అంచనా వేస్తాము.\n",
    "\n",
    "నెట్‌వర్క్ అవుట్‌పుట్ `out` అనేది `vocab_size` ఎలిమెంట్ల వెక్టర్, ఇది ప్రతి టోకెన్ యొక్క సంభావ్యతలను సూచిస్తుంది, మరియు `argmax` ఉపయోగించి అత్యంత సంభావ్యమైన టోకెన్ నంబర్‌ను కనుగొంటాము. ఆ తర్వాత ఆ అక్షరాన్ని జనరేట్ చేసిన టోకెన్ల జాబితాలో జోడించి, జనరేషన్ కొనసాగిస్తాము. ఒక అక్షరాన్ని జనరేట్ చేసే ఈ ప్రక్రియను అవసరమైన అక్షరాల సంఖ్య `size` సార్లు పునరావృతం చేస్తాము, మరియు `eos_token` కనిపించినప్పుడు ముందుగానే ముగిస్తాము.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today #39;s lead to strike for the strike for the strike for the strike (AFP)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(model,size=100,start='Today '):\n",
    "        inp = tokenizer.texts_to_sequences([start])[0]\n",
    "        chars = inp\n",
    "        for i in range(size):\n",
    "            out = model(tf.expand_dims(tf.one_hot(inp,vocab_size),0))[0][-1]\n",
    "            nc = tf.argmax(out)\n",
    "            if nc==eos_token:\n",
    "                break\n",
    "            chars.append(nc.numpy())\n",
    "            inp = inp+[nc]\n",
    "        return decode(chars)\n",
    "    \n",
    "generate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## శిక్షణ సమయంలో నమూనా అవుట్పుట్\n",
    "\n",
    "మాకు *ఖచ్చితత్వం* వంటి ఉపయోగకరమైన మెట్రిక్స్ లేవు కాబట్టి, మా మోడల్ మెరుగుపడుతున్నదని చూడగల唯一 మార్గం శిక్షణ సమయంలో ఉత్పత్తి చేసిన స్ట్రింగ్‌ను **నమూనా** చేయడం మాత్రమే. దీని కోసం, మేము **కాల్‌బ్యాక్‌లు** ఉపయోగిస్తాము, అంటే `fit` ఫంక్షన్‌కు పంపగల ఫంక్షన్లు, ఇవి శిక్షణ సమయంలో నిరంతరం పిలవబడతాయి.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15000/15000 [==============================] - 226s 15ms/step - loss: 1.2703\n",
      "Today #39;s a lead in the company for the strike\n",
      "Epoch 2/3\n",
      "15000/15000 [==============================] - 227s 15ms/step - loss: 1.2057\n",
      "Today #39;s the Market Service on Security Start (AP)\n",
      "Epoch 3/3\n",
      "15000/15000 [==============================] - 226s 15ms/step - loss: 1.1752\n",
      "Today #39;s a line on the strike to start for the start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa40c74e3d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_callback = keras.callbacks.LambdaCallback(\n",
    "  on_epoch_end = lambda batch, logs: print(generate(model))\n",
    ")\n",
    "\n",
    "model.fit(ds_train.batch(8).map(title_batch_fn),callbacks=[sampling_callback],epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఈ ఉదాహరణ ఇప్పటికే కొంత మంచి టెక్స్ట్‌ను ఉత్పత్తి చేస్తోంది, కానీ దీన్ని మరింత మెరుగుపరచవచ్చు కొన్ని మార్గాల్లో:\n",
    "* **మరింత టెక్స్ట్**. మనం మా పనికి కేవలం శీర్షికలను మాత్రమే ఉపయోగించాము, కానీ మీరు పూర్తి టెక్స్ట్‌తో ప్రయోగాలు చేయాలనుకోవచ్చు. RNNలు పొడవైన సీక్వెన్సులను నిర్వహించడంలో అంతగా బాగుండవు, కాబట్టి వాటిని చిన్న వాక్యాలుగా విభజించడం లేదా ఎప్పుడూ ఒక నిర్దిష్ట సీక్వెన్స్ పొడవైన `num_chars` (ఉదాహరణకు, 256) పై శిక్షణ ఇవ్వడం మంచిది. పై ఉదాహరణను ఇలాంటి నిర్మాణంగా మార్చడానికి మీరు [అధికారిక Keras ట్యుటోరియల్](https://keras.io/examples/generative/lstm_character_level_text_generation/) ను ప్రేరణగా తీసుకోవచ్చు.\n",
    "* **బహుళస్థాయి LSTM**. 2 లేదా 3 LSTM లేయర్లను ప్రయత్నించడం మంచిది. మునుపటి యూనిట్‌లో చెప్పినట్లుగా, ప్రతి LSTM లేయర్ టెక్స్ట్ నుండి నిర్దిష్ట నమూనాలను తీసుకుంటుంది, మరియు క్యారెక్టర్-స్థాయి జనరేటర్ సందర్భంలో తక్కువ LSTM స్థాయి సిలబుల్స్‌ను గుర్తించడానికి బాధ్యత వహిస్తుందని, మరియు ఉన్నత స్థాయిలు పదాలు మరియు పద సంయోజనాల కోసం ఉంటాయని ఆశించవచ్చు. ఇది LSTM కన్‌స్ట్రక్టర్‌కు లేయర్ల సంఖ్య పారామీటర్‌ను అందించడం ద్వారా సులభంగా అమలు చేయవచ్చు.\n",
    "* మీరు **GRU యూనిట్లతో** కూడా ప్రయోగాలు చేయాలనుకోవచ్చు మరియు ఏవి మెరుగ్గా పనిచేస్తాయో చూడవచ్చు, అలాగే **విభిన్న హిడెన్ లేయర్ పరిమాణాలతో** కూడా ప్రయత్నించవచ్చు. చాలా పెద్ద హిడెన్ లేయర్ ఓవర్‌ఫిట్టింగ్‌కు దారితీయవచ్చు (ఉదా: నెట్‌వర్క్ ఖచ్చితమైన టెక్స్ట్ నేర్చుకుంటుంది), మరియు చిన్న పరిమాణం మంచి ఫలితాన్ని ఇవ్వకపోవచ్చు.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## సాఫ్ట్ టెక్స్ట్ జనరేషన్ మరియు టెంపరేచర్\n",
    "\n",
    "మునుపటి `generate` నిర్వచనంలో, మేము ఎప్పుడూ అత్యధిక probability ఉన్న అక్షరాన్ని తదుపరి అక్షరంగా తీసుకుంటున్నాము. దీని వల్ల టెక్స్ట్ తరచుగా అదే అక్షరాల సీక్వెన్స్‌ల మధ్య \"సైకిల్\" అవుతుంది, ఈ ఉదాహరణలో కనిపించేలా:\n",
    "```\n",
    "today of the second the company and a second the company ...\n",
    "```\n",
    "\n",
    "కానీ, తదుపరి అక్షరానికి probability distribution చూస్తే, కొన్ని అత్యధిక probabilities మధ్య తేడా పెద్దది కాకపోవచ్చు, ఉదాహరణకు ఒక అక్షరానికి probability 0.2 ఉండొచ్చు, మరొకదానికి 0.19 ఉండొచ్చు. ఉదాహరణకు '*play*' సీక్వెన్స్‌లో తదుపరి అక్షరం space లేదా **e** (పదం *player* లో ఉన్నట్లు) రెండూ సమానంగా ఉండొచ్చు.\n",
    "\n",
    "దీని ద్వారా మనం తెలుసుకోవాలి, ఎప్పుడూ ఎక్కువ probability ఉన్న అక్షరాన్ని ఎంచుకోవడం \"న్యాయం\" కాదు, ఎందుకంటే రెండవ అత్యధిక probability ఉన్న అక్షరాన్ని ఎంచుకున్నా అర్థవంతమైన టెక్స్ట్ రావచ్చు. కాబట్టి నెట్‌వర్క్ అవుట్‌పుట్ ఇచ్చిన probability distribution నుండి అక్షరాలను **సాంపిల్** చేయడం మంచిది.\n",
    "\n",
    "ఈ సాంప్లింగ్ `np.multinomial` ఫంక్షన్ ఉపయోగించి చేయవచ్చు, ఇది **మల్టినోమియల్ డిస్ట్రిబ్యూషన్**ని అమలు చేస్తుంది. ఈ **సాఫ్ట్** టెక్స్ట్ జనరేషన్‌ను అమలు చేసే ఫంక్షన్ క్రింద నిర్వచించబడింది:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature = 0.3\n",
      "Today #39;s strike #39; to start at the store return\n",
      "On Sunday PO to Be Data Profit Up (Reuters)\n",
      "Moscow, SP wins straight to the Microsoft #39;s control of the space start\n",
      "President olding of the blast start for the strike to pay &lt;b&gt;...&lt;/b&gt;\n",
      "Little red riding hood ficed to the spam countered in European &lt;b&gt;...&lt;/b&gt;\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Today countie strikes ryder missile faces food market blut\n",
      "On Sunday collores lose-toppy of sale of Bullment in &lt;b&gt;...&lt;/b&gt;\n",
      "Moscow, IBM Diffeiting in Afghan Software Hotels (Reuters)\n",
      "President Ol Luster for Profit Peaced Raised (AP)\n",
      "Little red riding hood dace on depart talks #39; bank up\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Today wits House buiting debate fixes #39; supervice stake again\n",
      "On Sunday arling digital poaching In for level\n",
      "Moscow, DS Up 7, Top Proble Protest Caprey Mamarian Strike\n",
      "President teps help of roubler stepted lessabul-Dhalitics (AFP)\n",
      "Little red riding hood signs on cash in Carter-youb\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Today wits flawer ro, pSIA figat's co DroftwavesIs Talo up\n",
      "On Sunday hround elitwing wint EU Powerburlinetien\n",
      "Moscow, Bazz #39;s sentries olymen winnelds' next for Olympite Huc?\n",
      "President lost securitys from power Elections in Smiltrials\n",
      "Little red riding hood vides profit, exponituity, profitmainalist-at said listers\n",
      "\n",
      "--- Temperature = 1.8\n",
      "Today #39;It: He deat: N.KA Asside\n",
      "On Sunday i arry Par aldeup patient Wo stele1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-db32367a0feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Temperature = {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_soft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-db32367a0feb>\u001b[0m in \u001b[0;36mgenerate_soft\u001b[0;34m(model, size, start, temperature)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mchars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Today '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'On Sunday '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Moscow, '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'President '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Little red riding hood '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3f5fa6130b1d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3f5fa6130b1d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def generate_soft(model,size=100,start='Today ',temperature=1.0):\n",
    "        inp = tokenizer.texts_to_sequences([start])[0]\n",
    "        chars = inp\n",
    "        for i in range(size):\n",
    "            out = model(tf.expand_dims(tf.one_hot(inp,vocab_size),0))[0][-1]\n",
    "            probs = tf.exp(tf.math.log(out)/temperature).numpy().astype(np.float64)\n",
    "            probs = probs/np.sum(probs)\n",
    "            nc = np.argmax(np.random.multinomial(1,probs,1))\n",
    "            if nc==eos_token:\n",
    "                break\n",
    "            chars.append(nc)\n",
    "            inp = inp+[nc]\n",
    "        return decode(chars)\n",
    "\n",
    "words = ['Today ','On Sunday ','Moscow, ','President ','Little red riding hood ']\n",
    "    \n",
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"\\n--- Temperature = {i}\")\n",
    "    for j in range(5):\n",
    "        print(generate_soft(model,size=300,start=words[j],temperature=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మేము **తాపన** అనే మరో పారామితిని పరిచయం చేసాము, ఇది మేము అత్యధిక సంభావ్యతకు ఎంత కట్టుబడి ఉండాలో సూచించడానికి ఉపయోగిస్తారు. తాపన 1.0 అయితే, మేము సరైన మల్టినోమియల్ శాంప్లింగ్ చేస్తాము, మరియు తాపన అనంతానికి చేరినప్పుడు - అన్ని సంభావ్యతలు సమానంగా మారతాయి, మరియు మేము యాదృచ్ఛికంగా తదుపరి అక్షరాన్ని ఎంచుకుంటాము. క్రింది ఉదాహరణలో, తాపనను చాలా పెంచినప్పుడు టెక్స్ట్ అర్థరహితంగా మారిపోతుందని, మరియు అది 0కి దగ్గరగా ఉన్నప్పుడు \"సైకిల్డ్\" కఠినంగా ఉత్పత్తి చేసిన టెక్స్ట్ లాగా కనిపిస్తుందని మనం గమనించవచ్చు.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**అస్పష్టత**:  \nఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ఉపయోగించి అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో పొరపాట్లు లేదా తప్పిదాలు ఉండవచ్చు. మూల పత్రం దాని స్వదేశీ భాషలో అధికారిక మూలంగా పరిగణించాలి. ముఖ్యమైన సమాచారానికి, ప్రొఫెషనల్ మానవ అనువాదం సిఫార్సు చేయబడుతుంది. ఈ అనువాదం వాడకంలో ఏర్పడిన ఏవైనా అపార్థాలు లేదా తప్పుదారితీసే అర్థాలు కోసం మేము బాధ్యత వహించము.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16af2a8bbb083ea23e5e41c7f5787656b2ce26968575d8763f2c4b17f9cd711f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "coopTranslator": {
   "original_hash": "9fbb7d5fda708537649f71f5f646fcde",
   "translation_date": "2025-11-26T02:14:49+00:00",
   "source_file": "lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.ipynb",
   "language_code": "te"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}