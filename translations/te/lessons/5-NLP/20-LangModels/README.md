# ముందుగా శిక్షణ పొందిన పెద్ద భాషా మోడల్స్

మా గత పనులన్నింటిలోనూ, లేబుల్ చేయబడిన డేటాసెట్ ఉపయోగించి ఒక నిర్దిష్ట పని చేయడానికి న్యూరల్ నెట్‌వర్క్‌ను శిక్షణ ఇచ్చేవాళ్లం. BERT వంటి పెద్ద ట్రాన్స్‌ఫార్మర్ మోడల్స్‌తో, మేము స్వీయ-పర్యవేక్షణ విధానంలో భాషా మోడలింగ్ ఉపయోగించి భాషా మోడల్‌ను నిర్మిస్తాము, ఆ తర్వాత అదనపు డొమైన్-స్పెసిఫిక్ శిక్షణతో నిర్దిష్ట డౌన్‌స్ట్రీమ్ పనికి ప్రత్యేకత ఇస్తాము. అయితే, పెద్ద భాషా మోడల్స్ ఏ డొమైన్-స్పెసిఫిక్ శిక్షణ లేకుండానే కూడా అనేక పనులను పరిష్కరించగలవని నిరూపించబడింది. అటువంటి సామర్థ్యం కలిగిన మోడల్స్ కుటుంబాన్ని **GPT** అంటారు: జనరేటివ్ ప్రీ-ట్రెయిన్డ్ ట్రాన్స్‌ఫార్మర్.

## [పాఠం ముందు క్విజ్](https://ff-quizzes.netlify.app/en/ai/quiz/39)

## టెక్స్ట్ జనరేషన్ మరియు పర్ప్లెక్సిటీ

డౌన్‌స్ట్రీమ్ శిక్షణ లేకుండా సాధారణ పనులు చేయగల న్యూరల్ నెట్‌వర్క్ ఆలోచనను [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) పత్రంలో వివరించారు. ప్రధాన ఆలోచన ఏమిటంటే, అనేక ఇతర పనులను **టెక్స్ట్ జనరేషన్** ద్వారా మోడల్ చేయవచ్చు, ఎందుకంటే టెక్స్ట్‌ను అర్థం చేసుకోవడం అంటే దాన్ని ఉత్పత్తి చేయగలగడం. మోడల్ మానవ జ్ఞానాన్ని కవర్ చేసే భారీ టెక్స్ట్ డేటాపై శిక్షణ పొందినందున, ఇది విస్తృత విషయాలపై జ్ఞానం కలిగి ఉంటుంది.

> టెక్స్ట్‌ను అర్థం చేసుకోవడం మరియు ఉత్పత్తి చేయగలగడం అంటే మన చుట్టూ ఉన్న ప్రపంచం గురించి కూడా కొంత తెలుసుకోవడం. మనుషులు కూడా ఎక్కువగా చదవడం ద్వారా నేర్చుకుంటారు, GPT నెట్‌వర్క్ కూడా ఇదే విధంగా ఉంటుంది.

టెక్స్ట్ జనరేషన్ నెట్‌వర్క్స్ తదుపరి పదం $$P(w_N)$$ యొక్క సంభావ్యతను అంచనా వేస్తాయి. అయితే, తదుపరి పదం యొక్క అనియంత్రిత సంభావ్యత అంటే ఆ పదం టెక్స్ట్ కార్పస్‌లో కనిపించే సాంద్రత. GPT మాకు **పూర్వ పదాల ఆధారంగా** తదుపరి పదం యొక్క **నిబంధిత సంభావ్యత** ఇస్తుంది: $$P(w_N | w_{n-1}, ..., w_0)$$

> మీరు సంభావ్యతల గురించి మరింత తెలుసుకోవడానికి మా [డేటా సైన్స్ ఫర్ బిగినర్స్ పాఠ్యాంశం](https://github.com/microsoft/Data-Science-For-Beginners/tree/main/1-Introduction/04-stats-and-probability) చూడవచ్చు

భాషా ఉత్పత్తి మోడల్ నాణ్యతను **పర్ప్లెక్సిటీ** ద్వారా నిర్వచించవచ్చు. ఇది ఒక అంతర్గత ప్రమాణం, ఇది ఏదైనా పని-స్పెసిఫిక్ డేటాసెట్ లేకుండానే మోడల్ నాణ్యతను కొలవడానికి ఉపయోగపడుతుంది. ఇది *వాక్యం సంభావ్యత* అనే భావనపై ఆధారపడి ఉంటుంది - మోడల్ నిజమైనదిగా ఉండే వాక్యానికి ఎక్కువ సంభావ్యత ఇస్తుంది (అంటే మోడల్ దానితో **గందరగోళం చెందదు**), మరియు అర్థం తక్కువ ఉన్న వాక్యాలకు తక్కువ సంభావ్యత ఇస్తుంది (ఉదా: *Can it does what?*). మేము మోడల్‌కు నిజమైన టెక్స్ట్ కార్పస్ నుండి వాక్యాలు ఇస్తే, అవి ఎక్కువ సంభావ్యత కలిగి ఉండాలని, తక్కువ **పర్ప్లెక్సిటీ** కలిగి ఉండాలని ఆశిస్తాము. గణితంగా, ఇది పరీక్షా సెట్ యొక్క సాధారణీకరించిన వ్యతిరేక సంభావ్యతగా నిర్వచించబడుతుంది:
$$
\mathrm{Perplexity}(W) = \sqrt[N]{1\over P(W_1,...,W_N)}
$$ 

**మీరు [Hugging Face నుండి GPT ఆధారిత టెక్స్ట్ ఎడిటర్](https://transformer.huggingface.co/doc/gpt2-large) ఉపయోగించి టెక్స్ట్ జనరేషన్‌ను ప్రయోగించవచ్చు**. ఈ ఎడిటర్‌లో మీరు మీ టెక్స్ట్ రాయడం ప్రారంభిస్తారు, మరియు **[TAB]** నొక్కితే మీరు అనేక పూర్తి ఎంపికలను పొందుతారు. అవి చాలా చిన్నవిగా ఉంటే లేదా మీరు సంతృప్తి చెందకపోతే - మళ్లీ [TAB] నొక్కండి, మరిన్ని ఎంపికలు, దీర్ఘమైన టెక్స్ట్ భాగాలు కూడా అందుబాటులో ఉంటాయి.

## GPT ఒక కుటుంబం

GPT ఒకే ఒక మోడల్ కాదు, కానీ [OpenAI](https://openai.com) అభివృద్ధి చేసి శిక్షణ ఇచ్చిన మోడల్స్ సేకరణ.

GPT మోడల్స్ కింద:

| [GPT-2](https://huggingface.co/docs/transformers/model_doc/gpt2#openai-gpt2) | [GPT 3](https://openai.com/research/language-models-are-few-shot-learners) | [GPT-4](https://openai.com/gpt-4) |
| -- | -- | -- |
| 1.5 బిలియన్ పరిమాణాల భాషా మోడల్ | 175 బిలియన్ పరిమాణాల భాషా మోడల్ | 100 ట్రిలియన్ పరిమాణాలు, ఇమేజ్ మరియు టెక్స్ట్ ఇన్‌పుట్‌లను స్వీకరించి టెక్స్ట్ అవుట్‌పుట్ ఇస్తుంది |

GPT-3 మరియు GPT-4 మోడల్స్ [Microsoft Azure నుండి కాగ్నిటివ్ సర్వీస్‌గా](https://azure.microsoft.com/en-us/services/cognitive-services/openai-service/#overview?WT.mc_id=academic-77998-cacaste) మరియు [OpenAI API](https://openai.com/api/) ద్వారా అందుబాటులో ఉన్నాయి.

## ప్రాంప్ట్ ఇంజనీరింగ్

GPT భాష మరియు కోడ్‌ను అర్థం చేసుకోవడానికి విస్తృత డేటా వాల్యూమ్‌పై శిక్షణ పొందినందున, అవి ఇన్‌పుట్‌లకు (ప్రాంప్ట్‌లు) స్పందనగా అవుట్‌పుట్‌లను ఇస్తాయి. ప్రాంప్ట్‌లు అనగా GPT ఇన్‌పుట్‌లు లేదా ప్రశ్నలు, వీటిలో మోడల్స్‌కు తదుపరి పూర్తి చేయాల్సిన పనుల సూచనలు ఇస్తారు. కావలసిన ఫలితాన్ని పొందడానికి, సరైన పదాలు, ఫార్మాట్లు, పదబంధాలు లేదా చిహ్నాలను ఎంచుకోవడం అవసరం. ఈ విధానాన్ని [ప్రాంప్ట్ ఇంజనీరింగ్](https://learn.microsoft.com/en-us/shows/ai-show/the-basics-of-prompt-engineering-with-azure-openai-service?WT.mc_id=academic-77998-bethanycheum) అంటారు.

[ఈ డాక్యుమెంటేషన్](https://learn.microsoft.com/en-us/semantic-kernel/prompt-engineering/?WT.mc_id=academic-77998-bethanycheum) ప్రాంప్ట్ ఇంజనీరింగ్ గురించి మరిన్ని వివరాలు అందిస్తుంది.

## ✍️ ఉదాహరణ నోట్‌బుక్: [OpenAI-GPT తో ఆడుకోవడం](GPT-PyTorch.ipynb)

తదుపరి నోట్‌బుక్స్‌లో మీ అభ్యాసాన్ని కొనసాగించండి:

* [OpenAI-GPT మరియు Hugging Face Transformers తో టెక్స్ట్ జనరేట్ చేయడం](GPT-PyTorch.ipynb)

## ముగింపు

కొత్త సాధారణ ప్రీ-ట్రెయిన్డ్ భాషా మోడల్స్ కేవలం భాషా నిర్మాణాన్ని మాత్రమే కాకుండా, విస్తృత సహజ భాషా సమాచారాన్ని కూడా కలిగి ఉంటాయి. అందువల్ల, అవి జీరో-షాట్ లేదా ఫ్యూ-షాట్ సెట్టింగ్స్‌లో కొన్ని NLP పనులను సమర్థవంతంగా పరిష్కరించగలవు.

## [పాఠం తర్వాత క్విజ్](https://ff-quizzes.netlify.app/en/ai/quiz/40)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**అస్పష్టత**:  
ఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ఉపయోగించి అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో పొరపాట్లు లేదా తప్పిదాలు ఉండవచ్చు. మూల పత్రం దాని స్వదేశీ భాషలోనే అధికారిక మూలంగా పరిగణించాలి. ముఖ్యమైన సమాచారానికి, ప్రొఫెషనల్ మానవ అనువాదం సిఫార్సు చేయబడుతుంది. ఈ అనువాదం వాడకం వల్ల కలిగే ఏవైనా అపార్థాలు లేదా తప్పుదారితీసే అర్థాలు కోసం మేము బాధ్యత వహించము.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->