# الذكاء الاصطناعي الأخلاقي والمسؤول

لقد أوشكت على إنهاء هذه الدورة، وآمل أنه بحلول هذه المرحلة أصبحت ترى بوضوح أن الذكاء الاصطناعي يعتمد على عدد من الأساليب الرياضية الرسمية التي تسمح لنا باكتشاف العلاقات في البيانات وتدريب النماذج لتكرار بعض جوانب السلوك البشري. في هذه المرحلة من التاريخ، نعتبر الذكاء الاصطناعي أداة قوية جدًا لاستخراج الأنماط من البيانات وتطبيق تلك الأنماط لحل مشاكل جديدة.

## [اختبار ما قبل المحاضرة](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

ومع ذلك، في قصص الخيال العلمي غالبًا ما نرى قصصًا حيث يمثل الذكاء الاصطناعي خطرًا على البشرية. عادةً ما تكون هذه القصص متمحورة حول نوع من تمرد الذكاء الاصطناعي، عندما يقرر الذكاء الاصطناعي مواجهة البشر. هذا يشير إلى أن الذكاء الاصطناعي لديه نوع من المشاعر أو يمكنه اتخاذ قرارات غير متوقعة من قبل مطوريه.

النوع من الذكاء الاصطناعي الذي تعلمنا عنه في هذه الدورة ليس أكثر من عمليات حسابية على مصفوفات كبيرة. إنها أداة قوية جدًا تساعدنا في حل مشاكلنا، وكأي أداة قوية أخرى - يمكن استخدامها لأغراض جيدة أو سيئة. والأهم من ذلك، يمكن أن يتم *إساءة استخدامها*.

## مبادئ الذكاء الاصطناعي المسؤول

لتجنب هذا الاستخدام الخاطئ أو المتعمد للذكاء الاصطناعي، تحدد مايكروسوفت [مبادئ الذكاء الاصطناعي المسؤول](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste). تستند هذه المبادئ إلى المفاهيم التالية:

* **الإنصاف** يتعلق بالمشكلة المهمة المتعلقة بـ *تحيز النماذج*، والذي يمكن أن يحدث بسبب استخدام بيانات متحيزة للتدريب. على سبيل المثال، عندما نحاول التنبؤ باحتمالية حصول شخص على وظيفة كمطور برامج، من المحتمل أن يعطي النموذج تفضيلًا أعلى للذكور - فقط لأن مجموعة البيانات التدريبية كانت على الأرجح متحيزة نحو جمهور ذكوري. يجب علينا موازنة بيانات التدريب بعناية والتحقيق في النموذج لتجنب التحيزات، والتأكد من أن النموذج يأخذ في الاعتبار ميزات أكثر صلة.
* **الموثوقية والسلامة**. بطبيعتها، يمكن للنماذج الذكاء الاصطناعي أن ترتكب أخطاء. تعيد الشبكة العصبية احتمالات، ويجب أن نأخذ ذلك في الاعتبار عند اتخاذ القرارات. كل نموذج لديه دقة واسترجاع معين، ويجب أن نفهم ذلك لمنع الأضرار التي قد تسببها النصائح الخاطئة.
* **الخصوصية والأمان** لهما بعض الآثار الخاصة بالذكاء الاصطناعي. على سبيل المثال، عندما نستخدم بعض البيانات لتدريب نموذج، تصبح هذه البيانات بطريقة ما "مدمجة" في النموذج. من جهة، هذا يزيد من الأمان والخصوصية، ومن جهة أخرى - يجب أن نتذكر البيانات التي تم تدريب النموذج عليها.
* **الشمولية** تعني أننا لا نبني الذكاء الاصطناعي ليحل محل البشر، بل لتعزيز البشر وجعل عملنا أكثر إبداعًا. كما أنها مرتبطة بالإنصاف، لأنه عند التعامل مع المجتمعات غير الممثلة بشكل كافٍ، فإن معظم مجموعات البيانات التي نجمعها من المحتمل أن تكون متحيزة، ويجب أن نتأكد من أن تلك المجتمعات مشمولة ويتم التعامل معها بشكل صحيح بواسطة الذكاء الاصطناعي.
* **الشفافية**. يشمل ذلك التأكد من أننا دائمًا واضحون بشأن استخدام الذكاء الاصطناعي. أيضًا، حيثما أمكن، نريد استخدام أنظمة ذكاء اصطناعي تكون *قابلة للتفسير*.
* **المساءلة**. عندما تأتي نماذج الذكاء الاصطناعي ببعض القرارات، ليس من الواضح دائمًا من المسؤول عن تلك القرارات. يجب أن نتأكد من أننا نفهم أين تقع مسؤولية قرارات الذكاء الاصطناعي. في معظم الحالات، نرغب في تضمين البشر في عملية اتخاذ القرارات المهمة، بحيث يتم تحميل الأشخاص الفعليين المسؤولية.

## أدوات الذكاء الاصطناعي المسؤول

طورت مايكروسوفت [Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox) الذي يحتوي على مجموعة من الأدوات:

* لوحة التحكم لتفسير النماذج (InterpretML)
* لوحة التحكم للإنصاف (FairLearn)
* لوحة تحليل الأخطاء
* لوحة التحكم للذكاء الاصطناعي المسؤول التي تشمل:

   - EconML - أداة لتحليل السببية، تركز على أسئلة "ماذا لو"
   - DiCE - أداة لتحليل السيناريوهات البديلة تسمح لك برؤية الميزات التي تحتاج إلى تغييرها للتأثير على قرار النموذج

لمزيد من المعلومات حول أخلاقيات الذكاء الاصطناعي، يرجى زيارة [هذا الدرس](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste) في منهج تعلم الآلة الذي يتضمن مهامًا.

## المراجعة والدراسة الذاتية

خذ هذا [مسار التعلم](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste) لتتعلم المزيد عن الذكاء الاصطناعي المسؤول.

## [اختبار ما بعد المحاضرة](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.