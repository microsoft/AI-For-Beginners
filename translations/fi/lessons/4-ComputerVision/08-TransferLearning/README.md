# Esikoulutetut verkot ja siirt√§minen oppiminen

CNN:ien kouluttaminen voi vied√§ paljon aikaa, ja siihen tarvitaan runsaasti dataa. Suuri osa ajasta kuluu kuitenkin parhaita matalan tason suodattimia oppiessa, joita verkko voi k√§ytt√§√§ kuvioiden tunnistamiseen kuvista. Luonnollinen kysymys her√§√§ - voimmeko k√§ytt√§√§ yhdell√§ datasetill√§ koulutettua neuroverkkoa ja mukauttaa sen luokittelemaan erilaisia kuvia ilman t√§ydellist√§ koulutusprosessia?

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/15)

T√§t√§ l√§hestymistapaa kutsutaan **siirt√§miseksi oppimiseksi**, koska siirr√§mme tietoa yhdest√§ neuroverkkon mallista toiseen. Siirt√§misess√§ oppimisessa aloitamme yleens√§ esikoulutetulla mallilla, joka on koulutettu suurella kuvadatasetill√§, kuten **ImageNet**. N√§m√§ mallit osaavat jo hyvin tunnistaa erilaisia piirteit√§ yleisist√§ kuvista, ja monissa tapauksissa pelkk√§ luokittelijan rakentaminen n√§iden piirteiden p√§√§lle voi tuottaa hyvi√§ tuloksia.

> ‚úÖ Siirt√§minen oppiminen on termi, joka esiintyy my√∂s muilla akateemisilla aloilla, kuten kasvatustieteess√§. Se viittaa prosessiin, jossa tietoa siirret√§√§n yhdelt√§ alueelta toiselle.

## Esikoulutetut mallit piirteiden tunnistajina

Edellisess√§ osiossa k√§sitellyt konvoluutiot sis√§lt√§v√§t useita kerroksia, joista jokainen on tarkoitettu tunnistamaan piirteit√§ kuvasta, alkaen matalan tason pikseliyhdistelmist√§ (kuten vaakasuora/pystysuora viiva tai veto) ja p√§√§tyen korkeampien tasojen piirteisiin, jotka vastaavat esimerkiksi liekin silm√§√§. Jos koulutamme CNN:n riitt√§v√§n suurella datasetill√§, joka sis√§lt√§√§ yleisi√§ ja monipuolisia kuvia, verkon pit√§isi oppia tunnistamaan n√§m√§ yleiset piirteet.

Sek√§ Keras ett√§ PyTorch sis√§lt√§v√§t toimintoja, joilla voi helposti ladata esikoulutettuja neuroverkon painoja joillekin yleisille arkkitehtuureille, joista useimmat on koulutettu ImageNet-kuvilla. Useimmin k√§ytetyt arkkitehtuurit on kuvattu [CNN Architectures](../07-ConvNets/CNN_Architectures.md) -sivulla edellisess√§ oppitunnissa. Erityisesti kannattaa harkita seuraavia:

* **VGG-16/VGG-19**, jotka ovat suhteellisen yksinkertaisia malleja mutta tuottavat silti hyv√§√§ tarkkuutta. VGG:n k√§ytt√∂ ensimm√§isen√§ kokeiluna on hyv√§ valinta, kun halutaan n√§hd√§, miten siirt√§minen oppiminen toimii.
* **ResNet**, Microsoft Researchin vuonna 2015 ehdottama malliperhe. N√§iss√§ on enemm√§n kerroksia, ja ne vaativat enemm√§n resursseja.
* **MobileNet**, pienennettyjen mallien perhe, joka sopii mobiililaitteille. K√§yt√§ niit√§, jos sinulla on rajalliset resurssit ja voit tinki√§ hieman tarkkuudesta.

T√§ss√§ on esimerkki piirteist√§, jotka VGG-16-verkko on tunnistanut kissan kuvasta:

![Piirteet, jotka VGG-16 tunnisti](../../../../../translated_images/fi/features.6291f9c7ba3a0b95.webp)

## Kissojen ja koirien datasetti

T√§ss√§ esimerkiss√§ k√§yt√§mme [Kissojen ja koirien](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) datasetti√§, joka on hyvin l√§hell√§ todellista kuvanluokitteluskenaariota.

## ‚úçÔ∏è Harjoitus: Siirt√§minen oppiminen

Katsotaan siirt√§mist√§ oppimista k√§yt√§nn√∂ss√§ vastaavissa muistikirjoissa:

* [Siirt√§minen oppiminen - PyTorch](TransferLearningPyTorch.ipynb)
* [Siirt√§minen oppiminen - TensorFlow](TransferLearningTF.ipynb)

## Adversaarisen kissan visualisointi

Esikoulutettu neuroverkko sis√§lt√§√§ erilaisia kuvioita "aivoissaan", mukaan lukien k√§sityksi√§ **ihanteellisesta kissasta** (sek√§ ihanteellisesta koirasta, ihanteellisesta seeprasta jne.). Olisi mielenkiintoista jotenkin **visualisoida t√§m√§ kuva**. T√§m√§ ei kuitenkaan ole yksinkertaista, koska kuviot ovat hajautettu verkon painoihin ja j√§rjestetty hierarkkiseen rakenteeseen.

Yksi l√§hestymistapa on aloittaa satunnaisesta kuvasta ja yritt√§√§ k√§ytt√§√§ **gradient descent -optimointitekniikkaa** s√§√§t√§m√§√§n kuvaa niin, ett√§ verkko alkaa ajatella sen olevan kissa.

![Kuvan optimointisilmukka](../../../../../translated_images/fi/ideal-cat-loop.999fbb8ff306e044.webp)

Jos teemme n√§in, saamme jotain hyvin satunnaisen kohinan kaltaista. T√§m√§ johtuu siit√§, ett√§ *on monia tapoja saada verkko ajattelemaan, ett√§ sy√∂tekuva on kissa*, mukaan lukien sellaisia, jotka eiv√§t ole visuaalisesti j√§rkevi√§. Vaikka n√§m√§ kuvat sis√§lt√§v√§t paljon kissalle tyypillisi√§ kuvioita, mik√§√§n ei rajoita niit√§ olemaan visuaalisesti erottuvia.

Tuloksen parantamiseksi voimme lis√§t√§ toisen termin h√§vi√∂funktioon, jota kutsutaan **variation loss** -termiksi. Se on mittari, joka osoittaa, kuinka samanlaisia kuvan vierekk√§iset pikselit ovat. Variation lossin minimointi tekee kuvasta tasaisemman ja poistaa kohinaa - paljastaen visuaalisesti miellytt√§v√§mpi√§ kuvioita. T√§ss√§ esimerkki t√§llaisista "ihanteellisista" kuvista, jotka luokitellaan kissaksi ja seepraksi suurella todenn√§k√∂isyydell√§:

![Ihanteellinen kissa](../../../../../translated_images/fi/ideal-cat.203dd4597643d6b0.webp) | ![Ihanteellinen seepra](../../../../../translated_images/fi/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Ihanteellinen kissa* | *Ihanteellinen seepra*

Samaa l√§hestymistapaa voidaan k√§ytt√§√§ suorittamaan niin sanottuja **adversaarisia hy√∂kk√§yksi√§** neuroverkkoon. Oletetaan, ett√§ haluamme huijata neuroverkkoa ja saada koiran n√§ytt√§m√§√§n kissalta. Jos otamme koiran kuvan, jonka verkko tunnistaa koiraksi, voimme sitten s√§√§t√§√§ sit√§ hieman gradient descent -optimoinnin avulla, kunnes verkko alkaa luokitella sen kissaksi:

![Koiran kuva](../../../../../translated_images/fi/original-dog.8f68a67d2fe0911f.webp) | ![Kuva koirasta, joka luokitellaan kissaksi](../../../../../translated_images/fi/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Alkuper√§inen kuva koirasta* | *Kuva koirasta, joka luokitellaan kissaksi*

Katso koodi yll√§ olevien tulosten toistamiseen seuraavasta muistikirjasta:

* [Ihanteellinen ja adversaarinen kissa - TensorFlow](AdversarialCat_TF.ipynb)

## Yhteenveto

Siirt√§misen oppimisen avulla voit nopeasti rakentaa luokittelijan mukautettuun objektinluokitteluteht√§v√§√§n ja saavuttaa korkean tarkkuuden. N√§et, ett√§ monimutkaisemmat teht√§v√§t, joita nyt ratkaisemme, vaativat suurempaa laskentatehoa, eik√§ niit√§ voida helposti ratkaista CPU:lla. Seuraavassa osiossa yrit√§mme k√§ytt√§√§ kevyemp√§√§ toteutusta saman mallin kouluttamiseen pienemmill√§ laskentaresursseilla, mik√§ johtaa vain hieman alhaisempaan tarkkuuteen.

## üöÄ Haaste

Mukana olevissa muistikirjoissa on alaviitteit√§ siit√§, miten siirt√§misen oppiminen toimii parhaiten jossain m√§√§rin samanlaisen koulutusdatan kanssa (esimerkiksi uusi el√§inlaji). Tee kokeiluja t√§ysin uusilla kuvatyypeill√§ n√§hd√§ksesi, kuinka hyvin tai huonosti siirt√§misen oppimisen mallit toimivat.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Kertaus ja itseopiskelu

Lue [TrainingTricks.md](TrainingTricks.md) syvent√§√§ksesi tiet√§myst√§si muista tavoista kouluttaa mallejasi.

## [Teht√§v√§](lab/README.md)

T√§ss√§ laboratoriossa k√§yt√§mme todellista [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) lemmikkiel√§indatasetti√§, joka sis√§lt√§√§ 35 kissan- ja koirarotua, ja rakennamme siirt√§misen oppimisen luokittelijan.

---

