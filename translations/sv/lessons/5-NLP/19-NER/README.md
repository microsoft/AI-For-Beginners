# Namngiven Entityigenk√§nning

Hittills har vi mest fokuserat p√• en NLP-uppgift - klassificering. Men det finns ocks√• andra NLP-uppgifter som kan l√∂sas med neurala n√§tverk. En av dessa uppgifter √§r **[Namngiven Entityigenk√§nning](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), som handlar om att identifiera specifika entiteter i text, s√•som platser, personnamn, tidsintervall, kemiska formler och s√• vidare.

## [Quiz f√∂re f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Exempel p√• anv√§ndning av NER

Anta att du vill utveckla en naturlig spr√•kchatbot, liknande Amazon Alexa eller Google Assistant. Intelligenta chatbots fungerar genom att *f√∂rst√•* vad anv√§ndaren vill genom att utf√∂ra textklassificering p√• den inmatade meningen. Resultatet av denna klassificering √§r den s√• kallade **intentionen**, som avg√∂r vad chatboten ska g√∂ra.

<img alt="Bot NER" src="../../../../../translated_images/sv/bot-ner.4b09235dbb0ad275.webp" width="50%"/>

> Bild av f√∂rfattaren

Men en anv√§ndare kan ge vissa parametrar som en del av frasen. Till exempel, n√§r hon fr√•gar om v√§dret, kan hon ange en plats eller ett datum. En bot b√∂r kunna f√∂rst√• dessa entiteter och fylla i parameterf√§lten d√§refter innan den utf√∂r √•tg√§rden. Det √§r precis h√§r NER kommer in.

> ‚úÖ Ett annat exempel skulle vara [att analysera vetenskapliga medicinska artiklar](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). En av de viktigaste sakerna vi beh√∂ver leta efter √§r specifika medicinska termer, s√•som sjukdomar och medicinska substanser. Medan ett litet antal sjukdomar f√∂rmodligen kan extraheras med substring-s√∂kning, kr√§ver mer komplexa entiteter, s√•som kemiska f√∂reningar och medicinnamn, en mer avancerad metod.

## NER som Tokenklassificering

NER-modeller √§r i grunden **tokenklassificeringsmodeller**, eftersom vi f√∂r varje inmatad token m√•ste avg√∂ra om den tillh√∂r en entitet eller inte, och om den g√∂r det - vilken entitetsklass den tillh√∂r.

T√§nk p√• f√∂ljande artikelrubrik:

**Tricuspidalklaffinsufficiens** och **litiumkarbonat** **toxicitet** hos ett nyf√∂tt barn.

Entiteter h√§r √§r:

* Tricuspidalklaffinsufficiens √§r en sjukdom (`DIS`)
* Litiumkarbonat √§r en kemisk substans (`CHEM`)
* Toxicitet √§r ocks√• en sjukdom (`DIS`)

Observera att en entitet kan str√§cka sig √∂ver flera tokens. Och, som i detta fall, m√•ste vi skilja mellan tv√• p√• varandra f√∂ljande entiteter. D√§rf√∂r √§r det vanligt att anv√§nda tv√• klasser f√∂r varje entitet - en som anger den f√∂rsta token i entiteten (ofta anv√§nds prefixet `B-` f√∂r **b√∂rjan**), och en annan f√∂r forts√§ttningen av en entitet (`I-`, f√∂r **inre token). Vi anv√§nder ocks√• `O` som en klass f√∂r att representera alla **andra** tokens. S√•dan tokenm√§rkning kallas [BIO-m√§rkning](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (eller IOB). N√§r den √§r m√§rkt ser v√•r rubrik ut s√• h√§r:

Token | Tagg
------|-----
Tricuspidalklaff | B-DIS
insufficiens | I-DIS
och | O
litium | B-CHEM
karbonat | I-CHEM
toxicitet | B-DIS
hos | O
ett | O
nyf√∂tt | O
barn | O
. | O

Eftersom vi beh√∂ver bygga en en-till-en-korrespondens mellan tokens och klasser, kan vi tr√§na en h√∂gerst√§lld **m√•nga-till-m√•nga** neural n√§tverksmodell fr√•n denna bild:

![Bild som visar vanliga √•terkommande neurala n√§tverksm√∂nster.](../../../../../translated_images/sv/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> *Bild fr√•n [denna bloggpost](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) av [Andrej Karpathy](http://karpathy.github.io/). NER tokenklassificeringsmodeller motsvarar den h√∂gra n√§tverksarkitekturen p√• denna bild.*

## Tr√§ning av NER-modeller

Eftersom en NER-modell i grunden √§r en tokenklassificeringsmodell, kan vi anv√§nda RNN:er som vi redan √§r bekanta med f√∂r denna uppgift. I detta fall kommer varje block av det √•terkommande n√§tverket att returnera token-ID. F√∂ljande exempelnotebook visar hur man tr√§nar LSTM f√∂r tokenklassificering.

## ‚úçÔ∏è Exempelnotebooks: NER

Forts√§tt din inl√§rning i f√∂ljande notebook:

* [NER med TensorFlow](NER-TF.ipynb)

## Slutsats

En NER-modell √§r en **tokenklassificeringsmodell**, vilket inneb√§r att den kan anv√§ndas f√∂r att utf√∂ra tokenklassificering. Detta √§r en mycket vanlig uppgift inom NLP, som hj√§lper till att identifiera specifika entiteter i text, inklusive platser, namn, datum och mer.

## üöÄ Utmaning

Slutf√∂r uppgiften som √§r l√§nkad nedan f√∂r att tr√§na en namngiven entityigenk√§nningsmodell f√∂r medicinska termer, och testa den sedan p√• en annan dataset.

## [Quiz efter f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Granskning & Sj√§lvstudier

L√§s igenom bloggen [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) och f√∂lj med i avsnittet f√∂r vidare l√§sning i den artikeln f√∂r att f√∂rdjupa din kunskap.

## [Uppgift](lab/README.md)

I uppgiften f√∂r denna lektion kommer du att beh√∂va tr√§na en modell f√∂r medicinsk entityigenk√§nning. Du kan b√∂rja med att tr√§na en LSTM-modell som beskrivs i denna lektion, och forts√§tta med att anv√§nda BERT-transformermodellen. L√§s [instruktionerna](lab/README.md) f√∂r att f√• alla detaljer.

---

