# V칛lk칛nda CNN-arkitekturer

### VGG-16

VGG-16 칛r ett n칛tverk som uppn친dde 92,7% noggrannhet i ImageNet top-5 klassificering 친r 2014. Det har f칬ljande lagerstruktur:

![ImageNet Layers](../../../../../translated_images/sv/vgg-16-arch1.d901a5583b3a51ba.webp)

Som du kan se f칬ljer VGG en traditionell pyramidarkitektur, vilket 칛r en sekvens av konvolutions- och poolinglager.

![ImageNet Pyramid](../../../../../translated_images/sv/vgg-16-arch.64ff2137f50dd49f.webp)

> Bild fr친n [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet 칛r en familj av modeller som f칬reslogs av Microsoft Research 친r 2015. Huvudid칠n med ResNet 칛r att anv칛nda **residualblock**:

<img src="../../../../../translated_images/sv/resnet-block.aba4ccbcc0944434.webp" width="300"/>

> Bild fr친n [denna artikel](https://arxiv.org/pdf/1512.03385.pdf)

Anledningen till att anv칛nda identitetsgenomg친ng 칛r att l친ta lagret f칬ruts칛ga **skillnaden** mellan resultatet fr친n ett tidigare lager och utg친ngen fr친n residualblocket - d칛rav namnet *residual*. Dessa block 칛r mycket l칛ttare att tr칛na, och man kan konstruera n칛tverk med flera hundra s친dana block (de vanligaste varianterna 칛r ResNet-52, ResNet-101 och ResNet-152).

Du kan ocks친 t칛nka p친 detta n칛tverk som att det kan anpassa sin komplexitet till datasetet. I b칬rjan, n칛r du b칬rjar tr칛na n칛tverket, 칛r vikterna sm친 och det mesta av signalen g친r genom identitetslagren. N칛r tr칛ningen fortskrider och vikterna blir st칬rre, 칬kar betydelsen av n칛tverkets parametrar, och n칛tverket anpassar sig f칬r att tillhandah친lla den uttryckskraft som kr칛vs f칬r att korrekt klassificera tr칛ningsbilder.

### Google Inception

Google Inception-arkitekturen tar denna id칠 ett steg l칛ngre och bygger varje n칛tverkslager som en kombination av flera olika v칛gar:

<img src="../../../../../translated_images/sv/inception.a6605b85bcbc6f52.webp" width="400"/>

> Bild fr친n [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

H칛r beh칬ver vi betona rollen av 1x1-konvolutioner, eftersom de vid f칬rsta anblick inte verkar logiska. Varf칬r skulle vi beh칬va k칬ra genom bilden med ett 1x1-filter? Men du m친ste komma ih친g att konvolutionsfilter ocks친 arbetar med flera djupkanaler (ursprungligen - RGB-f칛rger, i efterf칬ljande lager - kanaler f칬r olika filter), och 1x1-konvolution anv칛nds f칬r att blanda dessa ing친ngskanaler med olika tr칛ningsbara vikter. Det kan ocks친 ses som en nedsampling (pooling) 칬ver kanaldimensionen.

H칛r 칛r [en bra bloggpost](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) om 칛mnet, och [den ursprungliga artikeln](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet 칛r en familj av modeller med reducerad storlek, l칛mpliga f칬r mobila enheter. Anv칛nd dem om du har begr칛nsade resurser och kan offra lite noggrannhet. Huvudid칠n bakom dem 칛r den s친 kallade **depthwise separable convolution**, som g칬r det m칬jligt att representera konvolutionsfilter genom en sammans칛ttning av rumsliga konvolutioner och 1x1-konvolution 칬ver djupkanaler. Detta minskar avsev칛rt antalet parametrar, vilket g칬r n칛tverket mindre i storlek och ocks친 l칛ttare att tr칛na med mindre data.

H칛r 칛r [en bra bloggpost om MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Slutsats

I denna enhet har du l칛rt dig huvudkonceptet bakom neurala n칛tverk f칬r datorseende - konvolutionsn칛tverk. Verkliga arkitekturer som driver bildklassificering, objektigenk칛nning och till och med bildgenereringsn칛tverk 칛r alla baserade p친 CNN, bara med fler lager och n친gra ytterligare tr칛ningsknep.

## 游 Utmaning

I de medf칬ljande anteckningsb칬ckerna finns det anteckningar l칛ngst ner om hur man kan uppn친 h칬gre noggrannhet. G칬r n친gra experiment f칬r att se om du kan uppn친 b칛ttre resultat.

## [Quiz efter f칬rel칛sningen](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Granskning & Sj칛lvstudier

츿ven om CNN oftast anv칛nds f칬r datorseendeuppgifter, 칛r de generellt bra p친 att extrahera m칬nster av fast storlek. Till exempel, om vi arbetar med ljud, kan vi ocks친 vilja anv칛nda CNN f칬r att leta efter specifika m칬nster i ljudsignalen - i s친 fall skulle filtren vara 1-dimensionella (och detta CNN skulle kallas 1D-CNN). Ibland anv칛nds ocks친 3D-CNN f칬r att extrahera funktioner i multidimensionellt utrymme, s친som vissa h칛ndelser som intr칛ffar p친 video - CNN kan f친nga vissa m칬nster av funktioner som f칬r칛ndras 칬ver tid. G칬r en granskning och sj칛lvstudier om andra uppgifter som kan utf칬ras med CNN.

## [Uppgift](lab/README.md)

I detta labb ska du klassificera olika katt- och hundraser. Dessa bilder 칛r mer komplexa 칛n MNIST-datasetet och har h칬gre dimensioner, och det finns fler 칛n 10 klasser.

---

