# Autoencoders

N√§r vi tr√§nar CNNs √§r ett av problemen att vi beh√∂ver mycket m√§rkt data. N√§r det g√§ller bildklassificering m√•ste vi dela upp bilder i olika klasser, vilket √§r en manuell process.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/17)

Men vi kanske vill anv√§nda r√• (om√§rkt) data f√∂r att tr√§na CNN-funktionsextraktorer, vilket kallas **sj√§lv√∂vervakad inl√§rning**. Ist√§llet f√∂r etiketter anv√§nder vi tr√§ningsbilder som b√•de n√§tverksinmatning och -utmatning. Huvudid√©n med en **autoencoder** √§r att vi har ett **encoder-n√§tverk** som omvandlar inmatningsbilden till n√•gon **latent space** (vanligtvis √§r det bara en vektor av mindre storlek), och sedan ett **decoder-n√§tverk**, vars m√•l √§r att rekonstruera den ursprungliga bilden.

> ‚úÖ En [autoencoder](https://wikipedia.org/wiki/Autoencoder) √§r "en typ av artificiellt neuralt n√§tverk som anv√§nds f√∂r att l√§ra sig effektiva kodningar av om√§rkt data."

Eftersom vi tr√§nar en autoencoder f√∂r att f√•nga s√• mycket information som m√∂jligt fr√•n den ursprungliga bilden f√∂r en korrekt rekonstruktion, f√∂rs√∂ker n√§tverket hitta den b√§sta **embedding** av inmatningsbilder f√∂r att f√•nga dess betydelse.

![AutoEncoder Diagram](../../../../../translated_images/sv/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> Bild fr√•n [Keras blog](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenarier f√∂r att anv√§nda Autoencoders

√Ñven om att rekonstruera ursprungliga bilder inte verkar anv√§ndbart i sig sj√§lvt, finns det n√•gra scenarier d√§r autoencoders √§r s√§rskilt anv√§ndbara:

* **Minska dimensionen p√• bilder f√∂r visualisering** eller **tr√§na bildembeddings**. Vanligtvis ger autoencoders b√§ttre resultat √§n PCA, eftersom de tar h√§nsyn till bilders spatiala natur och hierarkiska funktioner.
* **Denoising**, dvs. ta bort brus fr√•n bilden. Eftersom brus inneh√•ller mycket on√∂dig information kan autoencodern inte passa in allt i det relativt lilla latenta utrymmet, och f√•ngar d√§rf√∂r bara den viktiga delen av bilden. N√§r vi tr√§nar brusreducerare b√∂rjar vi med ursprungliga bilder och anv√§nder bilder med artificiellt tillagt brus som inmatning f√∂r autoencodern.
* **Superuppl√∂sning**, √∂ka bildens uppl√∂sning. Vi b√∂rjar med h√∂guppl√∂sta bilder och anv√§nder bilden med l√§gre uppl√∂sning som autoencoderns inmatning.
* **Generativa modeller**. N√§r vi har tr√§nat autoencodern kan den dekoderande delen anv√§ndas f√∂r att skapa nya objekt fr√•n slumpm√§ssiga latenta vektorer.

## Variational Autoencoders (VAE)

Traditionella autoencoders minskar dimensionen p√• inmatningsdata p√• n√•got s√§tt och identifierar viktiga funktioner i inmatningsbilder. Men latenta vektorer √§r ofta sv√•ra att tolka. Med andra ord, om vi tar MNIST-datasetet som exempel, √§r det inte enkelt att avg√∂ra vilka siffror som motsvarar olika latenta vektorer, eftersom n√§rliggande latenta vektorer inte n√∂dv√§ndigtvis motsvarar samma siffror.

F√∂r att tr√§na *generativa* modeller √§r det d√§remot b√§ttre att ha en viss f√∂rst√•else f√∂r det latenta utrymmet. Denna id√© leder oss till **variational autoencoder** (VAE).

VAE √§r en autoencoder som l√§r sig att f√∂ruts√§ga *statistisk f√∂rdelning* av de latenta parametrarna, den s√• kallade **latenta f√∂rdelningen**. Till exempel kanske vi vill att latenta vektorer ska vara normalt f√∂rdelade med en viss medelv√§rde z<sub>mean</sub> och standardavvikelse z<sub>sigma</sub> (b√•de medelv√§rde och standardavvikelse √§r vektorer med en viss dimension d). Encoder i VAE l√§r sig att f√∂ruts√§ga dessa parametrar, och sedan tar decodern en slumpm√§ssig vektor fr√•n denna f√∂rdelning f√∂r att rekonstruera objektet.

Sammanfattningsvis:

 * Fr√•n inmatningsvektorn f√∂ruts√§ger vi `z_mean` och `z_log_sigma` (ist√§llet f√∂r att f√∂ruts√§ga standardavvikelsen direkt, f√∂ruts√§ger vi dess logaritm)
 * Vi samplar en vektor `sample` fr√•n f√∂rdelningen N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Decodern f√∂rs√∂ker avkoda den ursprungliga bilden med `sample` som inmatningsvektor

 <img src="../../../../../translated_images/sv/vae.464c465a5b6a9e25.webp" width="50%">

> Bild fr√•n [denna blogginl√§gg](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) av Isaak Dykeman

Variational autoencoders anv√§nder en komplex f√∂rlustfunktion som best√•r av tv√• delar:

* **Rekonstruktionsf√∂rlust** √§r f√∂rlustfunktionen som visar hur n√§ra en rekonstruerad bild √§r m√•let (det kan vara Mean Squared Error, eller MSE). Det √§r samma f√∂rlustfunktion som i vanliga autoencoders.
* **KL-f√∂rlust**, som s√§kerst√§ller att latenta variabelns f√∂rdelning f√∂rblir n√§ra normalf√∂rdelning. Den baseras p√• begreppet [Kullback-Leibler divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - en metrik f√∂r att uppskatta hur lika tv√• statistiska f√∂rdelningar √§r.

En viktig f√∂rdel med VAEs √§r att de g√∂r det relativt enkelt att generera nya bilder, eftersom vi vet vilken f√∂rdelning vi ska sampla latenta vektorer fr√•n. Till exempel, om vi tr√§nar en VAE med en 2D latent vektor p√• MNIST, kan vi sedan variera komponenterna i den latenta vektorn f√∂r att f√• olika siffror:

<img alt="vaemnist" src="../../../../../translated_images/sv/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> Bild av [Dmitry Soshnikov](http://soshnikov.com)

Observera hur bilderna sm√§lter samman n√§r vi b√∂rjar f√• latenta vektorer fr√•n olika delar av det latenta parameterutrymmet. Vi kan ocks√• visualisera detta utrymme i 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/sv/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> Bild av [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è √ñvningar: Autoencoders

L√§r dig mer om autoencoders i dessa motsvarande notebooks:

* [Autoencoders i TensorFlow](AutoencodersTF.ipynb)
* [Autoencoders i PyTorch](AutoEncodersPyTorch.ipynb)

## Egenskaper hos Autoencoders

* **Dataspecifika** - de fungerar bara bra med den typ av bilder de har tr√§nats p√•. Till exempel, om vi tr√§nar ett n√§tverk f√∂r superuppl√∂sning p√• blommor, kommer det inte att fungera bra p√• portr√§tt. Detta beror p√• att n√§tverket kan producera h√∂guppl√∂sta bilder genom att ta fina detaljer fr√•n funktioner som l√§rts fr√•n tr√§ningsdatasetet.
* **F√∂rlustfyllda** - den rekonstruerade bilden √§r inte densamma som den ursprungliga bilden. F√∂rlustens natur definieras av den *f√∂rlustfunktion* som anv√§nds under tr√§ningen.
* Fungerar p√• **om√§rkt data**

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Slutsats

I denna lektion l√§rde du dig om de olika typerna av autoencoders som finns tillg√§ngliga f√∂r AI-forskaren. Du l√§rde dig hur man bygger dem och hur man anv√§nder dem f√∂r att rekonstruera bilder. Du l√§rde dig ocks√• om VAE och hur man anv√§nder det f√∂r att generera nya bilder.

## üöÄ Utmaning

I denna lektion l√§rde du dig om att anv√§nda autoencoders f√∂r bilder. Men de kan ocks√• anv√§ndas f√∂r musik! Kolla in Magenta-projektets [MusicVAE](https://magenta.tensorflow.org/music-vae)-projekt, som anv√§nder autoencoders f√∂r att l√§ra sig att rekonstruera musik. G√∂r n√•gra [experiment](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) med detta bibliotek f√∂r att se vad du kan skapa.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Granskning & Sj√§lvstudier

F√∂r referens, l√§s mer om autoencoders i dessa resurser:

* [Bygga Autoencoders i Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blogginl√§gg p√• NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Variational Autoencoders Explained](https://kvfrans.com/variational-autoencoders-explained/)
* [Conditional Variational Autoencoders](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Uppgift

I slutet av [denna notebook med TensorFlow](AutoencodersTF.ipynb) hittar du en 'uppgift' - anv√§nd detta som din uppgift.

---

