# F√∂rtr√§nade n√§tverk och transfer learning

Att tr√§na CNNs kan ta mycket tid, och det kr√§vs en stor m√§ngd data f√∂r att utf√∂ra uppgiften. Mycket av tiden g√•r √•t till att l√§ra n√§tverket de b√§sta l√•g-niv√•filtren f√∂r att kunna extrahera m√∂nster fr√•n bilder. En naturlig fr√•ga uppst√•r - kan vi anv√§nda ett neuralt n√§tverk som tr√§nats p√• ett dataset och anpassa det f√∂r att klassificera andra bilder utan att beh√∂va genomf√∂ra en fullst√§ndig tr√§ningsprocess?

## [Quiz f√∂re f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Denna metod kallas **transfer learning**, eftersom vi √∂verf√∂r viss kunskap fr√•n en neuralt n√§tverksmodell till en annan. Vid transfer learning b√∂rjar vi vanligtvis med en f√∂rtr√§nad modell, som har tr√§nats p√• ett stort bilddataset, s√•som **ImageNet**. Dessa modeller kan redan g√∂ra ett bra jobb med att extrahera olika funktioner fr√•n generiska bilder, och i m√•nga fall kan man uppn√• bra resultat genom att bygga en klassificerare ovanp√• de extraherade funktionerna.

> ‚úÖ Transfer learning √§r ett begrepp som √§ven f√∂rekommer inom andra akademiska omr√•den, s√•som utbildning. Det syftar p√• processen att ta kunskap fr√•n ett omr√•de och till√§mpa det p√• ett annat.

## F√∂rtr√§nade modeller som feature-extraktorer

De konvolutionella n√§tverk vi diskuterade i f√∂reg√•ende avsnitt inneh√•ller flera lager, d√§r varje lager √§r avsett att extrahera funktioner fr√•n bilden, fr√•n l√•g-niv√• pixelkombinationer (som horisontella/vertikala linjer eller streck) till h√∂gre niv√•kombinationer av funktioner, som exempelvis ett √∂ga eller en flamma. Om vi tr√§nar ett CNN p√• ett tillr√§ckligt stort dataset med generiska och varierande bilder, b√∂r n√§tverket l√§ra sig att extrahera dessa vanliga funktioner.

B√•de Keras och PyTorch inneh√•ller funktioner f√∂r att enkelt ladda f√∂rtr√§nade neurala n√§tverksvikter f√∂r n√•gra vanliga arkitekturer, varav de flesta har tr√§nats p√• ImageNet-bilder. De mest anv√§nda beskrivs p√• sidan [CNN Architectures](../07-ConvNets/CNN_Architectures.md) fr√•n f√∂reg√•ende lektion. I synnerhet kan du √∂verv√§ga att anv√§nda n√•gon av f√∂ljande:

* **VGG-16/VGG-19** √§r relativt enkla modeller som √§nd√• ger bra noggrannhet. Att anv√§nda VGG som ett f√∂rsta f√∂rs√∂k √§r ofta ett bra val f√∂r att se hur transfer learning fungerar.
* **ResNet** √§r en familj av modeller som f√∂reslogs av Microsoft Research 2015. De har fler lager och kr√§ver d√§rf√∂r mer resurser.
* **MobileNet** √§r en familj av modeller med reducerad storlek, l√§mpliga f√∂r mobila enheter. Anv√§nd dem om du har begr√§nsade resurser och kan kompromissa lite med noggrannheten.

H√§r √§r exempel p√• funktioner som extraherats fr√•n en bild av en katt med VGG-16-n√§tverket:

![Funktioner extraherade av VGG-16](../../../../../translated_images/sv/features.6291f9c7ba3a0b95.webp)

## Dataset f√∂r katter och hundar

I detta exempel kommer vi att anv√§nda ett dataset med [katter och hundar](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), vilket ligger n√§ra ett verkligt scenario f√∂r bildklassificering.

## ‚úçÔ∏è √ñvning: Transfer learning

L√•t oss se transfer learning i praktiken i motsvarande notebooks:

* [Transfer Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](TransferLearningTF.ipynb)

## Visualisering av en "idealkatt"

Ett f√∂rtr√§nat neuralt n√§tverk inneh√•ller olika m√∂nster i sitt *"hj√§rna"*, inklusive f√∂rest√§llningar om en **ideal katt** (liksom ideal hund, ideal zebra, etc.). Det vore intressant att p√• n√•got s√§tt **visualisera denna bild**. Men det √§r inte enkelt, eftersom m√∂nstren √§r spridda √∂ver n√§tverkets vikter och dessutom organiserade i en hierarkisk struktur.

En metod vi kan anv√§nda √§r att b√∂rja med en slumpm√§ssig bild och sedan f√∂rs√∂ka anv√§nda **gradient descent-optimering** f√∂r att justera bilden s√• att n√§tverket b√∂rjar tro att det √§r en katt.

![Bildoptimeringsloop](../../../../../translated_images/sv/ideal-cat-loop.999fbb8ff306e044.webp)

Om vi g√∂r detta kommer vi dock att f√• n√•got som liknar slumpm√§ssigt brus. Detta beror p√• att *det finns m√•nga s√§tt att f√• n√§tverket att tro att inmatningsbilden √§r en katt*, inklusive s√•dana som inte √§r visuellt meningsfulla. √Ñven om dessa bilder inneh√•ller m√•nga m√∂nster som √§r typiska f√∂r en katt, finns det inget som begr√§nsar dem till att vara visuellt distinkta.

F√∂r att f√∂rb√§ttra resultatet kan vi l√§gga till en annan term i f√∂rlustfunktionen, kallad **variation loss**. Det √§r en metrik som visar hur lika angr√§nsande pixlar i bilden √§r. Genom att minimera variation loss blir bilden mjukare och bruset f√∂rsvinner - vilket avsl√∂jar mer visuellt tilltalande m√∂nster. H√§r √§r exempel p√• s√•dana "ideala" bilder som klassificeras som katt och zebra med h√∂g sannolikhet:

![Ideal katt](../../../../../translated_images/sv/ideal-cat.203dd4597643d6b0.webp) | ![Ideal zebra](../../../../../translated_images/sv/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Ideal katt* | *Ideal zebra*

En liknande metod kan anv√§ndas f√∂r att utf√∂ra s√• kallade **adversarial attacks** p√• ett neuralt n√§tverk. Anta att vi vill lura ett neuralt n√§tverk och f√• en hund att se ut som en katt. Om vi tar en bild av en hund som n√§tverket k√§nner igen som en hund, kan vi sedan justera den lite med gradient descent-optimering tills n√§tverket b√∂rjar klassificera den som en katt:

![Bild av en hund](../../../../../translated_images/sv/original-dog.8f68a67d2fe0911f.webp) | ![Bild av en hund klassificerad som en katt](../../../../../translated_images/sv/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Originalbild av en hund* | *Bild av en hund klassificerad som en katt*

Se koden f√∂r att reproducera resultaten ovan i f√∂ljande notebook:

* [Ideal och adversarial katt - TensorFlow](AdversarialCat_TF.ipynb)

## Slutsats

Med transfer learning kan du snabbt s√§tta ihop en klassificerare f√∂r en anpassad objektklassificeringsuppgift och uppn√• h√∂g noggrannhet. Du kan se att mer komplexa uppgifter som vi l√∂ser nu kr√§ver h√∂gre ber√§kningskraft och inte enkelt kan l√∂sas p√• en CPU. I n√§sta enhet kommer vi att f√∂rs√∂ka anv√§nda en mer l√§ttviktig implementation f√∂r att tr√§na samma modell med l√§gre ber√§kningsresurser, vilket resulterar i bara n√•got l√§gre noggrannhet.

## üöÄ Utmaning

I de medf√∂ljande notebooks finns anteckningar l√§ngst ner om hur transfer knowledge fungerar b√§st med n√•got liknande tr√§ningsdata (en ny typ av djur, kanske). G√∂r n√•gra experiment med helt nya typer av bilder f√∂r att se hur bra eller d√•ligt dina transfer knowledge-modeller presterar.

## [Quiz efter f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Granskning & Sj√§lvstudier

L√§s igenom [TrainingTricks.md](TrainingTricks.md) f√∂r att f√∂rdjupa din kunskap om andra s√§tt att tr√§na dina modeller.

## [Uppgift](lab/README.md)

I detta labb kommer vi att anv√§nda det verkliga [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) pets-datasetet med 35 raser av katter och hundar, och vi kommer att bygga en transfer learning-klassificerare.

---

