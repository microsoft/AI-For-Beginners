# ReÈ›ele Pre-antrenate È™i ÃnvÄƒÈ›area prin Transfer

Antrenarea CNN-urilor poate dura mult timp È™i necesitÄƒ o cantitate mare de date. TotuÈ™i, o mare parte din timp este petrecut Ã®n Ã®nvÄƒÈ›area celor mai bune filtre de nivel scÄƒzut pe care o reÈ›ea le poate folosi pentru a extrage modele din imagini. O Ã®ntrebare naturalÄƒ apare - putem folosi o reÈ›ea neuronalÄƒ antrenatÄƒ pe un set de date È™i sÄƒ o adaptÄƒm pentru a clasifica imagini diferite fÄƒrÄƒ a necesita un proces complet de antrenare?

## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/15)

AceastÄƒ abordare se numeÈ™te **Ã®nvÄƒÈ›are prin transfer**, deoarece transferÄƒm o parte din cunoÈ™tinÈ›ele unui model de reÈ›ea neuronalÄƒ cÄƒtre altul. Ãn Ã®nvÄƒÈ›area prin transfer, de obicei Ã®ncepem cu un model pre-antrenat, care a fost antrenat pe un set mare de imagini, cum ar fi **ImageNet**. Aceste modele pot deja sÄƒ extragÄƒ caracteristici diferite din imagini generice, iar Ã®n multe cazuri, construirea unui clasificator pe baza acestor caracteristici extrase poate oferi un rezultat bun.

> âœ… ÃnvÄƒÈ›area prin transfer este un termen Ã®ntÃ¢lnit È™i Ã®n alte domenii academice, cum ar fi EducaÈ›ia. Se referÄƒ la procesul de aplicare a cunoÈ™tinÈ›elor dintr-un domeniu Ã®n altul.

## Modele Pre-antrenate ca Extractoare de Caracteristici

ReÈ›elele convoluÈ›ionale despre care am vorbit Ã®n secÈ›iunea anterioarÄƒ conÈ›ineau un numÄƒr de straturi, fiecare dintre ele fiind destinat sÄƒ extragÄƒ anumite caracteristici din imagine, Ã®ncepÃ¢nd de la combinaÈ›ii de pixeli de nivel scÄƒzut (cum ar fi linii orizontale/verticale sau trÄƒsÄƒturi), pÃ¢nÄƒ la combinaÈ›ii de caracteristici de nivel Ã®nalt, corespunzÄƒtoare unor lucruri precum un ochi sau o flacÄƒrÄƒ. DacÄƒ antrenÄƒm un CNN pe un set de date suficient de mare, cu imagini generice È™i diverse, reÈ›eaua ar trebui sÄƒ Ã®nveÈ›e sÄƒ extragÄƒ aceste caracteristici comune.

AtÃ¢t Keras, cÃ¢t È™i PyTorch conÈ›in funcÈ›ii pentru a Ã®ncÄƒrca cu uÈ™urinÈ›Äƒ greutÄƒÈ›i pre-antrenate ale reÈ›elelor neuronale pentru unele arhitecturi comune, majoritatea fiind antrenate pe imagini din ImageNet. Cele mai utilizate sunt descrise pe pagina [Arhitecturi CNN](../07-ConvNets/CNN_Architectures.md) din lecÈ›ia anterioarÄƒ. Ãn special, poate fi util sÄƒ folosiÈ›i una dintre urmÄƒtoarele:

* **VGG-16/VGG-19**, care sunt modele relativ simple, dar oferÄƒ o acurateÈ›e bunÄƒ. Deseori, utilizarea VGG ca primÄƒ Ã®ncercare este o alegere bunÄƒ pentru a vedea cum funcÈ›ioneazÄƒ Ã®nvÄƒÈ›area prin transfer.
* **ResNet** este o familie de modele propuse de Microsoft Research Ã®n 2015. Acestea au mai multe straturi È™i, prin urmare, necesitÄƒ mai multe resurse.
* **MobileNet** este o familie de modele cu dimensiuni reduse, potrivite pentru dispozitive mobile. FolosiÈ›i-le dacÄƒ aveÈ›i resurse limitate È™i puteÈ›i sacrifica puÈ›in din acurateÈ›e.

IatÄƒ caracteristici extrase dintr-o imagine cu o pisicÄƒ de cÄƒtre reÈ›eaua VGG-16:

![Caracteristici extrase de VGG-16](../../../../../translated_images/ro/features.6291f9c7ba3a0b95.webp)

## Setul de Date Pisici vs. CÃ¢ini

Ãn acest exemplu, vom folosi un set de date cu [Pisici È™i CÃ¢ini](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), care este foarte apropiat de un scenariu real de clasificare a imaginilor.

## âœï¸ ExerciÈ›iu: ÃnvÄƒÈ›area prin Transfer

SÄƒ vedem Ã®nvÄƒÈ›area prin transfer Ã®n acÈ›iune Ã®n caietele corespunzÄƒtoare:

* [ÃnvÄƒÈ›area prin Transfer - PyTorch](TransferLearningPyTorch.ipynb)
* [ÃnvÄƒÈ›area prin Transfer - TensorFlow](TransferLearningTF.ipynb)

## Vizualizarea Pisicii Adversariale

ReÈ›eaua neuronalÄƒ pre-antrenatÄƒ conÈ›ine diferite modele Ã®n "creierul" sÄƒu, inclusiv noÈ›iuni de **pisicÄƒ idealÄƒ** (precum È™i cÃ¢ine ideal, zebrÄƒ idealÄƒ etc.). Ar fi interesant sÄƒ **vizualizÄƒm aceastÄƒ imagine**. TotuÈ™i, nu este simplu, deoarece modelele sunt rÄƒspÃ¢ndite Ã®n greutÄƒÈ›ile reÈ›elei È™i sunt organizate Ã®ntr-o structurÄƒ ierarhicÄƒ.

O abordare pe care o putem adopta este sÄƒ Ã®ncepem cu o imagine aleatorie È™i apoi sÄƒ folosim tehnica de optimizare **gradient descent** pentru a ajusta acea imagine astfel Ã®ncÃ¢t reÈ›eaua sÄƒ Ã®nceapÄƒ sÄƒ creadÄƒ cÄƒ este o pisicÄƒ.

![BuclÄƒ de Optimizare a Imaginilor](../../../../../translated_images/ro/ideal-cat-loop.999fbb8ff306e044.webp)

TotuÈ™i, dacÄƒ facem acest lucru, vom obÈ›ine ceva foarte asemÄƒnÄƒtor cu un zgomot aleatoriu. Acest lucru se Ã®ntÃ¢mplÄƒ deoarece *existÄƒ multe moduri prin care reÈ›eaua poate crede cÄƒ imaginea de intrare este o pisicÄƒ*, inclusiv unele care nu au sens vizual. DeÈ™i aceste imagini conÈ›in multe modele tipice pentru o pisicÄƒ, nu existÄƒ nimic care sÄƒ le constrÃ¢ngÄƒ sÄƒ fie distincte vizual.

Pentru a Ã®mbunÄƒtÄƒÈ›i rezultatul, putem adÄƒuga un alt termen Ã®n funcÈ›ia de pierdere, numit **pierdere de variaÈ›ie**. Este o metricÄƒ care aratÄƒ cÃ¢t de similari sunt pixelii vecini ai imaginii. Minimizarea pierderii de variaÈ›ie face imaginea mai netedÄƒ È™i eliminÄƒ zgomotul - dezvÄƒluind astfel modele mai atractive vizual. IatÄƒ un exemplu de astfel de imagini "ideale", care sunt clasificate ca pisicÄƒ È™i ca zebrÄƒ cu o probabilitate mare:

![PisicÄƒ IdealÄƒ](../../../../../translated_images/ro/ideal-cat.203dd4597643d6b0.webp) | ![ZebrÄƒ IdealÄƒ](../../../../../translated_images/ro/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *PisicÄƒ IdealÄƒ* | *ZebrÄƒ IdealÄƒ*

O abordare similarÄƒ poate fi utilizatÄƒ pentru a efectua aÈ™a-numitele **atacuri adversariale** asupra unei reÈ›ele neuronale. SÄƒ presupunem cÄƒ dorim sÄƒ pÄƒcÄƒlim o reÈ›ea neuronalÄƒ È™i sÄƒ facem un cÃ¢ine sÄƒ arate ca o pisicÄƒ. DacÄƒ luÄƒm imaginea unui cÃ¢ine, care este recunoscutÄƒ de reÈ›ea ca fiind un cÃ¢ine, putem apoi sÄƒ o ajustÄƒm puÈ›in folosind optimizarea gradient descent, pÃ¢nÄƒ cÃ¢nd reÈ›eaua Ã®ncepe sÄƒ o clasifice ca fiind o pisicÄƒ:

![Imaginea unui CÃ¢ine](../../../../../translated_images/ro/original-dog.8f68a67d2fe0911f.webp) | ![Imaginea unui cÃ¢ine clasificat ca pisicÄƒ](../../../../../translated_images/ro/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Imagine originalÄƒ a unui cÃ¢ine* | *Imaginea unui cÃ¢ine clasificat ca pisicÄƒ*

ConsultaÈ›i codul pentru a reproduce rezultatele de mai sus Ã®n urmÄƒtorul caiet:

* [PisicÄƒ IdealÄƒ È™i AdversarialÄƒ - TensorFlow](AdversarialCat_TF.ipynb)

## Concluzie

Folosind Ã®nvÄƒÈ›area prin transfer, puteÈ›i crea rapid un clasificator pentru o sarcinÄƒ personalizatÄƒ de clasificare a obiectelor È™i obÈ›ine o acurateÈ›e ridicatÄƒ. PuteÈ›i observa cÄƒ sarcinile mai complexe pe care le rezolvÄƒm acum necesitÄƒ o putere de calcul mai mare È™i nu pot fi rezolvate uÈ™or pe CPU. Ãn unitatea urmÄƒtoare, vom Ã®ncerca sÄƒ folosim o implementare mai uÈ™oarÄƒ pentru a antrena acelaÈ™i model folosind resurse de calcul mai reduse, ceea ce duce la o acurateÈ›e doar uÈ™or mai scÄƒzutÄƒ.

## ğŸš€ Provocare

Ãn caietele Ã®nsoÈ›itoare, existÄƒ note la final despre cum funcÈ›ioneazÄƒ cel mai bine transferul de cunoÈ™tinÈ›e cu date de antrenament oarecum similare (poate un nou tip de animal). FaceÈ›i cÃ¢teva experimente cu tipuri complet noi de imagini pentru a vedea cÃ¢t de bine sau prost performeazÄƒ modelele voastre de transfer de cunoÈ™tinÈ›e.

## [Chestionar dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Recapitulare È™i Studiu Individual

CitiÈ›i [TrainingTricks.md](TrainingTricks.md) pentru a aprofunda cunoÈ™tinÈ›ele despre alte moduri de a vÄƒ antrena modelele.

## [TemÄƒ](lab/README.md)

Ãn acest laborator, vom folosi setul de date real [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) cu 35 de rase de pisici È™i cÃ¢ini È™i vom construi un clasificator bazat pe Ã®nvÄƒÈ›area prin transfer.

---

