# Autoencodere

CÃ¢nd antrenÄƒm CNN-uri, una dintre probleme este cÄƒ avem nevoie de o cantitate mare de date etichetate. Ãn cazul clasificÄƒrii imaginilor, trebuie sÄƒ separÄƒm imaginile Ã®n clase diferite, ceea ce presupune un efort manual.

## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/17)

TotuÈ™i, s-ar putea sÄƒ dorim sÄƒ folosim date brute (neetichetate) pentru a antrena extractoare de caracteristici CNN, ceea ce se numeÈ™te **Ã®nvÄƒÈ›are auto-supervizatÄƒ**. Ãn loc de etichete, vom folosi imaginile de antrenament atÃ¢t ca intrare, cÃ¢t È™i ca ieÈ™ire a reÈ›elei. Ideea principalÄƒ a unui **autoencoder** este cÄƒ vom avea o **reÈ›ea encoder** care converteÈ™te imaginea de intrare Ã®ntr-un **spaÈ›iu latent** (de obicei este doar un vector de dimensiune mai micÄƒ), apoi o **reÈ›ea decoder**, al cÄƒrei scop este sÄƒ reconstruiascÄƒ imaginea originalÄƒ.

> âœ… Un [autoencoder](https://wikipedia.org/wiki/Autoencoder) este â€un tip de reÈ›ea neuronalÄƒ artificialÄƒ utilizatÄƒ pentru a Ã®nvÄƒÈ›a codificÄƒri eficiente ale datelor neetichetate.â€

Deoarece antrenÄƒm un autoencoder pentru a captura cÃ¢t mai multÄƒ informaÈ›ie din imaginea originalÄƒ pentru o reconstrucÈ›ie precisÄƒ, reÈ›eaua Ã®ncearcÄƒ sÄƒ gÄƒseascÄƒ cea mai bunÄƒ **reprezentare** a imaginilor de intrare pentru a surprinde semnificaÈ›ia acestora.

![Diagrama Autoencoder](../../../../../translated_images/ro/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> Imagine de pe [blogul Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenarii pentru utilizarea Autoencoderelor

DeÈ™i reconstrucÈ›ia imaginilor originale nu pare utilÄƒ Ã®n sine, existÄƒ cÃ¢teva scenarii Ã®n care autoencoderele sunt deosebit de utile:

* **Reducerea dimensiunii imaginilor pentru vizualizare** sau **antrenarea reprezentÄƒrilor imagistice**. De obicei, autoencoderele oferÄƒ rezultate mai bune decÃ¢t PCA, deoarece iau Ã®n considerare natura spaÈ›ialÄƒ a imaginilor È™i caracteristicile ierarhice.
* **Eliminarea zgomotului**, adicÄƒ eliminarea zgomotului din imagine. Deoarece zgomotul conÈ›ine multe informaÈ›ii inutile, autoencoderul nu poate Ã®ncadra totul Ã®ntr-un spaÈ›iu latent relativ mic È™i, astfel, captureazÄƒ doar partea importantÄƒ a imaginii. CÃ¢nd antrenÄƒm eliminatoare de zgomot, pornim de la imagini originale È™i folosim imagini cu zgomot adÄƒugat artificial ca intrare pentru autoencoder.
* **Super-rezoluÈ›ie**, creÈ™terea rezoluÈ›iei imaginilor. Pornim de la imagini de Ã®naltÄƒ rezoluÈ›ie È™i folosim imaginea cu rezoluÈ›ie mai micÄƒ ca intrare pentru autoencoder.
* **Modele generative**. OdatÄƒ ce antrenÄƒm autoencoderul, partea de decoder poate fi utilizatÄƒ pentru a crea noi obiecte pornind de la vectori latenÈ›i aleatori.

## Autoencodere Variationale (VAE)

Autoencoderele tradiÈ›ionale reduc dimensiunea datelor de intrare Ã®ntr-un fel, identificÃ¢nd caracteristicile importante ale imaginilor de intrare. TotuÈ™i, vectorii latenÈ›i deseori nu au o semnificaÈ›ie clarÄƒ. Cu alte cuvinte, luÃ¢nd ca exemplu setul de date MNIST, identificarea cifrelor corespunzÄƒtoare diferiÈ›ilor vectori latenÈ›i nu este o sarcinÄƒ uÈ™oarÄƒ, deoarece vectorii latenÈ›i apropiaÈ›i nu corespund neapÄƒrat aceloraÈ™i cifre.

Pe de altÄƒ parte, pentru a antrena modele *generative*, este mai bine sÄƒ avem o Ã®nÈ›elegere a spaÈ›iului latent. AceastÄƒ idee ne conduce la **autoencoderul variaÈ›ional** (VAE).

VAE este un autoencoder care Ã®nvaÈ›Äƒ sÄƒ prezicÄƒ *distribuÈ›ia statisticÄƒ* a parametrilor latenÈ›i, aÈ™a-numita **distribuÈ›ie latentÄƒ**. De exemplu, putem dori ca vectorii latenÈ›i sÄƒ fie distribuiÈ›i normal cu o anumitÄƒ medie z<sub>mean</sub> È™i o deviaÈ›ie standard z<sub>sigma</sub> (atÃ¢t media, cÃ¢t È™i deviaÈ›ia standard sunt vectori de o anumitÄƒ dimensiune d). Encoderul din VAE Ã®nvaÈ›Äƒ sÄƒ prezicÄƒ aceÈ™ti parametri, iar decoderul ia un vector aleator din aceastÄƒ distribuÈ›ie pentru a reconstrui obiectul.

Pe scurt:

 * Din vectorul de intrare, prezicem `z_mean` È™i `z_log_sigma` (Ã®n loc sÄƒ prezicem deviaÈ›ia standard Ã®n sine, prezicem logaritmul acesteia)
 * EÈ™antionÄƒm un vector `sample` din distribuÈ›ia N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Decoderul Ã®ncearcÄƒ sÄƒ decodeze imaginea originalÄƒ folosind `sample` ca vector de intrare

 <img src="../../../../../translated_images/ro/vae.464c465a5b6a9e25.webp" width="50%">

> Imagine din [acest articol de blog](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) de Isaak Dykeman

Autoencoderele variaÈ›ionale folosesc o funcÈ›ie de pierdere complexÄƒ care constÄƒ din douÄƒ pÄƒrÈ›i:

* **Pierderea de reconstrucÈ›ie** este funcÈ›ia de pierdere care aratÄƒ cÃ¢t de aproape este o imagine reconstruitÄƒ de È›intÄƒ (poate fi Mean Squared Error sau MSE). Este aceeaÈ™i funcÈ›ie de pierdere ca Ã®n autoencoderele normale.
* **Pierderea KL**, care asigurÄƒ cÄƒ distribuÈ›iile variabilelor latente rÄƒmÃ¢n apropiate de distribuÈ›ia normalÄƒ. Se bazeazÄƒ pe noÈ›iunea de [divergenÈ›Äƒ Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - o metricÄƒ pentru a estima cÃ¢t de similare sunt douÄƒ distribuÈ›ii statistice.

Un avantaj important al VAE-urilor este cÄƒ permit generarea de imagini noi relativ uÈ™or, deoarece È™tim din ce distribuÈ›ie sÄƒ eÈ™antionÄƒm vectorii latenÈ›i. De exemplu, dacÄƒ antrenÄƒm un VAE cu un vector latent 2D pe MNIST, putem varia componentele vectorului latent pentru a obÈ›ine cifre diferite:

<img alt="vaemnist" src="../../../../../translated_images/ro/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> Imagine de [Dmitry Soshnikov](http://soshnikov.com)

ObservaÈ›i cum imaginile se Ã®mbinÄƒ Ã®ntre ele, pe mÄƒsurÄƒ ce Ã®ncepem sÄƒ obÈ›inem vectori latenÈ›i din diferite porÈ›iuni ale spaÈ›iului parametrilor latenÈ›i. Putem, de asemenea, sÄƒ vizualizÄƒm acest spaÈ›iu Ã®n 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/ro/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> Imagine de [Dmitry Soshnikov](http://soshnikov.com)

## âœï¸ ExerciÈ›ii: Autoencodere

AflaÈ›i mai multe despre autoencodere Ã®n aceste notebook-uri corespunzÄƒtoare:

* [Autoencodere Ã®n TensorFlow](AutoencodersTF.ipynb)
* [Autoencodere Ã®n PyTorch](AutoEncodersPyTorch.ipynb)

## ProprietÄƒÈ›i ale Autoencoderelor

* **Specifice datelor** - funcÈ›ioneazÄƒ bine doar cu tipul de imagini pe care au fost antrenate. De exemplu, dacÄƒ antrenÄƒm o reÈ›ea de super-rezoluÈ›ie pe flori, aceasta nu va funcÈ›iona bine pe portrete. Acest lucru se datoreazÄƒ faptului cÄƒ reÈ›eaua poate produce imagini de rezoluÈ›ie mai mare luÃ¢nd detalii fine din caracteristicile Ã®nvÄƒÈ›ate din setul de date de antrenament.
* **Pierdere de informaÈ›ie** - imaginea reconstruitÄƒ nu este aceeaÈ™i cu imaginea originalÄƒ. Natura pierderii este definitÄƒ de *funcÈ›ia de pierdere* utilizatÄƒ Ã®n timpul antrenamentului.
* FuncÈ›ioneazÄƒ pe **date neetichetate**

## [Chestionar dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Concluzie

Ãn aceastÄƒ lecÈ›ie, aÈ›i Ã®nvÄƒÈ›at despre diferitele tipuri de autoencodere disponibile pentru cercetÄƒtorii Ã®n AI. AÈ›i Ã®nvÄƒÈ›at cum sÄƒ le construiÈ›i È™i cum sÄƒ le utilizaÈ›i pentru a reconstrui imagini. De asemenea, aÈ›i Ã®nvÄƒÈ›at despre VAE È™i cum sÄƒ le utilizaÈ›i pentru a genera imagini noi.

## ğŸš€ Provocare

Ãn aceastÄƒ lecÈ›ie, aÈ›i Ã®nvÄƒÈ›at despre utilizarea autoencoderelor pentru imagini. Dar ele pot fi folosite È™i pentru muzicÄƒ! ConsultaÈ›i proiectul Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), care foloseÈ™te autoencodere pentru a Ã®nvÄƒÈ›a sÄƒ reconstruiascÄƒ muzicÄƒ. FaceÈ›i cÃ¢teva [experimente](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) cu aceastÄƒ bibliotecÄƒ pentru a vedea ce puteÈ›i crea.

## [Chestionar dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Recapitulare È™i Studiu Individual

Pentru referinÈ›Äƒ, citiÈ›i mai multe despre autoencodere Ã®n aceste resurse:

* [Construirea Autoencoderelor Ã®n Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Articol pe blogul NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Autoencodere Variationale Explicate](https://kvfrans.com/variational-autoencoders-explained/)
* [Autoencodere Variationale CondiÈ›ionale](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## TemÄƒ

La sfÃ¢rÈ™itul [acestui notebook folosind TensorFlow](AutoencodersTF.ipynb), veÈ›i gÄƒsi o â€sarcinÄƒâ€ - folosiÈ›i-o ca temÄƒ.

---

