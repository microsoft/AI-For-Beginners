<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-25T22:30:06+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "ro"
}
-->
# Autoencodere

CÃ¢nd antrenÄƒm CNN-uri, una dintre probleme este cÄƒ avem nevoie de o cantitate mare de date etichetate. Ãn cazul clasificÄƒrii imaginilor, trebuie sÄƒ separÄƒm imaginile Ã®n clase diferite, ceea ce necesitÄƒ un efort manual.

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

TotuÈ™i, am putea dori sÄƒ folosim date brute (neetichetate) pentru a antrena extractoare de caracteristici CNN, ceea ce se numeÈ™te **Ã®nvÄƒÈ›are auto-supervizatÄƒ**. Ãn loc de etichete, vom folosi imaginile de antrenament atÃ¢t ca intrare, cÃ¢t È™i ca ieÈ™ire pentru reÈ›ea. Ideea principalÄƒ a unui **autoencoder** este cÄƒ vom avea o **reÈ›ea encoder** care transformÄƒ imaginea de intrare Ã®ntr-un spaÈ›iu **latent** (de obicei, este doar un vector de dimensiune mai micÄƒ), apoi o **reÈ›ea decoder**, al cÄƒrei scop este sÄƒ reconstruiascÄƒ imaginea originalÄƒ.

> âœ… Un [autoencoder](https://wikipedia.org/wiki/Autoencoder) este â€un tip de reÈ›ea neuronalÄƒ artificialÄƒ utilizatÄƒ pentru a Ã®nvÄƒÈ›a codificÄƒri eficiente ale datelor neetichetate.â€

Deoarece antrenÄƒm un autoencoder pentru a captura cÃ¢t mai multe informaÈ›ii din imaginea originalÄƒ pentru o reconstrucÈ›ie precisÄƒ, reÈ›eaua Ã®ncearcÄƒ sÄƒ gÄƒseascÄƒ cea mai bunÄƒ **reprezentare** a imaginilor de intrare pentru a surprinde semnificaÈ›ia acestora.

![AutoEncoder Diagram](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.ro.jpg)

> Imagine de pe [blogul Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenarii pentru utilizarea Autoencoderelor

DeÈ™i reconstrucÈ›ia imaginilor originale nu pare utilÄƒ Ã®n sine, existÄƒ cÃ¢teva scenarii Ã®n care autoencoderele sunt deosebit de utile:

* **Reducerea dimensiunii imaginilor pentru vizualizare** sau **antrenarea reprezentÄƒrilor imaginilor**. De obicei, autoencoderele oferÄƒ rezultate mai bune decÃ¢t PCA, deoarece iau Ã®n considerare natura spaÈ›ialÄƒ a imaginilor È™i caracteristicile ierarhice.
* **Eliminarea zgomotului**, adicÄƒ eliminarea zgomotului din imagine. Deoarece zgomotul conÈ›ine multe informaÈ›ii inutile, autoencoderul nu poate Ã®ncadra totul Ã®ntr-un spaÈ›iu latent relativ mic È™i, astfel, surprinde doar partea importantÄƒ a imaginii. CÃ¢nd antrenÄƒm eliminatoare de zgomot, pornim de la imagini originale È™i folosim imagini cu zgomot adÄƒugat artificial ca intrare pentru autoencoder.
* **Super-rezoluÈ›ie**, creÈ™terea rezoluÈ›iei imaginilor. Pornim de la imagini de Ã®naltÄƒ rezoluÈ›ie È™i folosim imaginea cu rezoluÈ›ie mai micÄƒ ca intrare pentru autoencoder.
* **Modele generative**. OdatÄƒ ce antrenÄƒm autoencoderul, partea de decoder poate fi utilizatÄƒ pentru a crea noi obiecte pornind de la vectori latenti aleatori.

## Autoencodere Variationale (VAE)

Autoencoderele tradiÈ›ionale reduc dimensiunea datelor de intrare Ã®ntr-un mod oarecare, identificÃ¢nd caracteristicile importante ale imaginilor de intrare. TotuÈ™i, vectorii latenti deseori nu au o semnificaÈ›ie clarÄƒ. Cu alte cuvinte, luÃ¢nd ca exemplu dataset-ul MNIST, identificarea cifrelor corespunzÄƒtoare diferiÈ›ilor vectori latenti nu este o sarcinÄƒ uÈ™oarÄƒ, deoarece vectorii latenti apropiaÈ›i nu corespund neapÄƒrat aceloraÈ™i cifre.

Pe de altÄƒ parte, pentru a antrena modele *generative*, este mai bine sÄƒ avem o Ã®nÈ›elegere a spaÈ›iului latent. AceastÄƒ idee ne conduce la **autoencoderul variational** (VAE).

VAE este un autoencoder care Ã®nvaÈ›Äƒ sÄƒ prezicÄƒ *distribuÈ›ia statisticÄƒ* a parametrilor latenti, aÈ™a-numita **distribuÈ›ie latentÄƒ**. De exemplu, am putea dori ca vectorii latenti sÄƒ fie distribuiÈ›i normal cu o medie z<sub>mean</sub> È™i o deviaÈ›ie standard z<sub>sigma</sub> (atÃ¢t media, cÃ¢t È™i deviaÈ›ia standard sunt vectori de o anumitÄƒ dimensiune d). Encoderul din VAE Ã®nvaÈ›Äƒ sÄƒ prezicÄƒ aceÈ™ti parametri, iar decoderul ia un vector aleator din aceastÄƒ distribuÈ›ie pentru a reconstrui obiectul.

Pentru a rezuma:

 * Din vectorul de intrare, prezicem `z_mean` È™i `z_log_sigma` (Ã®n loc sÄƒ prezicem deviaÈ›ia standard Ã®n sine, prezicem logaritmul acesteia)
 * Extragem un vector `sample` din distribuÈ›ia N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Decoderul Ã®ncearcÄƒ sÄƒ decodeze imaginea originalÄƒ folosind `sample` ca vector de intrare

 <img src="images/vae.png" width="50%">

> Imagine din [acest articol](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) de Isaak Dykeman

Autoencoderele variationale folosesc o funcÈ›ie de pierdere complexÄƒ care constÄƒ din douÄƒ pÄƒrÈ›i:

* **Pierdere de reconstrucÈ›ie** este funcÈ›ia de pierdere care aratÄƒ cÃ¢t de apropiatÄƒ este imaginea reconstruitÄƒ de È›intÄƒ (poate fi Mean Squared Error sau MSE). Este aceeaÈ™i funcÈ›ie de pierdere ca Ã®n autoencoderele normale.
* **Pierdere KL**, care asigurÄƒ cÄƒ distribuÈ›iile variabilelor latente rÄƒmÃ¢n apropiate de distribuÈ›ia normalÄƒ. Se bazeazÄƒ pe noÈ›iunea de [divergenÈ›Äƒ Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - o metricÄƒ pentru a estima cÃ¢t de similare sunt douÄƒ distribuÈ›ii statistice.

Un avantaj important al VAE-urilor este cÄƒ permit generarea de imagini noi relativ uÈ™or, deoarece È™tim din ce distribuÈ›ie sÄƒ extragem vectorii latenti. De exemplu, dacÄƒ antrenÄƒm un VAE cu vector latent 2D pe MNIST, putem varia componentele vectorului latent pentru a obÈ›ine cifre diferite:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Imagine de [Dmitry Soshnikov](http://soshnikov.com)

ObservaÈ›i cum imaginile se Ã®mbinÄƒ Ã®ntre ele, pe mÄƒsurÄƒ ce Ã®ncepem sÄƒ obÈ›inem vectori latenti din diferite porÈ›iuni ale spaÈ›iului parametrilor latenti. De asemenea, putem vizualiza acest spaÈ›iu Ã®n 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Imagine de [Dmitry Soshnikov](http://soshnikov.com)

## âœï¸ ExerciÈ›ii: Autoencodere

AflaÈ›i mai multe despre autoencodere Ã®n aceste notebook-uri corespunzÄƒtoare:

* [Autoencodere Ã®n TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Autoencodere Ã®n PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## ProprietÄƒÈ›i ale Autoencoderelor

* **Specifice datelor** - funcÈ›ioneazÄƒ bine doar cu tipul de imagini pe care au fost antrenate. De exemplu, dacÄƒ antrenÄƒm o reÈ›ea de super-rezoluÈ›ie pe flori, aceasta nu va funcÈ›iona bine pe portrete. Acest lucru se datoreazÄƒ faptului cÄƒ reÈ›eaua poate produce imagini de rezoluÈ›ie mai mare prin preluarea detaliilor fine din caracteristicile Ã®nvÄƒÈ›ate din setul de date de antrenament.
* **Pierdere de informaÈ›ie** - imaginea reconstruitÄƒ nu este aceeaÈ™i cu imaginea originalÄƒ. Natura pierderii este definitÄƒ de *funcÈ›ia de pierdere* utilizatÄƒ Ã®n timpul antrenamentului.
* FuncÈ›ioneazÄƒ pe **date neetichetate**

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## Concluzie

Ãn aceastÄƒ lecÈ›ie, aÈ›i Ã®nvÄƒÈ›at despre diferitele tipuri de autoencodere disponibile pentru cercetÄƒtorii AI. AÈ›i Ã®nvÄƒÈ›at cum sÄƒ le construiÈ›i È™i cum sÄƒ le utilizaÈ›i pentru a reconstrui imagini. De asemenea, aÈ›i Ã®nvÄƒÈ›at despre VAE È™i cum sÄƒ le utilizaÈ›i pentru a genera imagini noi.

## ğŸš€ Provocare

Ãn aceastÄƒ lecÈ›ie, aÈ›i Ã®nvÄƒÈ›at despre utilizarea autoencoderelor pentru imagini. Dar ele pot fi folosite È™i pentru muzicÄƒ! ConsultaÈ›i proiectul Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), care foloseÈ™te autoencodere pentru a Ã®nvÄƒÈ›a sÄƒ reconstruiascÄƒ muzicÄƒ. FaceÈ›i cÃ¢teva [experimente](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) cu aceastÄƒ bibliotecÄƒ pentru a vedea ce puteÈ›i crea.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Recapitulare & Studiu Individual

Pentru referinÈ›Äƒ, citiÈ›i mai multe despre autoencodere Ã®n aceste resurse:

* [Construirea Autoencoderelor Ã®n Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Articol pe NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Autoencodere Variationale Explicate](https://kvfrans.com/variational-autoencoders-explained/)
* [Autoencodere Variationale CondiÈ›ionale](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## TemÄƒ

La sfÃ¢rÈ™itul [acestui notebook folosind TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb), veÈ›i gÄƒsi o â€sarcinÄƒâ€ - folosiÈ›i aceasta ca temÄƒ.

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.