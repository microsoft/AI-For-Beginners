# Detectarea Obiectelor

Modelele de clasificare a imaginilor pe care le-am abordat pÃ¢nÄƒ acum au luat o imagine È™i au produs un rezultat categoric, cum ar fi clasa 'numÄƒr' Ã®ntr-o problemÄƒ MNIST. TotuÈ™i, Ã®n multe cazuri nu dorim doar sÄƒ È™tim cÄƒ o imagine conÈ›ine obiecte - vrem sÄƒ putem determina locaÈ›ia lor exactÄƒ. Acesta este scopul **detectÄƒrii obiectelor**.

## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![Detectarea Obiectelor](../../../../../translated_images/ro/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be.webp)

> Imagine de pe [site-ul YOLO v2](https://pjreddie.com/darknet/yolov2/)

## O Abordare NaivÄƒ pentru Detectarea Obiectelor

PresupunÃ¢nd cÄƒ dorim sÄƒ gÄƒsim o pisicÄƒ Ã®ntr-o imagine, o abordare foarte naivÄƒ pentru detectarea obiectelor ar fi urmÄƒtoarea:

1. ÃmpÄƒrÈ›im imaginea Ã®n mai multe secÈ›iuni.
2. AplicÄƒm clasificarea imaginilor pe fiecare secÈ›iune.
3. SecÈ›iunile care genereazÄƒ o activare suficient de mare pot fi considerate ca conÈ›inÃ¢nd obiectul Ã®n cauzÄƒ.

![Detectare NaivÄƒ a Obiectelor](../../../../../translated_images/ro/naive-detection.e7f1ba220ccd08c6.webp)

> *Imagine din [Notebook-ul de exerciÈ›ii](ObjectDetection-TF.ipynb)*

TotuÈ™i, aceastÄƒ abordare este departe de a fi idealÄƒ, deoarece permite algoritmului sÄƒ localizeze foarte imprecis caseta de delimitare a obiectului. Pentru o localizare mai precisÄƒ, trebuie sÄƒ aplicÄƒm un fel de **regresie** pentru a prezice coordonatele casetelor de delimitare - È™i pentru aceasta, avem nevoie de seturi de date specifice.

## Regresie pentru Detectarea Obiectelor

[Acest articol de blog](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491) oferÄƒ o introducere excelentÄƒ Ã®n detectarea formelor.

## Seturi de Date pentru Detectarea Obiectelor

Este posibil sÄƒ Ã®ntÃ¢lniÈ›i urmÄƒtoarele seturi de date pentru aceastÄƒ sarcinÄƒ:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) - 20 clase
* [COCO](http://cocodataset.org/#home) - Obiecte Comune Ã®n Context. 80 clase, casete de delimitare È™i mÄƒÈ™ti de segmentare

![COCO](../../../../../translated_images/ro/coco-examples.71bc60380fa6cceb.webp)

## Metrice pentru Detectarea Obiectelor

### IntersecÈ›ia peste Uniune

Ãn timp ce pentru clasificarea imaginilor este uÈ™or sÄƒ mÄƒsurÄƒm cÃ¢t de bine performeazÄƒ algoritmul, pentru detectarea obiectelor trebuie sÄƒ mÄƒsurÄƒm atÃ¢t corectitudinea clasei, cÃ¢t È™i precizia locaÈ›iei casetei de delimitare inferate. Pentru aceasta din urmÄƒ, folosim aÈ™a-numita **IntersecÈ›ia peste Uniune** (IoU), care mÄƒsoarÄƒ cÃ¢t de bine se suprapun douÄƒ casete (sau douÄƒ zone arbitrare).

![IoU](../../../../../translated_images/ro/iou_equation.9a4751d40fff4e11.webp)

> *Figura 2 din [acest articol excelent despre IoU](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)*

Ideea este simplÄƒ - Ã®mpÄƒrÈ›im aria de intersecÈ›ie dintre douÄƒ figuri la aria uniunii lor. Pentru douÄƒ arii identice, IoU ar fi 1, Ã®n timp ce pentru arii complet separate va fi 0. Ãn alte cazuri, va varia de la 0 la 1. De obicei, luÄƒm Ã®n considerare doar acele casete de delimitare pentru care IoU depÄƒÈ™eÈ™te o anumitÄƒ valoare.

### Precizia Medie

SÄƒ presupunem cÄƒ dorim sÄƒ mÄƒsurÄƒm cÃ¢t de bine este recunoscutÄƒ o anumitÄƒ clasÄƒ de obiecte $C$. Pentru a mÄƒsura acest lucru, folosim metrica **Precizia Medie**, care se calculeazÄƒ astfel:

1. ConsiderÄƒm curba Precizie-Recall care aratÄƒ acurateÈ›ea Ã®n funcÈ›ie de o valoare de prag de detectare (de la 0 la 1).
2. Ãn funcÈ›ie de prag, vom detecta mai multe sau mai puÈ›ine obiecte Ã®n imagine È™i vom obÈ›ine valori diferite de precizie È™i recall.
3. Curba va arÄƒta astfel:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *Imagine din [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

Precizia Medie pentru o clasÄƒ datÄƒ $C$ este aria de sub aceastÄƒ curbÄƒ. Mai precis, axa Recall este de obicei Ã®mpÄƒrÈ›itÄƒ Ã®n 10 pÄƒrÈ›i, iar Precizia este mediatÄƒ pe toate aceste puncte:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP È™i IoU

Vom lua Ã®n considerare doar acele detectÄƒri pentru care IoU depÄƒÈ™eÈ™te o anumitÄƒ valoare. De exemplu, Ã®n setul de date PASCAL VOC, de obicei $\mbox{IoU Threshold} = 0.5$ este presupus, Ã®n timp ce Ã®n COCO AP este mÄƒsurat pentru diferite valori ale $\mbox{IoU Threshold}$.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *Imagine din [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

### Precizia Medie GeneralÄƒ - mAP

Principala metricÄƒ pentru detectarea obiectelor se numeÈ™te **Precizia Medie GeneralÄƒ**, sau **mAP**. Este valoarea Preciziei Medii, mediatÄƒ pe toate clasele de obiecte È™i, uneori, È™i pe $\mbox{IoU Threshold}$. Procesul de calculare a **mAP** este descris Ã®n detaliu
[Ã®n acest articol de blog](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3)), È™i de asemenea [aici cu exemple de cod](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734).

## Diferite AbordÄƒri pentru Detectarea Obiectelor

ExistÄƒ douÄƒ clase largi de algoritmi de detectare a obiectelor:

* **ReÈ›ele de Propunere a Regiunilor** (R-CNN, Fast R-CNN, Faster R-CNN). Ideea principalÄƒ este de a genera **Regiuni de Interes** (ROI) È™i de a aplica CNN pe acestea, cÄƒutÃ¢nd activarea maximÄƒ. Este oarecum similar cu abordarea naivÄƒ, cu excepÈ›ia faptului cÄƒ ROI-urile sunt generate Ã®ntr-un mod mai inteligent. Unul dintre principalele dezavantaje ale acestor metode este cÄƒ sunt lente, deoarece necesitÄƒ multe treceri ale clasificatorului CNN peste imagine.
* Metode **One-pass** (YOLO, SSD, RetinaNet). Ãn aceste arhitecturi, proiectÄƒm reÈ›eaua pentru a prezice atÃ¢t clasele, cÃ¢t È™i ROI-urile Ã®ntr-o singurÄƒ trecere.

### R-CNN: CNN Bazat pe Regiuni

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf) foloseÈ™te [Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) pentru a genera o structurÄƒ ierarhicÄƒ de regiuni ROI, care sunt apoi trecute prin extractoare de caracteristici CNN È™i clasificatoare SVM pentru a determina clasa obiectului, È™i regresie liniarÄƒ pentru a determina coordonatele *casetei de delimitare*. [Lucrare oficialÄƒ](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/ro/rcnn1.cae407020dfb1d1f.webp)

> *Imagine de van de Sande et al. ICCVâ€™11*

![RCNN-1](../../../../../translated_images/ro/rcnn2.2d9530bb83516484.webp)

> *Imagini din [acest blog](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)*

### F-RCNN - Fast R-CNN

AceastÄƒ abordare este similarÄƒ cu R-CNN, dar regiunile sunt definite dupÄƒ ce straturile de convoluÈ›ie au fost aplicate.

![FRCNN](../../../../../translated_images/ro/f-rcnn.3cda6d9bb4188875.webp)

> Imagine din [Lucrarea OficialÄƒ](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Faster R-CNN

Ideea principalÄƒ a acestei abordÄƒri este de a folosi o reÈ›ea neuronalÄƒ pentru a prezice ROI-urile - aÈ™a-numita *ReÈ›ea de Propunere a Regiunilor*. [Lucrare](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../translated_images/ro/faster-rcnn.8d46c099b87ef30a.webp)

> Imagine din [lucrarea oficialÄƒ](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: ReÈ›ea Complet ConvoluÈ›ionalÄƒ BazatÄƒ pe Regiuni

Acest algoritm este chiar mai rapid decÃ¢t Faster R-CNN. Ideea principalÄƒ este urmÄƒtoarea:

1. Extragem caracteristici folosind ResNet-101.
2. Caracteristicile sunt procesate de **Position-Sensitive Score Map**. Fiecare obiect din $C$ clase este Ã®mpÄƒrÈ›it Ã®n regiuni $k\times k$, È™i antrenÄƒm pentru a prezice pÄƒrÈ›i ale obiectelor.
3. Pentru fiecare parte din regiunile $k\times k$, toate reÈ›elele voteazÄƒ pentru clasele de obiecte, iar clasa de obiect cu votul maxim este selectatÄƒ.

![r-fcn image](../../../../../translated_images/ro/r-fcn.13eb88158b99a3da.webp)

> Imagine din [lucrarea oficialÄƒ](https://arxiv.org/abs/1605.06409)

### YOLO - You Only Look Once

YOLO este un algoritm Ã®n timp real, cu o singurÄƒ trecere. Ideea principalÄƒ este urmÄƒtoarea:

 * Imaginea este Ã®mpÄƒrÈ›itÄƒ Ã®n regiuni $S\times S$.
 * Pentru fiecare regiune, **CNN** prezice $n$ obiecte posibile, coordonatele *casetei de delimitare* È™i *Ã®ncrederea*=*probabilitatea* * IoU.

 ![YOLO](../../../../../translated_images/ro/yolo.a2648ec82ee8bb4e.webp)

> Imagine din [lucrarea oficialÄƒ](https://arxiv.org/abs/1506.02640)

### Alte Algoritmi

* RetinaNet: [lucrare oficialÄƒ](https://arxiv.org/abs/1708.02002)
   - [Implementare PyTorch Ã®n Torchvision](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Implementare Keras](https://github.com/fizyr/keras-retinanet)
   - [Detectarea Obiectelor cu RetinaNet](https://keras.io/examples/vision/retinanet/) Ã®n exemplele Keras
* SSD (Single Shot Detector): [lucrare oficialÄƒ](https://arxiv.org/abs/1512.02325)

## âœï¸ ExerciÈ›ii: Detectarea Obiectelor

ContinuÄƒ Ã®nvÄƒÈ›area Ã®n urmÄƒtorul notebook:

[ObjectDetection.ipynb](ObjectDetection.ipynb)

## Concluzie

Ãn aceastÄƒ lecÈ›ie ai explorat rapid toate modurile diferite prin care detectarea obiectelor poate fi realizatÄƒ!

## ğŸš€ Provocare

CiteÈ™te aceste articole È™i notebook-uri despre YOLO È™i Ã®ncearcÄƒ-le singur:

* [Articol de blog bun](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/) despre YOLO
 * [Site oficial](https://pjreddie.com/darknet/yolo/)
 * Yolo: [Implementare Keras](https://github.com/experiencor/keras-yolo2), [notebook pas cu pas](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * Yolo v2: [Implementare Keras](https://github.com/experiencor/keras-yolo2), [notebook pas cu pas](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [Chestionar dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## Recapitulare & Studiu Individual

* [Detectarea Obiectelor](https://tjmachinelearning.com/lectures/1718/obj/) de Nikhil Sardana
* [O comparaÈ›ie bunÄƒ a algoritmilor de detectare a obiectelor](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [Revizuirea algoritmilor de Ã®nvÄƒÈ›are profundÄƒ pentru detectarea obiectelor](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [Introducere pas cu pas Ã®n algoritmii de bazÄƒ pentru detectarea obiectelor](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Implementarea Faster R-CNN Ã®n Python pentru detectarea obiectelor](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [TemÄƒ: Detectarea Obiectelor](lab/README.md)

---

