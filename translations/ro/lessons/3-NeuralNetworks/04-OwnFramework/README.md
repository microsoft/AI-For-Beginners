# Introducere Ã®n ReÈ›ele Neuronale. Perceptron Multi-Stratificat

Ãn secÈ›iunea anterioarÄƒ, ai Ã®nvÄƒÈ›at despre cel mai simplu model de reÈ›ea neuronalÄƒ - perceptronul cu un singur strat, un model liniar de clasificare Ã®n douÄƒ clase.

Ãn aceastÄƒ secÈ›iune vom extinde acest model Ã®ntr-un cadru mai flexibil, care ne va permite sÄƒ:

* realizÄƒm **clasificare multi-clasÄƒ** pe lÃ¢ngÄƒ clasificarea Ã®n douÄƒ clase
* rezolvÄƒm **probleme de regresie** pe lÃ¢ngÄƒ clasificare
* separÄƒm clase care nu sunt liniar separabile

De asemenea, vom dezvolta propriul nostru cadru modular Ã®n Python, care ne va permite sÄƒ construim diferite arhitecturi de reÈ›ele neuronale.

## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/7)

## Formalizarea ÃnvÄƒÈ›Äƒrii Automate

SÄƒ Ã®ncepem prin formalizarea problemei de ÃnvÄƒÈ›are AutomatÄƒ. Presupunem cÄƒ avem un set de date de antrenament **X** cu etichete **Y**, È™i trebuie sÄƒ construim un model *f* care sÄƒ facÄƒ predicÈ›ii cÃ¢t mai precise. Calitatea predicÈ›iilor este mÄƒsuratÄƒ prin **funcÈ›ia de pierdere** &lagran;. UrmÄƒtoarele funcÈ›ii de pierdere sunt adesea utilizate:

* Pentru probleme de regresie, cÃ¢nd trebuie sÄƒ prezicem un numÄƒr, putem folosi **eroarea absolutÄƒ** &sum;<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| sau **eroarea pÄƒtraticÄƒ** &sum;<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Pentru clasificare, folosim **pierdere 0-1** (care este, Ã®n esenÈ›Äƒ, acelaÈ™i lucru cu **acurateÈ›ea** modelului) sau **pierdere logisticÄƒ**.

Pentru perceptronul cu un singur strat, funcÈ›ia *f* a fost definitÄƒ ca o funcÈ›ie liniarÄƒ *f(x)=wx+b* (aici *w* este matricea de greutÄƒÈ›i, *x* este vectorul de caracteristici de intrare, iar *b* este vectorul de bias). Pentru diferite arhitecturi de reÈ›ele neuronale, aceastÄƒ funcÈ›ie poate lua o formÄƒ mai complexÄƒ.

> Ãn cazul clasificÄƒrii, este adesea de dorit sÄƒ obÈ›inem probabilitÄƒÈ›ile claselor corespunzÄƒtoare ca ieÈ™ire a reÈ›elei. Pentru a converti numere arbitrare Ã®n probabilitÄƒÈ›i (de exemplu, pentru a normaliza ieÈ™irea), folosim adesea funcÈ›ia **softmax** &sigma;, iar funcÈ›ia *f* devine *f(x)=&sigma;(wx+b)*

Ãn definiÈ›ia lui *f* de mai sus, *w* È™i *b* sunt numite **parametri** &theta;=âŸ¨*w,b*âŸ©. AvÃ¢nd setul de date âŸ¨**X**,**Y**âŸ©, putem calcula o eroare generalÄƒ pe Ã®ntregul set de date ca o funcÈ›ie de parametri &theta;.

> âœ… **Scopul antrenÄƒrii reÈ›elei neuronale este de a minimiza eroarea prin variarea parametrilor &theta;**

## Optimizarea prin Gradient Descent

ExistÄƒ o metodÄƒ bine-cunoscutÄƒ de optimizare a funcÈ›iilor numitÄƒ **gradient descent**. Ideea este cÄƒ putem calcula o derivatÄƒ (Ã®n cazul multidimensional numitÄƒ **gradient**) a funcÈ›iei de pierdere Ã®n raport cu parametrii È™i sÄƒ variem parametrii astfel Ã®ncÃ¢t eroarea sÄƒ scadÄƒ. Acest lucru poate fi formalizat astfel:

* IniÈ›ializaÈ›i parametrii cu valori aleatorii w<sup>(0)</sup>, b<sup>(0)</sup>
* RepetaÈ›i urmÄƒtorul pas de mai multe ori:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-&eta;&part;&lagran;/&part;w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-&eta;&part;&lagran;/&part;b

Ãn timpul antrenÄƒrii, paÈ™ii de optimizare ar trebui sÄƒ fie calculaÈ›i luÃ¢nd Ã®n considerare Ã®ntregul set de date (amintiÈ›i-vÄƒ cÄƒ pierderea este calculatÄƒ ca o sumÄƒ pentru toate exemplele de antrenament). TotuÈ™i, Ã®n practicÄƒ, luÄƒm porÈ›iuni mici ale setului de date numite **minibatch-uri** È™i calculÄƒm gradientele pe baza unui subset de date. Deoarece subsetul este luat aleator de fiecare datÄƒ, aceastÄƒ metodÄƒ este numitÄƒ **stochastic gradient descent** (SGD).

## Perceptron Multi-Stratificat È™i Backpropagation

ReÈ›eaua cu un singur strat, aÈ™a cum am vÄƒzut mai sus, este capabilÄƒ sÄƒ clasifice clase liniar separabile. Pentru a construi un model mai bogat, putem combina mai multe straturi ale reÈ›elei. Matematic, aceasta ar Ã®nsemna cÄƒ funcÈ›ia *f* ar avea o formÄƒ mai complexÄƒ È™i va fi calculatÄƒ Ã®n mai mulÈ›i paÈ™i:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>&alpha;(z<sub>1</sub>)+b<sub>2</sub>
* f = &sigma;(z<sub>2</sub>)

Aici, &alpha; este o **funcÈ›ie de activare non-liniarÄƒ**, &sigma; este o funcÈ›ie softmax, iar parametrii &theta;=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Algoritmul gradient descent ar rÄƒmÃ¢ne acelaÈ™i, dar ar fi mai dificil de calculat gradientele. AvÃ¢nd regula de diferenÈ›iere Ã®n lanÈ›, putem calcula derivatele astfel:

* &part;&lagran;/&part;w<sub>2</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;w<sub>2</sub>)
* &part;&lagran;/&part;w<sub>1</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;&alpha;)(&part;&alpha;/&part;z<sub>1</sub>)(&part;z<sub>1</sub>/&part;w<sub>1</sub>)

> âœ… Regula de diferenÈ›iere Ã®n lanÈ› este utilizatÄƒ pentru a calcula derivatele funcÈ›iei de pierdere Ã®n raport cu parametrii.

ObservaÈ›i cÄƒ partea din stÃ¢nga a tuturor acestor expresii este aceeaÈ™i, È™i astfel putem calcula eficient derivatele Ã®ncepÃ¢nd de la funcÈ›ia de pierdere È™i mergÃ¢nd "Ã®napoi" prin graful computaÈ›ional. Astfel, metoda de antrenare a unui perceptron multi-stratificat este numitÄƒ **backpropagation**, sau 'backprop'.

<img alt="compute graph" src="../../../../../translated_images/ro/ComputeGraphGrad.4626252c0de03507.webp"/>

> TODO: citarea imaginii

> âœ… Vom acoperi backprop Ã®n mult mai multe detalii Ã®n exemplul nostru din notebook.  

## Concluzie

Ãn aceastÄƒ lecÈ›ie, am construit propria noastrÄƒ bibliotecÄƒ de reÈ›ele neuronale È™i am folosit-o pentru o sarcinÄƒ simplÄƒ de clasificare bidimensionalÄƒ.

## ğŸš€ Provocare

Ãn notebook-ul Ã®nsoÈ›itor, vei implementa propriul cadru pentru construirea È™i antrenarea perceptronilor multi-stratificaÈ›i. Vei putea vedea Ã®n detaliu cum funcÈ›ioneazÄƒ reÈ›elele neuronale moderne.

AcceseazÄƒ notebook-ul [OwnFramework](OwnFramework.ipynb) È™i parcurge-l.

## [Chestionar dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ai/quiz/8)

## Recapitulare È™i Studiu Individual

Backpropagation este un algoritm comun utilizat Ã®n AI È™i ML, meritÄƒ studiat [Ã®n detaliu](https://wikipedia.org/wiki/Backpropagation)

## [TemÄƒ](lab/README.md)

Ãn acest laborator, È›i se cere sÄƒ foloseÈ™ti cadrul pe care l-ai construit Ã®n aceastÄƒ lecÈ›ie pentru a rezolva clasificarea cifrelor scrise de mÃ¢nÄƒ din MNIST.

* [InstrucÈ›iuni](lab/README.md)
* [Notebook](lab/MyFW_MNIST.ipynb)

---

