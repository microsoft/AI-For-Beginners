# K칛nda CNN-arkitekturer

### VGG-16

VGG-16 칛r ett n칛tverk som uppn친dde 92,7% noggrannhet i ImageNet top-5 klassificering 2014. Det har f칬ljande lagerstruktur:

![ImageNet Layers](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.sw.jpg)

Som du kan se f칬ljer VGG en traditionell pyramidarkitektur, som 칛r en sekvens av konvolution-poolingslager.

![ImageNet Pyramid](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.sw.jpg)

> Bild fr친n [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet 칛r en familj av modeller som f칬reslogs av Microsoft Research 2015. Huvudid칠n med ResNet 칛r att anv칛nda **residualblock**:

<img src="images/resnet-block.png" width="300"/>

> Bild fr친n [denna artikel](https://arxiv.org/pdf/1512.03385.pdf)

Anledningen till att anv칛nda identitetspassering 칛r att f친 v친rt lager att f칬ruts칛ga **skillnaden** mellan resultatet av ett tidigare lager och utg친ngen av residualblocket - d칛rav namnet *residual*. Dessa block 칛r mycket l칛ttare att tr칛na, och man kan konstruera n칛tverk med flera hundra av dessa block (de vanligaste varianterna 칛r ResNet-52, ResNet-101 och ResNet-152).

Du kan ocks친 t칛nka p친 detta n칛tverk som kapabelt att justera sin komplexitet efter datasetet. I b칬rjan, n칛r du b칬rjar tr칛na n칛tverket, 칛r viktv칛rdena sm친, och mestadels av signalen g친r genom identitetslager. N칛r tr칛ningen fortskrider och vikterna blir st칬rre, v칛xer betydelsen av n칛tverksparametrarna, och n칛tverken justerar sig f칬r att rymma den n칬dv칛ndiga uttryckskraften f칬r att korrekt klassificera tr칛ningsbilder.

### Google Inception

Google Inception-arkitekturen tar denna id칠 ett steg l칛ngre och bygger varje n칛tverkslager som en kombination av flera olika v칛gar:

<img src="images/inception.png" width="400"/>

> Bild fr친n [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

H칛r beh칬ver vi betona rollen av 1x1-konvolutioner, eftersom de i b칬rjan inte verkar meningsfulla. Varf칬r skulle vi beh칬va k칬ra genom bilden med ett 1x1-filter? Men du m친ste komma ih친g att konvolutionsfilter ocks친 arbetar med flera djupkanaler (ursprungligen - RGB-f칛rger, i efterf칬ljande lager - kanaler f칬r olika filter), och 1x1-konvolution anv칛nds f칬r att blanda dessa ing친ngskanaler tillsammans med hj칛lp av olika tr칛ningsbara vikter. Det kan ocks친 ses som nedsampling (pooling) 칬ver kanalens dimension.

H칛r 칛r [ett bra blogginl칛gg](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) om 칛mnet, och [den ursprungliga artikeln](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet 칛r en familj av modeller med minskad storlek, l칛mpliga f칬r mobila enheter. Anv칛nd dem om du har begr칛nsade resurser och kan offra lite noggrannhet. Huvudid칠n bakom dem 칛r den s친 kallade **djupseparerade konvolutionen**, som till친ter att representera konvolutionsfilter genom en sammans칛ttning av rumsliga konvolutioner och 1x1-konvolution 칬ver djupkanaler. Detta minskar avsev칛rt antalet parametrar, vilket g칬r n칛tverket mindre i storlek och ocks친 l칛ttare att tr칛na med mindre data.

H칛r 칛r [ett bra blogginl칛gg om MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Slutsats

I denna enhet har du l칛rt dig det huvudsakliga konceptet bakom datorvisionsneuron칛tverk - konvolutionella n칛tverk. Verkliga arkitekturer som driver bildklassificering, objektdetektering och till och med bildgenereringsn칛tverk 칛r alla baserade p친 CNN, bara med fler lager och n친gra ytterligare tr칛ningsknep.

## 游 Utmaning

I de medf칬ljande anteckningarna finns det noteringar l칛ngst ner om hur man kan uppn친 st칬rre noggrannhet. G칬r n친gra experiment f칬r att se om du kan uppn친 h칬gre noggrannhet.

## [Efterf칬rel칛sningsquiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/207)

## Granskning & Sj칛lvstudie

츿ven om CNN oftast anv칛nds f칬r datorvisionsuppgifter, 칛r de generellt bra f칬r att extrahera m칬nster av fast storlek. Till exempel, om vi hanterar ljud, kan vi ocks친 vilja anv칛nda CNN f칬r att leta efter specifika m칬nster i ljudsignalen - i vilket fall filter skulle vara 1-dimensionella (och detta CNN skulle kallas 1D-CNN). Dessutom anv칛nds ibland 3D-CNN f칬r att extrahera funktioner i flerdimensionellt utrymme, s친som vissa h칛ndelser som intr칛ffar p친 video - CNN kan f친nga vissa m칬nster av funktioner som f칬r칛ndras 칬ver tid. G칬r en granskning och sj칛lvstudie om andra uppgifter som kan g칬ras med CNN.

## [Uppgift](lab/README.md)

I detta laboratorium 칛r du ansvarig f칬r att klassificera olika katt- och hundraser. Dessa bilder 칛r mer komplexa 칛n MNIST-datasetet och har h칬gre dimensioner, och det finns mer 칛n 10 klasser.

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av maskinbaserade AI-칬vers칛ttningstj칛nster. 츿ven om vi str칛var efter noggrannhet, v칛nligen var medveten om att automatiserade 칬vers칛ttningar kan inneh친lla fel eller oegentligheter. Det ursprungliga dokumentet p친 sitt modersm친l b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r n친gra missf칬rst친nd eller felaktiga tolkningar som uppst친r till f칬ljd av anv칛ndningen av denna 칬vers칛ttning.