<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-25T22:29:05+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "cs"
}
-->
# AutoenkodÃ©ry

PÅ™i trÃ©novÃ¡nÃ­ CNN je jednÃ­m z problÃ©mÅ¯ potÅ™eba velkÃ©ho mnoÅ¾stvÃ­ oznaÄenÃ½ch dat. V pÅ™Ã­padÄ› klasifikace obrÃ¡zkÅ¯ je nutnÃ© rozdÄ›lit obrÃ¡zky do rÅ¯znÃ½ch tÅ™Ã­d, coÅ¾ vyÅ¾aduje manuÃ¡lnÃ­ ÃºsilÃ­.

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

MÅ¯Å¾eme vÅ¡ak chtÃ­t pouÅ¾Ã­t surovÃ¡ (neoznaÄenÃ¡) data pro trÃ©novÃ¡nÃ­ CNN extraktorÅ¯ funkcÃ­, coÅ¾ se nazÃ½vÃ¡ **self-supervised learning**. MÃ­sto Å¡tÃ­tkÅ¯ pouÅ¾ijeme trÃ©novacÃ­ obrÃ¡zky jako vstup i vÃ½stup sÃ­tÄ›. HlavnÃ­ myÅ¡lenkou **autoenkodÃ©ru** je, Å¾e budeme mÃ­t **enkodÃ©r sÃ­Å¥**, kterÃ¡ pÅ™evede vstupnÃ­ obrÃ¡zek do nÄ›jakÃ©ho **latentnÃ­ho prostoru** (obvykle je to jen vektor menÅ¡Ã­ velikosti), a potÃ© **dekodÃ©r sÃ­Å¥**, jejÃ­mÅ¾ cÃ­lem bude rekonstruovat pÅ¯vodnÃ­ obrÃ¡zek.

> âœ… [AutoenkodÃ©r](https://wikipedia.org/wiki/Autoencoder) je "typ umÄ›lÃ© neuronovÃ© sÃ­tÄ› pouÅ¾Ã­vanÃ© k uÄenÃ­ efektivnÃ­ho kÃ³dovÃ¡nÃ­ neoznaÄenÃ½ch dat."

ProtoÅ¾e trÃ©nujeme autoenkodÃ©r, aby zachytil co nejvÃ­ce informacÃ­ z pÅ¯vodnÃ­ho obrÃ¡zku pro pÅ™esnou rekonstrukci, sÃ­Å¥ se snaÅ¾Ã­ najÃ­t nejlepÅ¡Ã­ **embedding** vstupnÃ­ch obrÃ¡zkÅ¯, aby zachytila jejich vÃ½znam.

![SchÃ©ma AutoenkodÃ©ru](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.cs.jpg)

> ObrÃ¡zek z [blogu Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## ScÃ©nÃ¡Å™e pouÅ¾itÃ­ AutoenkodÃ©rÅ¯

AÄkoli samotnÃ¡ rekonstrukce pÅ¯vodnÃ­ch obrÃ¡zkÅ¯ nemusÃ­ bÃ½t uÅ¾iteÄnÃ¡, existuje nÄ›kolik scÃ©nÃ¡Å™Å¯, kde jsou autoenkodÃ©ry obzvlÃ¡Å¡tÄ› uÅ¾iteÄnÃ©:

* **SnÃ­Å¾enÃ­ dimenze obrÃ¡zkÅ¯ pro vizualizaci** nebo **trÃ©novÃ¡nÃ­ embeddingÅ¯ obrÃ¡zkÅ¯**. AutoenkodÃ©ry obvykle poskytujÃ­ lepÅ¡Ã­ vÃ½sledky neÅ¾ PCA, protoÅ¾e berou v Ãºvahu prostorovou povahu obrÃ¡zkÅ¯ a hierarchickÃ© funkce.
* **OdstraÅˆovÃ¡nÃ­ Å¡umu**, tj. odstranÄ›nÃ­ Å¡umu z obrÃ¡zku. ProtoÅ¾e Å¡um obsahuje mnoho zbyteÄnÃ½ch informacÃ­, autoenkodÃ©r nemÅ¯Å¾e vÅ¡e vmÄ›stnat do relativnÄ› malÃ©ho latentnÃ­ho prostoru, a tak zachytÃ­ pouze dÅ¯leÅ¾itÃ© ÄÃ¡sti obrÃ¡zku. PÅ™i trÃ©novÃ¡nÃ­ odstraÅˆovaÄÅ¯ Å¡umu zaÄÃ­nÃ¡me s pÅ¯vodnÃ­mi obrÃ¡zky a pouÅ¾Ã­vÃ¡me obrÃ¡zky s umÄ›le pÅ™idanÃ½m Å¡umem jako vstup pro autoenkodÃ©r.
* **Super-rezoluce**, zvÃ½Å¡enÃ­ rozliÅ¡enÃ­ obrÃ¡zku. ZaÄÃ­nÃ¡me s obrÃ¡zky ve vysokÃ©m rozliÅ¡enÃ­ a pouÅ¾Ã­vÃ¡me obrÃ¡zky s niÅ¾Å¡Ã­m rozliÅ¡enÃ­m jako vstup pro autoenkodÃ©r.
* **GenerativnÃ­ modely**. Jakmile autoenkodÃ©r vytrÃ©nujeme, dekodÃ©r mÅ¯Å¾e bÃ½t pouÅ¾it k vytvoÅ™enÃ­ novÃ½ch objektÅ¯ na zÃ¡kladÄ› nÃ¡hodnÃ½ch latentnÃ­ch vektorÅ¯.

## VariabilnÃ­ AutoenkodÃ©ry (VAE)

TradiÄnÃ­ autoenkodÃ©ry nÄ›jakÃ½m zpÅ¯sobem sniÅ¾ujÃ­ dimenzi vstupnÃ­ch dat a zjiÅ¡Å¥ujÃ­ dÅ¯leÅ¾itÃ© vlastnosti vstupnÃ­ch obrÃ¡zkÅ¯. LatentnÃ­ vektory vÅ¡ak Äasto nedÃ¡vajÃ­ pÅ™Ã­liÅ¡ smysl. JinÃ½mi slovy, pokud vezmeme dataset MNIST jako pÅ™Ã­klad, zjistit, kterÃ© ÄÃ­slice odpovÃ­dajÃ­ rÅ¯znÃ½m latentnÃ­m vektorÅ¯m, nenÃ­ snadnÃ½ Ãºkol, protoÅ¾e blÃ­zkÃ© latentnÃ­ vektory nemusÃ­ nutnÄ› odpovÃ­dat stejnÃ½m ÄÃ­slicÃ­m.

Na druhou stranu, pro trÃ©novÃ¡nÃ­ *generativnÃ­ch* modelÅ¯ je lepÅ¡Ã­ mÃ­t nÄ›jakÃ© porozumÄ›nÃ­ latentnÃ­mu prostoru. Tato myÅ¡lenka nÃ¡s vede k **variabilnÃ­mu autoenkodÃ©ru** (VAE).

VAE je autoenkodÃ©r, kterÃ½ se uÄÃ­ pÅ™edpovÃ­dat *statistickÃ© rozdÄ›lenÃ­* latentnÃ­ch parametrÅ¯, tzv. **latentnÃ­ rozdÄ›lenÃ­**. NapÅ™Ã­klad mÅ¯Å¾eme chtÃ­t, aby latentnÃ­ vektory byly normÃ¡lnÄ› rozdÄ›lenÃ© s nÄ›jakÃ½m prÅ¯mÄ›rem z<sub>mean</sub> a standardnÃ­ odchylkou z<sub>sigma</sub> (prÅ¯mÄ›r i standardnÃ­ odchylka jsou vektory nÄ›jakÃ© dimenze d). EnkodÃ©r ve VAE se uÄÃ­ pÅ™edpovÃ­dat tyto parametry a dekodÃ©r potÃ© vezme nÃ¡hodnÃ½ vektor z tohoto rozdÄ›lenÃ­ k rekonstrukci objektu.

ShrnutÃ­:

 * Ze vstupnÃ­ho vektoru pÅ™edpovÃ­dÃ¡me `z_mean` a `z_log_sigma` (mÃ­sto pÅ™edpovÃ­dÃ¡nÃ­ samotnÃ© standardnÃ­ odchylky pÅ™edpovÃ­dÃ¡me jejÃ­ logaritmus)
 * Vzorkujeme vektor `sample` z rozdÄ›lenÃ­ N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * DekodÃ©r se snaÅ¾Ã­ dekÃ³dovat pÅ¯vodnÃ­ obrÃ¡zek pomocÃ­ `sample` jako vstupnÃ­ho vektoru

 <img src="images/vae.png" width="50%">

> ObrÃ¡zek z [tohoto blogovÃ©ho pÅ™Ã­spÄ›vku](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) od Isaaka Dykemana

VariabilnÃ­ autoenkodÃ©ry pouÅ¾Ã­vajÃ­ komplexnÃ­ ztrÃ¡tovou funkci, kterÃ¡ se sklÃ¡dÃ¡ ze dvou ÄÃ¡stÃ­:

* **ZtrÃ¡ta rekonstrukce** je ztrÃ¡tovÃ¡ funkce, kterÃ¡ ukazuje, jak blÃ­zko je rekonstruovanÃ½ obrÃ¡zek cÃ­li (mÅ¯Å¾e to bÃ½t Mean Squared Error, nebo MSE). Je to stejnÃ¡ ztrÃ¡tovÃ¡ funkce jako u bÄ›Å¾nÃ½ch autoenkodÃ©rÅ¯.
* **KL ztrÃ¡ta**, kterÃ¡ zajiÅ¡Å¥uje, Å¾e rozdÄ›lenÃ­ latentnÃ­ch promÄ›nnÃ½ch zÅ¯stÃ¡vÃ¡ blÃ­zko normÃ¡lnÃ­mu rozdÄ›lenÃ­. Je zaloÅ¾ena na pojmu [Kullback-Leibler divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - metrice pro odhad podobnosti dvou statistickÃ½ch rozdÄ›lenÃ­.

Jednou z dÅ¯leÅ¾itÃ½ch vÃ½hod VAE je, Å¾e umoÅ¾ÅˆujÃ­ relativnÄ› snadno generovat novÃ© obrÃ¡zky, protoÅ¾e vÃ­me, z jakÃ©ho rozdÄ›lenÃ­ vzorkovat latentnÃ­ vektory. NapÅ™Ã­klad pokud trÃ©nujeme VAE s 2D latentnÃ­m vektorem na MNIST, mÅ¯Å¾eme potÃ© mÄ›nit komponenty latentnÃ­ho vektoru, abychom zÃ­skali rÅ¯znÃ© ÄÃ­slice:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> ObrÃ¡zek od [Dmitry Soshnikov](http://soshnikov.com)

Pozorujte, jak se obrÃ¡zky prolÃ­najÃ­, kdyÅ¾ zaÄneme zÃ­skÃ¡vat latentnÃ­ vektory z rÅ¯znÃ½ch ÄÃ¡stÃ­ prostoru latentnÃ­ch parametrÅ¯. Tento prostor mÅ¯Å¾eme takÃ© vizualizovat ve 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> ObrÃ¡zek od [Dmitry Soshnikov](http://soshnikov.com)

## âœï¸ CviÄenÃ­: AutoenkodÃ©ry

ZjistÄ›te vÃ­ce o autoenkodÃ©rech v tÄ›chto odpovÃ­dajÃ­cÃ­ch noteboocÃ­ch:

* [AutoenkodÃ©ry v TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [AutoenkodÃ©ry v PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Vlastnosti AutoenkodÃ©rÅ¯

* **SpecifickÃ© pro data** - fungujÃ­ dobÅ™e pouze s typem obrÃ¡zkÅ¯, na kterÃ½ch byly trÃ©novÃ¡ny. NapÅ™Ã­klad pokud trÃ©nujeme sÃ­Å¥ pro super-rezoluce na kvÄ›tinÃ¡ch, nebude dobÅ™e fungovat na portrÃ©tech. Je to proto, Å¾e sÃ­Å¥ mÅ¯Å¾e vytvoÅ™it obrÃ¡zek ve vyÅ¡Å¡Ã­m rozliÅ¡enÃ­ tÃ­m, Å¾e vezme jemnÃ© detaily z funkcÃ­ nauÄenÃ½ch z trÃ©novacÃ­ho datasetu.
* **ZtrÃ¡tovÃ©** - rekonstruovanÃ½ obrÃ¡zek nenÃ­ stejnÃ½ jako pÅ¯vodnÃ­ obrÃ¡zek. Povaha ztrÃ¡ty je definovÃ¡na *ztrÃ¡tovou funkcÃ­* pouÅ¾itou bÄ›hem trÃ©novÃ¡nÃ­.
* FungujÃ­ na **neoznaÄenÃ½ch datech**

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## ZÃ¡vÄ›r

V tÃ©to lekci jste se nauÄili o rÅ¯znÃ½ch typech autoenkodÃ©rÅ¯ dostupnÃ½ch pro vÄ›dce v oblasti AI. NauÄili jste se, jak je vytvoÅ™it a jak je pouÅ¾Ã­t k rekonstrukci obrÃ¡zkÅ¯. TakÃ© jste se nauÄili o VAE a jak je pouÅ¾Ã­t k generovÃ¡nÃ­ novÃ½ch obrÃ¡zkÅ¯.

## ğŸš€ VÃ½zva

V tÃ©to lekci jste se nauÄili pouÅ¾Ã­vat autoenkodÃ©ry pro obrÃ¡zky. Ale mohou bÃ½t takÃ© pouÅ¾ity pro hudbu! PodÃ­vejte se na projekt Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), kterÃ½ pouÅ¾Ã­vÃ¡ autoenkodÃ©ry k uÄenÃ­ rekonstrukce hudby. UdÄ›lejte nÄ›kolik [experimentÅ¯](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) s touto knihovnou a zjistÄ›te, co mÅ¯Å¾ete vytvoÅ™it.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## PÅ™ehled & Samostudium

Pro referenci si pÅ™eÄtÄ›te vÃ­ce o autoenkodÃ©rech v tÄ›chto zdrojÃ­ch:

* [Building Autoencoders in Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [BlogovÃ½ pÅ™Ã­spÄ›vek na NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Variational Autoencoders Explained](https://kvfrans.com/variational-autoencoders-explained/)
* [Conditional Variational Autoencoders](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Ãškol

Na konci [tohoto notebooku s TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) najdete 'Ãºkol' - pouÅ¾ijte jej jako svÅ¯j domÃ¡cÃ­ Ãºkol.

**ProhlÃ¡Å¡enÃ­:**  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.