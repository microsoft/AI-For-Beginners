# AutoenkodÃ©ry

PÅ™i trÃ©novÃ¡nÃ­ CNN je jednÃ­m z problÃ©mÅ¯, Å¾e potÅ™ebujeme velkÃ© mnoÅ¾stvÃ­ oznaÄenÃ½ch dat. V pÅ™Ã­padÄ› klasifikace obrÃ¡zkÅ¯ musÃ­me obrÃ¡zky rozdÄ›lit do rÅ¯znÃ½ch tÅ™Ã­d, coÅ¾ je manuÃ¡lnÃ­ prÃ¡ce.

## [KvÃ­z pÅ™ed lekcÃ­](https://ff-quizzes.netlify.app/en/ai/quiz/17)

NicmÃ©nÄ› bychom mohli chtÃ­t pouÅ¾Ã­t surovÃ¡ (neoznaÄenÃ¡) data pro trÃ©novÃ¡nÃ­ extraktorÅ¯ funkcÃ­ CNN, coÅ¾ se nazÃ½vÃ¡ **self-supervised learning** (samostatnÄ› Å™Ã­zenÃ© uÄenÃ­). MÃ­sto Å¡tÃ­tkÅ¯ pouÅ¾ijeme trÃ©novacÃ­ obrÃ¡zky jako vstup i vÃ½stup sÃ­tÄ›. HlavnÃ­ myÅ¡lenkou **autoenkodÃ©ru** je, Å¾e budeme mÃ­t **enkodÃ©rovou sÃ­Å¥**, kterÃ¡ pÅ™evÃ¡dÃ­ vstupnÃ­ obrÃ¡zek do nÄ›jakÃ©ho **latentnÃ­ho prostoru** (obvykle je to jen vektor menÅ¡Ã­ velikosti), a potÃ© **dekodÃ©rovou sÃ­Å¥**, jejÃ­mÅ¾ cÃ­lem bude rekonstruovat pÅ¯vodnÃ­ obrÃ¡zek.

> âœ… [AutoenkodÃ©r](https://wikipedia.org/wiki/Autoencoder) je "typ umÄ›lÃ© neuronovÃ© sÃ­tÄ› pouÅ¾Ã­vanÃ© k uÄenÃ­ efektivnÃ­ho kÃ³dovÃ¡nÃ­ neoznaÄenÃ½ch dat."

ProtoÅ¾e trÃ©nujeme autoenkodÃ©r, aby zachytil co nejvÃ­ce informacÃ­ z pÅ¯vodnÃ­ho obrÃ¡zku pro pÅ™esnou rekonstrukci, sÃ­Å¥ se snaÅ¾Ã­ najÃ­t nejlepÅ¡Ã­ **embedding** vstupnÃ­ch obrÃ¡zkÅ¯, aby zachytila jejich vÃ½znam.

![SchÃ©ma AutoenkodÃ©ru](../../../../../translated_images/cs/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> ObrÃ¡zek z [blogu Keras](https://blog.keras.io/building-autoencoders-in-keras.html)

## ScÃ©nÃ¡Å™e pouÅ¾itÃ­ autoenkodÃ©rÅ¯

AÄkoli samotnÃ¡ rekonstrukce pÅ¯vodnÃ­ch obrÃ¡zkÅ¯ nemusÃ­ bÃ½t uÅ¾iteÄnÃ¡, existuje nÄ›kolik scÃ©nÃ¡Å™Å¯, kde jsou autoenkodÃ©ry obzvlÃ¡Å¡tÄ› uÅ¾iteÄnÃ©:

* **SnÃ­Å¾enÃ­ dimenze obrÃ¡zkÅ¯ pro vizualizaci** nebo **trÃ©novÃ¡nÃ­ obrazovÃ½ch embeddingÅ¯**. AutoenkodÃ©ry obvykle poskytujÃ­ lepÅ¡Ã­ vÃ½sledky neÅ¾ PCA, protoÅ¾e berou v Ãºvahu prostorovou povahu obrÃ¡zkÅ¯ a hierarchickÃ© funkce.
* **OdstraÅˆovÃ¡nÃ­ Å¡umu**, tj. odstranÄ›nÃ­ Å¡umu z obrÃ¡zku. ProtoÅ¾e Å¡um obsahuje mnoho zbyteÄnÃ½ch informacÃ­, autoenkodÃ©r nemÅ¯Å¾e vÅ¡e vmÄ›stnat do relativnÄ› malÃ©ho latentnÃ­ho prostoru, a tak zachytÃ­ pouze dÅ¯leÅ¾itÃ© ÄÃ¡sti obrÃ¡zku. PÅ™i trÃ©novÃ¡nÃ­ odstraÅˆovaÄÅ¯ Å¡umu zaÄÃ­nÃ¡me s pÅ¯vodnÃ­mi obrÃ¡zky a pouÅ¾Ã­vÃ¡me obrÃ¡zky s umÄ›le pÅ™idanÃ½m Å¡umem jako vstup pro autoenkodÃ©r.
* **Super-rezoluce**, zvÃ½Å¡enÃ­ rozliÅ¡enÃ­ obrÃ¡zku. ZaÄÃ­nÃ¡me s obrÃ¡zky ve vysokÃ©m rozliÅ¡enÃ­ a pouÅ¾Ã­vÃ¡me obrÃ¡zek s niÅ¾Å¡Ã­m rozliÅ¡enÃ­m jako vstup pro autoenkodÃ©r.
* **GenerativnÃ­ modely**. Jakmile autoenkodÃ©r vytrÃ©nujeme, dekodÃ©rovou ÄÃ¡st mÅ¯Å¾eme pouÅ¾Ã­t k vytvoÅ™enÃ­ novÃ½ch objektÅ¯ na zÃ¡kladÄ› nÃ¡hodnÃ½ch latentnÃ­ch vektorÅ¯.

## VariabilnÃ­ autoenkodÃ©ry (VAE)

TradiÄnÃ­ autoenkodÃ©ry nÄ›jakÃ½m zpÅ¯sobem sniÅ¾ujÃ­ dimenzi vstupnÃ­ch dat a zjiÅ¡Å¥ujÃ­ dÅ¯leÅ¾itÃ© vlastnosti vstupnÃ­ch obrÃ¡zkÅ¯. LatentnÃ­ vektory vÅ¡ak Äasto nedÃ¡vajÃ­ pÅ™Ã­liÅ¡ smysl. JinÃ½mi slovy, pokud vezmeme dataset MNIST jako pÅ™Ã­klad, zjistit, kterÃ© ÄÃ­slice odpovÃ­dajÃ­ rÅ¯znÃ½m latentnÃ­m vektorÅ¯m, nenÃ­ snadnÃ½ Ãºkol, protoÅ¾e blÃ­zkÃ© latentnÃ­ vektory nemusÃ­ nutnÄ› odpovÃ­dat stejnÃ½m ÄÃ­slicÃ­m.

Na druhou stranu, pro trÃ©novÃ¡nÃ­ *generativnÃ­ch* modelÅ¯ je lepÅ¡Ã­ mÃ­t nÄ›jakÃ© pochopenÃ­ latentnÃ­ho prostoru. Tato myÅ¡lenka nÃ¡s vede k **variabilnÃ­mu autoenkodÃ©ru** (VAE).

VAE je autoenkodÃ©r, kterÃ½ se uÄÃ­ pÅ™edpovÃ­dat *statistickÃ© rozloÅ¾enÃ­* latentnÃ­ch parametrÅ¯, tzv. **latentnÃ­ rozloÅ¾enÃ­**. NapÅ™Ã­klad mÅ¯Å¾eme chtÃ­t, aby latentnÃ­ vektory byly normÃ¡lnÄ› rozloÅ¾eny s nÄ›jakÃ½m prÅ¯mÄ›rem z<sub>mean</sub> a smÄ›rodatnou odchylkou z<sub>sigma</sub> (prÅ¯mÄ›r i smÄ›rodatnÃ¡ odchylka jsou vektory urÄitÃ© dimenze d). EnkodÃ©r ve VAE se uÄÃ­ pÅ™edpovÃ­dat tyto parametry a dekodÃ©r potÃ© vezme nÃ¡hodnÃ½ vektor z tohoto rozloÅ¾enÃ­ k rekonstrukci objektu.

ShrnutÃ­:

 * Ze vstupnÃ­ho vektoru pÅ™edpovÃ­dÃ¡me `z_mean` a `z_log_sigma` (mÃ­sto pÅ™edpovÃ­dÃ¡nÃ­ samotnÃ© smÄ›rodatnÃ© odchylky pÅ™edpovÃ­dÃ¡me jejÃ­ logaritmus)
 * Vzorkujeme vektor `sample` z rozloÅ¾enÃ­ N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * DekodÃ©r se snaÅ¾Ã­ dekÃ³dovat pÅ¯vodnÃ­ obrÃ¡zek pomocÃ­ `sample` jako vstupnÃ­ho vektoru

 <img src="../../../../../translated_images/cs/vae.464c465a5b6a9e25.webp" width="50%">

> ObrÃ¡zek z [tohoto blogovÃ©ho pÅ™Ã­spÄ›vku](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) od Isaaka Dykemana

VariabilnÃ­ autoenkodÃ©ry pouÅ¾Ã­vajÃ­ sloÅ¾itou ztrÃ¡tovou funkci, kterÃ¡ se sklÃ¡dÃ¡ ze dvou ÄÃ¡stÃ­:

* **ZtrÃ¡ta rekonstrukce** je ztrÃ¡tovÃ¡ funkce, kterÃ¡ ukazuje, jak blÃ­zko je rekonstruovanÃ½ obrÃ¡zek cÃ­li (mÅ¯Å¾e to bÃ½t Mean Squared Error, nebo MSE). Je to stejnÃ¡ ztrÃ¡tovÃ¡ funkce jako u bÄ›Å¾nÃ½ch autoenkodÃ©rÅ¯.
* **KL ztrÃ¡ta**, kterÃ¡ zajiÅ¡Å¥uje, Å¾e rozloÅ¾enÃ­ latentnÃ­ch promÄ›nnÃ½ch zÅ¯stÃ¡vÃ¡ blÃ­zko normÃ¡lnÃ­mu rozloÅ¾enÃ­. Je zaloÅ¾ena na pojmu [Kullback-Leiblerovy divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - metriky pro odhad podobnosti dvou statistickÃ½ch rozloÅ¾enÃ­.

Jednou z dÅ¯leÅ¾itÃ½ch vÃ½hod VAE je, Å¾e nÃ¡m umoÅ¾ÅˆujÃ­ relativnÄ› snadno generovat novÃ© obrÃ¡zky, protoÅ¾e vÃ­me, z jakÃ©ho rozloÅ¾enÃ­ vzorkovat latentnÃ­ vektory. NapÅ™Ã­klad pokud trÃ©nujeme VAE s 2D latentnÃ­m vektorem na MNIST, mÅ¯Å¾eme potÃ© mÄ›nit komponenty latentnÃ­ho vektoru, abychom zÃ­skali rÅ¯znÃ© ÄÃ­slice:

<img alt="vaemnist" src="../../../../../translated_images/cs/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> ObrÃ¡zek od [Dmitrije Soshnikova](http://soshnikov.com)

Pozorujte, jak se obrÃ¡zky prolÃ­najÃ­, kdyÅ¾ zaÄneme zÃ­skÃ¡vat latentnÃ­ vektory z rÅ¯znÃ½ch ÄÃ¡stÃ­ latentnÃ­ho prostoru parametrÅ¯. Tento prostor mÅ¯Å¾eme takÃ© vizualizovat ve 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/cs/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> ObrÃ¡zek od [Dmitrije Soshnikova](http://soshnikov.com)

## âœï¸ CviÄenÃ­: AutoenkodÃ©ry

ZjistÄ›te vÃ­ce o autoenkodÃ©rech v tÄ›chto odpovÃ­dajÃ­cÃ­ch noteboocÃ­ch:

* [AutoenkodÃ©ry v TensorFlow](AutoencodersTF.ipynb)
* [AutoenkodÃ©ry v PyTorch](AutoEncodersPyTorch.ipynb)

## Vlastnosti autoenkodÃ©rÅ¯

* **SpecifickÃ© pro data** - fungujÃ­ dobÅ™e pouze s typem obrÃ¡zkÅ¯, na kterÃ½ch byly trÃ©novÃ¡ny. NapÅ™Ã­klad pokud trÃ©nujeme sÃ­Å¥ pro super-rezoluce na kvÄ›tinÃ¡ch, nebude dobÅ™e fungovat na portrÃ©tech. Je to proto, Å¾e sÃ­Å¥ mÅ¯Å¾e vytvoÅ™it obrÃ¡zek ve vyÅ¡Å¡Ã­m rozliÅ¡enÃ­ tÃ­m, Å¾e vezme jemnÃ© detaily z funkcÃ­ nauÄenÃ½ch z trÃ©novacÃ­ho datasetu.
* **ZtrÃ¡tovÃ©** - rekonstruovanÃ½ obrÃ¡zek nenÃ­ stejnÃ½ jako pÅ¯vodnÃ­ obrÃ¡zek. Povaha ztrÃ¡ty je definovÃ¡na *ztrÃ¡tovou funkcÃ­* pouÅ¾itou bÄ›hem trÃ©novÃ¡nÃ­.
* Funguje na **neoznaÄenÃ½ch datech**

## [KvÃ­z po lekci](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## ZÃ¡vÄ›r

V tÃ©to lekci jste se nauÄili o rÅ¯znÃ½ch typech autoenkodÃ©rÅ¯ dostupnÃ½ch pro vÄ›dce v oblasti AI. NauÄili jste se, jak je vytvoÅ™it a jak je pouÅ¾Ã­t k rekonstrukci obrÃ¡zkÅ¯. TakÃ© jste se nauÄili o VAE a jak je pouÅ¾Ã­t k generovÃ¡nÃ­ novÃ½ch obrÃ¡zkÅ¯.

## ğŸš€ VÃ½zva

V tÃ©to lekci jste se nauÄili pouÅ¾Ã­vat autoenkodÃ©ry pro obrÃ¡zky. Ale mohou bÃ½t pouÅ¾ity i pro hudbu! PodÃ­vejte se na projekt Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), kterÃ½ pouÅ¾Ã­vÃ¡ autoenkodÃ©ry k uÄenÃ­ rekonstrukce hudby. UdÄ›lejte si [experimenty](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) s touto knihovnou a zjistÄ›te, co mÅ¯Å¾ete vytvoÅ™it.

## [KvÃ­z po lekci](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## PÅ™ehled & Samostudium

Pro referenci si pÅ™eÄtÄ›te vÃ­ce o autoenkodÃ©rech v tÄ›chto zdrojÃ­ch:

* [VytvÃ¡Å™enÃ­ autoenkodÃ©rÅ¯ v Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [BlogovÃ½ pÅ™Ã­spÄ›vek na NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [VysvÄ›tlenÃ­ variabilnÃ­ch autoenkodÃ©rÅ¯](https://kvfrans.com/variational-autoencoders-explained/)
* [PodmÃ­nÄ›nÃ© variabilnÃ­ autoenkodÃ©ry](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## ZadÃ¡nÃ­

Na konci [tohoto notebooku s TensorFlow](AutoencodersTF.ipynb) najdete 'Ãºkol' - pouÅ¾ijte jej jako svÃ© zadÃ¡nÃ­.

---

