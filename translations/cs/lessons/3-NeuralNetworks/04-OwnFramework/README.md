# Ãšvod do neuronovÃ½ch sÃ­tÃ­. VÃ­cevrstvÃ½ perceptron

V pÅ™edchozÃ­ ÄÃ¡sti jste se seznÃ¡mili s nejjednoduÅ¡Å¡Ã­m modelem neuronovÃ© sÃ­tÄ› â€“ jednovrstvÃ½m perceptronem, coÅ¾ je lineÃ¡rnÃ­ model pro dvoutÅ™Ã­dnÃ­ klasifikaci.

V tÃ©to ÄÃ¡sti tento model rozÅ¡Ã­Å™Ã­me do flexibilnÄ›jÅ¡Ã­ho rÃ¡mce, kterÃ½ nÃ¡m umoÅ¾nÃ­:

* provÃ¡dÄ›t **vÃ­cetÅ™Ã­dnÃ­ klasifikaci** kromÄ› dvoutÅ™Ã­dnÃ­
* Å™eÅ¡it **regresnÃ­ Ãºlohy** kromÄ› klasifikace
* oddÄ›lovat tÅ™Ã­dy, kterÃ© nejsou lineÃ¡rnÄ› separovatelnÃ©

TakÃ© si vytvoÅ™Ã­me vlastnÃ­ modulÃ¡rnÃ­ rÃ¡mec v Pythonu, kterÃ½ nÃ¡m umoÅ¾nÃ­ sestavovat rÅ¯znÃ© architektury neuronovÃ½ch sÃ­tÃ­.

## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ai/quiz/7)

## Formalizace strojovÃ©ho uÄenÃ­

ZaÄnÄ›me formalizacÃ­ problÃ©mu strojovÃ©ho uÄenÃ­. PÅ™edpoklÃ¡dejme, Å¾e mÃ¡me trÃ©novacÃ­ dataset **X** s popisky **Y**, a potÅ™ebujeme vytvoÅ™it model *f*, kterÃ½ bude poskytovat co nejpÅ™esnÄ›jÅ¡Ã­ pÅ™edpovÄ›di. Kvalita pÅ™edpovÄ›dÃ­ se mÄ›Å™Ã­ pomocÃ­ **ztrÃ¡tovÃ© funkce** &lagran;. ÄŒasto se pouÅ¾Ã­vajÃ­ nÃ¡sledujÃ­cÃ­ ztrÃ¡tovÃ© funkce:

* Pro regresnÃ­ Ãºlohy, kdy potÅ™ebujeme pÅ™edpovÄ›dÄ›t ÄÃ­slo, mÅ¯Å¾eme pouÅ¾Ã­t **absolutnÃ­ chybu** &sum;<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| nebo **kvadratickou chybu** &sum;<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Pro klasifikaci pouÅ¾Ã­vÃ¡me **0-1 ztrÃ¡tu** (coÅ¾ je v podstatÄ› totÃ©Å¾ jako **pÅ™esnost** modelu) nebo **logistickou ztrÃ¡tu**.

Pro jednovrstvÃ½ perceptron byla funkce *f* definovÃ¡na jako lineÃ¡rnÃ­ funkce *f(x)=wx+b* (kde *w* je matice vah, *x* je vektor vstupnÃ­ch pÅ™Ã­znakÅ¯ a *b* je vektor biasu). U rÅ¯znÃ½ch architektur neuronovÃ½ch sÃ­tÃ­ mÅ¯Å¾e mÃ­t tato funkce sloÅ¾itÄ›jÅ¡Ã­ podobu.

> V pÅ™Ã­padÄ› klasifikace je Äasto Å¾Ã¡doucÃ­ zÃ­skat pravdÄ›podobnosti odpovÃ­dajÃ­cÃ­ch tÅ™Ã­d jako vÃ½stup sÃ­tÄ›. Pro pÅ™evod libovolnÃ½ch ÄÃ­sel na pravdÄ›podobnosti (napÅ™. pro normalizaci vÃ½stupu) Äasto pouÅ¾Ã­vÃ¡me funkci **softmax** &sigma;, a funkce *f* se stÃ¡vÃ¡ *f(x)=&sigma;(wx+b)*.

V definici *f* vÃ½Å¡e se *w* a *b* nazÃ½vajÃ­ **parametry** &theta;=âŸ¨*w,b*âŸ©. Na zÃ¡kladÄ› datasetu âŸ¨**X**,**Y**âŸ© mÅ¯Å¾eme vypoÄÃ­tat celkovou chybu na celÃ©m datasetu jako funkci parametrÅ¯ &theta;.

> âœ… **CÃ­lem trÃ©novÃ¡nÃ­ neuronovÃ© sÃ­tÄ› je minimalizovat chybu zmÄ›nou parametrÅ¯ &theta;**

## Optimalizace pomocÃ­ gradientnÃ­ho sestupu

Existuje znÃ¡mÃ¡ metoda optimalizace funkcÃ­ nazÃ½vanÃ¡ **gradientnÃ­ sestup**. MyÅ¡lenka spoÄÃ­vÃ¡ v tom, Å¾e mÅ¯Å¾eme vypoÄÃ­tat derivaci (v multidimenzionÃ¡lnÃ­m pÅ™Ã­padÄ› nazÃ½vanou **gradient**) ztrÃ¡tovÃ© funkce vzhledem k parametrÅ¯m a mÄ›nit parametry tak, aby se chyba sniÅ¾ovala. To lze formalizovat nÃ¡sledovnÄ›:

* Inicializujte parametry nÃ¡hodnÃ½mi hodnotami w<sup>(0)</sup>, b<sup>(0)</sup>
* Opakujte nÃ¡sledujÃ­cÃ­ krok mnohokrÃ¡t:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-&eta;&part;&lagran;/&part;w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-&eta;&part;&lagran;/&part;b

BÄ›hem trÃ©novÃ¡nÃ­ by mÄ›ly bÃ½t optimalizaÄnÃ­ kroky poÄÃ­tÃ¡ny s ohledem na celÃ½ dataset (pamatujte, Å¾e ztrÃ¡ta se poÄÃ­tÃ¡ jako souÄet pÅ™es vÅ¡echny trÃ©novacÃ­ vzorky). V praxi vÅ¡ak bereme malÃ© ÄÃ¡sti datasetu nazÃ½vanÃ© **minibatch** a poÄÃ­tÃ¡me gradienty na zÃ¡kladÄ› podmnoÅ¾iny dat. ProtoÅ¾e je podmnoÅ¾ina pokaÅ¾dÃ© vybÃ­rÃ¡na nÃ¡hodnÄ›, nazÃ½vÃ¡ se tato metoda **stochastickÃ½ gradientnÃ­ sestup** (SGD).

## VÃ­cevrstvÃ© perceptrony a zpÄ›tnÃ¡ propagace

JednovrstvÃ¡ sÃ­Å¥, jak jsme vidÄ›li vÃ½Å¡e, je schopna klasifikovat lineÃ¡rnÄ› separovatelnÃ© tÅ™Ã­dy. Pro vytvoÅ™enÃ­ bohatÅ¡Ã­ho modelu mÅ¯Å¾eme kombinovat nÄ›kolik vrstev sÃ­tÄ›. Matematicky to znamenÃ¡, Å¾e funkce *f* bude mÃ­t sloÅ¾itÄ›jÅ¡Ã­ podobu a bude vypoÄÃ­tÃ¡vÃ¡na v nÄ›kolika krocÃ­ch:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>&alpha;(z<sub>1</sub>)+b<sub>2</sub>
* f = &sigma;(z<sub>2</sub>)

Zde &alpha; je **nelineÃ¡rnÃ­ aktivaÄnÃ­ funkce**, &sigma; je softmax funkce a parametry &theta;=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Algoritmus gradientnÃ­ho sestupu zÅ¯stane stejnÃ½, ale vÃ½poÄet gradientÅ¯ bude sloÅ¾itÄ›jÅ¡Ã­. Na zÃ¡kladÄ› pravidla Å™etÄ›zovÃ©ho diferenciÃ¡lu mÅ¯Å¾eme derivace vypoÄÃ­tat takto:

* &part;&lagran;/&part;w<sub>2</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;w<sub>2</sub>)
* &part;&lagran;/&part;w<sub>1</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;&alpha;)(&part;&alpha;/&part;z<sub>1</sub>)(&part;z<sub>1</sub>/&part;w<sub>1</sub>)

> âœ… Pravidlo Å™etÄ›zovÃ©ho diferenciÃ¡lu se pouÅ¾Ã­vÃ¡ k vÃ½poÄtu derivacÃ­ ztrÃ¡tovÃ© funkce vzhledem k parametrÅ¯m.

VÅ¡imnÄ›te si, Å¾e levÃ¡ ÄÃ¡st vÅ¡ech tÄ›chto vÃ½razÅ¯ je stejnÃ¡, a proto mÅ¯Å¾eme efektivnÄ› poÄÃ­tat derivace poÄÃ­naje ztrÃ¡tovou funkcÃ­ a postupovat "zpÄ›tnÄ›" skrze vÃ½poÄetnÃ­ graf. Proto se metoda trÃ©novÃ¡nÃ­ vÃ­cevrstvÃ©ho perceptronu nazÃ½vÃ¡ **zpÄ›tnÃ¡ propagace** nebo 'backprop'.

<img alt="vÃ½poÄetnÃ­ graf" src="../../../../../translated_images/cs/ComputeGraphGrad.4626252c0de03507.webp"/>

> TODO: citace obrÃ¡zku

> âœ… ZpÄ›tnou propagaci probereme mnohem podrobnÄ›ji v naÅ¡em pÅ™Ã­kladovÃ©m notebooku.  

## ZÃ¡vÄ›r

V tÃ©to lekci jsme vytvoÅ™ili vlastnÃ­ knihovnu neuronovÃ½ch sÃ­tÃ­ a pouÅ¾ili jsme ji pro jednoduchou dvourozmÄ›rnou klasifikaÄnÃ­ Ãºlohu.

## ğŸš€ VÃ½zva

V pÅ™iloÅ¾enÃ©m notebooku implementujete vlastnÃ­ rÃ¡mec pro vytvÃ¡Å™enÃ­ a trÃ©novÃ¡nÃ­ vÃ­cevrstvÃ½ch perceptronÅ¯. Budete moci podrobnÄ› vidÄ›t, jak modernÃ­ neuronovÃ© sÃ­tÄ› fungujÃ­.

PokraÄujte do notebooku [OwnFramework](OwnFramework.ipynb) a projdÄ›te si jej.

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ai/quiz/8)

## PÅ™ehled a samostudium

ZpÄ›tnÃ¡ propagace je bÄ›Å¾nÃ½ algoritmus pouÅ¾Ã­vanÃ½ v AI a ML, stojÃ­ za to ji [prostudovat podrobnÄ›ji](https://wikipedia.org/wiki/Backpropagation).

## [Ãškol](lab/README.md)

V tomto laboratornÃ­m cviÄenÃ­ mÃ¡te za Ãºkol pouÅ¾Ã­t rÃ¡mec, kterÃ½ jste vytvoÅ™ili v tÃ©to lekci, k Å™eÅ¡enÃ­ klasifikace ruÄnÄ› psanÃ½ch ÄÃ­slic z datasetu MNIST.

* [Instrukce](lab/README.md)
* [Notebook](lab/MyFW_MNIST.ipynb)

---

