<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5d1cbc67a9690adb5b33adf297794087",
  "translation_date": "2025-08-25T22:17:34+00:00",
  "source_file": "lessons/1-Intro/README.md",
  "language_code": "cs"
}
-->
> ObrÃ¡zek od [Dmitry Soshnikov](http://soshnikov.com)

S postupem Äasu se vÃ½poÄetnÃ­ zdroje staly levnÄ›jÅ¡Ã­mi a dostupnost dat se zvÃ½Å¡ila, coÅ¾ umoÅ¾nilo pÅ™Ã­stupÅ¯m zaloÅ¾enÃ½m na neuronovÃ½ch sÃ­tÃ­ch dosahovat skvÄ›lÃ½ch vÃ½sledkÅ¯ v konkurenci s lidskÃ½mi schopnostmi v mnoha oblastech, jako je poÄÃ­taÄovÃ© vidÄ›nÃ­ nebo porozumÄ›nÃ­ Å™eÄi. V poslednÃ­m desetiletÃ­ se termÃ­n UmÄ›lÃ¡ inteligence Äasto pouÅ¾Ã­vÃ¡ jako synonymum pro neuronovÃ© sÃ­tÄ›, protoÅ¾e vÄ›tÅ¡ina ÃºspÄ›chÅ¯ AI, o kterÃ½ch slyÅ¡Ã­me, je zaloÅ¾ena prÃ¡vÄ› na nich.

MÅ¯Å¾eme pozorovat, jak se pÅ™Ã­stupy mÄ›nily, napÅ™Ã­klad pÅ™i tvorbÄ› poÄÃ­taÄovÃ©ho programu hrajÃ­cÃ­ho Å¡achy:

* RanÃ© Å¡achovÃ© programy byly zaloÅ¾eny na vyhledÃ¡vÃ¡nÃ­ â€“ program se explicitnÄ› snaÅ¾il odhadnout moÅ¾nÃ© tahy soupeÅ™e pro danÃ½ poÄet nÃ¡sledujÃ­cÃ­ch tahÅ¯ a vybral optimÃ¡lnÃ­ tah na zÃ¡kladÄ› nejlepÅ¡Ã­ pozice, kterou lze dosÃ¡hnout bÄ›hem nÄ›kolika tahÅ¯. To vedlo k vÃ½voji tzv. [alpha-beta oÅ™ezÃ¡vacÃ­ho](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning) vyhledÃ¡vacÃ­ho algoritmu.
* Strategie vyhledÃ¡vÃ¡nÃ­ fungujÃ­ dobÅ™e ke konci hry, kdy je vyhledÃ¡vacÃ­ prostor omezen malÃ½m poÄtem moÅ¾nÃ½ch tahÅ¯. Na zaÄÃ¡tku hry je vÅ¡ak vyhledÃ¡vacÃ­ prostor obrovskÃ½ a algoritmus lze zlepÅ¡it uÄenÃ­m z existujÃ­cÃ­ch zÃ¡pasÅ¯ mezi lidskÃ½mi hrÃ¡Äi. NÃ¡slednÃ© experimenty vyuÅ¾Ã­valy tzv. [case-based reasoning](https://en.wikipedia.org/wiki/Case-based_reasoning), kde program hledal pÅ™Ã­pady v databÃ¡zi znalostÃ­, kterÃ© jsou velmi podobnÃ© aktuÃ¡lnÃ­ pozici ve hÅ™e.
* ModernÃ­ programy, kterÃ© porÃ¡Å¾ejÃ­ lidskÃ© hrÃ¡Äe, jsou zaloÅ¾eny na neuronovÃ½ch sÃ­tÃ­ch a [posilovanÃ©m uÄenÃ­](https://en.wikipedia.org/wiki/Reinforcement_learning), kde se programy uÄÃ­ hrÃ¡t vÃ½hradnÄ› tÃ­m, Å¾e dlouho hrajÃ­ samy proti sobÄ› a uÄÃ­ se ze svÃ½ch vlastnÃ­ch chyb â€“ podobnÄ› jako lidÃ©, kdyÅ¾ se uÄÃ­ hrÃ¡t Å¡achy. PoÄÃ­taÄovÃ½ program vÅ¡ak mÅ¯Å¾e odehrÃ¡t mnohem vÃ­ce her za mnohem kratÅ¡Ã­ dobu, a tÃ­m se uÄÃ­ mnohem rychleji.

âœ… UdÄ›lejte si malÃ½ prÅ¯zkum o dalÅ¡Ã­ch hrÃ¡ch, kterÃ© byly hrÃ¡ny AI.

PodobnÄ› mÅ¯Å¾eme vidÄ›t, jak se pÅ™Ã­stup k vytvÃ¡Å™enÃ­ â€mluvÃ­cÃ­ch programÅ¯â€œ (kterÃ© by mohly projÃ­t TuringovÃ½m testem) zmÄ›nil:

* RanÃ© programy tohoto typu, jako napÅ™Ã­klad [Eliza](https://en.wikipedia.org/wiki/ELIZA), byly zaloÅ¾eny na velmi jednoduchÃ½ch gramatickÃ½ch pravidlech a pÅ™eformulovÃ¡nÃ­ vstupnÃ­ vÄ›ty do otÃ¡zky.
* ModernÃ­ asistenti, jako Cortana, Siri nebo Google Assistant, jsou hybridnÃ­ systÃ©my, kterÃ© vyuÅ¾Ã­vajÃ­ neuronovÃ© sÃ­tÄ› k pÅ™evodu Å™eÄi na text a rozpoznÃ¡nÃ­ naÅ¡eho zÃ¡mÄ›ru, a potÃ© pouÅ¾Ã­vajÃ­ urÄitÃ© formy logickÃ©ho uvaÅ¾ovÃ¡nÃ­ nebo explicitnÃ­ algoritmy k provedenÃ­ poÅ¾adovanÃ½ch akcÃ­.
* V budoucnu mÅ¯Å¾eme oÄekÃ¡vat kompletnÃ­ model zaloÅ¾enÃ½ na neuronovÃ½ch sÃ­tÃ­ch, kterÃ½ bude schopen samostatnÄ› zvlÃ¡dnout dialog. NedÃ¡vnÃ© rodiny neuronovÃ½ch sÃ­tÃ­ GPT a [Turing-NLG](https://turing.microsoft.com/) ukazujÃ­ v tÃ©to oblasti velkÃ½ ÃºspÄ›ch.

> ObrÃ¡zek od Dmitry Soshnikov, [fotografie](https://unsplash.com/photos/r8LmVbUKgns) od [Marina Abrosimova](https://unsplash.com/@abrosimova_marina_foto), Unsplash

## NedÃ¡vnÃ½ vÃ½zkum v oblasti AI

ObrovskÃ½ nÃ¡rÅ¯st vÃ½zkumu neuronovÃ½ch sÃ­tÃ­ zaÄal kolem roku 2010, kdy se zaÄaly objevovat velkÃ© veÅ™ejnÃ© datovÃ© sady. ObrovskÃ¡ sbÃ­rka obrÃ¡zkÅ¯ nazvanÃ¡ [ImageNet](https://en.wikipedia.org/wiki/ImageNet), kterÃ¡ obsahuje pÅ™ibliÅ¾nÄ› 14 milionÅ¯ anotovanÃ½ch obrÃ¡zkÅ¯, dala vzniknout [ImageNet Large Scale Visual Recognition Challenge](https://image-net.org/challenges/LSVRC/).

![PÅ™esnost ILSVRC](../../../../lessons/1-Intro/images/ilsvrc.gif)

> ObrÃ¡zek od [Dmitry Soshnikov](http://soshnikov.com)

V roce 2012 byly [KonvoluÄnÃ­ neuronovÃ© sÃ­tÄ›](../4-ComputerVision/07-ConvNets/README.md) poprvÃ© pouÅ¾ity pro klasifikaci obrÃ¡zkÅ¯, coÅ¾ vedlo k vÃ½raznÃ©mu snÃ­Å¾enÃ­ chybovosti klasifikace (z tÃ©mÄ›Å™ 30 % na 16,4 %). V roce 2015 architektura ResNet od Microsoft Research [dosÃ¡hla ÃºrovnÄ› pÅ™esnosti srovnatelnÃ© s ÄlovÄ›kem](https://doi.org/10.1109/ICCV.2015.123).

Od tÃ© doby neuronovÃ© sÃ­tÄ› prokÃ¡zaly velmi ÃºspÄ›Å¡nÃ© chovÃ¡nÃ­ v mnoha ÃºlohÃ¡ch:

---

Rok | DosaÅ¾enÃ­ ÃºrovnÄ› srovnatelnÃ© s ÄlovÄ›kem
-----|--------
2015 | [Klasifikace obrÃ¡zkÅ¯](https://doi.org/10.1109/ICCV.2015.123)
2016 | [RozpoznÃ¡vÃ¡nÃ­ konverzaÄnÃ­ Å™eÄi](https://arxiv.org/abs/1610.05256)
2018 | [AutomatickÃ½ strojovÃ½ pÅ™eklad](https://arxiv.org/abs/1803.05567) (z ÄÃ­nÅ¡tiny do angliÄtiny)
2020 | [PopisovÃ¡nÃ­ obrÃ¡zkÅ¯](https://arxiv.org/abs/2009.13682)

V poslednÃ­ch nÄ›kolika letech jsme byli svÄ›dky obrovskÃ½ch ÃºspÄ›chÅ¯ s velkÃ½mi jazykovÃ½mi modely, jako jsou BERT a GPT-3. To se stalo pÅ™edevÅ¡Ã­m dÃ­ky tomu, Å¾e je k dispozici velkÃ© mnoÅ¾stvÃ­ obecnÃ½ch textovÃ½ch dat, kterÃ¡ nÃ¡m umoÅ¾ÅˆujÃ­ trÃ©novat modely tak, aby zachytily strukturu a vÃ½znam textÅ¯, pÅ™edtrÃ©novat je na obecnÃ½ch textovÃ½ch kolekcÃ­ch a potÃ© tyto modely specializovat na konkrÃ©tnÄ›jÅ¡Ã­ Ãºkoly. O [zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka](../5-NLP/README.md) se dozvÃ­me vÃ­ce pozdÄ›ji v tomto kurzu.

## ğŸš€ VÃ½zva

Prozkoumejte internet a urÄete, kde je podle vÃ¡s AI nejefektivnÄ›ji vyuÅ¾Ã­vÃ¡na. Je to v mapovacÃ­ aplikaci, nÄ›jakÃ© sluÅ¾bÄ› pÅ™evodu Å™eÄi na text nebo ve videohÅ™e? ZjistÄ›te, jak byl tento systÃ©m vytvoÅ™en.

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ai/quiz/2)

## PÅ™ehled a samostudium

ProjdÄ›te si historii AI a ML pÅ™eÄtenÃ­m [tÃ©to lekce](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/2-history-of-ML). Vyberte si prvek ze sketchnotu na zaÄÃ¡tku tÃ©to lekce nebo tÃ©to a prozkoumejte jej podrobnÄ›ji, abyste pochopili kulturnÃ­ kontext, kterÃ½ ovlivnil jeho vÃ½voj.

**Ãškol**: [Game Jam](assignment.md)

**ProhlÃ¡Å¡enÃ­:**  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.