<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "bd10f434e444bce61b7f97eeb1ff6a55",
  "translation_date": "2025-08-25T22:10:29+00:00",
  "source_file": "lessons/5-NLP/19-NER/README.md",
  "language_code": "cs"
}
-->
# RozpoznÃ¡vÃ¡nÃ­ pojmenovanÃ½ch entit

Doposud jsme se vÄ›tÅ¡inou soustÅ™edili na jeden Ãºkol NLP - klasifikaci. ExistujÃ­ vÅ¡ak i dalÅ¡Ã­ Ãºkoly NLP, kterÃ© lze Å™eÅ¡it pomocÃ­ neuronovÃ½ch sÃ­tÃ­. JednÃ­m z tÄ›chto ÃºkolÅ¯ je **[rozpoznÃ¡vÃ¡nÃ­ pojmenovanÃ½ch entit](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), kterÃ© se zabÃ½vÃ¡ identifikacÃ­ konkrÃ©tnÃ­ch entit v textu, jako jsou mÃ­sta, jmÃ©na osob, ÄasovÃ© intervaly, chemickÃ© vzorce a podobnÄ›.

## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## PÅ™Ã­klad pouÅ¾itÃ­ NER

PÅ™edstavte si, Å¾e chcete vyvinout chatbot pro pÅ™irozenÃ½ jazyk, podobnÃ½ Amazon Alexa nebo Google Assistant. InteligentnÃ­ chatboti fungujÃ­ tak, Å¾e *rozumÃ­* tomu, co uÅ¾ivatel chce, pomocÃ­ klasifikace textu na vstupnÃ­ vÄ›tÄ›. VÃ½sledkem tÃ©to klasifikace je tzv. **zÃ¡mÄ›r** (intent), kterÃ½ urÄuje, co by mÄ›l chatbot udÄ›lat.

<img alt="Bot NER" src="images/bot-ner.png" width="50%"/>

> ObrÃ¡zek od autora

UÅ¾ivatel vÅ¡ak mÅ¯Å¾e jako souÄÃ¡st frÃ¡ze poskytnout nÄ›kterÃ© parametry. NapÅ™Ã­klad pÅ™i dotazu na poÄasÃ­ mÅ¯Å¾e specifikovat mÃ­sto nebo datum. Bot by mÄ›l bÃ½t schopen tyto entity pochopit a odpovÃ­dajÃ­cÃ­m zpÅ¯sobem vyplnit parametry pÅ™ed provedenÃ­m akce. A prÃ¡vÄ› zde pÅ™ichÃ¡zÃ­ na Å™adu NER.

> âœ… DalÅ¡Ã­m pÅ™Ã­kladem by mohlo bÃ½t [analyzovÃ¡nÃ­ vÄ›deckÃ½ch lÃ©kaÅ™skÃ½ch ÄlÃ¡nkÅ¯](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Jednou z hlavnÃ­ch vÄ›cÃ­, kterÃ© je tÅ™eba hledat, jsou specifickÃ© lÃ©kaÅ™skÃ© termÃ­ny, jako jsou nemoci a lÃ©kaÅ™skÃ© lÃ¡tky. ZatÃ­mco malÃ½ poÄet nemocÃ­ lze pravdÄ›podobnÄ› extrahovat pomocÃ­ vyhledÃ¡vÃ¡nÃ­ podÅ™etÄ›zcÅ¯, sloÅ¾itÄ›jÅ¡Ã­ entity, jako jsou chemickÃ© slouÄeniny a nÃ¡zvy lÃ©kÅ¯, vyÅ¾adujÃ­ sloÅ¾itÄ›jÅ¡Ã­ pÅ™Ã­stup.

## NER jako klasifikace tokenÅ¯

Modely NER jsou v podstatÄ› **modely klasifikace tokenÅ¯**, protoÅ¾e pro kaÅ¾dÃ½ vstupnÃ­ token musÃ­me rozhodnout, zda patÅ™Ã­ k nÄ›jakÃ© entitÄ›, a pokud ano, ke kterÃ© tÅ™Ã­dÄ› entity.

ZvaÅ¾te nÃ¡sledujÃ­cÃ­ nÃ¡zev ÄlÃ¡nku:

**Regurgitace trikuspidÃ¡lnÃ­ chlopnÄ›** a **uhliÄitan lithnÃ½** **toxicita** u novorozence.

Entity zde jsou:

* Regurgitace trikuspidÃ¡lnÃ­ chlopnÄ› je nemoc (`DIS`)
* UhliÄitan lithnÃ½ je chemickÃ¡ lÃ¡tka (`CHEM`)
* Toxicita je takÃ© nemoc (`DIS`)

VÅ¡imnÄ›te si, Å¾e jedna entita mÅ¯Å¾e zahrnovat nÄ›kolik tokenÅ¯. A, jako v tomto pÅ™Ã­padÄ›, musÃ­me rozliÅ¡it mezi dvÄ›ma po sobÄ› jdoucÃ­mi entitami. Proto je bÄ›Å¾nÃ© pouÅ¾Ã­vat dvÄ› tÅ™Ã­dy pro kaÅ¾dou entitu - jednu, kterÃ¡ specifikuje prvnÃ­ token entity (Äasto se pouÅ¾Ã­vÃ¡ pÅ™edpona `B-` pro **b**eginning), a druhou pro pokraÄovÃ¡nÃ­ entity (`I-`, pro **i**nner token). Pro vÅ¡echny **o**statnÃ­ tokeny pouÅ¾Ã­vÃ¡me tÅ™Ã­du `O`. TakovÃ© oznaÄovÃ¡nÃ­ tokenÅ¯ se nazÃ½vÃ¡ [BIO oznaÄovÃ¡nÃ­](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (nebo IOB). Po oznaÄenÃ­ bude nÃ¡Å¡ nÃ¡zev vypadat takto:

Token | Tag
------|-----
TrikuspidÃ¡lnÃ­ | B-DIS
chlopnÄ› | I-DIS
regurgitace | I-DIS
a | O
uhliÄitan | B-CHEM
lithnÃ½ | I-CHEM
toxicita | B-DIS
u | O
novorozence | O
. | O

ProtoÅ¾e potÅ™ebujeme vytvoÅ™it jednoznaÄnou korespondenci mezi tokeny a tÅ™Ã­dami, mÅ¯Å¾eme trÃ©novat pravostrannÃ½ **many-to-many** model neuronovÃ© sÃ­tÄ› podle tohoto obrÃ¡zku:

![ObrÃ¡zek ukazujÃ­cÃ­ bÄ›Å¾nÃ© vzory rekurentnÃ­ch neuronovÃ½ch sÃ­tÃ­.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.cs.jpg)

> *ObrÃ¡zek z [tohoto blogovÃ©ho pÅ™Ã­spÄ›vku](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) od [Andreje Karpathyho](http://karpathy.github.io/). Modely klasifikace tokenÅ¯ NER odpovÃ­dajÃ­ pravostrannÃ© architektuÅ™e sÃ­tÄ› na tomto obrÃ¡zku.*

## TrÃ©novÃ¡nÃ­ modelÅ¯ NER

ProtoÅ¾e model NER je v podstatÄ› modelem klasifikace tokenÅ¯, mÅ¯Å¾eme pro tento Ãºkol pouÅ¾Ã­t RNN, se kterÃ½mi jsme se jiÅ¾ seznÃ¡mili. V tomto pÅ™Ã­padÄ› kaÅ¾dÃ½ blok rekurentnÃ­ sÃ­tÄ› vrÃ¡tÃ­ ID tokenu. NÃ¡sledujÃ­cÃ­ ukÃ¡zkovÃ½ notebook ukazuje, jak trÃ©novat LSTM pro klasifikaci tokenÅ¯.

## âœï¸ UkÃ¡zkovÃ© notebooky: NER

PokraÄujte ve svÃ©m uÄenÃ­ v nÃ¡sledujÃ­cÃ­m notebooku:

* [NER s TensorFlow](../../../../../lessons/5-NLP/19-NER/NER-TF.ipynb)

## ZÃ¡vÄ›r

Model NER je **modelem klasifikace tokenÅ¯**, coÅ¾ znamenÃ¡, Å¾e jej lze pouÅ¾Ã­t k provÃ¡dÄ›nÃ­ klasifikace tokenÅ¯. JednÃ¡ se o velmi bÄ›Å¾nÃ½ Ãºkol v NLP, kterÃ½ pomÃ¡hÃ¡ rozpoznÃ¡vat konkrÃ©tnÃ­ entity v textu, vÄetnÄ› mÃ­st, jmen, dat a dalÅ¡Ã­ch.

## ğŸš€ VÃ½zva

DokonÄete Ãºkol uvedenÃ½ nÃ­Å¾e, abyste natrÃ©novali model pro rozpoznÃ¡vÃ¡nÃ­ pojmenovanÃ½ch entit v lÃ©kaÅ™skÃ½ch termÃ­nech, a potÃ© jej vyzkouÅ¡ejte na jinÃ©m datasetu.

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## PÅ™ehled a samostudium

ProjdÄ›te si blog [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) a nÃ¡sledujte sekci DalÅ¡Ã­ ÄtenÃ­ v tomto ÄlÃ¡nku, abyste si prohloubili svÃ© znalosti.

## [Ãškol](lab/README.md)

V Ãºkolu pro tuto lekci budete muset natrÃ©novat model pro rozpoznÃ¡vÃ¡nÃ­ lÃ©kaÅ™skÃ½ch entit. MÅ¯Å¾ete zaÄÃ­t trÃ©novÃ¡nÃ­m modelu LSTM, jak je popsÃ¡no v tÃ©to lekci, a pokraÄovat pouÅ¾itÃ­m modelu transformÃ¡toru BERT. PÅ™eÄtÄ›te si [pokyny](lab/README.md) pro vÅ¡echny podrobnosti.

**ProhlÃ¡Å¡enÃ­:**  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ© nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.