# RozpoznÃ¡vÃ¡nÃ­ pojmenovanÃ½ch entit

Doposud jsme se pÅ™evÃ¡Å¾nÄ› soustÅ™edili na jeden Ãºkol v oblasti zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka (NLP) â€“ klasifikaci. ExistujÃ­ vÅ¡ak i dalÅ¡Ã­ Ãºkoly v NLP, kterÃ© lze Å™eÅ¡it pomocÃ­ neuronovÃ½ch sÃ­tÃ­. JednÃ­m z tÄ›chto ÃºkolÅ¯ je **[rozpoznÃ¡vÃ¡nÃ­ pojmenovanÃ½ch entit](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), kterÃ© se zabÃ½vÃ¡ identifikacÃ­ konkrÃ©tnÃ­ch entit v textu, jako jsou mÃ­sta, jmÃ©na osob, ÄasovÃ© intervaly, chemickÃ© vzorce a podobnÄ›.

## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## PÅ™Ã­klad pouÅ¾itÃ­ NER

PÅ™edstavte si, Å¾e chcete vytvoÅ™it chatbot pro pÅ™irozenÃ½ jazyk, podobnÃ½ Amazon Alexe nebo Google Asistentovi. InteligentnÃ­ chatboti fungujÃ­ tak, Å¾e *rozumÃ­* tomu, co uÅ¾ivatel chce, pomocÃ­ klasifikace textu na vstupnÃ­ vÄ›tÄ›. VÃ½sledkem tÃ©to klasifikace je tzv. **zÃ¡mÄ›r** (intent), kterÃ½ urÄuje, co by mÄ›l chatbot udÄ›lat.

<img alt="Bot NER" src="../../../../../translated_images/cs/bot-ner.4b09235dbb0ad275.webp" width="50%"/>

> ObrÃ¡zek od autora

UÅ¾ivatel vÅ¡ak mÅ¯Å¾e v rÃ¡mci frÃ¡ze poskytnout i nÄ›kterÃ© parametry. NapÅ™Ã­klad pÅ™i dotazu na poÄasÃ­ mÅ¯Å¾e specifikovat mÃ­sto nebo datum. Chatbot by mÄ›l bÃ½t schopen tyto entity pochopit a vyplnit pÅ™Ã­sluÅ¡nÃ© parametry pÅ™ed provedenÃ­m akce. A prÃ¡vÄ› zde pÅ™ichÃ¡zÃ­ na Å™adu NER.

> âœ… DalÅ¡Ã­m pÅ™Ã­kladem by mohlo bÃ½t [analyzovÃ¡nÃ­ vÄ›deckÃ½ch lÃ©kaÅ™skÃ½ch ÄlÃ¡nkÅ¯](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). JednÃ­m z hlavnÃ­ch cÃ­lÅ¯ je hledÃ¡nÃ­ specifickÃ½ch lÃ©kaÅ™skÃ½ch termÃ­nÅ¯, jako jsou nemoci a lÃ©ÄivÃ© lÃ¡tky. ZatÃ­mco malÃ½ poÄet nemocÃ­ lze pravdÄ›podobnÄ› extrahovat pomocÃ­ vyhledÃ¡vÃ¡nÃ­ podÅ™etÄ›zcÅ¯, sloÅ¾itÄ›jÅ¡Ã­ entity, jako jsou chemickÃ© slouÄeniny a nÃ¡zvy lÃ©kÅ¯, vyÅ¾adujÃ­ komplexnÄ›jÅ¡Ã­ pÅ™Ã­stup.

## NER jako klasifikace tokenÅ¯

Modely NER jsou v podstatÄ› **modely pro klasifikaci tokenÅ¯**, protoÅ¾e pro kaÅ¾dÃ½ vstupnÃ­ token musÃ­me rozhodnout, zda patÅ™Ã­ k nÄ›jakÃ© entitÄ›, a pokud ano, ke kterÃ© tÅ™Ã­dÄ› entity.

ZvaÅ¾te nÃ¡sledujÃ­cÃ­ nÃ¡zev ÄlÃ¡nku:

**Regurgitace trikuspidÃ¡lnÃ­ chlopnÄ›** a **uhliÄitan lithnÃ½** **toxicita** u novorozence.

Entity zde jsou:

* Regurgitace trikuspidÃ¡lnÃ­ chlopnÄ› je nemoc (`DIS`)
* UhliÄitan lithnÃ½ je chemickÃ¡ lÃ¡tka (`CHEM`)
* Toxicita je takÃ© nemoc (`DIS`)

VÅ¡imnÄ›te si, Å¾e jedna entita mÅ¯Å¾e zahrnovat nÄ›kolik tokenÅ¯. A, jako v tomto pÅ™Ã­padÄ›, musÃ­me rozliÅ¡it mezi dvÄ›ma po sobÄ› jdoucÃ­mi entitami. Proto je bÄ›Å¾nÃ© pouÅ¾Ã­vat dvÄ› tÅ™Ã­dy pro kaÅ¾dou entitu â€“ jednu pro oznaÄenÃ­ prvnÃ­ho tokenu entity (Äasto se pouÅ¾Ã­vÃ¡ pÅ™edpona `B-` pro **b**eginning, zaÄÃ¡tek) a druhou pro pokraÄovÃ¡nÃ­ entity (`I-`, pro **i**nner token, vnitÅ™nÃ­ token). Pro oznaÄenÃ­ vÅ¡ech **o**statnÃ­ch tokenÅ¯ pouÅ¾Ã­vÃ¡me `O`. TakovÃ© oznaÄovÃ¡nÃ­ tokenÅ¯ se nazÃ½vÃ¡ [BIO oznaÄovÃ¡nÃ­](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (nebo IOB). Po oznaÄenÃ­ bude nÃ¡Å¡ nÃ¡zev vypadat takto:

Token | Tag
------|-----
TrikuspidÃ¡lnÃ­ | B-DIS
chlopnÄ› | I-DIS
regurgitace | I-DIS
a | O
uhliÄitan | B-CHEM
lithnÃ½ | I-CHEM
toxicita | B-DIS
u | O
novorozence | O
. | O

ProtoÅ¾e potÅ™ebujeme vytvoÅ™it jednoznaÄnou korespondenci mezi tokeny a tÅ™Ã­dami, mÅ¯Å¾eme trÃ©novat pravostrannÃ½ **many-to-many** model neuronovÃ© sÃ­tÄ› podle tohoto obrÃ¡zku:

![ObrÃ¡zek ukazujÃ­cÃ­ bÄ›Å¾nÃ© vzory rekurentnÃ­ch neuronovÃ½ch sÃ­tÃ­.](../../../../../translated_images/cs/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> *ObrÃ¡zek z [tohoto blogovÃ©ho pÅ™Ã­spÄ›vku](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) od [Andreje Karpathyho](http://karpathy.github.io/). Modely pro klasifikaci tokenÅ¯ v NER odpovÃ­dajÃ­ pravostrannÃ© architektuÅ™e na tomto obrÃ¡zku.*

## TrÃ©novÃ¡nÃ­ modelÅ¯ NER

ProtoÅ¾e model NER je v podstatÄ› modelem pro klasifikaci tokenÅ¯, mÅ¯Å¾eme pro tento Ãºkol pouÅ¾Ã­t RNN, kterÃ© jiÅ¾ znÃ¡me. V tomto pÅ™Ã­padÄ› kaÅ¾dÃ½ blok rekurentnÃ­ sÃ­tÄ› vrÃ¡tÃ­ ID tokenu. NÃ¡sledujÃ­cÃ­ ukÃ¡zkovÃ½ notebook ukazuje, jak trÃ©novat LSTM pro klasifikaci tokenÅ¯.

## âœï¸ UkÃ¡zkovÃ© notebooky: NER

PokraÄujte ve studiu v nÃ¡sledujÃ­cÃ­m notebooku:

* [NER s TensorFlow](NER-TF.ipynb)

## ZÃ¡vÄ›r

Model NER je **model pro klasifikaci tokenÅ¯**, coÅ¾ znamenÃ¡, Å¾e jej lze pouÅ¾Ã­t k provÃ¡dÄ›nÃ­ klasifikace tokenÅ¯. JednÃ¡ se o velmi bÄ›Å¾nÃ½ Ãºkol v NLP, kterÃ½ pomÃ¡hÃ¡ rozpoznÃ¡vat specifickÃ© entity v textu, vÄetnÄ› mÃ­st, jmen, dat a dalÅ¡Ã­ch.

## ğŸš€ VÃ½zva

DokonÄete Ãºkol uvedenÃ½ nÃ­Å¾e, kde budete trÃ©novat model pro rozpoznÃ¡vÃ¡nÃ­ pojmenovanÃ½ch entit v lÃ©kaÅ™skÃ½ch termÃ­nech, a potÃ© jej vyzkouÅ¡ejte na jinÃ©m datasetu.

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## PÅ™ehled a samostudium

ProjdÄ›te si blog [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) a nÃ¡sledujte sekci DalÅ¡Ã­ ÄtenÃ­ v tomto ÄlÃ¡nku, abyste si prohloubili znalosti.

## [Ãškol](lab/README.md)

V Ãºkolu pro tuto lekci budete muset natrÃ©novat model pro rozpoznÃ¡vÃ¡nÃ­ lÃ©kaÅ™skÃ½ch entit. MÅ¯Å¾ete zaÄÃ­t trÃ©novÃ¡nÃ­m modelu LSTM, jak je popsÃ¡no v tÃ©to lekci, a pokraÄovat pouÅ¾itÃ­m modelu BERT. PÅ™eÄtÄ›te si [instrukce](lab/README.md) pro vÅ¡echny podrobnosti.

---

