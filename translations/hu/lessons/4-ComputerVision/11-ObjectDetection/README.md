<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d85c8b08f6d1b48fd7f35b99f93c1138",
  "translation_date": "2025-08-25T22:43:06+00:00",
  "source_file": "lessons/4-ComputerVision/11-ObjectDetection/README.md",
  "language_code": "hu"
}
-->
# Objektumfelismer√©s

Az eddig t√°rgyalt k√©poszt√°lyoz√°si modellek egy k√©pet vettek alapul, √©s egy kateg√≥ri√°t eredm√©nyeztek, p√©ld√°ul az 'sz√°m' oszt√°lyt egy MNIST probl√©m√°ban. Azonban sok esetben nem el√©g tudni, hogy egy k√©p t√°rgyakat √°br√°zol - szeretn√©nk meghat√°rozni azok pontos hely√©t is. Ez az **objektumfelismer√©s** l√©nyege.

## [El≈ëad√°s el≈ëtti kv√≠z](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![Objektumfelismer√©s](../../../../../translated_images/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be1b905373ed9c858102c054b16e4595c76ec3f7bba0feb549.hu.png)

> K√©p a [YOLO v2 weboldal√°r√≥l](https://pjreddie.com/darknet/yolov2/)

## Egy naiv megk√∂zel√≠t√©s az objektumfelismer√©shez

Tegy√ºk fel, hogy egy k√©pen szeretn√©nk megtal√°lni egy macsk√°t. Egy nagyon egyszer≈± megk√∂zel√≠t√©s az al√°bbi lenne:

1. A k√©pet felosztjuk t√∂bb csemp√©re.
2. K√©poszt√°lyoz√°st futtatunk minden csemp√©n.
3. Azok a csemp√©k, amelyekn√©l el√©g magas aktiv√°ci√≥t kapunk, tartalmazhatj√°k a keresett objektumot.

![Naiv objektumfelismer√©s](../../../../../translated_images/naive-detection.e7f1ba220ccd08c68a2ea8e06a7ed75c3fcc738c2372f9e00b7f4299a8659c01.hu.png)

> *K√©p az [Exercise Notebook](../../../../../lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection-TF.ipynb) f√°jlb√≥l*

Ez a megk√∂zel√≠t√©s azonban messze nem ide√°lis, mivel az algoritmus csak nagyon pontatlanul tudja meghat√°rozni az objektum hat√°rol√≥ doboz√°t. A pontosabb helymeghat√°roz√°shoz valamilyen **regresszi√≥t** kell futtatnunk a hat√°rol√≥ doboz koordin√°t√°inak el≈ërejelz√©s√©re - ehhez pedig speci√°lis adat√°llom√°nyokra van sz√ºks√©g.

## Regresszi√≥ az objektumfelismer√©shez

[Ez a blogbejegyz√©s](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491) remek bevezet≈ët ny√∫jt az alakzatok felismer√©s√©hez.

## Adat√°llom√°nyok objektumfelismer√©shez

Az al√°bbi adat√°llom√°nyokkal tal√°lkozhatsz ebben a feladatban:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) - 20 oszt√°ly
* [COCO](http://cocodataset.org/#home) - K√∂z√∂ns√©ges t√°rgyak kontextusban. 80 oszt√°ly, hat√°rol√≥ dobozok √©s szegment√°ci√≥s maszkok

![COCO](../../../../../translated_images/coco-examples.71bc60380fa6cceb7caad48bd09e35b6028caabd363aa04fee89c414e0870e86.hu.jpg)

## Objektumfelismer√©si metrik√°k

### Metszet az uni√≥ felett

M√≠g a k√©poszt√°lyoz√°sn√°l k√∂nny≈± m√©rni az algoritmus teljes√≠tm√©ny√©t, az objektumfelismer√©sn√©l nemcsak az oszt√°ly helyess√©g√©t kell m√©rni, hanem a hat√°rol√≥ doboz hely√©nek pontoss√°g√°t is. Ehhez az √∫gynevezett **Metszet az uni√≥ felett** (IoU) metrik√°t haszn√°ljuk, amely azt m√©ri, hogy k√©t doboz (vagy k√©t tetsz≈ëleges ter√ºlet) mennyire fedik egym√°st.

![IoU](../../../../../translated_images/iou_equation.9a4751d40fff4e119ecd0a7bcca4e71ab1dc83e0d4f2a0d66ff0859736f593cf.hu.png)

> *2. √°bra [ebb≈ël a kiv√°l√≥ blogbejegyz√©sb≈ël az IoU-r√≥l](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)*

Az √∂tlet egyszer≈± - a k√©t alakzat metszet√©nek ter√ºlet√©t elosztjuk az uni√≥juk ter√ºlet√©vel. K√©t azonos ter√ºlet eset√©n az IoU √©rt√©ke 1, m√≠g teljesen k√ºl√∂n√°ll√≥ ter√ºletekn√©l 0. Egy√©bk√©nt 0 √©s 1 k√∂z√∂tt v√°ltozik. √Åltal√°ban csak azokat a hat√°rol√≥ dobozokat vessz√ºk figyelembe, amelyek IoU √©rt√©ke egy bizonyos √©rt√©k felett van.

### √Åtlagos pontoss√°g

Tegy√ºk fel, hogy egy adott $C$ oszt√°ly√∫ objektum felismer√©s√©nek hat√©konys√°g√°t szeretn√©nk m√©rni. Ehhez az **√Åtlagos Pontoss√°g** metrik√°t haszn√°ljuk, amelyet az al√°bbiak szerint sz√°m√≠tunk ki:

1. Vegy√ºk a Pontoss√°g-Visszah√≠v√°s g√∂rb√©t, amely az √©rz√©kenys√©get mutatja a detekt√°l√°si k√ºsz√∂b√©rt√©k f√ºggv√©ny√©ben (0-t√≥l 1-ig).
2. A k√ºsz√∂b√©rt√©kt≈ël f√ºgg≈ëen t√∂bb vagy kevesebb objektumot detekt√°lunk a k√©pen, √©s k√ºl√∂nb√∂z≈ë pontoss√°g- √©s visszah√≠v√°s√©rt√©keket kapunk.
3. A g√∂rbe √≠gy n√©z ki:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *K√©p a [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop) oldalr√≥l*

Az adott $C$ oszt√°ly √°tlagos pontoss√°ga a g√∂rbe alatti ter√ºlet. Pontosabban, a Visszah√≠v√°s tengelyt √°ltal√°ban 10 r√©szre osztjuk, √©s a Pontoss√°got √°tlagoljuk ezeken a pontokon:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP √©s IoU

Csak azokat a detekt√°l√°sokat vessz√ºk figyelembe, amelyek IoU √©rt√©ke egy bizonyos k√ºsz√∂b√©rt√©k felett van. P√©ld√°ul a PASCAL VOC adat√°llom√°nyban √°ltal√°ban $\mbox{IoU Threshold} = 0.5$ √©rt√©ket felt√©telez√ºnk, m√≠g a COCO eset√©ben az AP-t k√ºl√∂nb√∂z≈ë $\mbox{IoU Threshold}$ √©rt√©kekre m√©rj√ºk.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *K√©p a [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop) oldalr√≥l*

### √Åtlagos Pontoss√°g - mAP

Az objektumfelismer√©s f≈ë metrik√°ja az **√Åtlagos Pontoss√°g**, vagy **mAP**. Ez az √Åtlagos Pontoss√°g √©rt√©ke, amelyet az √∂sszes objektumoszt√°lyra √°tlagolunk, √©s n√©ha az $\mbox{IoU Threshold}$ √©rt√©kekre is. Az **mAP** sz√°m√≠t√°s√°nak r√©szleteit
[ebben a blogbejegyz√©sben](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3)), valamint [itt k√≥ddal](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734) tal√°lod.

## K√ºl√∂nb√∂z≈ë objektumfelismer√©si megk√∂zel√≠t√©sek

Az objektumfelismer√©si algoritmusoknak k√©t f≈ë t√≠pusa van:

* **R√©gi√≥javasl√≥ h√°l√≥zatok** (R-CNN, Fast R-CNN, Faster R-CNN). Az alap√∂tlet az, hogy **√©rdekl≈ëd√©si r√©gi√≥kat** (ROI) gener√°lunk, √©s CNN-t futtatunk rajtuk, keresve a maxim√°lis aktiv√°ci√≥t. Ez kiss√© hasonl√≠t a naiv megk√∂zel√≠t√©shez, azzal a k√ºl√∂nbs√©ggel, hogy az ROI-kat okosabb m√≥don gener√°ljuk. Az egyik f≈ë h√°tr√°nya ezeknek a m√≥dszereknek, hogy lass√∫ak, mivel sok CNN oszt√°lyoz√≥t kell futtatni a k√©pen.
* **Egyszeri futtat√°s√∫** (YOLO, SSD, RetinaNet) m√≥dszerek. Ezekben az architekt√∫r√°kban a h√°l√≥zatot √∫gy tervezz√ºk, hogy egyszerre el≈ërejelezze az oszt√°lyokat √©s az ROI-kat.

### R-CNN: R√©gi√≥alap√∫ CNN

Az [R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf) [Szelekt√≠v Keres√©st](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) haszn√°l az ROI r√©gi√≥k hierarchikus strukt√∫r√°j√°nak gener√°l√°s√°ra, amelyeket ezut√°n CNN jellemz≈ëkivon√≥k √©s SVM-oszt√°lyoz√≥k dolgoznak fel az objektumoszt√°ly meghat√°roz√°s√°ra, valamint line√°ris regresszi√≥val a *hat√°rol√≥ doboz* koordin√°t√°inak meghat√°roz√°s√°ra. [Hivatalos tanulm√°ny](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/rcnn1.cae407020dfb1d1fb572656e44f75cd6c512cc220591c116c506652c10e47f26.hu.png)

> *K√©p van de Sande et al. ICCV‚Äô11*

![RCNN-1](../../../../../translated_images/rcnn2.2d9530bb83516484ec65b250c22dbf37d3d23244f32864ebcb91d98fe7c3112c.hu.png)

> *K√©pek [ebb≈ël a blogb√≥l](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)*

### F-RCNN - Gyors R-CNN

Ez a megk√∂zel√≠t√©s hasonl√≥ az R-CNN-hez, de a r√©gi√≥kat a konvol√∫ci√≥s r√©tegek alkalmaz√°sa ut√°n hat√°rozz√°k meg.

![FRCNN](../../../../../translated_images/f-rcnn.3cda6d9bb41888754037d2d9763e2298a96de5d9bc2a21db3147357aa5da9b1a.hu.png)

> K√©p a [hivatalos tanulm√°nyb√≥l](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Gyorsabb R-CNN

Ennek a megk√∂zel√≠t√©snek az alap√∂tlete, hogy neur√°lis h√°l√≥zatot haszn√°lunk az ROI-k el≈ërejelz√©s√©re - az √∫gynevezett *R√©gi√≥javasl√≥ H√°l√≥zat*. [Tanulm√°ny](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../translated_images/faster-rcnn.8d46c099b87ef30ab2ea26dbc4bdd85b974a57ba8eb526f65dc4cd0a4711de30.hu.png)

> K√©p a [hivatalos tanulm√°nyb√≥l](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: R√©gi√≥alap√∫ Teljesen Konvol√∫ci√≥s H√°l√≥zat

Ez az algoritmus m√©g gyorsabb, mint a Gyorsabb R-CNN. Az alap√∂tlet a k√∂vetkez≈ë:

1. Jellemz≈ëket vonunk ki ResNet-101 seg√≠ts√©g√©vel.
2. A jellemz≈ëket **Poz√≠ci√≥√©rz√©keny Pontsz√°m T√©rk√©pek** dolgozz√°k fel. Minden objektumot $C$ oszt√°lyb√≥l $k\times k$ r√©gi√≥kra osztunk, √©s az objektumok r√©szeinek el≈ërejelz√©s√©re tan√≠tjuk a h√°l√≥zatot.
3. Minden r√©szre a $k\times k$ r√©gi√≥kb√≥l a h√°l√≥zatok szavaznak az objektumoszt√°lyokra, √©s a maxim√°lis szavazatot kap√≥ oszt√°lyt v√°lasztjuk.

![r-fcn image](../../../../../translated_images/r-fcn.13eb88158b99a3da50fa2787a6be5cb310d47f0e9655cc93a1090dc7aab338d1.hu.png)

> K√©p a [hivatalos tanulm√°nyb√≥l](https://arxiv.org/abs/1605.06409)

### YOLO - You Only Look Once

A YOLO egy val√≥s idej≈± egyszeri futtat√°s√∫ algoritmus. Az alap√∂tlet a k√∂vetkez≈ë:

 * A k√©pet $S\times S$ r√©gi√≥kra osztjuk.
 * Minden r√©gi√≥ra **CNN** el≈ërejelzi $n$ lehets√©ges objektumot, *hat√°rol√≥ doboz* koordin√°t√°kat √©s *bizalom*=*val√≥sz√≠n≈±s√©g* * IoU.

 ![YOLO](../../../../../translated_images/yolo.a2648ec82ee8bb4ea27537677adb482fd4b733ca1705c561b6a24a85102dced5.hu.png)

> K√©p a [hivatalos tanulm√°nyb√≥l](https://arxiv.org/abs/1506.02640)

### Egy√©b algoritmusok

* RetinaNet: [hivatalos tanulm√°ny](https://arxiv.org/abs/1708.02002)
   - [PyTorch Implement√°ci√≥ Torchvisionben](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Keras Implement√°ci√≥](https://github.com/fizyr/keras-retinanet)
   - [Objektumfelismer√©s RetinaNet seg√≠ts√©g√©vel](https://keras.io/examples/vision/retinanet/) Keras p√©ld√°kban
* SSD (Single Shot Detector): [hivatalos tanulm√°ny](https://arxiv.org/abs/1512.02325)

## ‚úçÔ∏è Gyakorlatok: Objektumfelismer√©s

Folytasd a tanul√°st az al√°bbi jegyzetf√ºzetben:

[ObjectDetection.ipynb](../../../../../lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb)

## √ñsszegz√©s

Ebben a leck√©ben gyors √°ttekint√©st kapt√°l az objektumfelismer√©s k√ºl√∂nb√∂z≈ë megk√∂zel√≠t√©seir≈ël!

## üöÄ Kih√≠v√°s

Olvasd el ezeket a cikkeket √©s jegyzetf√ºzeteket a YOLO-r√≥l, √©s pr√≥b√°ld ki ≈ëket magad:

* [J√≥ blogbejegyz√©s](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/) a YOLO-r√≥l
 * [Hivatalos oldal](https://pjreddie.com/darknet/yolo/)
 * Yolo: [Keras implement√°ci√≥](https://github.com/experiencor/keras-yolo2), [l√©p√©sr≈ël l√©p√©sre jegyzetf√ºzet](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * Yolo v2: [Keras implement√°ci√≥](https://github.com/experiencor/keras-yolo2), [l√©p√©sr≈ël l√©p√©sre jegyzetf√ºzet](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [El≈ëad√°s ut√°ni kv√≠z](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

* [Objektumfelismer√©s](https://tjmachinelearning.com/lectures/1718/obj/) Nikhil Sardana √°ltal
* [J√≥ √∂sszehasonl√≠t√°s az objektumfelismer√©si algoritmusokr√≥l](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [√Åttekint√©s a m√©ly tanul√°si algoritmusokr√≥l objektumfelismer√©shez](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [L√©p√©sr≈ël l√©p√©sre bevezet√©s az alapvet≈ë objektumfelismer√©si algoritmusokba](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Gyorsabb R-CNN implement√°ci√≥ Pythonban objektumfelismer√©shez](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [Feladat: Objektumfelismer√©s](lab/README.md)

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.