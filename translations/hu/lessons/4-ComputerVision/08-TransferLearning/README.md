# El≈ëre betan√≠tott h√°l√≥zatok √©s transzfer tanul√°s

A CNN-ek (konvol√∫ci√≥s neur√°lis h√°l√≥zatok) betan√≠t√°sa sok id≈ët vehet ig√©nybe, √©s ehhez rengeteg adat sz√ºks√©ges. Az id≈ë nagy r√©sz√©t azonban az alacsony szint≈± sz≈±r≈ëk megtanul√°sa teszi ki, amelyek seg√≠ts√©g√©vel a h√°l√≥zat mint√°kat tud kinyerni a k√©pekb≈ël. Felmer√ºl a term√©szetes k√©rd√©s: haszn√°lhatunk-e egy m√°sik adathalmazon betan√≠tott neur√°lis h√°l√≥zatot, √©s adapt√°lhatjuk-e azt m√°s k√©pek oszt√°lyoz√°s√°ra an√©lk√ºl, hogy teljes betan√≠t√°si folyamatra lenne sz√ºks√©g?

## [El≈ëad√°s el≈ëtti kv√≠z](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Ezt a megk√∂zel√≠t√©st **transzfer tanul√°snak** nevezz√ºk, mivel egy neur√°lis h√°l√≥zati modellb≈ël sz√°rmaz√≥ tud√°st √°tvisz√ºnk egy m√°sikba. A transzfer tanul√°s sor√°n √°ltal√°ban egy el≈ëre betan√≠tott modellel kezd√ºnk, amelyet egy nagy k√©padathalmazon, p√©ld√°ul az **ImageNet**-en tan√≠tottak be. Ezek a modellek m√°r k√©pesek k√ºl√∂nb√∂z≈ë jellemz≈ëket kinyerni √°ltal√°nos k√©pekb≈ël, √©s sok esetben elegend≈ë egy oszt√°lyoz√≥t √©p√≠teni ezekre a kinyert jellemz≈ëkre, hogy j√≥ eredm√©nyt √©rj√ºnk el.

> ‚úÖ A transzfer tanul√°s kifejez√©s m√°s tudom√°nyter√ºleteken is el≈ëfordul, p√©ld√°ul az oktat√°sban. Arra a folyamatra utal, amikor egy ter√ºleten szerzett tud√°st egy m√°sik ter√ºleten alkalmazunk.

## El≈ëre betan√≠tott modellek mint jellemz≈ëkivon√≥k

Az el≈ëz≈ë szakaszban t√°rgyalt konvol√∫ci√≥s h√°l√≥zatok t√∂bb r√©tegb≈ël √°lltak, amelyek mindegyike bizonyos jellemz≈ëket hivatott kinyerni a k√©pb≈ël, kezdve az alacsony szint≈± pixelkombin√°ci√≥kt√≥l (p√©ld√°ul v√≠zszintes/f√ºgg≈ëleges vonalak vagy von√°sok), eg√©szen a magasabb szint≈± jellemz≈ëkombin√°ci√≥kig, amelyek p√©ld√°ul egy l√°ng szemeinek felelnek meg. Ha egy CNN-t el√©g nagy √©s v√°ltozatos k√©padathalmazon tan√≠tunk be, a h√°l√≥zatnak meg kell tanulnia ezeket a k√∂z√∂s jellemz≈ëket kinyerni.

Mind a Keras, mind a PyTorch tartalmaz funkci√≥kat, amelyekkel k√∂nnyen bet√∂lthet≈ëk el≈ëre betan√≠tott neur√°lis h√°l√≥zati s√∫lyok n√©h√°ny gyakori architekt√∫r√°hoz, amelyek t√∂bbs√©g√©t ImageNet k√©peken tan√≠tott√°k be. A leggyakrabban haszn√°ltakat a [CNN Architekt√∫r√°k](../07-ConvNets/CNN_Architectures.md) oldalon ismertett√ºk az el≈ëz≈ë leck√©ben. K√ºl√∂n√∂sen √©rdemes megfontolni az al√°bbiak haszn√°lat√°t:

* **VGG-16/VGG-19**, amelyek viszonylag egyszer≈± modellek, de m√©gis j√≥ pontoss√°got ny√∫jtanak. Gyakran j√≥ v√°laszt√°s a VGG haszn√°lata els≈ë pr√≥b√°lkoz√°sk√©nt, hogy l√°ssuk, hogyan m≈±k√∂dik a transzfer tanul√°s.
* **ResNet**, amelyet a Microsoft Research javasolt 2015-ben. Ezek a modellek t√∂bb r√©teggel rendelkeznek, √≠gy t√∂bb er≈ëforr√°st ig√©nyelnek.
* **MobileNet**, amely egy kisebb m√©ret≈± modellcsal√°d, mobil eszk√∂z√∂kre optimaliz√°lva. Haszn√°lja ≈ëket, ha kev√©s az er≈ëforr√°s, √©s hajland√≥ egy kis pontoss√°got fel√°ldozni.

√çme egy p√©lda a VGG-16 h√°l√≥zat √°ltal egy macska k√©p√©b≈ël kinyert jellemz≈ëkre:

![A VGG-16 √°ltal kinyert jellemz≈ëk](../../../../../translated_images/hu/features.6291f9c7ba3a0b95.webp)

## Macsk√°k √©s kuty√°k adathalmaz

Ebben a p√©ld√°ban a [Macsk√°k √©s Kuty√°k](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) adathalmazt fogjuk haszn√°lni, amely nagyon k√∂zel √°ll egy val√≥s √©letbeli k√©poszt√°lyoz√°si feladathoz.

## ‚úçÔ∏è Gyakorlat: Transzfer tanul√°s

N√©zz√ºk meg a transzfer tanul√°st m≈±k√∂d√©s k√∂zben a megfelel≈ë jegyzetf√ºzetekben:

* [Transzfer tanul√°s - PyTorch](TransferLearningPyTorch.ipynb)
* [Transzfer tanul√°s - TensorFlow](TransferLearningTF.ipynb)

## Az "ide√°lis macska" vizualiz√°l√°sa

Egy el≈ëre betan√≠tott neur√°lis h√°l√≥zat k√ºl√∂nb√∂z≈ë mint√°kat tartalmaz az *agy√°ban*, bele√©rtve az **ide√°lis macska** (valamint az ide√°lis kutya, ide√°lis zebra stb.) fogalm√°t. √ârdekes lenne valahogy **vizualiz√°lni ezt a k√©pet**. Ez azonban nem egyszer≈±, mert a mint√°k a h√°l√≥zat s√∫lyaiban sz√©tsz√≥rva tal√°lhat√≥k, √©s hierarchikus strukt√∫r√°ban vannak szervezve.

Egy megk√∂zel√≠t√©s az lehet, hogy egy v√©letlenszer≈± k√©ppel kezd√ºnk, majd a **gradiens-deszcendens optimaliz√°ci√≥s** technik√°t alkalmazzuk, hogy √∫gy m√≥dos√≠tsuk a k√©pet, hogy a h√°l√≥zat elkezdje azt macsk√°nak gondolni.

![K√©poptimaliz√°ci√≥s ciklus](../../../../../translated_images/hu/ideal-cat-loop.999fbb8ff306e044.webp)

Ha azonban ezt tessz√ºk, akkor valami nagyon hasonl√≥t kapunk, mint egy v√©letlenszer≈± zaj. Ennek oka, hogy *sokf√©lek√©ppen lehet a h√°l√≥zatot r√°venni arra, hogy a bemeneti k√©pet macsk√°nak gondolja*, bele√©rtve olyanokat is, amelyek vizu√°lisan nem √©rtelmezhet≈ëk. B√°r ezek a k√©pek sok, a macsk√°kra jellemz≈ë mint√°t tartalmaznak, semmi sem k√©nyszer√≠ti ≈ëket arra, hogy vizu√°lisan megk√ºl√∂nb√∂ztethet≈ëk legyenek.

Az eredm√©ny jav√≠t√°sa √©rdek√©ben hozz√°adhatunk egy m√°sik tagot a vesztes√©gf√ºggv√©nyhez, amelyet **vari√°ci√≥s vesztes√©gnek** nevez√ºnk. Ez egy olyan metrika, amely megmutatja, mennyire hasonl√≥ak a k√©p szomsz√©dos pixelei. A vari√°ci√≥s vesztes√©g minimaliz√°l√°sa sim√°bb√° teszi a k√©pet, √©s megszabad√≠tja a zajt√≥l ‚Äì √≠gy vizu√°lisan vonz√≥bb mint√°kat t√°r fel. √çme egy p√©lda az ilyen "ide√°lis" k√©pekre, amelyeket nagy val√≥sz√≠n≈±s√©ggel macsk√°nak √©s zebr√°nak oszt√°lyoznak:

![Ide√°lis macska](../../../../../translated_images/hu/ideal-cat.203dd4597643d6b0.webp) | ![Ide√°lis zebra](../../../../../translated_images/hu/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
*Ide√°lis macska* | *Ide√°lis zebra*

Hasonl√≥ megk√∂zel√≠t√©st lehet alkalmazni √∫gynevezett **adverz√°lis t√°mad√°sok** v√©grehajt√°s√°ra egy neur√°lis h√°l√≥zaton. Tegy√ºk fel, hogy szeretn√©nk megt√©veszteni egy neur√°lis h√°l√≥zatot, √©s egy kuty√°t macsk√°nak l√°ttatni. Ha vesz√ºnk egy kutya k√©p√©t, amelyet a h√°l√≥zat kutyak√©nt ismer fel, akkor azt egy kicsit m√≥dos√≠thatjuk a gradiens-deszcendens optimaliz√°ci√≥ seg√≠ts√©g√©vel, am√≠g a h√°l√≥zat macskak√©nt nem kezdi oszt√°lyozni:

![K√©p egy kuty√°r√≥l](../../../../../translated_images/hu/original-dog.8f68a67d2fe0911f.webp) | ![K√©p egy kuty√°r√≥l, amelyet macsk√°nak oszt√°lyoznak](../../../../../translated_images/hu/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Eredeti k√©p egy kuty√°r√≥l* | *K√©p egy kuty√°r√≥l, amelyet macsk√°nak oszt√°lyoznak*

Az eredm√©nyek reproduk√°l√°s√°hoz sz√ºks√©ges k√≥dot az al√°bbi jegyzetf√ºzetben tal√°lja:

* [Ide√°lis √©s adverz√°lis macska - TensorFlow](AdversarialCat_TF.ipynb)

## K√∂vetkeztet√©s

A transzfer tanul√°s seg√≠ts√©g√©vel gyorsan √∂ssze√°ll√≠that egy oszt√°lyoz√≥t egyedi objektumok oszt√°lyoz√°si feladat√°hoz, √©s magas pontoss√°got √©rhet el. L√°that√≥, hogy az egyre √∂sszetettebb feladatok, amelyeket most megoldunk, nagyobb sz√°m√≠t√°si teljes√≠tm√©nyt ig√©nyelnek, √©s nem oldhat√≥k meg k√∂nnyen CPU-n. A k√∂vetkez≈ë egys√©gben egy k√∂nnyebb implement√°ci√≥t pr√≥b√°lunk ki, hogy ugyanazt a modellt alacsonyabb sz√°m√≠t√°si er≈ëforr√°sokkal tan√≠tsuk, ami csak kiss√© alacsonyabb pontoss√°got eredm√©nyez.

## üöÄ Kih√≠v√°s

A mell√©kelt jegyzetf√ºzetekben megjegyz√©sek tal√°lhat√≥k arr√≥l, hogy a transzfer tud√°s legjobban hasonl√≥ edz√©si adatokkal m≈±k√∂dik (p√©ld√°ul egy √∫j √°llatfajta). K√≠s√©rletezzen teljesen √∫j t√≠pus√∫ k√©pekkel, hogy l√°ssa, mennyire j√≥l vagy rosszul teljes√≠tenek a transzfer tud√°s modellek.

## [El≈ëad√°s ut√°ni kv√≠z](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

Olvassa el a [TrainingTricks.md](TrainingTricks.md) f√°jlt, hogy elm√©ly√≠tse tud√°s√°t a modellek betan√≠t√°s√°nak egy√©b m√≥djair√≥l.

## [Feladat](lab/README.md)

Ebben a laborban a val√≥s √©letb≈ël vett [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) h√°zi√°llat-adathalmazt fogjuk haszn√°lni, amely 35 macska- √©s kutyafajt√°t tartalmaz, √©s egy transzfer tanul√°si oszt√°lyoz√≥t fogunk √©p√≠teni.

---

