# 道德與負責任的人工智能

你已經快完成這門課程了，希望到目前為止，你已清楚了解到人工智能是基於一系列正式的數學方法，這些方法能幫助我們在數據中找到關係，並訓練模型來模仿某些人類行為。在這個歷史時刻，我們認為人工智能是一個非常強大的工具，可以從數據中提取模式，並應用這些模式來解決新的問題。

## [課前測驗](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

然而，在科幻作品中，我們經常看到人工智能對人類構成威脅的故事。通常這些故事圍繞某種人工智能叛變展開，當人工智能決定與人類對抗時，這暗示人工智能擁有某種情感或能做出開發者未預見的決定。

我們在這門課程中學到的人工智能僅僅是大型矩陣運算。它是一個非常強大的工具，可以幫助我們解決問題，但和其他任何強大的工具一樣——它既可以用於好的目的，也可以用於壞的目的。重要的是，它可能會被*濫用*。

## 負責任人工智能的原則

為了避免人工智能的意外或故意濫用，Microsoft 提出了重要的[負責任人工智能原則](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste)。以下概念是這些原則的基礎：

* **公平性**與*模型偏差*這個重要問題相關，模型偏差可能是由於使用了有偏差的數據進行訓練。例如，當我們嘗試預測某人獲得軟件開發工作機會的概率時，模型可能更偏向男性——僅僅因為訓練數據集可能偏向男性群體。我們需要仔細平衡訓練數據並調查模型以避免偏差，確保模型考慮到更相關的特徵。
* **可靠性與安全性**。人工智能模型本質上可能會犯錯。一個神經網絡返回的是概率，我們需要在做決策時考慮到這一點。每個模型都有一定的精確度和召回率，我們需要理解這些指標以防止錯誤建議可能造成的傷害。
* **隱私與安全性**有一些人工智能特定的影響。例如，當我們使用某些數據來訓練模型時，這些數據會以某種方式“整合”到模型中。一方面，這提高了安全性和隱私性，另一方面——我們需要記住模型是基於哪些數據訓練的。
* **包容性**意味著我們不是在構建人工智能來取代人類，而是為了增強人類並使我們的工作更具創造性。這也與公平性相關，因為在處理代表性不足的社群時，我們收集的大多數數據集可能存在偏差，我們需要確保這些社群被納入並正確地由人工智能處理。
* **透明性**。這包括確保我們始終清楚地表明人工智能正在被使用。此外，在可能的情況下，我們希望使用*可解釋*的人工智能系統。
* **問責性**。當人工智能模型做出某些決定時，並不總是清楚誰應對這些決定負責。我們需要確保我們理解人工智能決策的責任所在。在大多數情況下，我們希望將人類納入重要決策的過程中，以便實際的人對決策負責。

## 負責任人工智能的工具

Microsoft 開發了[負責任人工智能工具箱](https://github.com/microsoft/responsible-ai-toolbox)，其中包含一系列工具：

* 解釋性儀表板 (InterpretML)
* 公平性儀表板 (FairLearn)
* 錯誤分析儀表板
* 負責任人工智能儀表板，包括：

   - EconML - 用於因果分析的工具，專注於假設性問題
   - DiCE - 用於反事實分析的工具，讓你了解需要改變哪些特徵才能影響模型的決策

有關人工智能倫理的更多信息，請訪問[這節課](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste)，它是機器學習課程的一部分，並包含作業。

## 回顧與自學

參加這個[學習路徑](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste)，以了解更多關於負責任人工智能的內容。

## [課後測驗](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**免責聲明**：  
本文件已使用人工智能翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。我們致力於提供準確的翻譯，但請注意，自動翻譯可能包含錯誤或不準確之處。應以原文文件作為權威來源。對於關鍵資訊，建議尋求專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或誤釋不承擔責任。