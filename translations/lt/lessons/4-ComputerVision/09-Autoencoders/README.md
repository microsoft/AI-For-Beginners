# Autoenkoderiai

Mokant CNN, viena iÅ¡ problemÅ³ yra ta, kad reikia daug paÅ¾ymÄ—tÅ³ duomenÅ³. VaizdÅ³ klasifikavimo atveju reikia rankiniu bÅ«du suskirstyti vaizdus Ä¯ skirtingas klases.

## [PrieÅ¡ paskaitos testas](https://ff-quizzes.netlify.app/en/ai/quiz/17)

TaÄiau galime norÄ—ti naudoti neapdorotus (nepaÅ¾ymÄ—tus) duomenis CNN funkcijÅ³ iÅ¡traukikliams mokyti, vadinamÄ… **savivaldÅ¾iu mokymusi**. Vietoj Å¾ymiÅ³ naudosime mokymo vaizdus tiek kaip tinklo Ä¯vestÄ¯, tiek kaip iÅ¡vestÄ¯. PagrindinÄ— **autoenkoderio** idÄ—ja yra turÄ—ti **enkoderio tinklÄ…**, kuris paverÄia Ä¯vesties vaizdÄ… Ä¯ tam tikrÄ… **latentÄ™ erdvÄ™** (paprastai tai yra maÅ¾esnio dydÅ¾io vektorius), ir **dekoderio tinklÄ…**, kurio tikslas yra atkurti originalÅ³ vaizdÄ….

> âœ… [Autoenkoderis](https://wikipedia.org/wiki/Autoencoder) yra "dirbtinio neuroninio tinklo tipas, naudojamas efektyviam nepaÅ¾ymÄ—tÅ³ duomenÅ³ kodavimui iÅ¡mokti."

Kadangi mokome autoenkoderÄ¯ uÅ¾fiksuoti kuo daugiau informacijos iÅ¡ originalaus vaizdo, kad bÅ«tÅ³ galima tiksliai jÄ¯ atkurti, tinklas stengiasi rasti geriausiÄ… **Ä¯terpimÄ…** Ä¯vesties vaizdams, kad uÅ¾fiksuotÅ³ jÅ³ prasmÄ™.

![Autoenkoderio schema](../../../../../translated_images/lt/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> Vaizdas iÅ¡ [Keras tinklaraÅ¡Äio](https://blog.keras.io/building-autoencoders-in-keras.html)

## AutoenkoderiÅ³ naudojimo scenarijai

Nors originaliÅ³ vaizdÅ³ atkÅ«rimas pats savaime neatrodo naudingas, yra keletas scenarijÅ³, kur autoenkoderiai yra ypaÄ naudingi:

* **VaizdÅ³ dimensijos maÅ¾inimas vizualizacijai** arba **vaizdÅ³ Ä¯terpimÅ³ mokymui**. Paprastai autoenkoderiai duoda geresnius rezultatus nei PCA, nes jie atsiÅ¾velgia Ä¯ vaizdÅ³ erdvinÄ™ prigimtÄ¯ ir hierarchines savybes.
* **TriukÅ¡mo Å¡alinimas**, t. y. triukÅ¡mo paÅ¡alinimas iÅ¡ vaizdo. Kadangi triukÅ¡mas perduoda daug nereikalingos informacijos, autoenkoderis negali viso to sutalpinti Ä¯ palyginti maÅ¾Ä… latentÄ™ erdvÄ™, todÄ—l jis uÅ¾fiksuoja tik svarbiÄ… vaizdo dalÄ¯. Mokant triukÅ¡mo Å¡alinimo tinklus, pradedame nuo originaliÅ³ vaizdÅ³ ir naudojame vaizdus su dirbtinai pridÄ—tu triukÅ¡mu kaip autoenkoderio Ä¯vestÄ¯.
* **Superrezoliucija**, vaizdo raiÅ¡kos didinimas. Pradedame nuo aukÅ¡tos raiÅ¡kos vaizdÅ³ ir naudojame vaizdÄ… su maÅ¾esne raiÅ¡ka kaip autoenkoderio Ä¯vestÄ¯.
* **Generatyviniai modeliai**. Kai iÅ¡mokome autoenkoderÄ¯, dekoderio dalis gali bÅ«ti naudojama naujiems objektams kurti, pradedant nuo atsitiktiniÅ³ latentÄ—s vektoriÅ³.

## Variaciniai autoenkoderiai (VAE)

Tradiciniai autoenkoderiai kaÅ¾kaip sumaÅ¾ina Ä¯vesties duomenÅ³ dimensijÄ…, nustatydami svarbias Ä¯vesties vaizdÅ³ savybes. TaÄiau latentÄ—s vektoriai daÅ¾nai neturi aiÅ¡kios prasmÄ—s. Kitaip tariant, naudojant MNIST duomenÅ³ rinkinÄ¯ kaip pavyzdÄ¯, nustatyti, kurie skaitmenys atitinka skirtingus latentÄ—s vektorius, nÄ—ra lengva uÅ¾duotis, nes artimi latentÄ—s vektoriai nebÅ«tinai atitiks tuos paÄius skaitmenis.

Kita vertus, norint mokyti *generatyvinius* modelius, geriau turÄ—ti tam tikrÄ… supratimÄ… apie latentÄ™ erdvÄ™. Å i idÄ—ja veda mus prie **variacinio autoenkoderio** (VAE).

VAE yra autoenkoderis, kuris mokosi prognozuoti *statistinÄ¯ pasiskirstymÄ…* latentÄ—s parametrÅ³, vadinamÄ… **latentÄ—s pasiskirstymu**. PavyzdÅ¾iui, galime norÄ—ti, kad latentÄ—s vektoriai bÅ«tÅ³ normaliai pasiskirstÄ™ su tam tikru vidurkiu z<sub>mean</sub> ir standartiniu nuokrypiu z<sub>sigma</sub> (tiek vidurkis, tiek standartinis nuokrypis yra tam tikro dimensijos vektoriai). Enkoderis VAE mokosi prognozuoti Å¡iuos parametrus, o dekoderis paima atsitiktinÄ¯ vektoriÅ³ iÅ¡ Å¡io pasiskirstymo, kad atkurtÅ³ objektÄ….

Apibendrinant:

 * IÅ¡ Ä¯vesties vektoriaus prognozuojame `z_mean` ir `z_log_sigma` (vietoj standartinio nuokrypio prognozuojame jo logaritmÄ…)
 * Imame vektoriÅ³ `sample` iÅ¡ pasiskirstymo N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Dekoderis bando dekoduoti originalÅ³ vaizdÄ…, naudodamas `sample` kaip Ä¯vesties vektoriÅ³

 <img src="../../../../../translated_images/lt/vae.464c465a5b6a9e25.webp" width="50%">

> Vaizdas iÅ¡ [Å¡io tinklaraÅ¡Äio Ä¯raÅ¡o](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) Isaak Dykeman

Variaciniai autoenkoderiai naudoja sudÄ—tingÄ… nuostoliÅ³ funkcijÄ…, kuriÄ… sudaro dvi dalys:

* **AtkÅ«rimo nuostolis** yra nuostoliÅ³ funkcija, rodanti, kaip arti atkurtas vaizdas yra tikslui (tai gali bÅ«ti vidutinÄ— kvadratinÄ— paklaida arba MSE). Tai ta pati nuostoliÅ³ funkcija kaip ir Ä¯prastuose autoenkoderiuose.
* **KL nuostolis**, kuris uÅ¾tikrina, kad latentÄ—s kintamÅ³jÅ³ pasiskirstymas iÅ¡liktÅ³ artimas normaliam pasiskirstymui. Jis pagrÄ¯stas [Kullback-Leibler divergencijos](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) sÄ…voka - metrika, skirta Ä¯vertinti, kaip panaÅ¡Å«s yra du statistiniai pasiskirstymai.

Vienas svarbus VAE privalumas yra tas, kad jie leidÅ¾ia gana lengvai generuoti naujus vaizdus, nes Å¾inome, iÅ¡ kurio pasiskirstymo imti latentÄ—s vektorius. PavyzdÅ¾iui, jei mokome VAE su 2D latentÄ—s vektoriumi MNIST duomenÅ³ rinkinyje, galime keisti latentÄ—s vektoriaus komponentus, kad gautume skirtingus skaitmenis:

<img alt="vaemnist" src="../../../../../translated_images/lt/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> Vaizdas [Dmitrijaus Soshnikovo](http://soshnikov.com)

StebÄ—kite, kaip vaizdai susilieja vienas su kitu, kai pradedame gauti latentÄ—s vektorius iÅ¡ skirtingÅ³ latentÄ—s parametrÅ³ erdvÄ—s daliÅ³. Taip pat galime vizualizuoti Å¡iÄ… erdvÄ™ 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/lt/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> Vaizdas [Dmitrijaus Soshnikovo](http://soshnikov.com)

## âœï¸ Pratimai: Autoenkoderiai

SuÅ¾inokite daugiau apie autoenkoderius Å¡iuose atitinkamuose uÅ¾raÅ¡Å³ knygelÄ—se:

* [Autoenkoderiai TensorFlow](AutoencodersTF.ipynb)
* [Autoenkoderiai PyTorch](AutoEncodersPyTorch.ipynb)

## AutoenkoderiÅ³ savybÄ—s

* **DuomenÅ³ specifika** - jie gerai veikia tik su tokio tipo vaizdais, su kuriais buvo mokomi. PavyzdÅ¾iui, jei mokome superrezoliucijos tinklÄ… su gÄ—lÄ—mis, jis neveiks gerai su portretais. Taip yra todÄ—l, kad tinklas gali sukurti aukÅ¡tesnÄ—s raiÅ¡kos vaizdÄ…, naudodamas smulkias detales iÅ¡ mokymo duomenÅ³ rinkinio iÅ¡moktÅ³ savybiÅ³.
* **Nuostolingumas** - atkurtas vaizdas nÄ—ra toks pat kaip originalus vaizdas. NuostoliÅ³ pobÅ«dis apibrÄ—Å¾iamas *nuostoliÅ³ funkcija*, naudojama mokymo metu.
* Veikia su **nepaÅ¾ymÄ—tais duomenimis**

## [Po paskaitos testas](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## IÅ¡vada

Å ioje pamokoje suÅ¾inojote apie Ä¯vairius autoenkoderiÅ³ tipus, kuriuos gali naudoti AI mokslininkas. SuÅ¾inojote, kaip juos kurti ir kaip naudoti juos vaizdams atkurti. Taip pat suÅ¾inojote apie VAE ir kaip jÄ¯ naudoti naujiems vaizdams generuoti.

## ğŸš€ IÅ¡Å¡Å«kis

Å ioje pamokoje suÅ¾inojote apie autoenkoderiÅ³ naudojimÄ… vaizdams. TaÄiau jie gali bÅ«ti naudojami ir muzikai! PaÅ¾iÅ«rÄ—kite Ä¯ Magenta projekto [MusicVAE](https://magenta.tensorflow.org/music-vae) projektÄ…, kuris naudoja autoenkoderius muzikai rekonstruoti. Atlikite keletÄ… [eksperimentÅ³](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) su Å¡ia biblioteka ir paÅ¾iÅ«rÄ—kite, kÄ… galite sukurti.

## [Po paskaitos testas](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

Daugiau informacijos apie autoenkoderius rasite Å¡iuose Å¡altiniuose:

* [AutoenkoderiÅ³ kÅ«rimas Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [TinklaraÅ¡Äio Ä¯raÅ¡as NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Variaciniai autoenkoderiai paaiÅ¡kinti](https://kvfrans.com/variational-autoencoders-explained/)
* [SÄ…lyginiai variaciniai autoenkoderiai](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## UÅ¾duotis

Å ios [uÅ¾raÅ¡Å³ knygelÄ—s su TensorFlow](AutoencodersTF.ipynb) pabaigoje rasite "uÅ¾duotÄ¯" - naudokite jÄ… kaip savo uÅ¾duotÄ¯.

---

