# IÅ¡ anksto apmokyti tinklai ir perkÄ—limo mokymasis

CNN mokymas gali uÅ¾trukti daug laiko, o tam reikia daug duomenÅ³. TaÄiau didÅ¾ioji dalis laiko praleidÅ¾iama mokantis geriausiÅ³ Å¾emo lygio filtrÅ³, kuriuos tinklas gali naudoti norÄ—damas iÅ¡gauti vaizdÅ³ Å¡ablonus. Kyla natÅ«ralus klausimas â€“ ar galime naudoti neuroninÄ¯ tinklÄ…, apmokytÄ… viename duomenÅ³ rinkinyje, ir pritaikyti jÄ¯ kitÅ³ vaizdÅ³ klasifikavimui, nereikalaujant pilno mokymo proceso?

## [PrieÅ¡ paskaitÄ… vykdomas testas](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Å is metodas vadinamas **perkÄ—limo mokymusi**, nes mes perkeliam tam tikras Å¾inias iÅ¡ vieno neuroninio tinklo modelio Ä¯ kitÄ…. PerkÄ—limo mokymesi paprastai pradedame nuo iÅ¡ anksto apmokyto modelio, kuris buvo apmokytas naudojant didelÄ¯ vaizdÅ³ duomenÅ³ rinkinÄ¯, pvz., **ImageNet**. Tokie modeliai jau geba gerai iÅ¡gauti Ä¯vairias savybes iÅ¡ bendrÅ³ vaizdÅ³, ir daugeliu atvejÅ³ tiesiog sukÅ«rus klasifikatoriÅ³ ant tÅ³ iÅ¡gautÅ³ savybiÅ³ galima pasiekti gerÅ³ rezultatÅ³.

> âœ… PerkÄ—limo mokymasis yra terminas, kurÄ¯ galima rasti ir kitose akademinÄ—se srityse, pvz., Å¡vietime. Jis reiÅ¡kia procesÄ…, kai Å¾inios iÅ¡ vienos srities pritaikomos kitoje.

## IÅ¡ anksto apmokyti modeliai kaip savybiÅ³ iÅ¡gavimo Ä¯rankiai

Konvoliuciniai tinklai, apie kuriuos kalbÄ—jome ankstesniame skyriuje, turi daugybÄ™ sluoksniÅ³, kuriÅ³ kiekvienas skirtas iÅ¡gauti tam tikras savybes iÅ¡ vaizdo, pradedant nuo Å¾emo lygio pikseliÅ³ kombinacijÅ³ (pvz., horizontalios/vertikalios linijos ar brÅ«kÅ¡niai), iki aukÅ¡tesnio lygio savybiÅ³ kombinacijÅ³, atitinkanÄiÅ³, pavyzdÅ¾iui, liepsnos akÄ¯. Jei apmokysime CNN su pakankamai dideliu bendrÅ³ ir Ä¯vairiÅ³ vaizdÅ³ duomenÅ³ rinkiniu, tinklas turÄ—tÅ³ iÅ¡mokti iÅ¡gauti tas bendras savybes.

Tiek Keras, tiek PyTorch turi funkcijas, leidÅ¾ianÄias lengvai Ä¯kelti iÅ¡ anksto apmokytus neuroninio tinklo svorius kai kurioms Ä¯prastoms architektÅ«roms, dauguma kuriÅ³ buvo apmokytos naudojant ImageNet vaizdus. DaÅ¾niausiai naudojamos architektÅ«ros apraÅ¡ytos [CNN ArchitektÅ«ros](../07-ConvNets/CNN_Architectures.md) puslapyje iÅ¡ ankstesnÄ—s pamokos. YpaÄ galite apsvarstyti vienÄ… iÅ¡ Å¡iÅ³:

* **VGG-16/VGG-19** â€“ tai palyginti paprasti modeliai, kurie vis dar uÅ¾tikrina gerÄ… tikslumÄ…. DaÅ¾nai VGG naudojimas kaip pirmasis bandymas yra geras pasirinkimas norint pamatyti, kaip veikia perkÄ—limo mokymasis.
* **ResNet** â€“ tai modeliÅ³ Å¡eima, kuriÄ… 2015 m. pasiÅ«lÄ— Microsoft Research. Jie turi daugiau sluoksniÅ³, todÄ—l reikalauja daugiau resursÅ³.
* **MobileNet** â€“ tai modeliÅ³ Å¡eima su sumaÅ¾intu dydÅ¾iu, tinkama mobiliesiems Ä¯renginiams. Naudokite juos, jei turite maÅ¾ai resursÅ³ ir galite paaukoti Å¡iek tiek tikslumo.

Å tai pavyzdinÄ—s savybÄ—s, iÅ¡gautos iÅ¡ katÄ—s nuotraukos naudojant VGG-16 tinklÄ…:

![SavybÄ—s, iÅ¡gautos naudojant VGG-16](../../../../../translated_images/lt/features.6291f9c7ba3a0b95.webp)

## KaÄiÅ³ ir Å¡unÅ³ duomenÅ³ rinkinys

Å iame pavyzdyje naudosime [KaÄiÅ³ ir Å¡unÅ³](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) duomenÅ³ rinkinÄ¯, kuris yra labai artimas realaus gyvenimo vaizdÅ³ klasifikavimo scenarijui.

## âœï¸ UÅ¾duotis: PerkÄ—limo mokymasis

PaÅ¾iÅ«rÄ—kime, kaip veikia perkÄ—limo mokymasis atitinkamuose uÅ¾raÅ¡Å³ knygelÄ—se:

* [PerkÄ—limo mokymasis - PyTorch](TransferLearningPyTorch.ipynb)
* [PerkÄ—limo mokymasis - TensorFlow](TransferLearningTF.ipynb)

## Vizualizuojame prieÅ¡iÅ¡kÄ… katÄ™

IÅ¡ anksto apmokytas neuroninis tinklas savo â€smegenyseâ€œ turi Ä¯vairius Å¡ablonus, Ä¯skaitant **idealios katÄ—s** (taip pat idealios Å¡uns, idealios zebros ir kt.) sampratas. BÅ«tÅ³ Ä¯domu kaÅ¾kaip **vizualizuoti Å¡Ä¯ vaizdÄ…**. TaÄiau tai nÄ—ra paprasta, nes Å¡ablonai yra iÅ¡sklaidyti visame tinklo svoriuose ir taip pat organizuoti hierarchine struktÅ«ra.

Vienas iÅ¡ bÅ«dÅ³, kurÄ¯ galime naudoti, yra pradÄ—ti nuo atsitiktinio vaizdo ir tada bandyti naudoti **gradientinio nusileidimo optimizavimo** technikÄ…, kad pakoreguotume tÄ… vaizdÄ… taip, jog tinklas pradÄ—tÅ³ manyti, kad tai yra katÄ—.

![Vaizdo optimizavimo ciklas](../../../../../translated_images/lt/ideal-cat-loop.999fbb8ff306e044.webp)

TaÄiau, jei tai padarysime, gausime kaÅ¾kÄ… labai panaÅ¡aus Ä¯ atsitiktinÄ¯ triukÅ¡mÄ…. Taip yra todÄ—l, kad *yra daug bÅ«dÅ³, kaip tinklas gali manyti, kad Ä¯vesties vaizdas yra katÄ—*, Ä¯skaitant kai kuriuos, kurie vizualiai neturi prasmÄ—s. Nors tie vaizdai turi daug Å¡ablonÅ³, bÅ«dingÅ³ katei, nÄ—ra nieko, kas juos apribotÅ³ vizualiai iÅ¡skirtiniais.

NorÄ—dami pagerinti rezultatÄ…, galime pridÄ—ti dar vienÄ… terminÄ… Ä¯ nuostoliÅ³ funkcijÄ…, vadinamÄ… **variacijos nuostoliu**. Tai metrika, rodanti, kaip panaÅ¡Å«s yra kaimyniniai vaizdo pikseliai. MaÅ¾inant variacijos nuostolÄ¯ vaizdas tampa lygesnis ir atsikratoma triukÅ¡mo â€“ taip atskleidÅ¾iami vizualiai patrauklesni Å¡ablonai. Å tai pavyzdys tokiÅ³ â€idealiÅ³â€œ vaizdÅ³, kurie su didele tikimybe klasifikuojami kaip katÄ— ir kaip zebra:

![Ideali katÄ—](../../../../../translated_images/lt/ideal-cat.203dd4597643d6b0.webp) | ![Ideali zebra](../../../../../translated_images/lt/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Ideali katÄ—* | *Ideali zebra*

PanaÅ¡us metodas gali bÅ«ti naudojamas atliekant vadinamuosius **prieÅ¡iÅ¡kus iÅ¡puolius** prieÅ¡ neuroninÄ¯ tinklÄ…. Tarkime, norime apgauti neuroninÄ¯ tinklÄ… ir priversti Å¡unÄ¯ atrodyti kaip katÄ™. Jei paimsime Å¡uns vaizdÄ…, kurÄ¯ tinklas atpaÅ¾Ä¯sta kaip Å¡unÄ¯, galime Å¡iek tiek jÄ¯ pakoreguoti naudodami gradientinio nusileidimo optimizavimÄ…, kol tinklas pradÄ—s jÄ¯ klasifikuoti kaip katÄ™:

![Å uns nuotrauka](../../../../../translated_images/lt/original-dog.8f68a67d2fe0911f.webp) | ![Å uns nuotrauka, klasifikuojama kaip katÄ—](../../../../../translated_images/lt/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Originali Å¡uns nuotrauka* | *Å uns nuotrauka, klasifikuojama kaip katÄ—*

Å½r. kodÄ…, kaip atkurti aukÅ¡Äiau pateiktus rezultatus, Å¡ioje uÅ¾raÅ¡Å³ knygelÄ—je:

* [Ideali ir prieÅ¡iÅ¡ka katÄ— - TensorFlow](AdversarialCat_TF.ipynb)

## IÅ¡vada

Naudodami perkÄ—limo mokymÄ…si, galite greitai sukurti klasifikatoriÅ³ pagal individualÅ³ objektÅ³ klasifikavimo uÅ¾davinÄ¯ ir pasiekti aukÅ¡tÄ… tikslumÄ…. Matote, kad sudÄ—tingesni uÅ¾daviniai, kuriuos sprendÅ¾iame dabar, reikalauja didesnÄ—s skaiÄiavimo galios ir negali bÅ«ti lengvai iÅ¡sprÄ™sti naudojant CPU. Kitame skyriuje bandysime naudoti lengvesnÄ™ Ä¯gyvendinimo versijÄ…, kad apmokytume tÄ… patÄ¯ modelÄ¯ naudodami maÅ¾esnius skaiÄiavimo resursus, kas lemia tik Å¡iek tiek maÅ¾esnÄ¯ tikslumÄ….

## ğŸš€ IÅ¡Å¡Å«kis

Pridedamose uÅ¾raÅ¡Å³ knygelÄ—se yra pastabÅ³ apaÄioje apie tai, kaip perkeltos Å¾inios geriausiai veikia su Å¡iek tiek panaÅ¡iais mokymo duomenimis (pvz., naujo tipo gyvÅ«nu). Atlikite eksperimentus su visiÅ¡kai naujais vaizdÅ³ tipais, kad pamatytumÄ—te, kaip gerai ar prastai veikia jÅ«sÅ³ perkeltÅ³ Å¾iniÅ³ modeliai.

## [Po paskaitos vykdomas testas](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

Perskaitykite [TrainingTricks.md](TrainingTricks.md), kad pagilintumÄ—te savo Å¾inias apie kitus bÅ«dus, kaip mokyti savo modelius.

## [UÅ¾duotis](lab/README.md)

Å iame laboratoriniame darbe naudosime realaus gyvenimo [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) naminiÅ³ gyvÅ«nÅ³ duomenÅ³ rinkinÄ¯ su 35 kaÄiÅ³ ir Å¡unÅ³ veislÄ—mis ir sukursime perkÄ—limo mokymosi klasifikatoriÅ³.

---

