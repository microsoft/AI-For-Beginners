<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d85c8b08f6d1b48fd7f35b99f93c1138",
  "translation_date": "2025-08-31T17:40:39+00:00",
  "source_file": "lessons/4-ComputerVision/11-ObjectDetection/README.md",
  "language_code": "lt"
}
-->
# ObjektÅ³ atpaÅ¾inimas

VaizdÅ³ klasifikavimo modeliai, su kuriais dirbome iki Å¡iol, paimdavo vaizdÄ… ir pateikdavo kategorinÄ¯ rezultatÄ…, pavyzdÅ¾iui, klasÄ™ â€skaiÄiusâ€œ MNIST uÅ¾duotyje. TaÄiau daugeliu atvejÅ³ mums nepakanka Å¾inoti, kad paveikslÄ—lyje yra objektÅ³ â€“ mes norime nustatyti jÅ³ tiksliÄ… vietÄ…. BÅ«tent tai ir yra **objektÅ³ atpaÅ¾inimo** esmÄ—.

## [PrieÅ¡ paskaitÄ…: testas](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![ObjektÅ³ atpaÅ¾inimas](../../../../../translated_images/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be1b905373ed9c858102c054b16e4595c76ec3f7bba0feb549.lt.png)

> Vaizdas iÅ¡ [YOLO v2 svetainÄ—s](https://pjreddie.com/darknet/yolov2/)

## Naivus poÅ¾iÅ«ris Ä¯ objektÅ³ atpaÅ¾inimÄ…

Tarkime, norime rasti katÄ™ paveikslÄ—lyje. Labai naivus poÅ¾iÅ«ris Ä¯ objektÅ³ atpaÅ¾inimÄ… galÄ—tÅ³ bÅ«ti toks:

1. Suskaidykite paveikslÄ—lÄ¯ Ä¯ daugybÄ™ plyteliÅ³.
2. Atlikite vaizdÅ³ klasifikavimÄ… kiekvienoje plytelÄ—je.
3. Tos plytelÄ—s, kuriose aktyvacija yra pakankamai aukÅ¡ta, gali bÅ«ti laikomos turinÄiomis ieÅ¡komÄ… objektÄ….

![Naivus objektÅ³ atpaÅ¾inimas](../../../../../translated_images/naive-detection.e7f1ba220ccd08c68a2ea8e06a7ed75c3fcc738c2372f9e00b7f4299a8659c01.lt.png)

> *Vaizdas iÅ¡ [uÅ¾duoÄiÅ³ sÄ…siuvinio](ObjectDetection-TF.ipynb)*

TaÄiau Å¡is metodas toli graÅ¾u nÄ—ra idealus, nes leidÅ¾ia algoritmui labai netiksliai nustatyti objekto ribÅ³ dÄ—Å¾utÄ™. Norint tiksliau nustatyti vietÄ…, reikia atlikti tam tikrÄ… **regresijÄ…**, kad bÅ«tÅ³ galima prognozuoti ribÅ³ dÄ—Å¾uÄiÅ³ koordinates â€“ tam reikalingi specifiniai duomenÅ³ rinkiniai.

## Regresija objektÅ³ atpaÅ¾inimui

[Å is tinklaraÅ¡Äio Ä¯raÅ¡as](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491) puikiai supaÅ¾indina su formÅ³ atpaÅ¾inimu.

## DuomenÅ³ rinkiniai objektÅ³ atpaÅ¾inimui

Å iai uÅ¾duoÄiai galite susidurti su Å¡iais duomenÅ³ rinkiniais:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) â€“ 20 klasiÅ³
* [COCO](http://cocodataset.org/#home) â€“ â€Common Objects in Contextâ€œ. 80 klasiÅ³, ribÅ³ dÄ—Å¾utÄ—s ir segmentavimo kaukÄ—s

![COCO](../../../../../translated_images/coco-examples.71bc60380fa6cceb7caad48bd09e35b6028caabd363aa04fee89c414e0870e86.lt.jpg)

## ObjektÅ³ atpaÅ¾inimo metrikos

### Sankirta per sÄ…jungÄ… (Intersection over Union)

VaizdÅ³ klasifikavimui lengva iÅ¡matuoti, kaip gerai veikia algoritmas, taÄiau objektÅ³ atpaÅ¾inimui reikia Ä¯vertinti tiek klasÄ—s teisingumÄ…, tiek numatytos ribÅ³ dÄ—Å¾utÄ—s vietos tikslumÄ…. Pastarajam naudojame vadinamÄ…jÄ… **sankirtÄ… per sÄ…jungÄ…** (IoU), kuri matuoja, kaip gerai dvi dÄ—Å¾utÄ—s (ar dvi savavaliÅ¡kos sritys) persidengia.

![IoU](../../../../../translated_images/iou_equation.9a4751d40fff4e119ecd0a7bcca4e71ab1dc83e0d4f2a0d66ff0859736f593cf.lt.png)

> *2 pav. iÅ¡ [puikaus tinklaraÅ¡Äio Ä¯raÅ¡o apie IoU](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)*

IdÄ—ja paprasta â€“ padalijame dviejÅ³ figÅ«rÅ³ sankirtos plotÄ… iÅ¡ jÅ³ sÄ…jungos ploto. DviejÅ³ identiÅ¡kÅ³ sriÄiÅ³ IoU bÅ«tÅ³ 1, o visiÅ¡kai nesutampanÄiÅ³ sriÄiÅ³ â€“ 0. Kitais atvejais reikÅ¡mÄ— svyruos nuo 0 iki 1. Paprastai atsiÅ¾velgiame tik Ä¯ tas ribÅ³ dÄ—Å¾utes, kuriÅ³ IoU virÅ¡ija tam tikrÄ… vertÄ™.

### VidutinÄ— tikslumo reikÅ¡mÄ— (Average Precision)

Tarkime, norime Ä¯vertinti, kaip gerai atpaÅ¾Ä¯stama tam tikra objektÅ³ klasÄ— $C$. Tam naudojame **vidutinio tikslumo** metrikÄ…, kuri apskaiÄiuojama taip:

1. Apsvarstykite tikslumo ir atgaminimo (Precision-Recall) kreivÄ™, kuri rodo tikslumÄ… priklausomai nuo aptikimo slenksÄio vertÄ—s (nuo 0 iki 1).
2. Priklausomai nuo slenksÄio, paveikslÄ—lyje aptinkama daugiau ar maÅ¾iau objektÅ³, o tikslumo ir atgaminimo reikÅ¡mÄ—s skiriasi.
3. KreivÄ— atrodys taip:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *Vaizdas iÅ¡ [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

VidutinÄ— tikslumo reikÅ¡mÄ— klasei $C$ yra plotas po Å¡ia kreive. Tiksliau, atgaminimo aÅ¡is paprastai padalijama Ä¯ 10 daliÅ³, o tikslumas vidurkinamas per visas Å¡ias taÅ¡kus:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP ir IoU

Apsvarstysime tik tuos aptikimus, kuriÅ³ IoU virÅ¡ija tam tikrÄ… vertÄ™. PavyzdÅ¾iui, PASCAL VOC duomenÅ³ rinkinyje paprastai $\mbox{IoU Threshold} = 0.5$, o COCO AP matuojamas skirtingoms $\mbox{IoU Threshold}$ reikÅ¡mÄ—ms.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *Vaizdas iÅ¡ [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

### VidutinÄ— vidutinio tikslumo reikÅ¡mÄ— â€“ mAP

PagrindinÄ— objektÅ³ atpaÅ¾inimo metrika vadinama **vidutine vidutinio tikslumo reikÅ¡me** arba **mAP**. Tai yra vidutinio tikslumo reikÅ¡mÄ—, vidurkinama per visas objektÅ³ klases, o kartais ir per $\mbox{IoU Threshold}$. IÅ¡samesnis **mAP** skaiÄiavimo procesas apraÅ¡ytas
[Å¡iame tinklaraÅ¡Äio Ä¯raÅ¡e](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3), taip pat [Äia su kodo pavyzdÅ¾iais](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734).

## Skirtingi objektÅ³ atpaÅ¾inimo metodai

Yra dvi pagrindinÄ—s objektÅ³ atpaÅ¾inimo algoritmÅ³ klasÄ—s:

* **RegionÅ³ pasiÅ«lymÅ³ tinklai** (R-CNN, Fast R-CNN, Faster R-CNN). PagrindinÄ— idÄ—ja â€“ generuoti **dominantiesiems regionams** (ROI) ir praleisti CNN per juos, ieÅ¡kant maksimalaus aktyvavimo. Tai Å¡iek tiek panaÅ¡u Ä¯ naivÅ³ metodÄ…, iÅ¡skyrus tai, kad ROI generuojami protingesniu bÅ«du. Vienas pagrindiniÅ³ Å¡iÅ³ metodÅ³ trÅ«kumÅ³ yra lÄ—tumas, nes reikia daug CNN klasifikatoriaus praleidimÅ³ per vaizdÄ….
* **Vieno praleidimo** (YOLO, SSD, RetinaNet) metodai. Å iose architektÅ«rose tinklas suprojektuotas taip, kad vienu praleidimu prognozuotÅ³ tiek klases, tiek ROI.

### R-CNN: Region-Based CNN

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf) naudoja [Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf), kad generuotÅ³ hierarchinÄ™ ROI regionÅ³ struktÅ«rÄ…, kuri vÄ—liau perduodama per CNN poÅ¾ymiÅ³ iÅ¡gavimo ir SVM klasifikatorius, kad bÅ«tÅ³ nustatyta objekto klasÄ—, o linijinÄ— regresija naudojama *ribÅ³ dÄ—Å¾utÄ—s* koordinatÄ—ms nustatyti. [Oficialus straipsnis](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/rcnn1.cae407020dfb1d1fb572656e44f75cd6c512cc220591c116c506652c10e47f26.lt.png)

> *Vaizdas iÅ¡ van de Sande et al. ICCVâ€™11*

![RCNN-1](../../../../../translated_images/rcnn2.2d9530bb83516484ec65b250c22dbf37d3d23244f32864ebcb91d98fe7c3112c.lt.png)

> *Vaizdai iÅ¡ [Å¡io tinklaraÅ¡Äio](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)*

### F-RCNN â€“ Fast R-CNN

Å is metodas panaÅ¡us Ä¯ R-CNN, taÄiau regionai apibrÄ—Å¾iami po konvoliuciniÅ³ sluoksniÅ³ pritaikymo.

![FRCNN](../../../../../translated_images/f-rcnn.3cda6d9bb41888754037d2d9763e2298a96de5d9bc2a21db3147357aa5da9b1a.lt.png)

> Vaizdas iÅ¡ [oficialaus straipsnio](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Faster R-CNN

PagrindinÄ— Å¡io metodo idÄ—ja â€“ naudoti neuroninÄ¯ tinklÄ… ROI prognozavimui â€“ vadinamÄ…jÄ¯ *Region Proposal Network*. [Straipsnis](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../translated_images/faster-rcnn.8d46c099b87ef30ab2ea26dbc4bdd85b974a57ba8eb526f65dc4cd0a4711de30.lt.png)

> Vaizdas iÅ¡ [oficialaus straipsnio](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: Region-Based Fully Convolutional Network

Å is algoritmas dar greitesnis nei Faster R-CNN. PagrindinÄ— idÄ—ja:

1. IÅ¡gauname poÅ¾ymius naudodami ResNet-101.
2. PoÅ¾ymiai apdorojami **Position-Sensitive Score Map**. Kiekvienas objektas iÅ¡ $C$ klasiÅ³ padalijamas Ä¯ $k\times k$ regionus, ir mes mokome prognozuoti objektÅ³ dalis.
3. Kiekvienai daliai iÅ¡ $k\times k$ regionÅ³ visi tinklai balsuoja uÅ¾ objektÅ³ klases, ir pasirenkama klasÄ— su didÅ¾iausiu balsÅ³ skaiÄiumi.

![r-fcn image](../../../../../translated_images/r-fcn.13eb88158b99a3da50fa2787a6be5cb310d47f0e9655cc93a1090dc7aab338d1.lt.png)

> Vaizdas iÅ¡ [oficialaus straipsnio](https://arxiv.org/abs/1605.06409)

### YOLO â€“ You Only Look Once

YOLO yra realaus laiko vieno praleidimo algoritmas. PagrindinÄ— idÄ—ja:

 * Vaizdas padalijamas Ä¯ $S\times S$ regionus.
 * Kiekvienam regionui **CNN** prognozuoja $n$ galimÅ³ objektÅ³, *ribÅ³ dÄ—Å¾utÄ—s* koordinates ir *pasitikÄ—jimÄ…*=*tikimybÄ™* * IoU.

 ![YOLO](../../../../../translated_images/yolo.a2648ec82ee8bb4ea27537677adb482fd4b733ca1705c561b6a24a85102dced5.lt.png)

> Vaizdas iÅ¡ [oficialaus straipsnio](https://arxiv.org/abs/1506.02640)

### Kiti algoritmai

* RetinaNet: [oficialus straipsnis](https://arxiv.org/abs/1708.02002)
   - [PyTorch Ä¯gyvendinimas Torchvision](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Keras Ä¯gyvendinimas](https://github.com/fizyr/keras-retinanet)
   - [ObjektÅ³ atpaÅ¾inimas su RetinaNet](https://keras.io/examples/vision/retinanet/) Keras pavyzdÅ¾iuose
* SSD (Single Shot Detector): [oficialus straipsnis](https://arxiv.org/abs/1512.02325)

## âœï¸ Pratimai: ObjektÅ³ atpaÅ¾inimas

TÄ™skite mokymÄ…si Å¡iame sÄ…siuvinyje:

[ObjectDetection.ipynb](ObjectDetection.ipynb)

## IÅ¡vada

Å ioje pamokoje greitai apÅ¾velgÄ—te Ä¯vairius bÅ«dus, kaip galima atlikti objektÅ³ atpaÅ¾inimÄ…!

## ğŸš€ IÅ¡Å¡Å«kis

Perskaitykite Å¡iuos straipsnius ir sÄ…siuvinius apie YOLO ir iÅ¡bandykite juos patys:

* [Geras tinklaraÅ¡Äio Ä¯raÅ¡as](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/) apie YOLO
 * [Oficiali svetainÄ—](https://pjreddie.com/darknet/yolo/)
 * Yolo: [Keras Ä¯gyvendinimas](https://github.com/experiencor/keras-yolo2), [Å¾ingsnis po Å¾ingsnio sÄ…siuvinis](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * Yolo v2: [Keras Ä¯gyvendinimas](https://github.com/experiencor/keras-yolo2), [Å¾ingsnis po Å¾ingsnio sÄ…siuvinis](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [Po paskaitos: testas](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

* [ObjektÅ³ atpaÅ¾inimas](https://tjmachinelearning.com/lectures/1718/obj/) Nikhil Sardana
* [Geras objektÅ³ atpaÅ¾inimo algoritmÅ³ palyginimas](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [GiliÅ³jÅ³ mokymosi algoritmÅ³ apÅ¾valga objektÅ³ atpaÅ¾inimui](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [Å½ingsnis po Å¾ingsnio Ä¯vadas Ä¯ pagrindinius objektÅ³ atpaÅ¾inimo algoritmus](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Faster R-CNN Ä¯gyvendinimas Python kalba objektÅ³ atpaÅ¾inimui](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [UÅ¾duotis: ObjektÅ³ atpaÅ¾inimas](lab/README.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama profesionali Å¾mogaus vertimo paslauga. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar klaidingus interpretavimus, atsiradusius dÄ—l Å¡io vertimo naudojimo.