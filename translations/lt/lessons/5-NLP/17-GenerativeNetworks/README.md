<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d9de7847385eeeda67cfdcce1640ab72",
  "translation_date": "2025-08-31T17:55:40+00:00",
  "source_file": "lessons/5-NLP/17-GenerativeNetworks/README.md",
  "language_code": "lt"
}
-->
# Generatyviniai tinklai

## [Klausimynas prieÅ¡ paskaitÄ…](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/117)

PasikartojanÄiÅ³ neuroniniÅ³ tinklÅ³ (RNN) ir jÅ³ vartÅ³ lÄ…steliÅ³ variantai, tokie kaip ilgos trumpos atminties lÄ…stelÄ—s (LSTM) ir vartÅ³ pasikartojanÄios vienetai (GRU), suteikÄ— mechanizmÄ… kalbos modeliavimui, nes jie gali iÅ¡mokti Å¾odÅ¾iÅ³ tvarkÄ… ir pateikti prognozes apie kitÄ… Å¾odÄ¯ sekoje. Tai leidÅ¾ia mums naudoti RNN **generatyvinÄ—ms uÅ¾duotims**, tokioms kaip paprastas teksto generavimas, maÅ¡ininis vertimas ir net vaizdÅ³ apraÅ¡ymas.

> âœ… Pagalvokite apie visas situacijas, kai pasinaudojote generatyvinÄ—mis uÅ¾duotimis, pavyzdÅ¾iui, teksto uÅ¾baigimu raÅ¡ant. Atlikite tyrimÄ… apie savo mÄ—gstamas programas ir suÅ¾inokite, ar jos naudojo RNN.

RNN architektÅ«roje, kuriÄ… aptarÄ—me ankstesniame skyriuje, kiekvienas RNN vienetas generavo kitÄ… paslÄ—ptÄ… bÅ«senÄ… kaip iÅ¡vestÄ¯. TaÄiau mes taip pat galime pridÄ—ti kitÄ… iÅ¡vestÄ¯ prie kiekvieno pasikartojanÄio vieneto, kuris leistÅ³ generuoti **sekÄ…** (lygiÄ… pradinÄ—s sekos ilgiui). Be to, galime naudoti RNN vienetus, kurie kiekviename Å¾ingsnyje nepriima Ä¯vesties, o tiesiog naudoja pradinÄ¯ bÅ«senos vektoriÅ³ ir generuoja iÅ¡vesties sekÄ….

Tai leidÅ¾ia sukurti skirtingas neuronines architektÅ«ras, kurios parodytos paveikslÄ—lyje Å¾emiau:

![PaveikslÄ—lis, rodantis Ä¯prastus pasikartojanÄiÅ³ neuroniniÅ³ tinklÅ³ modelius.](../../../../../translated_images/unreasonable-effectiveness-of-rnn.541ead816778f42dce6c42d8a56c184729aa2378d059b851be4ce12b993033df.lt.jpg)

> PaveikslÄ—lis iÅ¡ tinklaraÅ¡Äio Ä¯raÅ¡o [Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) autoriaus [Andrej Karpaty](http://karpathy.github.io/)

* **Vienas Ä¯ vienÄ…** yra tradicinis neuroninis tinklas su viena Ä¯vestimi ir viena iÅ¡vestimi
* **Vienas Ä¯ daug** yra generatyvinÄ— architektÅ«ra, kuri priima vienÄ… Ä¯vesties reikÅ¡mÄ™ ir generuoja iÅ¡vesties reikÅ¡miÅ³ sekÄ…. PavyzdÅ¾iui, jei norime apmokyti **vaizdÅ³ apraÅ¡ymo** tinklÄ…, kuris generuotÅ³ tekstinÄ¯ paveikslÄ—lio apraÅ¡ymÄ…, galime naudoti paveikslÄ—lÄ¯ kaip Ä¯vestÄ¯, perduoti jÄ¯ per CNN, kad gautume paslÄ—ptÄ… bÅ«senÄ…, o tada pasikartojanti grandinÄ— generuotÅ³ apraÅ¡ymÄ… Å¾odis po Å¾odÅ¾io.
* **Daug Ä¯ vienÄ…** atitinka RNN architektÅ«ras, kurias apraÅ¡Ä—me ankstesniame skyriuje, pavyzdÅ¾iui, teksto klasifikavimÄ….
* **Daug Ä¯ daug**, arba **seka Ä¯ sekÄ…**, atitinka uÅ¾duotis, tokias kaip **maÅ¡ininis vertimas**, kur pirmasis RNN surenka visÄ… informacijÄ… iÅ¡ Ä¯vesties sekos Ä¯ paslÄ—ptÄ… bÅ«senÄ…, o kita RNN grandinÄ— iÅ¡skleidÅ¾ia Å¡iÄ… bÅ«senÄ… Ä¯ iÅ¡vesties sekÄ….

Å iame skyriuje mes sutelksime dÄ—mesÄ¯ Ä¯ paprastus generatyvinius modelius, kurie padeda generuoti tekstÄ…. Paprastumo dÄ—lei naudosime simboliÅ³ lygio tokenizacijÄ….

Mes apmokysime Å¡Ä¯ RNN generuoti tekstÄ… Å¾ingsnis po Å¾ingsnio. Kiekviename Å¾ingsnyje imsime simboliÅ³ sekÄ…, kurios ilgis yra `nchars`, ir papraÅ¡ysime tinklo generuoti kitÄ… iÅ¡vesties simbolÄ¯ kiekvienam Ä¯vesties simboliui:

![PaveikslÄ—lis, rodantis RNN generavimo pavyzdÄ¯ su Å¾odÅ¾iu 'HELLO'.](../../../../../translated_images/rnn-generate.56c54afb52f9781d63a7c16ea9c1b86cb70e6e1eae6a742b56b7b37468576b17.lt.png)

Generuojant tekstÄ… (inferencijos metu), pradedame nuo tam tikro **pradÅ¾ios taÅ¡ko**, kuris perduodamas per RNN lÄ…steles, kad generuotÅ³ tarpinÄ™ bÅ«senÄ…, o tada iÅ¡ Å¡ios bÅ«senos prasideda generavimas. Generuojame po vienÄ… simbolÄ¯, perduodame bÅ«senÄ… ir sugeneruotÄ… simbolÄ¯ kitai RNN lÄ…stelei, kad sugeneruotume kitÄ… simbolÄ¯, kol sugeneruojame pakankamai simboliÅ³.

<img src="images/rnn-generate-inf.png" width="60%"/>

> PaveikslÄ—lis autoriaus

## âœï¸ Pratimai: Generatyviniai tinklai

TÄ™skite mokymÄ…si Å¡iuose uÅ¾raÅ¡uose:

* [Generatyviniai tinklai su PyTorch](GenerativePyTorch.ipynb)
* [Generatyviniai tinklai su TensorFlow](GenerativeTF.ipynb)

## MinkÅ¡tas teksto generavimas ir temperatÅ«ra

Kiekvienos RNN lÄ…stelÄ—s iÅ¡vestis yra simboliÅ³ tikimybiÅ³ pasiskirstymas. Jei visada pasirinksime simbolÄ¯ su didÅ¾iausia tikimybe kaip kitÄ… simbolÄ¯ generuojamame tekste, tekstas daÅ¾nai gali "uÅ¾strigti" tarp tÅ³ paÄiÅ³ simboliÅ³ sekÅ³, kaip Å¡iame pavyzdyje:

```
today of the second the company and a second the company ...
```

TaÄiau, jei paÅ¾velgsime Ä¯ tikimybiÅ³ pasiskirstymÄ… kitam simboliui, gali bÅ«ti, kad keliÅ³ didÅ¾iausiÅ³ tikimybiÅ³ skirtumas nÄ—ra didelis, pvz., vienas simbolis gali turÄ—ti tikimybÄ™ 0.2, o kitas - 0.19 ir t.t. PavyzdÅ¾iui, ieÅ¡kant kito simbolio sekoje '*play*', kitas simbolis gali bÅ«ti tiek tarpas, tiek **e** (kaip Å¾odyje *player*).

Tai veda prie iÅ¡vados, kad ne visada "teisinga" pasirinkti simbolÄ¯ su didÅ¾iausia tikimybe, nes pasirinkus antrÄ… pagal dydÄ¯ vis tiek galime gauti prasmingÄ… tekstÄ…. Protingiau yra **imti mÄ—ginius** iÅ¡ tikimybiÅ³ pasiskirstymo, kurÄ¯ pateikia tinklo iÅ¡vestis. Taip pat galime naudoti parametrÄ… **temperatÅ«ra**, kuris iÅ¡lygins tikimybiÅ³ pasiskirstymÄ…, jei norime pridÄ—ti daugiau atsitiktinumo, arba padaryti jÄ¯ statesnÄ¯, jei norime labiau laikytis didÅ¾iausios tikimybÄ—s simboliÅ³.

IÅ¡bandykite, kaip Å¡is minkÅ¡tas teksto generavimas Ä¯gyvendinamas uÅ¾raÅ¡uose, pateiktuose aukÅ¡Äiau.

## IÅ¡vada

Nors teksto generavimas gali bÅ«ti naudingas pats savaime, pagrindiniai privalumai atsiranda iÅ¡ galimybÄ—s generuoti tekstÄ… naudojant RNN iÅ¡ tam tikro pradinio poÅ¾ymiÅ³ vektoriaus. PavyzdÅ¾iui, teksto generavimas naudojamas kaip maÅ¡ininio vertimo dalis (seka Ä¯ sekÄ…, Å¡iuo atveju bÅ«senos vektorius iÅ¡ *koduotojo* naudojamas generuoti arba *dekoduoti* iÅ¡verstÄ… praneÅ¡imÄ…), arba generuojant tekstinÄ¯ vaizdo apraÅ¡ymÄ… (Å¡iuo atveju poÅ¾ymiÅ³ vektorius bÅ«tÅ³ gaunamas iÅ¡ CNN ekstraktoriaus).

## ğŸš€ IÅ¡Å¡Å«kis

Pasimokykite apie Å¡iÄ… temÄ… Microsoft Learn platformoje:

* Teksto generavimas su [PyTorch](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/6-generative-networks/?WT.mc_id=academic-77998-cacaste)/[TensorFlow](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-tensorflow/5-generative-networks/?WT.mc_id=academic-77998-cacaste)

## [Klausimynas po paskaitos](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/217)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

Å tai keletas straipsniÅ³, kurie padÄ—s praplÄ—sti Å¾inias:

* Skirtingi teksto generavimo metodai naudojant Markovo grandinÄ™, LSTM ir GPT-2: [tinklaraÅ¡Äio Ä¯raÅ¡as](https://towardsdatascience.com/text-generation-gpt-2-lstm-markov-chain-9ea371820e1e)
* Teksto generavimo pavyzdys [Keras dokumentacijoje](https://keras.io/examples/generative/lstm_character_level_text_generation/)

## [UÅ¾duotis](lab/README.md)

Mes matÄ—me, kaip generuoti tekstÄ… simbolis po simbolio. Laboratorijoje tyrinÄ—site teksto generavimÄ… Å¾odÅ¾iÅ³ lygiu.

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama naudoti profesionalÅ³ Å¾mogaus vertimÄ…. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar klaidingus interpretavimus, atsiradusius dÄ—l Å¡io vertimo naudojimo.