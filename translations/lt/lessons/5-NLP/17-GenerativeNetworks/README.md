# Generatyviniai tinklai

## [Klausimynas prieÅ¡ paskaitÄ…](https://ff-quizzes.netlify.app/en/ai/quiz/33)

PasikartojanÄiÅ³ neuroniniÅ³ tinklÅ³ (RNN) ir jÅ³ vartÅ³ lÄ…steliÅ³ variantÅ³, tokiÅ³ kaip ilgos trumpos atminties lÄ…stelÄ—s (LSTM) ir vartÅ³ pasikartojanÄios vienetai (GRU), mechanizmas leidÅ¾ia modeliuoti kalbÄ…, nes jie gali iÅ¡mokti Å¾odÅ¾iÅ³ tvarkÄ… ir numatyti kitÄ… Å¾odÄ¯ sekoje. Tai leidÅ¾ia naudoti RNN **generatyvinÄ—ms uÅ¾duotims**, tokioms kaip paprastas teksto generavimas, maÅ¡ininis vertimas ar net vaizdÅ³ apraÅ¡ymas.

> âœ… Pagalvokite apie visas situacijas, kai pasinaudojote generatyvinÄ—mis uÅ¾duotimis, pavyzdÅ¾iui, teksto uÅ¾baigimu raÅ¡ant. PasidomÄ—kite savo mÄ—gstamomis programomis ir suÅ¾inokite, ar jos naudojo RNN.

RNN architektÅ«roje, kuriÄ… aptarÄ—me ankstesniame skyriuje, kiekvienas RNN vienetas generavo kitÄ… paslÄ—ptÄ… bÅ«senÄ… kaip iÅ¡vestÄ¯. TaÄiau mes taip pat galime pridÄ—ti kitÄ… iÅ¡vestÄ¯ prie kiekvieno pasikartojanÄio vieneto, kuris leistÅ³ generuoti **sekÄ…** (lygiÄ… pradinÄ—s sekos ilgiui). Be to, galime naudoti RNN vienetus, kurie kiekviename Å¾ingsnyje nepriima Ä¯vesties, o tiesiog naudoja pradinÄ¯ bÅ«senos vektoriÅ³ ir generuoja iÅ¡vesties sekÄ….

Tai leidÅ¾ia sukurti skirtingas neuronines architektÅ«ras, kurios parodytos Å¾emiau esanÄiame paveikslÄ—lyje:

![PaveikslÄ—lis, rodantis Ä¯prastus pasikartojanÄiÅ³ neuroniniÅ³ tinklÅ³ modelius.](../../../../../translated_images/lt/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> PaveikslÄ—lis iÅ¡ tinklaraÅ¡Äio Ä¯raÅ¡o [Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) autoriaus [Andrej Karpaty](http://karpathy.github.io/)

* **Vienas su vienu** yra tradicinis neuroninis tinklas su viena Ä¯vestimi ir viena iÅ¡vestimi
* **Vienas su daugeliu** yra generatyvinÄ— architektÅ«ra, kuri priima vienÄ… Ä¯vesties reikÅ¡mÄ™ ir generuoja iÅ¡vesties reikÅ¡miÅ³ sekÄ…. PavyzdÅ¾iui, jei norime iÅ¡mokyti tinklÄ… **vaizdÅ³ apraÅ¡ymui**, kuris generuotÅ³ tekstinÄ¯ paveikslÄ—lio apraÅ¡ymÄ…, galime naudoti paveikslÄ—lÄ¯ kaip Ä¯vestÄ¯, perduoti jÄ¯ per CNN, kad gautume paslÄ—ptÄ… bÅ«senÄ…, o tada pasikartojanti grandinÄ— generuotÅ³ apraÅ¡ymÄ… Å¾odis po Å¾odÅ¾io.
* **Daug su vienu** atitinka RNN architektÅ«ras, kurias apraÅ¡Ä—me ankstesniame skyriuje, pavyzdÅ¾iui, teksto klasifikavimÄ….
* **Daug su daugeliu**, arba **seka Ä¯ sekÄ…**, atitinka uÅ¾duotis, tokias kaip **maÅ¡ininis vertimas**, kur pirmasis RNN surenka visÄ… informacijÄ… iÅ¡ Ä¯vesties sekos Ä¯ paslÄ—ptÄ… bÅ«senÄ…, o kita RNN grandinÄ— iÅ¡skleidÅ¾ia Å¡iÄ… bÅ«senÄ… Ä¯ iÅ¡vesties sekÄ….

Å iame skyriuje mes sutelksime dÄ—mesÄ¯ Ä¯ paprastus generatyvinius modelius, kurie padeda generuoti tekstÄ…. Paprastumo dÄ—lei naudosime simboliÅ³ lygio tokenizacijÄ….

Mes iÅ¡mokysime Å¡Ä¯ RNN generuoti tekstÄ… Å¾ingsnis po Å¾ingsnio. Kiekviename Å¾ingsnyje imsime simboliÅ³ sekÄ…, kurios ilgis yra `nchars`, ir papraÅ¡ysime tinklo generuoti kitÄ… iÅ¡vesties simbolÄ¯ kiekvienam Ä¯vesties simboliui:

![PaveikslÄ—lis, rodantis RNN generavimo pavyzdÄ¯ su Å¾odÅ¾iu 'HELLO'.](../../../../../translated_images/lt/rnn-generate.56c54afb52f9781d.webp)

Generuojant tekstÄ… (inference metu), pradedame nuo tam tikro **pradÅ¾ios taÅ¡ko**, kuris perduodamas per RNN lÄ…steles, kad bÅ«tÅ³ generuojama tarpinÄ— bÅ«sena, o tada iÅ¡ Å¡ios bÅ«senos prasideda generavimas. Generuojame po vienÄ… simbolÄ¯, perduodame bÅ«senÄ… ir sugeneruotÄ… simbolÄ¯ kitai RNN lÄ…stelei, kad sugeneruotume kitÄ…, kol sugeneruojame pakankamai simboliÅ³.

<img src="../../../../../translated_images/lt/rnn-generate-inf.5168dc65e0370eea.webp" width="60%"/>

> PaveikslÄ—lis autoriaus

## âœï¸ Pratimai: Generatyviniai tinklai

TÄ™skite mokymÄ…si Å¡iuose uÅ¾raÅ¡uose:

* [Generatyviniai tinklai su PyTorch](GenerativePyTorch.ipynb)
* [Generatyviniai tinklai su TensorFlow](GenerativeTF.ipynb)

## MinkÅ¡tas teksto generavimas ir temperatÅ«ra

Kiekvienos RNN lÄ…stelÄ—s iÅ¡vestis yra simboliÅ³ tikimybiÅ³ pasiskirstymas. Jei visada pasirinksime simbolÄ¯ su didÅ¾iausia tikimybe kaip kitÄ… simbolÄ¯ generuojamame tekste, tekstas daÅ¾nai gali "uÅ¾strigti" tarp tÅ³ paÄiÅ³ simboliÅ³ sekÅ³, kaip Å¡iame pavyzdyje:

```
today of the second the company and a second the company ...
```

TaÄiau, jei paÅ¾velgsime Ä¯ tikimybiÅ³ pasiskirstymÄ… kitam simboliui, gali bÅ«ti, kad keliÅ³ didÅ¾iausiÅ³ tikimybiÅ³ skirtumas nÄ—ra didelis, pvz., vienas simbolis gali turÄ—ti tikimybÄ™ 0.2, o kitas - 0.19 ir pan. PavyzdÅ¾iui, ieÅ¡kant kito simbolio sekoje '*play*', kitas simbolis gali bÅ«ti tiek tarpas, tiek **e** (kaip Å¾odyje *player*).

Tai veda prie iÅ¡vados, kad ne visada "teisinga" pasirinkti simbolÄ¯ su didÅ¾iausia tikimybe, nes pasirinkus antrÄ… pagal dydÄ¯ vis tiek galime gauti prasmingÄ… tekstÄ…. Protingiau yra **imti mÄ—ginius** iÅ¡ tikimybiÅ³ pasiskirstymo, kurÄ¯ pateikia tinklo iÅ¡vestis. Taip pat galime naudoti parametrÄ… **temperatÅ«ra**, kuris iÅ¡lygins tikimybiÅ³ pasiskirstymÄ…, jei norime pridÄ—ti daugiau atsitiktinumo, arba padaryti jÄ¯ statesnÄ¯, jei norime labiau laikytis didÅ¾iausios tikimybÄ—s simboliÅ³.

IÅ¡bandykite, kaip Å¡is minkÅ¡tas teksto generavimas Ä¯gyvendinamas aukÅ¡Äiau pateiktuose uÅ¾raÅ¡uose.

## IÅ¡vada

Nors teksto generavimas gali bÅ«ti naudingas pats savaime, pagrindiniai privalumai atsiranda iÅ¡ galimybÄ—s generuoti tekstÄ… naudojant RNN iÅ¡ tam tikro pradinio funkcijÅ³ vektoriaus. PavyzdÅ¾iui, teksto generavimas naudojamas kaip maÅ¡ininio vertimo dalis (seka Ä¯ sekÄ…, Å¡iuo atveju bÅ«senos vektorius iÅ¡ *encoder* naudojamas generuoti arba *decode* iÅ¡verstÄ… praneÅ¡imÄ…) arba generuojant tekstinÄ¯ vaizdo apraÅ¡ymÄ… (Å¡iuo atveju funkcijÅ³ vektorius bÅ«tÅ³ gaunamas iÅ¡ CNN ekstraktoriaus).

## ğŸš€ IÅ¡Å¡Å«kis

Pasimokykite apie Å¡iÄ… temÄ… Microsoft Learn platformoje:

* Teksto generavimas su [PyTorch](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/6-generative-networks/?WT.mc_id=academic-77998-cacaste)/[TensorFlow](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-tensorflow/5-generative-networks/?WT.mc_id=academic-77998-cacaste)

## [Klausimynas po paskaitos](https://ff-quizzes.netlify.app/en/ai/quiz/34)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

Å tai keletas straipsniÅ³, kurie padÄ—s praplÄ—sti Å¾inias:

* Skirtingi teksto generavimo metodai naudojant Markovo grandinÄ™, LSTM ir GPT-2: [tinklaraÅ¡Äio Ä¯raÅ¡as](https://towardsdatascience.com/text-generation-gpt-2-lstm-markov-chain-9ea371820e1e)
* Teksto generavimo pavyzdys [Keras dokumentacijoje](https://keras.io/examples/generative/lstm_character_level_text_generation/)

## [UÅ¾duotis](lab/README.md)

Mes matÄ—me, kaip generuoti tekstÄ… simbolis po simbolio. Laboratorijoje tyrinÄ—site teksto generavimÄ… Å¾odÅ¾iÅ³ lygiu.

---

