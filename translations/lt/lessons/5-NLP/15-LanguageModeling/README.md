# Kalbos modeliavimas

Semantiniai Ä¯terpiniai, tokie kaip Word2Vec ir GloVe, iÅ¡ tiesÅ³ yra pirmasis Å¾ingsnis link **kalbos modeliavimo** â€“ modeliÅ³ kÅ«rimo, kurie kaÅ¾kaip *supranta* (arba *atspindi*) kalbos prigimtÄ¯.

## [PrieÅ¡ paskaitÄ… vykdomas testas](https://ff-quizzes.netlify.app/en/ai/quiz/29)

PagrindinÄ— kalbos modeliavimo idÄ—ja yra jÅ³ mokymas naudojant nepaÅ¾ymÄ—tus duomenÅ³ rinkinius nesupervizuotu bÅ«du. Tai svarbu, nes turime didÅ¾iulius kiekius nepaÅ¾ymÄ—to teksto, o paÅ¾ymÄ—to teksto kiekis visada bus ribotas dÄ—l pastangÅ³, reikalingÅ³ jÄ¯ paÅ¾ymÄ—ti. DaÅ¾niausiai galime kurti kalbos modelius, kurie gali **prognozuoti trÅ«kstamus Å¾odÅ¾ius** tekste, nes lengva atsitiktinai uÅ¾maskuoti Å¾odÄ¯ tekste ir naudoti jÄ¯ kaip mokymo pavyzdÄ¯.

## Ä®terpiniÅ³ mokymas

Ankstesniuose pavyzdÅ¾iuose naudojome iÅ¡ anksto apmokytus semantinius Ä¯terpinius, taÄiau Ä¯domu pamatyti, kaip Å¡iuos Ä¯terpinius galima apmokyti. Yra keletas galimÅ³ idÄ—jÅ³, kurias galima naudoti:

* **N-Gram** kalbos modeliavimas, kai prognozuojame Å¾odÄ¯, remdamiesi N ankstesniais Å¾odÅ¾iais (N-grama).
* **Nuolatinis Å¾odÅ¾iÅ³ maiÅ¡as** (CBoW), kai prognozuojame vidurinÄ¯ Å¾odÄ¯ $W_0$ Å¾odÅ¾iÅ³ sekoje $W_{-N}$, ..., $W_N$.
* **Skip-gram**, kai prognozuojame kaimyniniÅ³ Å¾odÅ¾iÅ³ rinkinÄ¯ {$W_{-N},\dots, W_{-1}, W_1,\dots, W_N$} iÅ¡ vidurinio Å¾odÅ¾io $W_0$.

![vaizdas iÅ¡ straipsnio apie Å¾odÅ¾iÅ³ konvertavimÄ… Ä¯ vektorius](../../../../../translated_images/lt/example-algorithms-for-converting-words-to-vectors.fbe9207a726922f6.webp)

> Vaizdas iÅ¡ [Å¡io straipsnio](https://arxiv.org/pdf/1301.3781.pdf)

## âœï¸ Pavyzdiniai uÅ¾raÅ¡ai: CBoW modelio mokymas

TÄ™skite mokymÄ…si naudodamiesi Å¡iais uÅ¾raÅ¡ais:

* [CBoW Word2Vec mokymas su TensorFlow](CBoW-TF.ipynb)
* [CBoW Word2Vec mokymas su PyTorch](CBoW-PyTorch.ipynb)

## IÅ¡vada

AnkstesnÄ—je pamokoje matÄ—me, kad Å¾odÅ¾iÅ³ Ä¯terpiniai veikia kaip magija! Dabar Å¾inome, kad Å¾odÅ¾iÅ³ Ä¯terpiniÅ³ mokymas nÄ—ra labai sudÄ—tinga uÅ¾duotis, ir prireikus turÄ—tume sugebÄ—ti apmokyti savo Ä¯terpinius specifiniam tekstui.

## [Po paskaitos vykdomas testas](https://ff-quizzes.netlify.app/en/ai/quiz/30)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

* [Oficialus PyTorch kalbos modeliavimo vadovas](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).
* [Oficialus TensorFlow vadovas apie Word2Vec modelio mokymÄ…](https://www.TensorFlow.org/tutorials/text/word2vec).
* Naudojant **gensim** sistemÄ…, daÅ¾niausiai naudojamÅ³ Ä¯terpiniÅ³ mokymas keliose kodo eilutÄ—se apraÅ¡ytas [Å¡ioje dokumentacijoje](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).

## ğŸš€ [UÅ¾duotis: Skip-Gram modelio mokymas](lab/README.md)

Laboratorijoje kvieÄiame jus pakeisti Å¡ios pamokos kodÄ…, kad bÅ«tÅ³ mokomas Skip-Gram modelis vietoj CBoW. [Skaitykite detales](lab/README.md)

---

