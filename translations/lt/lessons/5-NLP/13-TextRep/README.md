<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4522e22e150be0845e03aa41209a39d5",
  "translation_date": "2025-08-31T18:02:10+00:00",
  "source_file": "lessons/5-NLP/13-TextRep/README.md",
  "language_code": "lt"
}
-->
# Teksto atvaizdavimas kaip tensoriai

## [PrieÅ¡ paskaitos testas](https://ff-quizzes.netlify.app/en/ai/quiz/25)

## Teksto klasifikavimas

Pirmoje Å¡ios dalies dalyje mes sutelksime dÄ—mesÄ¯ Ä¯ **teksto klasifikavimo** uÅ¾duotÄ¯. Naudosime [AG News](https://www.kaggle.com/amananandrai/ag-news-classification-dataset) duomenÅ³ rinkinÄ¯, kuriame yra naujienÅ³ straipsniai, pavyzdÅ¾iui:

* Kategorija: Mokslas/Technologijos  
* Pavadinimas: Ky. Ä®monÄ— laimi dotacijÄ… peptidÅ³ tyrimams (AP)  
* Turinys: AP - Ä®monÄ—, Ä¯kurta chemijos tyrÄ—jo iÅ¡ Luisvilio universiteto, laimÄ—jo dotacijÄ…, skirtÄ… plÄ—trai...

MÅ«sÅ³ tikslas bus klasifikuoti naujienÅ³ straipsnÄ¯ Ä¯ vienÄ… iÅ¡ kategorijÅ³ pagal tekstÄ….

## Teksto atvaizdavimas

Jei norime sprÄ™sti natÅ«ralios kalbos apdorojimo (NLP) uÅ¾duotis naudojant neuroninius tinklus, mums reikia bÅ«do, kaip tekstÄ… paversti tensoriais. Kompiuteriai jau atvaizduoja tekstinius simbolius kaip skaiÄius, kurie atitinka Å¡riftus jÅ«sÅ³ ekrane, naudodami tokius kodavimus kaip ASCII ar UTF-8.

<img alt="Vaizdas, rodantis simbolio atvaizdavimÄ… ASCII ir dvejetainiu formatu" src="images/ascii-character-map.png" width="50%"/>

> [Vaizdo Å¡altinis](https://www.seobility.net/en/wiki/ASCII)

Kaip Å¾monÄ—s, mes suprantame, kÄ… kiekviena raidÄ— **reiÅ¡kia**, ir kaip visi simboliai susijungia Ä¯ Å¾odÅ¾ius sakinyje. TaÄiau kompiuteriai patys savaime tokio supratimo neturi, o neuroninis tinklas turi iÅ¡mokti reikÅ¡mÄ™ mokymo metu.

TodÄ—l galime naudoti skirtingus poÅ¾iÅ«rius, kai atvaizduojame tekstÄ…:

* **SimboliÅ³ lygmens atvaizdavimas**, kai tekstÄ… atvaizduojame, kiekvienÄ… simbolÄ¯ traktuodami kaip skaiÄiÅ³. Jei turime *C* skirtingÅ³ simboliÅ³ savo teksto korpuse, Å¾odis *Hello* bÅ«tÅ³ atvaizduotas kaip 5x*C* tensorius. Kiekviena raidÄ— atitiktÅ³ tensoriaus stulpelÄ¯ vieno karÅ¡to kodavimo (one-hot encoding) formatu.  
* **Å½odÅ¾iÅ³ lygmens atvaizdavimas**, kai sukuriame visÅ³ Å¾odÅ¾iÅ³ **Å¾odynÄ…** ir tada Å¾odÅ¾ius atvaizduojame naudojant vieno karÅ¡to kodavimÄ…. Å is poÅ¾iÅ«ris yra Å¡iek tiek geresnis, nes kiekviena raidÄ— pati savaime neturi daug reikÅ¡mÄ—s, todÄ—l naudojant aukÅ¡tesnio lygio semantines sÄ…vokas â€“ Å¾odÅ¾ius â€“ supaprastiname uÅ¾duotÄ¯ neuroniniam tinklui. TaÄiau dÄ—l didelio Å¾odyno dydÅ¾io turime susidoroti su didelÄ—s dimensijos retiniais tensoriais.

Nepriklausomai nuo atvaizdavimo, pirmiausia turime tekstÄ… paversti **Å¾enklais** (tokenais), kur vienas Å¾enklas gali bÅ«ti simbolis, Å¾odis ar net Å¾odÅ¾io dalis. Tada Å¾enklÄ… paverÄiame skaiÄiumi, paprastai naudodami **Å¾odynÄ…**, ir Å¡is skaiÄius gali bÅ«ti perduotas Ä¯ neuroninÄ¯ tinklÄ… naudojant vieno karÅ¡to kodavimÄ….

## N-Gramai

NatÅ«ralioje kalboje tiksli Å¾odÅ¾iÅ³ reikÅ¡mÄ— gali bÅ«ti nustatyta tik kontekste. PavyzdÅ¾iui, *neuroninis tinklas* ir *Å¾vejybinis tinklas* turi visiÅ¡kai skirtingas reikÅ¡mes. Vienas iÅ¡ bÅ«dÅ³ tai Ä¯vertinti yra kurti modelÄ¯, pagrÄ¯stÄ… Å¾odÅ¾iÅ³ poromis, ir traktuoti Å¾odÅ¾iÅ³ poras kaip atskirus Å¾odyno Å¾enklus. Tokiu bÅ«du sakinys *Man patinka eiti Å¾vejoti* bus atvaizduotas tokia Å¾enklÅ³ seka: *Man patinka*, *patinka eiti*, *eiti Å¾vejoti*. Problema su Å¡iuo poÅ¾iÅ«riu yra ta, kad Å¾odyno dydis Å¾ymiai padidÄ—ja, o tokios kombinacijos kaip *eiti Å¾vejoti* ir *eiti apsipirkti* yra pateikiamos kaip skirtingi Å¾enklai, kurie neturi jokio semantinio panaÅ¡umo, nepaisant to paties veiksmaÅ¾odÅ¾io.

Kai kuriais atvejais galime apsvarstyti tri-gramÅ³ â€“ trijÅ³ Å¾odÅ¾iÅ³ kombinacijÅ³ â€“ naudojimÄ…. TodÄ—l Å¡is poÅ¾iÅ«ris daÅ¾nai vadinamas **n-gramais**. Taip pat prasminga naudoti n-gramus su simboliÅ³ lygmens atvaizdavimu, tokiu atveju n-gramai apytiksliai atitiks skirtingus skiemenis.

## Å½odÅ¾iÅ³ maiÅ¡as (Bag-of-Words) ir TF/IDF

SprendÅ¾iant tokias uÅ¾duotis kaip teksto klasifikavimas, mums reikia galimybÄ—s atvaizduoti tekstÄ… kaip vienÄ… fiksuoto dydÅ¾io vektoriÅ³, kurÄ¯ naudosime kaip Ä¯vestÄ¯ galutiniam tankiam klasifikatoriui. Vienas paprasÄiausiÅ³ bÅ«dÅ³ tai padaryti yra sujungti visas atskiras Å¾odÅ¾iÅ³ reprezentacijas, pvz., jas sudedant. Jei sudÄ—sime kiekvieno Å¾odÅ¾io vieno karÅ¡to kodavimus, gausime daÅ¾niÅ³ vektoriÅ³, rodantÄ¯, kiek kartÅ³ kiekvienas Å¾odis pasirodo tekste. Toks teksto atvaizdavimas vadinamas **Å¾odÅ¾iÅ³ maiÅ¡u** (BoW).

<img src="images/bow.png" width="90%"/>

> Vaizdas sukurtas autoriaus

BoW iÅ¡ esmÄ—s parodo, kurie Å¾odÅ¾iai pasirodo tekste ir kokiais kiekiais, o tai gali bÅ«ti geras rodiklis, apie kÄ… yra tekstas. PavyzdÅ¾iui, naujienÅ³ straipsnis apie politikÄ… greiÄiausiai turÄ—s tokius Å¾odÅ¾ius kaip *prezidentas* ir *Å¡alis*, o mokslinis straipsnis â€“ tokius kaip *kolideris*, *atrasta* ir pan. Taigi, Å¾odÅ¾iÅ³ daÅ¾niai daugeliu atvejÅ³ gali bÅ«ti geras teksto turinio rodiklis.

Problema su BoW yra ta, kad tam tikri daÅ¾ni Å¾odÅ¾iai, tokie kaip *ir*, *yra* ir pan., pasirodo daugumoje tekstÅ³ ir turi didÅ¾iausius daÅ¾nius, uÅ¾goÅ¾dami tikrai svarbius Å¾odÅ¾ius. Mes galime sumaÅ¾inti Å¡iÅ³ Å¾odÅ¾iÅ³ svarbÄ…, atsiÅ¾velgdami Ä¯ daÅ¾nÄ¯, kuriuo Å¾odÅ¾iai pasirodo visoje dokumentÅ³ kolekcijoje. Tai yra pagrindinÄ— TF/IDF metodo idÄ—ja, kuri iÅ¡samiau aptariama Å¡ios pamokos pridedamuose uÅ¾raÅ¡uose.

TaÄiau nÄ— vienas iÅ¡ Å¡iÅ³ metodÅ³ negali visiÅ¡kai Ä¯vertinti teksto **semantikos**. Tam mums reikia galingesniÅ³ neuroniniÅ³ tinklÅ³ modeliÅ³, kuriuos aptarsime vÄ—liau Å¡ioje dalyje.

## âœï¸ Pratimai: Teksto atvaizdavimas

TÄ™skite mokymÄ…si Å¡iuose uÅ¾raÅ¡uose:

* [Teksto atvaizdavimas su PyTorch](TextRepresentationPyTorch.ipynb)  
* [Teksto atvaizdavimas su TensorFlow](TextRepresentationTF.ipynb)  

## IÅ¡vada

Iki Å¡iol iÅ¡nagrinÄ—jome metodus, kurie gali pridÄ—ti daÅ¾nio svorÄ¯ skirtingiems Å¾odÅ¾iams. TaÄiau jie negali atvaizduoti reikÅ¡mÄ—s ar tvarkos. Kaip garsus lingvistas J. R. Firth pasakÄ— 1935 m., â€VisapusiÅ¡ka Å¾odÅ¾io reikÅ¡mÄ— visada yra kontekstinÄ—, ir joks reikÅ¡mÄ—s tyrimas, atskirtas nuo konteksto, negali bÅ«ti laikomas rimtu.â€œ VÄ—liau kurse suÅ¾inosime, kaip iÅ¡ teksto iÅ¡gauti kontekstinÄ™ informacijÄ… naudojant kalbos modeliavimÄ….

## ğŸš€ IÅ¡Å¡Å«kis

IÅ¡bandykite kitus pratimus, naudodami Å¾odÅ¾iÅ³ maiÅ¡Ä… ir skirtingus duomenÅ³ modelius. Jus gali Ä¯kvÄ—pti Å¡is [Kaggle konkursas](https://www.kaggle.com/competitions/word2vec-nlp-tutorial/overview/part-1-for-beginners-bag-of-words).

## [Po paskaitos testas](https://ff-quizzes.netlify.app/en/ai/quiz/26)

## PerÅ¾iÅ«ra ir savarankiÅ¡kas mokymasis

Praktikuokite savo Ä¯gÅ«dÅ¾ius su teksto Ä¯terpimais ir Å¾odÅ¾iÅ³ maiÅ¡o technikomis [Microsoft Learn](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-pytorch/?WT.mc_id=academic-77998-cacaste).

## [UÅ¾duotis: UÅ¾raÅ¡ai](assignment.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama naudoti profesionalÅ³ Å¾mogaus vertimÄ…. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar klaidingus interpretavimus, atsiradusius dÄ—l Å¡io vertimo naudojimo.