<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f07c85bbf05a1f67505da98f4ecc124c",
  "translation_date": "2025-08-25T22:41:09+00:00",
  "source_file": "lessons/4-ComputerVision/10-GANs/README.md",
  "language_code": "hr"
}
-->
# Generativne suparniÄke mreÅ¾e

U prethodnom dijelu nauÄili smo o **generativnim modelima**: modelima koji mogu generirati nove slike sliÄne onima iz skupa za treniranje. VAE je bio dobar primjer generativnog modela.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/19)

MeÄ‘utim, ako pokuÅ¡amo generirati neÅ¡to zaista znaÄajno, poput slike visoke rezolucije, s VAE-om, vidjet Ä‡emo da treniranje ne konvergira dobro. Za ovaj sluÄaj trebali bismo nauÄiti o drugoj arhitekturi koja je posebno usmjerena na generativne modele - **Generativne suparniÄke mreÅ¾e**, ili GAN-ove.

Glavna ideja GAN-a je imati dvije neuronske mreÅ¾e koje se treniraju jedna protiv druge:

<img src="images/gan_architecture.png" width="70%"/>

> Slika od [Dmitry Soshnikov](http://soshnikov.com)

> âœ… Malo vokabulara:
> * **Generator** je mreÅ¾a koja uzima neki sluÄajni vektor i kao rezultat proizvodi sliku
> * **Diskriminator** je mreÅ¾a koja uzima sliku i treba odrediti je li to stvarna slika (iz skupa za treniranje) ili ju je generirao generator. U suÅ¡tini, to je klasifikator slika.

### Diskriminator

Arhitektura diskriminatora ne razlikuje se od obiÄne mreÅ¾e za klasifikaciju slika. U najjednostavnijem sluÄaju moÅ¾e biti potpuno povezan klasifikator, ali najvjerojatnije Ä‡e biti [konvolucijska mreÅ¾a](../07-ConvNets/README.md).

> âœ… GAN temeljen na konvolucijskim mreÅ¾ama naziva se [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

CNN diskriminator sastoji se od sljedeÄ‡ih slojeva: nekoliko konvolucija+poolinga (s smanjenjem prostorne veliÄine) i jednog ili viÅ¡e potpuno povezanih slojeva za dobivanje "vektora znaÄajki", te konaÄnog binarnog klasifikatora.

> âœ… 'Pooling' u ovom kontekstu je tehnika koja smanjuje veliÄinu slike. "Pooling slojevi smanjuju dimenzije podataka kombiniranjem izlaza klastera neurona u jednom sloju u jedan neuron u sljedeÄ‡em sloju." - [izvor](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

Generator je malo sloÅ¾eniji. MoÅ¾ete ga smatrati obrnutim diskriminatorom. PoÄevÅ¡i od latentnog vektora (umjesto vektora znaÄajki), ima potpuno povezani sloj za pretvaranje u potrebnu veliÄinu/oblik, praÄ‡en dekonvolucijama+skaliranjem. Ovo je sliÄno *dekoderu* dijela [autoenkodera](../09-Autoencoders/README.md).

> âœ… BuduÄ‡i da je konvolucijski sloj implementiran kao linearni filter koji prolazi kroz sliku, dekonvolucija je u suÅ¡tini sliÄna konvoluciji i moÅ¾e se implementirati koristeÄ‡i istu logiku sloja.

<img src="images/gan_arch_detail.png" width="70%"/>

> Slika od [Dmitry Soshnikov](http://soshnikov.com)

### Treniranje GAN-a

GAN-ovi se nazivaju **suparniÄkim** jer postoji stalna konkurencija izmeÄ‘u generatora i diskriminatora. Tijekom ove konkurencije, i generator i diskriminator se poboljÅ¡avaju, Äime mreÅ¾a uÄi proizvoditi sve bolje slike.

Treniranje se odvija u dvije faze:

* **Treniranje diskriminatora**. Ovaj zadatak je priliÄno jednostavan: generiramo seriju slika pomoÄ‡u generatora, oznaÄavajuÄ‡i ih s 0, Å¡to oznaÄava laÅ¾nu sliku, i uzimamo seriju slika iz ulaznog skupa podataka (s oznakom 1, stvarna slika). Dobivamo neki *gubitak diskriminatora* i provodimo povratnu propagaciju.
* **Treniranje generatora**. Ovo je malo sloÅ¾enije jer ne znamo oÄekivani izlaz za generator izravno. Uzimamo cijelu GAN mreÅ¾u koja se sastoji od generatora praÄ‡enog diskriminatorom, hranimo je nekim sluÄajnim vektorima i oÄekujemo da rezultat bude 1 (Å¡to odgovara stvarnim slikama). Zatim zamrzavamo parametre diskriminatora (ne Å¾elimo da se trenira u ovom koraku) i provodimo povratnu propagaciju.

Tijekom ovog procesa, gubici generatora i diskriminatora ne opadaju znaÄajno. U idealnoj situaciji, trebali bi oscilirati, Å¡to odgovara poboljÅ¡anju performansi obje mreÅ¾e.

## âœï¸ VjeÅ¾be: GAN-ovi

* [GAN Notebook u TensorFlow/Keras](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [GAN Notebook u PyTorch](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### Problemi s treniranjem GAN-ova

Poznato je da su GAN-ovi posebno teÅ¡ki za treniranje. Evo nekoliko problema:

* **Kolaps moda**. Ovim pojmom mislimo da generator nauÄi proizvoditi jednu uspjeÅ¡nu sliku koja zavarava generator, a ne raznolikost razliÄitih slika.
* **Osjetljivost na hiperparametre**. ÄŒesto moÅ¾ete vidjeti da GAN uopÄ‡e ne konvergira, a zatim iznenada smanjenje stope uÄenja dovodi do konvergencije.
* OdrÅ¾avanje **ravnoteÅ¾e** izmeÄ‘u generatora i diskriminatora. U mnogim sluÄajevima gubitak diskriminatora moÅ¾e relativno brzo pasti na nulu, Å¡to rezultira time da generator ne moÅ¾e dalje trenirati. Da bismo to prevladali, moÅ¾emo pokuÅ¡ati postaviti razliÄite stope uÄenja za generator i diskriminator ili preskoÄiti treniranje diskriminatora ako je gubitak veÄ‡ prenizak.
* Treniranje za **visoku rezoluciju**. OdraÅ¾avajuÄ‡i isti problem kao kod autoenkodera, ovaj problem se javlja jer rekonstrukcija previÅ¡e slojeva konvolucijske mreÅ¾e dovodi do artefakata. Ovaj problem se obiÄno rjeÅ¡ava tzv. **progresivnim rastom**, kada se prvo nekoliko slojeva trenira na slikama niske rezolucije, a zatim se slojevi "otkljuÄavaju" ili dodaju. Drugo rjeÅ¡enje bilo bi dodavanje dodatnih veza izmeÄ‘u slojeva i treniranje nekoliko rezolucija odjednom - pogledajte ovaj [Multi-Scale Gradient GANs paper](https://arxiv.org/abs/1903.06048) za detalje.

## Prijenos stila

GAN-ovi su izvrstan naÄin za generiranje umjetniÄkih slika. Druga zanimljiva tehnika je tzv. **prijenos stila**, koji uzima jednu **sliku sadrÅ¾aja** i ponovno je crta u drugaÄijem stilu, primjenjujuÄ‡i filtre iz **slike stila**.

Kako to funkcionira:
* PoÄinjemo s nasumiÄnom slikom Å¡uma (ili sa slikom sadrÅ¾aja, ali radi lakÅ¡eg razumijevanja lakÅ¡e je poÄeti s nasumiÄnim Å¡umom)
* NaÅ¡ cilj bi bio stvoriti takvu sliku koja bi bila bliska i slici sadrÅ¾aja i slici stila. To bi se odredilo pomoÄ‡u dvije funkcije gubitka:
   - **Gubitak sadrÅ¾aja** se raÄuna na temelju znaÄajki koje CNN izvuÄe na nekim slojevima iz trenutne slike i slike sadrÅ¾aja
   - **Gubitak stila** se raÄuna izmeÄ‘u trenutne slike i slike stila na pametan naÄin koristeÄ‡i Gram matrice (viÅ¡e detalja u [primjeru notebooka](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb))
* Kako bismo sliku uÄinili glaÄ‘om i uklonili Å¡um, uvodimo i **Gubitak varijacije**, koji raÄuna prosjeÄnu udaljenost izmeÄ‘u susjednih piksela
* Glavna petlja optimizacije prilagoÄ‘ava trenutnu sliku koristeÄ‡i gradijentni spust (ili neki drugi algoritam optimizacije) kako bi se minimizirao ukupni gubitak, koji je ponderirani zbroj svih triju gubitaka.

## âœï¸ Primjer: [Prijenos stila](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## ZakljuÄak

U ovoj lekciji nauÄili ste o GAN-ovima i kako ih trenirati. TakoÄ‘er ste nauÄili o posebnim izazovima s kojima se ovaj tip neuronske mreÅ¾e moÅ¾e suoÄiti i nekim strategijama kako ih prevladati.

## ğŸš€ Izazov

ProÄ‘ite kroz [Style Transfer notebook](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) koristeÄ‡i vlastite slike.

## Pregled i samostalno uÄenje

Za referencu, proÄitajte viÅ¡e o GAN-ovima u ovim resursima:

* Marco Pasini, [10 Lekcija koje sam nauÄio trenirajuÄ‡i GAN-ove godinu dana](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), *de facto* GAN arhitektura koju treba razmotriti
* [Stvaranje generativne umjetnosti koristeÄ‡i GAN-ove na Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Zadatak

Ponovno pregledajte jedan od dva notebooka povezana s ovom lekcijom i ponovno trenirajte GAN na vlastitim slikama. Å to moÅ¾ete stvoriti?

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.