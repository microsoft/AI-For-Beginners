<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-25T22:31:34+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "hr"
}
-->
# Autoenkoderi

Prilikom treniranja CNN-ova, jedan od problema je Å¡to nam treba puno oznaÄenih podataka. U sluÄaju klasifikacije slika, moramo razdvojiti slike u razliÄite klase, Å¡to zahtijeva ruÄni rad.

## [Kviz prije predavanja](https://ff-quizzes.netlify.app/en/ai/quiz/17)

MeÄ‘utim, moÅ¾da bismo Å¾eljeli koristiti sirove (neoznaÄene) podatke za treniranje CNN ekstraktora znaÄajki, Å¡to se naziva **samostalno uÄenje**. Umjesto oznaka, koristit Ä‡emo slike za treniranje kao ulaz i izlaz mreÅ¾e. Glavna ideja **autoenkodera** je da imamo **enkodersku mreÅ¾u** koja pretvara ulaznu sliku u neki **latentni prostor** (obiÄno je to vektor manje dimenzije), a zatim **dekodersku mreÅ¾u**, Äiji je cilj rekonstruirati izvornu sliku.

> âœ… [Autoenkoder](https://wikipedia.org/wiki/Autoencoder) je "vrsta umjetne neuronske mreÅ¾e koja se koristi za uÄenje uÄinkovitih kodiranja neoznaÄenih podataka."

BuduÄ‡i da treniramo autoenkoder kako bi uhvatio Å¡to viÅ¡e informacija iz izvorne slike za toÄnu rekonstrukciju, mreÅ¾a pokuÅ¡ava pronaÄ‡i najbolju **ugradnju** ulaznih slika kako bi uhvatila njihovo znaÄenje.

![Dijagram Autoenkodera](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.hr.jpg)

> Slika s [Keras bloga](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenariji za koriÅ¡tenje autoenkodera

Iako rekonstrukcija izvornih slika sama po sebi moÅ¾da ne izgleda korisna, postoje neki scenariji u kojima su autoenkoderi posebno korisni:

* **Smanjenje dimenzije slika za vizualizaciju** ili **treniranje ugraÄ‘ivanja slika**. Autoenkoderi obiÄno daju bolje rezultate od PCA jer uzimaju u obzir prostornu prirodu slika i hijerarhijske znaÄajke.
* **Uklanjanje Å¡uma**, tj. uklanjanje Å¡uma sa slike. BuduÄ‡i da Å¡um nosi puno beskorisnih informacija, autoenkoder ne moÅ¾e sve to uklopiti u relativno mali latentni prostor, pa hvata samo vaÅ¾ne dijelove slike. Prilikom treniranja za uklanjanje Å¡uma, poÄinjemo s izvornim slikama i koristimo slike s umjetno dodanim Å¡umom kao ulaz za autoenkoder.
* **Super-rezolucija**, poveÄ‡anje rezolucije slike. PoÄinjemo s visokorezolucijskim slikama i koristimo slike niÅ¾e rezolucije kao ulaz za autoenkoder.
* **Generativni modeli**. Nakon Å¡to istreniramo autoenkoder, dekoderski dio moÅ¾e se koristiti za stvaranje novih objekata poÄevÅ¡i od sluÄajnih latentnih vektora.

## Varijacijski autoenkoderi (VAE)

Tradicionalni autoenkoderi na neki naÄin smanjuju dimenziju ulaznih podataka, otkrivajuÄ‡i vaÅ¾ne znaÄajke ulaznih slika. MeÄ‘utim, latentni vektori Äesto nemaju puno smisla. Drugim rijeÄima, uzimajuÄ‡i MNIST dataset kao primjer, nije lako odrediti koji brojevi odgovaraju razliÄitim latentnim vektorima, jer bliski latentni vektori ne moraju nuÅ¾no odgovarati istim brojevima.

S druge strane, za treniranje *generativnih* modela bolje je imati neko razumijevanje latentnog prostora. Ova ideja vodi nas do **varijacijskog autoenkodera** (VAE).

VAE je autoenkoder koji uÄi predvidjeti *statistiÄku distribuciju* latentnih parametara, tzv. **latentnu distribuciju**. Na primjer, moÅ¾emo Å¾eljeti da latentni vektori budu normalno distribuirani s nekom sredinom z<sub>mean</sub> i standardnom devijacijom z<sub>sigma</sub> (i sredina i standardna devijacija su vektori neke dimenzije d). Enkoder u VAE-u uÄi predvidjeti te parametre, a zatim dekoder uzima sluÄajni vektor iz te distribucije za rekonstrukciju objekta.

Ukratko:

 * Iz ulaznog vektora predviÄ‘amo `z_mean` i `z_log_sigma` (umjesto da predviÄ‘amo standardnu devijaciju, predviÄ‘amo njezin logaritam)
 * Uzorkujemo vektor `sample` iz distribucije N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Dekoder pokuÅ¡ava dekodirati izvornu sliku koristeÄ‡i `sample` kao ulazni vektor

 <img src="images/vae.png" width="50%">

> Slika iz [ovog blog posta](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) autora Isaaka Dykemana

Varijacijski autoenkoderi koriste sloÅ¾enu funkciju gubitka koja se sastoji od dva dijela:

* **Gubitak rekonstrukcije** je funkcija gubitka koja pokazuje koliko je rekonstruirana slika bliska ciljanoj slici (moÅ¾e biti srednja kvadratna pogreÅ¡ka, ili MSE). To je ista funkcija gubitka kao kod obiÄnih autoenkodera.
* **KL gubitak**, koji osigurava da distribucija latentnih varijabli ostane bliska normalnoj distribuciji. Temelji se na konceptu [Kullback-Leiblerove divergencije](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - metriÄke mjere sliÄnosti izmeÄ‘u dvije statistiÄke distribucije.

Jedna vaÅ¾na prednost VAE-a je Å¡to omoguÄ‡uju relativno jednostavno generiranje novih slika, jer znamo iz koje distribucije uzorkovati latentne vektore. Na primjer, ako treniramo VAE s 2D latentnim vektorom na MNIST-u, moÅ¾emo zatim mijenjati komponente latentnog vektora kako bismo dobili razliÄite brojeve:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Slika autora [Dmitryja Soshnikova](http://soshnikov.com)

Primijetite kako se slike stapaju jedna u drugu dok poÄinjemo dobivati latentne vektore iz razliÄitih dijelova latentnog prostora parametara. TakoÄ‘er moÅ¾emo vizualizirati ovaj prostor u 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Slika autora [Dmitryja Soshnikova](http://soshnikov.com)

## âœï¸ VjeÅ¾be: Autoenkoderi

Saznajte viÅ¡e o autoenkoderima u ovim odgovarajuÄ‡im biljeÅ¾nicama:

* [Autoenkoderi u TensorFlowu](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Autoenkoderi u PyTorchu](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Svojstva autoenkodera

* **SpecifiÄni za podatke** - dobro rade samo s vrstom slika na kojima su trenirani. Na primjer, ako treniramo mreÅ¾u za super-rezoluciju na cvijeÄ‡u, neÄ‡e dobro raditi na portretima. To je zato Å¡to mreÅ¾a moÅ¾e proizvesti sliku viÅ¡e rezolucije koristeÄ‡i fine detalje iz znaÄajki nauÄenih iz skupa podataka za treniranje.
* **Gubitak informacija** - rekonstruirana slika nije ista kao izvorna slika. Priroda gubitka definirana je *funkcijom gubitka* koriÅ¡tenom tijekom treniranja.
* Radi na **neoznaÄenim podacima**

## [Kviz nakon predavanja](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## ZakljuÄak

U ovoj lekciji nauÄili ste o razliÄitim vrstama autoenkodera dostupnih AI znanstvenicima. NauÄili ste kako ih izgraditi i kako ih koristiti za rekonstrukciju slika. TakoÄ‘er ste nauÄili o VAE-u i kako ga koristiti za generiranje novih slika.

## ğŸš€ Izazov

U ovoj lekciji nauÄili ste o koriÅ¡tenju autoenkodera za slike. Ali oni se takoÄ‘er mogu koristiti za glazbu! Pogledajte projekt Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), koji koristi autoenkodere za uÄenje rekonstrukcije glazbe. Napravite nekoliko [eksperimenata](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) s ovom bibliotekom kako biste vidjeli Å¡to moÅ¾ete stvoriti.

## [Kviz nakon predavanja](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Pregled i samostalno uÄenje

Za referencu, proÄitajte viÅ¡e o autoenkoderima u ovim resursima:

* [Izgradnja autoenkodera u Kerasu](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blog post na NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [ObjaÅ¡njenje varijacijskih autoenkodera](https://kvfrans.com/variational-autoencoders-explained/)
* [Uvjetni varijacijski autoenkoderi](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Zadatak

Na kraju [ove biljeÅ¾nice koristeÄ‡i TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb), pronaÄ‡i Ä‡ete 'zadatak' - koristite ga kao svoj zadatak.

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za nesporazume ili pogreÅ¡na tumaÄenja koja mogu proizaÄ‡i iz koriÅ¡tenja ovog prijevoda.