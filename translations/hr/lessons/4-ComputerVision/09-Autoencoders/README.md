# Autoenkoderi

Kod treniranja CNN-a, jedan od problema je potreba za velikom koliÄinom oznaÄenih podataka. U sluÄaju klasifikacije slika, potrebno je razvrstati slike u razliÄite klase, Å¡to zahtijeva ruÄni rad.

## [Pre-predavanje kviz](https://ff-quizzes.netlify.app/en/ai/quiz/17)

MeÄ‘utim, moÅ¾da bismo Å¾eljeli koristiti sirove (neoznaÄene) podatke za treniranje CNN ekstraktora znaÄajki, Å¡to se naziva **samostalno nadzirano uÄenje**. Umjesto oznaka, koristit Ä‡emo slike za treniranje kao ulaz i izlaz mreÅ¾e. Glavna ideja **autoenkodera** je da Ä‡emo imati **enkodersku mreÅ¾u** koja pretvara ulaznu sliku u neki **latentni prostor** (obiÄno je to samo vektor manje veliÄine), a zatim **dekodersku mreÅ¾u**, Äiji je cilj rekonstruirati originalnu sliku.

> âœ… [Autoenkoder](https://wikipedia.org/wiki/Autoencoder) je "vrsta umjetne neuronske mreÅ¾e koja se koristi za uÄenje uÄinkovitih kodiranja neoznaÄenih podataka."

BuduÄ‡i da treniramo autoenkoder kako bi uhvatio Å¡to viÅ¡e informacija iz originalne slike za toÄnu rekonstrukciju, mreÅ¾a pokuÅ¡ava pronaÄ‡i najbolju **ugradnju** ulaznih slika kako bi uhvatila njihovo znaÄenje.

![Dijagram Autoenkodera](../../../../../translated_images/hr/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> Slika s [Keras bloga](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenariji za koriÅ¡tenje autoenkodera

Iako rekonstrukcija originalnih slika sama po sebi ne izgleda korisno, postoje neki scenariji u kojima su autoenkoderi posebno korisni:

* **Smanjenje dimenzije slika za vizualizaciju** ili **treniranje ugraÄ‘ivanja slika**. ObiÄno autoenkoderi daju bolje rezultate od PCA, jer uzimaju u obzir prostornu prirodu slika i hijerarhijske znaÄajke.
* **Uklanjanje Å¡uma**, tj. uklanjanje Å¡uma sa slike. BuduÄ‡i da Å¡um nosi puno beskorisnih informacija, autoenkoder ne moÅ¾e sve to uklopiti u relativno mali latentni prostor, pa hvata samo vaÅ¾an dio slike. Kod treniranja za uklanjanje Å¡uma, poÄinjemo s originalnim slikama i koristimo slike s umjetno dodanim Å¡umom kao ulaz za autoenkoder.
* **Super-rezolucija**, poveÄ‡anje rezolucije slike. PoÄinjemo s slikama visoke rezolucije i koristimo sliku niÅ¾e rezolucije kao ulaz za autoenkoder.
* **Generativni modeli**. Nakon Å¡to treniramo autoenkoder, dekoderski dio moÅ¾e se koristiti za stvaranje novih objekata poÄevÅ¡i od sluÄajnih latentnih vektora.

## Varijacijski autoenkoderi (VAE)

Tradicionalni autoenkoderi smanjuju dimenziju ulaznih podataka na neki naÄin, otkrivajuÄ‡i vaÅ¾ne znaÄajke ulaznih slika. MeÄ‘utim, latentni vektori Äesto nemaju puno smisla. Drugim rijeÄima, uzimajuÄ‡i MNIST dataset kao primjer, otkrivanje koji brojevi odgovaraju razliÄitim latentnim vektorima nije jednostavan zadatak, jer bliski latentni vektori ne moraju nuÅ¾no odgovarati istim brojevima.

S druge strane, za treniranje *generativnih* modela bolje je imati neko razumijevanje latentnog prostora. Ova ideja vodi nas do **varijacijskog autoenkodera** (VAE).

VAE je autoenkoder koji uÄi predviÄ‘ati *statistiÄku distribuciju* latentnih parametara, tzv. **latentnu distribuciju**. Na primjer, moÅ¾da Å¾elimo da latentni vektori budu normalno distribuirani s nekom srednjom vrijednosti z<sub>mean</sub> i standardnom devijacijom z<sub>sigma</sub> (srednja vrijednost i standardna devijacija su vektori neke dimenzionalnosti d). Enkoder u VAE-u uÄi predviÄ‘ati te parametre, a zatim dekoder uzima sluÄajni vektor iz te distribucije za rekonstrukciju objekta.

Ukratko:

 * Iz ulaznog vektora predviÄ‘amo `z_mean` i `z_log_sigma` (umjesto da predviÄ‘amo samu standardnu devijaciju, predviÄ‘amo njezin logaritam)
 * Uzorkujemo vektor `sample` iz distribucije N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Dekoder pokuÅ¡ava dekodirati originalnu sliku koristeÄ‡i `sample` kao ulazni vektor

 <img src="../../../../../translated_images/hr/vae.464c465a5b6a9e25.webp" width="50%">

> Slika iz [ovog blog posta](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) autora Isaaka Dykemana

Varijacijski autoenkoderi koriste sloÅ¾enu funkciju gubitka koja se sastoji od dva dijela:

* **Gubitak rekonstrukcije** je funkcija gubitka koja pokazuje koliko je rekonstruirana slika bliska cilju (moÅ¾e biti srednja kvadratna pogreÅ¡ka, ili MSE). To je ista funkcija gubitka kao kod normalnih autoenkodera.
* **KL gubitak**, koji osigurava da distribucija latentnih varijabli ostane blizu normalne distribucije. Temelji se na konceptu [Kullback-Leiblerove divergencije](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - metriÄki naÄin procjene koliko su dvije statistiÄke distribucije sliÄne.

Jedna vaÅ¾na prednost VAE-a je da nam omoguÄ‡uju relativno lako generiranje novih slika, jer znamo iz koje distribucije uzorkovati latentne vektore. Na primjer, ako treniramo VAE s 2D latentnim vektorom na MNIST datasetu, moÅ¾emo zatim mijenjati komponente latentnog vektora kako bismo dobili razliÄite brojeve:

<img alt="vaemnist" src="../../../../../translated_images/hr/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> Slika autora [Dmitry Soshnikov](http://soshnikov.com)

Primijetite kako se slike stapaju jedna u drugu, dok poÄinjemo dobivati latentne vektore iz razliÄitih dijelova latentnog prostora parametara. TakoÄ‘er moÅ¾emo vizualizirati ovaj prostor u 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/hr/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> Slika autora [Dmitry Soshnikov](http://soshnikov.com)

## âœï¸ VjeÅ¾be: Autoenkoderi

Saznajte viÅ¡e o autoenkoderima u ovim pripadajuÄ‡im biljeÅ¾nicama:

* [Autoenkoderi u TensorFlowu](AutoencodersTF.ipynb)
* [Autoenkoderi u PyTorchu](AutoEncodersPyTorch.ipynb)

## Svojstva autoenkodera

* **SpecifiÄni za podatke** - dobro funkcioniraju samo s vrstom slika na kojima su trenirani. Na primjer, ako treniramo mreÅ¾u za super-rezoluciju na cvjetovima, neÄ‡e dobro funkcionirati na portretima. To je zato Å¡to mreÅ¾a moÅ¾e proizvesti sliku viÅ¡e rezolucije uzimajuÄ‡i fine detalje iz znaÄajki nauÄenih iz skupa podataka za treniranje.
* **Gubitni** - rekonstruirana slika nije ista kao originalna slika. Priroda gubitka definirana je *funkcijom gubitka* koriÅ¡tenom tijekom treniranja.
* Funkcionira na **neoznaÄenim podacima**

## [Post-predavanje kviz](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## ZakljuÄak

U ovoj lekciji nauÄili ste o razliÄitim vrstama autoenkodera dostupnih AI znanstveniku. NauÄili ste kako ih izgraditi i kako ih koristiti za rekonstrukciju slika. TakoÄ‘er ste nauÄili o VAE-u i kako ga koristiti za generiranje novih slika.

## ğŸš€ Izazov

U ovoj lekciji nauÄili ste o koriÅ¡tenju autoenkodera za slike. No, oni se mogu koristiti i za glazbu! Pogledajte projekt Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), koji koristi autoenkodere za uÄenje rekonstrukcije glazbe. Napravite nekoliko [eksperimenata](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) s ovom bibliotekom kako biste vidjeli Å¡to moÅ¾ete stvoriti.

## [Post-predavanje kviz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Pregled i samostalno uÄenje

Za referencu, proÄitajte viÅ¡e o autoenkoderima u ovim resursima:

* [Izgradnja autoenkodera u Kerasu](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blog post na NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [ObjaÅ¡njenje varijacijskih autoenkodera](https://kvfrans.com/variational-autoencoders-explained/)
* [Uvjetni varijacijski autoenkoderi](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Zadatak

Na kraju [ove biljeÅ¾nice koristeÄ‡i TensorFlow](AutoencodersTF.ipynb), pronaÄ‡i Ä‡ete 'zadatak' - koristite ga kao svoj zadatak.

---

