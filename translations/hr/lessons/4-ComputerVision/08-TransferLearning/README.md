# Pretrenirane mreÅ¾e i prijenos uÄenja

Treniranje CNN-a moÅ¾e zahtijevati puno vremena, a za taj zadatak potrebno je mnogo podataka. MeÄ‘utim, velik dio vremena troÅ¡i se na uÄenje najboljih niskorazinskih filtera koje mreÅ¾a moÅ¾e koristiti za izdvajanje uzoraka iz slika. Postavlja se prirodno pitanje - moÅ¾emo li koristiti neuronsku mreÅ¾u treniranu na jednom skupu podataka i prilagoditi je za klasifikaciju razliÄitih slika bez potrebe za potpunim procesom treniranja?

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Ovaj pristup naziva se **prijenos uÄenja**, jer prenosimo dio znanja iz jednog modela neuronske mreÅ¾e u drugi. Kod prijenosa uÄenja obiÄno poÄinjemo s unaprijed treniranim modelom, koji je treniran na nekom velikom skupu slika, poput **ImageNet**. Ti modeli veÄ‡ dobro obavljaju posao izdvajanja razliÄitih znaÄajki iz generiÄkih slika, a u mnogim sluÄajevima samo izgradnja klasifikatora na temelju tih izdvojenih znaÄajki moÅ¾e dati dobre rezultate.

> âœ… Prijenos uÄenja je pojam koji se koristi i u drugim akademskim podruÄjima, poput obrazovanja. Odnosi se na proces primjene znanja iz jedne domene u drugu.

## Pretrenirani modeli kao ekstraktori znaÄajki

Konvolucijske mreÅ¾e o kojima smo govorili u prethodnom dijelu sadrÅ¾e niz slojeva, od kojih svaki treba izdvojiti neke znaÄajke iz slike, poÄevÅ¡i od niskorazinskih kombinacija piksela (poput horizontalnih/vertikalnih linija ili poteza), pa sve do viÅ¡erazinskih kombinacija znaÄajki koje odgovaraju stvarima poput oka ili plamena. Ako treniramo CNN na dovoljno velikom skupu generiÄkih i raznolikih slika, mreÅ¾a bi trebala nauÄiti izdvajati te zajedniÄke znaÄajke.

I Keras i PyTorch sadrÅ¾e funkcije za jednostavno uÄitavanje unaprijed treniranih teÅ¾ina neuronske mreÅ¾e za neke uobiÄajene arhitekture, od kojih je veÄ‡ina trenirana na slikama iz ImageNet-a. NajÄeÅ¡Ä‡e koriÅ¡tene opisane su na stranici [CNN Architectures](../07-ConvNets/CNN_Architectures.md) iz prethodne lekcije. Konkretno, moÅ¾ete razmotriti koriÅ¡tenje jednog od sljedeÄ‡ih modela:

* **VGG-16/VGG-19** koji su relativno jednostavni modeli, a ipak daju dobru toÄnost. ÄŒesto je koriÅ¡tenje VGG-a kao prvog pokuÅ¡aja dobar izbor za provjeru kako prijenos uÄenja funkcionira.
* **ResNet** je obitelj modela koju je predloÅ¾io Microsoft Research 2015. godine. Imaju viÅ¡e slojeva, pa stoga zahtijevaju viÅ¡e resursa.
* **MobileNet** je obitelj modela smanjene veliÄine, prikladna za mobilne ureÄ‘aje. Koristite ih ako imate ograniÄene resurse i moÅ¾ete Å¾rtvovati malo toÄnosti.

Evo primjera znaÄajki koje je VGG-16 mreÅ¾a izdvojila iz slike maÄke:

![Features extracted by VGG-16](../../../../../translated_images/hr/features.6291f9c7ba3a0b95.webp)

## Skup podataka MaÄke vs. Psi

U ovom primjeru koristit Ä‡emo skup podataka [MaÄke i Psi](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), koji je vrlo blizak stvarnom scenariju klasifikacije slika.

## âœï¸ VjeÅ¾ba: Prijenos uÄenja

Pogledajmo prijenos uÄenja u praksi u pripadajuÄ‡im biljeÅ¾nicama:

* [Transfer Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](TransferLearningTF.ipynb)

## Vizualizacija idealne maÄke

Unaprijed trenirana neuronska mreÅ¾a sadrÅ¾i razliÄite uzorke unutar svog *mozga*, ukljuÄujuÄ‡i pojmove **idealne maÄke** (kao i idealnog psa, idealne zebre itd.). Bilo bi zanimljivo nekako **vizualizirati ovu sliku**. MeÄ‘utim, to nije jednostavno, jer su uzorci rasporeÄ‘eni po teÅ¾inama mreÅ¾e i organizirani u hijerarhijsku strukturu.

Jedan pristup koji moÅ¾emo koristiti je zapoÄeti s nasumiÄnom slikom, a zatim pokuÅ¡ati koristiti tehniku **optimizacije gradijentnog spuÅ¡tanja** kako bismo prilagodili tu sliku na naÄin da mreÅ¾a poÄne misliti da je to maÄka.

![Image Optimization Loop](../../../../../translated_images/hr/ideal-cat-loop.999fbb8ff306e044.webp)

MeÄ‘utim, ako to uÄinimo, dobit Ä‡emo neÅ¡to vrlo sliÄno nasumiÄnom Å¡umu. To je zato Å¡to *postoji mnogo naÄina da mreÅ¾a pomisli da je ulazna slika maÄka*, ukljuÄujuÄ‡i neke koji vizualno nemaju smisla. Iako te slike sadrÅ¾e mnogo uzoraka tipiÄnih za maÄku, niÅ¡ta ih ne ograniÄava da budu vizualno prepoznatljive.

Kako bismo poboljÅ¡ali rezultat, moÅ¾emo dodati joÅ¡ jedan Älan u funkciju gubitka, koji se naziva **gubitak varijacije**. To je metrika koja pokazuje koliko su sliÄni susjedni pikseli slike. Minimiziranje gubitka varijacije Äini sliku glaÄ‘om i uklanja Å¡um - otkrivajuÄ‡i tako vizualno privlaÄnije uzorke. Evo primjera takvih "idealnih" slika koje se klasificiraju kao maÄka i zebra s visokom vjerojatnoÅ¡Ä‡u:

![Ideal Cat](../../../../../translated_images/hr/ideal-cat.203dd4597643d6b0.webp) | ![Ideal Zebra](../../../../../translated_images/hr/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Idealna maÄka* | *Idealna zebra*

SliÄan pristup moÅ¾e se koristiti za izvoÄ‘enje takozvanih **adversarijalnih napada** na neuronsku mreÅ¾u. Pretpostavimo da Å¾elimo zavarati neuronsku mreÅ¾u i uÄiniti da pas izgleda kao maÄka. Ako uzmemo sliku psa, koju mreÅ¾a prepoznaje kao psa, moÅ¾emo je malo prilagoditi koristeÄ‡i optimizaciju gradijentnog spuÅ¡tanja dok mreÅ¾a ne poÄne klasificirati sliku kao maÄku:

![Picture of a Dog](../../../../../translated_images/hr/original-dog.8f68a67d2fe0911f.webp) | ![Picture of a dog classified as a cat](../../../../../translated_images/hr/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Izvorna slika psa* | *Slika psa klasificirana kao maÄka*

Pogledajte kod za reprodukciju gore navedenih rezultata u sljedeÄ‡oj biljeÅ¾nici:

* [Ideal and Adversarial Cat - TensorFlow](AdversarialCat_TF.ipynb)

## ZakljuÄak

KoristeÄ‡i prijenos uÄenja, moÅ¾ete brzo sastaviti klasifikator za zadatak klasifikacije prilagoÄ‘enih objekata i postiÄ‡i visoku toÄnost. MoÅ¾ete vidjeti da sloÅ¾eniji zadaci koje sada rjeÅ¡avamo zahtijevaju veÄ‡u raÄunalnu snagu i ne mogu se lako rijeÅ¡iti na CPU-u. U sljedeÄ‡oj jedinici pokuÅ¡at Ä‡emo koristiti lakÅ¡u implementaciju za treniranje istog modela koristeÄ‡i manje raÄunalne resurse, Å¡to rezultira samo malo niÅ¾om toÄnoÅ¡Ä‡u.

## ğŸš€ Izazov

U prateÄ‡im biljeÅ¾nicama postoje biljeÅ¡ke na dnu o tome kako prijenos znanja najbolje funkcionira s donekle sliÄnim podacima za treniranje (novi tip Å¾ivotinje, moÅ¾da). Eksperimentirajte s potpuno novim vrstama slika kako biste vidjeli koliko dobro ili loÅ¡e vaÅ¡i modeli prijenosa znanja funkcioniraju.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Pregled i samostalno uÄenje

ProÄitajte [TrainingTricks.md](TrainingTricks.md) kako biste produbili svoje znanje o nekim drugim naÄinima treniranja modela.

## [Zadatak](lab/README.md)

U ovom laboratoriju koristit Ä‡emo stvarni skup podataka [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) o kuÄ‡nim ljubimcima s 35 pasmina maÄaka i pasa te Ä‡emo izgraditi klasifikator prijenosa uÄenja.

---

