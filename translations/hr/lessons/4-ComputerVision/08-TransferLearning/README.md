<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-25T23:08:57+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "hr"
}
-->
# Predtrenirane mreÅ¾e i prijenos uÄenja

Treniranje CNN-a moÅ¾e zahtijevati puno vremena i veliku koliÄinu podataka. MeÄ‘utim, veÄ‡ina vremena troÅ¡i se na uÄenje najboljih niskorazinskih filtera koje mreÅ¾a moÅ¾e koristiti za izdvajanje uzoraka iz slika. Postavlja se prirodno pitanje - moÅ¾emo li koristiti neuronsku mreÅ¾u treniranu na jednom skupu podataka i prilagoditi je za klasifikaciju razliÄitih slika bez potrebe za potpunim procesom treniranja?

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Ovaj pristup naziva se **prijenos uÄenja**, jer prenosimo dio znanja iz jednog modela neuronske mreÅ¾e u drugi. Kod prijenosa uÄenja obiÄno poÄinjemo s predtreniranim modelom, koji je treniran na nekom velikom skupu slika, poput **ImageNet**. Ti modeli veÄ‡ dobro obavljaju posao izdvajanja razliÄitih znaÄajki iz generiÄkih slika, a u mnogim sluÄajevima samo izgradnja klasifikatora na temelju tih izdvojenih znaÄajki moÅ¾e dati dobre rezultate.

> âœ… Prijenos uÄenja je pojam koji se koristi i u drugim akademskim podruÄjima, poput obrazovanja. Odnosi se na proces primjene znanja iz jedne domene u drugu.

## Predtrenirani modeli kao ekstraktori znaÄajki

Konvolucijske mreÅ¾e o kojima smo govorili u prethodnom dijelu sadrÅ¾avale su niz slojeva, od kojih je svaki trebao izdvojiti odreÄ‘ene znaÄajke iz slike, poÄevÅ¡i od niskorazinskih kombinacija piksela (poput horizontalnih/vertikalnih linija ili poteza), pa sve do viÅ¡erazinskih kombinacija znaÄajki koje odgovaraju stvarima poput oka ili plamena. Ako treniramo CNN na dovoljno velikom skupu generiÄkih i raznolikih slika, mreÅ¾a bi trebala nauÄiti izdvajati te zajedniÄke znaÄajke.

I Keras i PyTorch sadrÅ¾e funkcije za jednostavno uÄitavanje predtrenirane teÅ¾ine neuronske mreÅ¾e za neke uobiÄajene arhitekture, od kojih je veÄ‡ina trenirana na slikama iz ImageNet-a. NajÄeÅ¡Ä‡e koriÅ¡tene opisane su na stranici [CNN Architectures](../07-ConvNets/CNN_Architectures.md) iz prethodne lekcije. Konkretno, moÅ¾ete razmotriti koriÅ¡tenje jedne od sljedeÄ‡ih:

* **VGG-16/VGG-19** su relativno jednostavni modeli koji i dalje daju dobru toÄnost. ÄŒesto je koriÅ¡tenje VGG-a kao prvog pokuÅ¡aja dobar izbor za provjeru kako prijenos uÄenja funkcionira.
* **ResNet** je obitelj modela koju je predloÅ¾io Microsoft Research 2015. godine. Imaju viÅ¡e slojeva i stoga zahtijevaju viÅ¡e resursa.
* **MobileNet** je obitelj modela smanjene veliÄine, prikladna za mobilne ureÄ‘aje. Koristite ih ako imate ograniÄene resurse i moÅ¾ete Å¾rtvovati malo toÄnosti.

Evo primjera znaÄajki izdvojenih iz slike maÄke pomoÄ‡u VGG-16 mreÅ¾e:

![ZnaÄajke izdvojene pomoÄ‡u VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.hr.png)

## Skup podataka MaÄke vs. Psi

U ovom primjeru koristit Ä‡emo skup podataka [MaÄke i Psi](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), koji je vrlo blizak stvarnom scenariju klasifikacije slika.

## âœï¸ VjeÅ¾ba: Prijenos uÄenja

Pogledajmo prijenos uÄenja u praksi u pripadajuÄ‡im biljeÅ¾nicama:

* [Prijenos uÄenja - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Prijenos uÄenja - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Vizualizacija idealne maÄke

Predtrenirana neuronska mreÅ¾a sadrÅ¾i razliÄite uzorke unutar svog *mozga*, ukljuÄujuÄ‡i pojmove **idealne maÄke** (kao i idealnog psa, idealne zebre itd.). Bilo bi zanimljivo nekako **vizualizirati ovu sliku**. MeÄ‘utim, to nije jednostavno, jer su uzorci rasporeÄ‘eni po teÅ¾inama mreÅ¾e i organizirani u hijerarhijsku strukturu.

Jedan pristup koji moÅ¾emo koristiti je zapoÄeti s nasumiÄnom slikom, a zatim pokuÅ¡ati koristiti tehniku **optimizacije gradijentnog spuÅ¡tanja** kako bismo prilagodili tu sliku na naÄin da mreÅ¾a poÄne misliti da je to maÄka.

![Petlja optimizacije slike](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.hr.png)

MeÄ‘utim, ako to uÄinimo, dobit Ä‡emo neÅ¡to vrlo sliÄno nasumiÄnom Å¡umu. To je zato Å¡to *postoji mnogo naÄina da mreÅ¾a pomisli da je ulazna slika maÄka*, ukljuÄujuÄ‡i neke koji vizualno nemaju smisla. Iako te slike sadrÅ¾e mnogo uzoraka tipiÄnih za maÄku, niÅ¡ta ih ne ograniÄava da budu vizualno prepoznatljive.

Kako bismo poboljÅ¡ali rezultat, moÅ¾emo dodati joÅ¡ jedan Älan u funkciju gubitka, koji se naziva **gubitak varijacije**. To je metrika koja pokazuje koliko su sliÄni susjedni pikseli slike. Minimiziranje gubitka varijacije Äini sliku glaÄ‘om i uklanja Å¡um - otkrivajuÄ‡i tako vizualno privlaÄnije uzorke. Evo primjera takvih "idealnih" slika koje se klasificiraju kao maÄka i zebra s velikom vjerojatnoÅ¡Ä‡u:

![Idealna maÄka](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.hr.png) | ![Idealna zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.hr.png)
-----|-----
*Idealna maÄka* | *Idealna zebra*

SliÄan pristup moÅ¾e se koristiti za provoÄ‘enje takozvanih **adversarijalnih napada** na neuronsku mreÅ¾u. Pretpostavimo da Å¾elimo zavarati neuronsku mreÅ¾u i uÄiniti da pas izgleda kao maÄka. Ako uzmemo sliku psa, koju mreÅ¾a prepoznaje kao psa, moÅ¾emo je malo prilagoditi pomoÄ‡u optimizacije gradijentnog spuÅ¡tanja dok mreÅ¾a ne poÄne klasificirati sliku kao maÄku:

![Slika psa](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.hr.png) | ![Slika psa klasificirana kao maÄka](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.hr.png)
-----|-----
*Izvorna slika psa* | *Slika psa klasificirana kao maÄka*

Pogledajte kod za reprodukciju gore navedenih rezultata u sljedeÄ‡oj biljeÅ¾nici:

* [Idealna i adversarijalna maÄka - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## ZakljuÄak

KoristeÄ‡i prijenos uÄenja, moÅ¾ete brzo sastaviti klasifikator za zadatak klasifikacije prilagoÄ‘enih objekata i postiÄ‡i visoku toÄnost. MoÅ¾ete vidjeti da sloÅ¾eniji zadaci koje sada rjeÅ¡avamo zahtijevaju veÄ‡u raÄunalnu snagu i ne mogu se lako rijeÅ¡iti na CPU-u. U sljedeÄ‡oj jedinici pokuÅ¡at Ä‡emo koristiti lakÅ¡u implementaciju za treniranje istog modela koristeÄ‡i manje raÄunalne resurse, Å¡to rezultira samo malo niÅ¾om toÄnoÅ¡Ä‡u.

## ğŸš€ Izazov

U pripadajuÄ‡im biljeÅ¾nicama postoje biljeÅ¡ke na dnu o tome kako prijenos znanja najbolje funkcionira s donekle sliÄnim podacima za treniranje (moÅ¾da nova vrsta Å¾ivotinje). Eksperimentirajte s potpuno novim vrstama slika kako biste vidjeli koliko dobro ili loÅ¡e vaÅ¡i modeli prijenosa znanja funkcioniraju.

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Pregled i samostalno uÄenje

ProÄitajte [TrainingTricks.md](TrainingTricks.md) kako biste produbili svoje znanje o nekim drugim naÄinima treniranja modela.

## [Zadatak](lab/README.md)

U ovom laboratoriju koristit Ä‡emo stvarni [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) skup podataka o kuÄ‡nim ljubimcima s 35 pasmina maÄaka i pasa te Ä‡emo izgraditi klasifikator prijenosa uÄenja.

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za bilo kakve nesporazume ili pogreÅ¡ne interpretacije koje proizlaze iz koriÅ¡tenja ovog prijevoda.