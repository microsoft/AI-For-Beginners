# Uvod u neuronske mreÅ¾e. ViÅ¡eslojni perceptron

U prethodnom dijelu nauÄili ste o najjednostavnijem modelu neuronske mreÅ¾e - jednoslojnom perceptronu, linearnom modelu za klasifikaciju s dvije klase.

U ovom dijelu proÅ¡irit Ä‡emo ovaj model u fleksibilniji okvir koji nam omoguÄ‡uje:

* obavljanje **klasifikacije s viÅ¡e klasa** uz klasifikaciju s dvije klase
* rjeÅ¡avanje **problema regresije** uz klasifikaciju
* razdvajanje klasa koje nisu linearno razdvojive

TakoÄ‘er Ä‡emo razviti vlastiti modularni okvir u Pythonu koji Ä‡e nam omoguÄ‡iti konstrukciju razliÄitih arhitektura neuronskih mreÅ¾a.

## [Kviz prije predavanja](https://ff-quizzes.netlify.app/en/ai/quiz/7)

## Formalizacija strojnog uÄenja

ZapoÄnimo formalizacijom problema strojnog uÄenja. Pretpostavimo da imamo skup podataka za treniranje **X** s oznakama **Y**, i trebamo izgraditi model *f* koji Ä‡e davati najtoÄnije predikcije. Kvaliteta predikcija mjeri se pomoÄ‡u **funkcije gubitka** &lagran;. ÄŒesto se koriste sljedeÄ‡e funkcije gubitka:

* Za problem regresije, kada trebamo predvidjeti broj, moÅ¾emo koristiti **apsolutnu pogreÅ¡ku** &sum;<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| ili **kvadratnu pogreÅ¡ku** &sum;<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Za klasifikaciju koristimo **0-1 gubitak** (Å¡to je u suÅ¡tini isto kao **toÄnost** modela) ili **logistiÄki gubitak**.

Za jednoslojni perceptron, funkcija *f* bila je definirana kao linearna funkcija *f(x)=wx+b* (ovdje je *w* matrica teÅ¾ina, *x* je vektor ulaznih znaÄajki, a *b* je vektor pomaka). Za razliÄite arhitekture neuronskih mreÅ¾a, ova funkcija moÅ¾e poprimiti sloÅ¾eniji oblik.

> U sluÄaju klasifikacije, Äesto je poÅ¾eljno dobiti vjerojatnosti odgovarajuÄ‡ih klasa kao izlaz mreÅ¾e. Kako bismo pretvorili proizvoljne brojeve u vjerojatnosti (npr. normalizirali izlaz), Äesto koristimo **softmax** funkciju &sigma;, pa funkcija *f* postaje *f(x)=&sigma;(wx+b)*

U definiciji *f* iznad, *w* i *b* nazivaju se **parametri** &theta;=âŸ¨*w,b*âŸ©. S obzirom na skup podataka âŸ¨**X**,**Y**âŸ©, moÅ¾emo izraÄunati ukupnu pogreÅ¡ku na cijelom skupu podataka kao funkciju parametara &theta;.

> âœ… **Cilj treniranja neuronske mreÅ¾e je minimizirati pogreÅ¡ku mijenjanjem parametara &theta;**

## Optimizacija gradijentnim spuÅ¡tanjem

Postoji dobro poznata metoda optimizacije funkcija nazvana **gradijentno spuÅ¡tanje**. Ideja je da moÅ¾emo izraÄunati derivaciju (u viÅ¡edimenzionalnom sluÄaju nazvanu **gradijent**) funkcije gubitka u odnosu na parametre i mijenjati parametre na naÄin da se pogreÅ¡ka smanji. To se moÅ¾e formalizirati na sljedeÄ‡i naÄin:

* Inicijalizirajte parametre s nekim sluÄajnim vrijednostima w<sup>(0)</sup>, b<sup>(0)</sup>
* Ponavljajte sljedeÄ‡i korak mnogo puta:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-&eta;&part;&lagran;/&part;w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-&eta;&part;&lagran;/&part;b

Tijekom treniranja, koraci optimizacije trebali bi se izraÄunavati uzimajuÄ‡i u obzir cijeli skup podataka (sjetite se da se gubitak raÄuna kao zbroj kroz sve uzorke za treniranje). MeÄ‘utim, u stvarnosti uzimamo male dijelove skupa podataka nazvane **minibatch**, i izraÄunavamo gradijente na temelju podskupa podataka. BuduÄ‡i da se podskup uzima sluÄajno svaki put, takva metoda naziva se **stohastiÄko gradijentno spuÅ¡tanje** (SGD).

## ViÅ¡eslojni perceptroni i povratna propagacija

Jednoslojna mreÅ¾a, kao Å¡to smo vidjeli gore, sposobna je klasificirati linearno razdvojive klase. Kako bismo izgradili bogatiji model, moÅ¾emo kombinirati nekoliko slojeva mreÅ¾e. MatematiÄki bi to znaÄilo da funkcija *f* ima sloÅ¾eniji oblik i raÄuna se u nekoliko koraka:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>&alpha;(z<sub>1</sub>)+b<sub>2</sub>
* f = &sigma;(z<sub>2</sub>)

Ovdje je &alpha; **nelinearna aktivacijska funkcija**, &sigma; je softmax funkcija, a parametri su &theta;=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Algoritam gradijentnog spuÅ¡tanja ostaje isti, ali postaje teÅ¾e izraÄunati gradijente. S obzirom na pravilo diferencijacije lanca, moÅ¾emo izraÄunati derivacije kao:

* &part;&lagran;/&part;w<sub>2</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;w<sub>2</sub>)
* &part;&lagran;/&part;w<sub>1</sub> = (&part;&lagran;/&part;&sigma;)(&part;&sigma;/&part;z<sub>2</sub>)(&part;z<sub>2</sub>/&part;&alpha;)(&part;&alpha;/&part;z<sub>1</sub>)(&part;z<sub>1</sub>/&part;w<sub>1</sub>)

> âœ… Pravilo diferencijacije lanca koristi se za izraÄunavanje derivacija funkcije gubitka u odnosu na parametre.

Primijetite da je lijevi dio svih tih izraza isti, i stoga moÅ¾emo uÄinkovito izraÄunavati derivacije poÄevÅ¡i od funkcije gubitka i iduÄ‡i "unatrag" kroz raÄunski graf. Stoga se metoda treniranja viÅ¡eslojnog perceptrona naziva **povratna propagacija**, ili 'backprop'.

<img alt="raÄunski graf" src="../../../../../translated_images/hr/ComputeGraphGrad.4626252c0de03507.webp"/>

> TODO: citiranje slike

> âœ… Povratnu propagaciju Ä‡emo detaljnije obraditi u naÅ¡em primjeru u biljeÅ¾nici.

## ZakljuÄak

U ovoj lekciji izgradili smo vlastitu biblioteku za neuronske mreÅ¾e i koristili je za jednostavan zadatak klasifikacije u dvije dimenzije.

## ğŸš€ Izazov

U prateÄ‡oj biljeÅ¾nici implementirat Ä‡ete vlastiti okvir za izgradnju i treniranje viÅ¡eslojnih perceptrona. MoÄ‡i Ä‡ete detaljno vidjeti kako moderne neuronske mreÅ¾e funkcioniraju.

Nastavite na biljeÅ¾nicu [OwnFramework](OwnFramework.ipynb) i proÄ‘ite kroz nju.

## [Kviz nakon predavanja](https://ff-quizzes.netlify.app/en/ai/quiz/8)

## Pregled i samostalno uÄenje

Povratna propagacija je uobiÄajeni algoritam koji se koristi u AI i ML, vrijedan prouÄavanja [detaljnije](https://wikipedia.org/wiki/Backpropagation)

## [Zadatak](lab/README.md)

U ovom laboratorijskom zadatku traÅ¾i se da koristite okvir koji ste izgradili u ovoj lekciji za rjeÅ¡avanje klasifikacije rukom pisanih znamenki iz MNIST skupa podataka.

* [Upute](lab/README.md)
* [BiljeÅ¾nica](lab/MyFW_MNIST.ipynb)

---

