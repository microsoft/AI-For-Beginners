#  拽砖  砖 专住驻专专

## [砖 驻 专爪](https://ff-quizzes.netlify.app/en/ai/quiz/35)

转 注转 砖转 转专 转 注 砖驻 注转 (NLP)  **转专 **, 砖 转 砖注转 住住   Google Translate. 拽  转拽 转专 ,  驻  转专,  砖 砖 *专爪祝-专爪祝* (  **注专转 砖驻**).

注 专砖转转 RNN, 砖转 专爪祝-专爪祝 砖转 爪注转 砖转 专砖转转 专转, 砖专 专砖转 转, -**encoder**, 住转 专爪祝 拽 爪 住转专, 注 专砖转 专转, -**decoder**, 驻转转 转 爪 住转专 转爪 转专转. 砖  注转 砖 :

* 爪 住驻 砖 专砖转 -encoder 转拽砖 专 转 转转 砖驻,  砖专 转  砖  砖驻 专.
*   专爪祝 砖 砖驻注  注 转爪. 爪转, 注转 转,  住转 专爪祝 拽 砖 砖驻注 专 转专 注 驻 砖专 专转.

** 拽砖** 住驻拽 专 砖拽 转 砖驻注 拽砖专转 砖  拽专 拽 注  转转 驻 砖 -RNN.  砖 注  爪专转 拽爪专 专  爪  砖 -RNN 拽  -RNN 驻. , 注转 爪专转 住 驻 y<sub>t</sub>, 拽 砖 转  爪 住转专 砖 拽 h<sub>i</sub>, 注 拽 砖拽 砖 &alpha;<sub>t,i</sub>.

![转 爪  encoder/decoder 注 砖转 拽砖 转](../../../../../translated_images/he/encoder-decoder-attention.7a726296894fb567.webp)

>  -encoder-decoder 注  拽砖  转 [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf), 爪 转 [驻住  ](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

专爪转 拽砖 {&alpha;<sub>i,j</sub>} 爪转 转  砖  住转 拽 砖驻注转 注 爪专转  住转 驻.   专爪 :

![转 爪 砖专  砖爪 注  RNNsearch-50, 转 Bahdanau - arviz.org](../../../../../translated_images/he/bahdanau-fig3.09ba2d37f202a6af.webp)

> 专 转 [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf) (专 3)

 拽砖 专 拽  爪   拽专 转专 砖 转 转 -NLP. 注 转, 住驻转 拽砖   转 住驻专 驻专专 砖 ,  砖 注转 拽  注 RNNs.  专转 砖 拽  砖 RNNs  砖驻 专 砖  拽砖 注 爪注  拽. -RNN   专爪祝 爪专 转 注 住专 专爪祝,  砖拽砖 注 爪注 拽.

![Encoder Decoder 注 拽砖](../../../../../lessons/5-NLP/18-Transformers/images/EncDecAttention.gif)

> 专 转 [ 砖 Google](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)

抓 砖  拽砖 砖 注    爪专转  砖 专住驻专专,  BERT -Open-GPT3, 砖   转.

##  砖 专住驻专专

转 专注转 专 专 专住驻专专  注 驻 专爪祝 砖 RNNs 爪专  砖转 爪注 注  拽.  砖 注  砖 砖 专注转:

* 拽 拽 (positional encoding)
* 砖砖  拽砖 注爪 (self-attention)  转 转转 拽 RNNs ( CNNs).  住 砖专 砖爪 转 专住驻专专 拽专 *[Attention is all you need](https://arxiv.org/abs/1706.03762)*.

### 拽/注转 拽

专注 砖 拽 拽  拽:
1. 砖砖 -RNNs, 拽 住 砖 拽 爪 注  住驻专 爪注,   爪专 爪 驻专砖.
2. 注 转, 砖专 注专 拽砖, 砖 注转 转 拽 住 砖 拽 转 专爪祝.
3.  拽 拽 拽,  住驻 专爪祝 拽 专爪祝 砖 拽 拽 (专, 专爪祝 砖 住驻专 0,1, ...).
4. 专   注专 转 拽 拽 注 拽专 注 砖 拽.  驻 转 拽 (住驻专 砖) 拽专, 转 砖转砖 砖转 砖转:

* 注 转转 ,  注转 拽.  砖 砖砖拽 .  砖 砖转 注 注  拽 拽 砖, 拽 拽专 注 转 , 转  专 .
* 驻拽爪转 拽 拽 拽注, 驻 砖爪注 专 拽专.

<img src="../../../../../translated_images/he/pos-embedding.e41ce9b6cf6078af.webp" width="50%"/>

> 转 转 专

转爪 砖 拽 注 注转 拽 砖转  转 拽 拽专  转 拽 转 专爪祝.

### 拽砖 注爪 专-专砖

注转, 注 转 转转 转 专爪祝 砖. 砖 , 专住驻专专 砖转砖  **拽砖 注爪**, 砖 注砖 拽砖 砖 注 转 专爪祝 拽 驻. 砖 拽砖 注爪 驻砖专  拽转 砖 **拽砖专** 转 砖驻 专转   拽砖专转  . ,  驻砖专  专转   转住转  爪注转 转住转  *it*,  拽转 转 拽砖专 砖:

![](../../../../../translated_images/he/CoreferenceResolution.861924d6d384a7d6.webp)

> 转 转 [ 砖 Google](https://research.googleblog.com/2017/08/transformer-novel-neural-network.html)

专住驻专专,  砖转砖 **拽砖 专-专砖**  转转 专砖转 转 转 转 住 砖 砖 转转, 砖, 住    专 注转  拽爪专, 转住转 砖转驻转 注转 砖 专, '.

[专转 TensorFlow](TransformersTF.ipynb)  驻专 住驻 注 砖 砖转 专住驻专专.

### 拽砖  拽 驻注

专住驻专专, 拽砖 砖砖 砖 拽转:

*  转 转转 转 拽住 拽 爪注转 拽砖 注爪.
*  爪注 转专 专爪祝 -  砖转 拽砖  -encoder -decoder.

拽砖  拽 驻注    拽砖 砖砖 -RNNs, 驻 砖转专 转转 拽 . 专   住专 转 转驻拽 拽砖  拽 驻注.

![GIF  爪 爪 转爪注转 注专转  砖 专住驻专专.](../../../../../lessons/5-NLP/18-Transformers/images/transformer-animated-explanation.gif)

 砖 拽 拽 驻 驻 注爪  拽 驻, 专住驻专专  爪注 驻注转 拽  转专 -RNNs,  砖驻砖专  砖   转专.  专砖 拽砖  砖砖 转 住 砖  ,  砖砖驻专 砖转 注 砖驻 注转.

## BERT

**BERT** (Bidirectional Encoder Representations from Transformers)  专砖转 专住驻专专   注 12 砖转 注专 *BERT-base*, -24 注专 *BERT-large*.   转 注 专 拽住  (拽驻 + 住驻专) 爪注转   驻拽 (  住转专转 砖驻).   专砖,  住驻 专转 砖注转转 砖 转 砖驻, 砖转 专  爪 注 注专 转 专 爪注转  注. 转  拽专 **转 注专**.

![转 转 http://jalammar.github.io/illustrated-bert/](../../../../../translated_images/he/jalammarBERT-language-modeling-masked-lm.34f113ea5fec4362.webp)

> 拽专 转 [](http://jalammar.github.io/illustrated-bert/)

## 锔 转专: 专住驻专专

砖  专转 转:

* [专住驻专专 -PyTorch](TransformersPyTorch.ipynb)
* [专住驻专专 -TensorFlow](TransformersTF.ipynb)

## 住

砖注专  转 注 专住驻专专  拽砖,   专  砖 NLP. 砖 专爪转 专转 砖 专拽专转 专住驻专专,  BERT, DistilBERT, BigBird, OpenGPT3 注, 砖转 . 转 [HuggingFace](https://github.com/huggingface/) 住驻拽转 专  专转 专拽专转  注 PyTorch -TensorFlow.

##  转专

## [砖 专 专爪](https://ff-quizzes.netlify.app/en/ai/quiz/36)

## 住拽专  注爪转

* [驻住 ](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/), 住专 转 专 拽住 [Attention is all you need](https://arxiv.org/abs/1706.03762) 注 专住驻专专.
* [住专转 驻住 ](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452) 注 专住驻专专, 住专 转 专拽专 驻专.

## [](assignment.md)

---

