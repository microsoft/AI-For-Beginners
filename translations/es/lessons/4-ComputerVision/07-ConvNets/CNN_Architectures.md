# Arquitecturas de CNN Bien Conocidas

### VGG-16

VGG-16 es una red que logr칩 una precisi칩n del 92.7% en la clasificaci칩n top-5 de ImageNet en 2014. Tiene la siguiente estructura de capas:

![ImageNet Layers](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.es.jpg)

Como puedes ver, VGG sigue una arquitectura de pir치mide tradicional, que es una secuencia de capas de convoluci칩n y agrupamiento.

![ImageNet Pyramid](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.es.jpg)

> Imagen de [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet es una familia de modelos propuesta por Microsoft Research en 2015. La idea principal de ResNet es utilizar **bloques residuales**:

<img src="images/resnet-block.png" width="300"/>

> Imagen de [este art칤culo](https://arxiv.org/pdf/1512.03385.pdf)

La raz칩n para usar la conexi칩n de identidad es permitir que nuestra capa prediga **la diferencia** entre el resultado de una capa anterior y la salida del bloque residual; de ah칤 el nombre *residual*. Estos bloques son mucho m치s f치ciles de entrenar, y se pueden construir redes con varios cientos de esos bloques (las variantes m치s comunes son ResNet-52, ResNet-101 y ResNet-152).

Tambi칠n puedes pensar en esta red como capaz de ajustar su complejidad al conjunto de datos. Inicialmente, cuando comienzas a entrenar la red, los valores de los pesos son peque침os, y la mayor parte de la se침al pasa a trav칠s de capas de identidad. A medida que avanza el entrenamiento y los pesos se vuelven m치s grandes, la importancia de los par치metros de la red crece, y la red se ajusta para acomodar el poder expresivo requerido para clasificar correctamente las im치genes de entrenamiento.

### Google Inception

La arquitectura Google Inception lleva esta idea un paso m치s all치 y construye cada capa de la red como una combinaci칩n de varios caminos diferentes:

<img src="images/inception.png" width="400"/>

> Imagen de [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Aqu칤, necesitamos enfatizar el papel de las convoluciones 1x1, porque al principio no tienen sentido. 쯇or qu칠 necesitar칤amos pasar por la imagen con un filtro 1x1? Sin embargo, debes recordar que los filtros de convoluci칩n tambi칠n trabajan con varios canales de profundidad (originalmente - colores RGB, en capas subsiguientes - canales para diferentes filtros), y la convoluci칩n 1x1 se utiliza para mezclar esos canales de entrada utilizando diferentes pesos entrenables. Tambi칠n puede verse como un muestreo (agrupamiento) sobre la dimensi칩n de los canales.

Aqu칤 hay [una buena publicaci칩n de blog](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) sobre el tema, y [el art칤culo original](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet es una familia de modelos de tama침o reducido, adecuada para dispositivos m칩viles. 칔salos si tienes pocos recursos y puedes sacrificar un poco de precisi칩n. La idea principal detr치s de ellos es la llamada **convoluci칩n separable en profundidad**, que permite representar los filtros de convoluci칩n mediante una composici칩n de convoluciones espaciales y convoluciones 1x1 sobre los canales de profundidad. Esto reduce significativamente el n칰mero de par치metros, haciendo que la red sea m치s peque침a en tama침o y tambi칠n m치s f치cil de entrenar con menos datos.

Aqu칤 hay [una buena publicaci칩n de blog sobre MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Conclusi칩n

En esta unidad, has aprendido el concepto principal detr치s de las redes neuronales de visi칩n por computadora: las redes convolucionales. Las arquitecturas de la vida real que impulsan la clasificaci칩n de im치genes, la detecci칩n de objetos e incluso las redes de generaci칩n de im치genes se basan en CNN, solo que con m치s capas y algunos trucos de entrenamiento adicionales.

## 游 Desaf칤o

En los cuadernos adjuntos, hay notas al final sobre c칩mo obtener una mayor precisi칩n. Realiza algunos experimentos para ver si puedes lograr una mayor precisi칩n.

## [Cuestionario posterior a la conferencia](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/207)

## Revisi칩n y Autoestudio

Aunque las CNN se utilizan m치s com칰nmente para tareas de Visi칩n por Computadora, son generalmente buenas para extraer patrones de tama침o fijo. Por ejemplo, si estamos tratando con sonidos, tambi칠n podr칤amos querer usar CNN para buscar algunos patrones espec칤ficos en la se침al de audio; en cuyo caso los filtros ser칤an unidimensionales (y esta CNN se llamar칤a 1D-CNN). Adem치s, a veces se utiliza 3D-CNN para extraer caracter칤sticas en un espacio multidimensional, como ciertos eventos que ocurren en un video; la CNN puede capturar ciertos patrones de cambio de caracter칤sticas a lo largo del tiempo. Realiza algunas revisiones y autoestudios sobre otras tareas que se pueden realizar con CNN.

## [Asignaci칩n](lab/README.md)

En este laboratorio, se te encarga clasificar diferentes razas de gatos y perros. Estas im치genes son m치s complejas que el conjunto de datos MNIST y de dimensiones m치s altas, y hay m치s de 10 clases.

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducci칩n autom치tica basados en IA. Si bien nos esforzamos por lograr precisi칩n, tenga en cuenta que las traducciones autom치ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci칩n cr칤tica, se recomienda una traducci칩n profesional humana. No nos hacemos responsables de malentendidos o malas interpretaciones que surjan del uso de esta traducci칩n.