# Detecci√≥n de Objetos

Los modelos de clasificaci√≥n de im√°genes que hemos tratado hasta ahora toman una imagen y producen un resultado categ√≥rico, como la clase 'n√∫mero' en un problema de MNIST. Sin embargo, en muchos casos no solo queremos saber que una imagen contiene objetos, sino que queremos determinar su ubicaci√≥n precisa. Este es precisamente el objetivo de la **detecci√≥n de objetos**.

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![Detecci√≥n de Objetos](../../../../../translated_images/es/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be.webp)

> Imagen de [sitio web de YOLO v2](https://pjreddie.com/darknet/yolov2/)

## Un Enfoque Ingenuo para la Detecci√≥n de Objetos

Supongamos que queremos encontrar un gato en una imagen. Un enfoque muy ingenuo para la detecci√≥n de objetos ser√≠a el siguiente:

1. Dividir la imagen en varias secciones.
2. Ejecutar clasificaci√≥n de im√°genes en cada secci√≥n.
3. Las secciones que resulten en una activaci√≥n suficientemente alta pueden considerarse que contienen el objeto en cuesti√≥n.

![Detecci√≥n Ingenua de Objetos](../../../../../translated_images/es/naive-detection.e7f1ba220ccd08c6.webp)

> *Imagen del [Cuaderno de Ejercicios](ObjectDetection-TF.ipynb)*

Sin embargo, este enfoque est√° lejos de ser ideal, ya que solo permite al algoritmo localizar el cuadro delimitador del objeto de manera muy imprecisa. Para una ubicaci√≥n m√°s precisa, necesitamos ejecutar alg√∫n tipo de **regresi√≥n** para predecir las coordenadas de los cuadros delimitadores, y para ello necesitamos conjuntos de datos espec√≠ficos.

## Regresi√≥n para la Detecci√≥n de Objetos

[Este art√≠culo](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491) ofrece una excelente introducci√≥n a la detecci√≥n de formas.

## Conjuntos de Datos para la Detecci√≥n de Objetos

Es posible que encuentres los siguientes conjuntos de datos para esta tarea:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) - 20 clases
* [COCO](http://cocodataset.org/#home) - Objetos Comunes en Contexto. 80 clases, cuadros delimitadores y m√°scaras de segmentaci√≥n.

![COCO](../../../../../translated_images/es/coco-examples.71bc60380fa6cceb.webp)

## M√©tricas de Detecci√≥n de Objetos

### Intersecci√≥n sobre Uni√≥n

Mientras que para la clasificaci√≥n de im√°genes es f√°cil medir qu√© tan bien funciona el algoritmo, para la detecci√≥n de objetos necesitamos medir tanto la correcci√≥n de la clase como la precisi√≥n de la ubicaci√≥n inferida del cuadro delimitador. Para esto √∫ltimo, usamos la llamada **Intersecci√≥n sobre Uni√≥n** (IoU), que mide qu√© tan bien se superponen dos cuadros (o dos √°reas arbitrarias).

![IoU](../../../../../translated_images/es/iou_equation.9a4751d40fff4e11.webp)

> *Figura 2 de [este excelente art√≠culo sobre IoU](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)*

La idea es simple: dividimos el √°rea de intersecci√≥n entre dos figuras por el √°rea de su uni√≥n. Para dos √°reas id√©nticas, IoU ser√≠a 1, mientras que para √°reas completamente separadas ser√° 0. En otros casos, variar√° de 0 a 1. Normalmente solo consideramos aquellos cuadros delimitadores para los cuales IoU est√° por encima de un cierto valor.

### Precisi√≥n Promedio

Supongamos que queremos medir qu√© tan bien se reconoce una clase de objetos $C$. Para medirlo, usamos la m√©trica de **Precisi√≥n Promedio**, que se calcula de la siguiente manera:

1. Considerar la curva de Precisi√≥n-Recall que muestra la precisi√≥n dependiendo de un valor de umbral de detecci√≥n (de 0 a 1).
2. Dependiendo del umbral, obtendremos m√°s o menos objetos detectados en la imagen y diferentes valores de precisi√≥n y recall.
3. La curva se ver√° as√≠:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *Imagen de [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

La Precisi√≥n Promedio para una clase dada $C$ es el √°rea bajo esta curva. M√°s precisamente, el eje de Recall se divide t√≠picamente en 10 partes, y la Precisi√≥n se promedia en todos esos puntos:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP e IoU

Solo consideraremos aquellas detecciones para las cuales IoU est√° por encima de un cierto valor. Por ejemplo, en el conjunto de datos PASCAL VOC t√≠picamente $\mbox{IoU Threshold} = 0.5$, mientras que en COCO AP se mide para diferentes valores de $\mbox{IoU Threshold}$.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *Imagen de [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

### Precisi√≥n Promedio Media - mAP

La m√©trica principal para la detecci√≥n de objetos se llama **Precisi√≥n Promedio Media**, o **mAP**. Es el valor de la Precisi√≥n Promedio, promediado entre todas las clases de objetos, y a veces tambi√©n sobre $\mbox{IoU Threshold}$. En m√°s detalle, el proceso de c√°lculo de **mAP** se describe
[en este art√≠culo](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3), y tambi√©n [aqu√≠ con ejemplos de c√≥digo](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734).

## Diferentes Enfoques para la Detecci√≥n de Objetos

Existen dos grandes clases de algoritmos de detecci√≥n de objetos:

* **Redes de Propuesta de Regiones** (R-CNN, Fast R-CNN, Faster R-CNN). La idea principal es generar **Regiones de Inter√©s** (ROI) y ejecutar CNN sobre ellas, buscando la activaci√≥n m√°xima. Es un poco similar al enfoque ingenuo, con la excepci√≥n de que las ROI se generan de manera m√°s inteligente. Una de las principales desventajas de estos m√©todos es que son lentos, porque necesitamos muchas pasadas del clasificador CNN sobre la imagen.
* M√©todos de **una sola pasada** (YOLO, SSD, RetinaNet). En estas arquitecturas dise√±amos la red para predecir tanto las clases como las ROI en una sola pasada.

### R-CNN: CNN Basada en Regiones

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf) utiliza [Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) para generar una estructura jer√°rquica de regiones ROI, que luego se pasan por extractores de caracter√≠sticas CNN y clasificadores SVM para determinar la clase del objeto, y regresi√≥n lineal para determinar las coordenadas del *cuadro delimitador*. [Art√≠culo Oficial](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/es/rcnn1.cae407020dfb1d1f.webp)

> *Imagen de van de Sande et al. ICCV‚Äô11*

![RCNN-1](../../../../../translated_images/es/rcnn2.2d9530bb83516484.webp)

> *Im√°genes de [este art√≠culo](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)*

### F-RCNN - Fast R-CNN

Este enfoque es similar a R-CNN, pero las regiones se definen despu√©s de que se han aplicado las capas de convoluci√≥n.

![FRCNN](../../../../../translated_images/es/f-rcnn.3cda6d9bb4188875.webp)

> Imagen del [Art√≠culo Oficial](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Faster R-CNN

La idea principal de este enfoque es usar una red neuronal para predecir las ROI, llamada *Red de Propuesta de Regiones*. [Art√≠culo](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../translated_images/es/faster-rcnn.8d46c099b87ef30a.webp)

> Imagen del [Art√≠culo Oficial](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: Red Totalmente Convolucional Basada en Regiones

Este algoritmo es incluso m√°s r√°pido que Faster R-CNN. La idea principal es la siguiente:

1. Extraemos caracter√≠sticas usando ResNet-101.
1. Las caracter√≠sticas se procesan mediante **Position-Sensitive Score Map**. Cada objeto de $C$ clases se divide en regiones de $k\times k$, y entrenamos para predecir partes de objetos.
1. Para cada parte de las regiones de $k\times k$, todas las redes votan por las clases de objetos, y se selecciona la clase de objeto con el voto m√°ximo.

![r-fcn image](../../../../../translated_images/es/r-fcn.13eb88158b99a3da.webp)

> Imagen del [Art√≠culo Oficial](https://arxiv.org/abs/1605.06409)

### YOLO - You Only Look Once

YOLO es un algoritmo de una sola pasada en tiempo real. La idea principal es la siguiente:

 * La imagen se divide en regiones de $S\times S$.
 * Para cada regi√≥n, **CNN** predice $n$ posibles objetos, las coordenadas del *cuadro delimitador* y la *confianza*=*probabilidad* * IoU.

 ![YOLO](../../../../../translated_images/es/yolo.a2648ec82ee8bb4e.webp)

> Imagen del [Art√≠culo Oficial](https://arxiv.org/abs/1506.02640)

### Otros Algoritmos

* RetinaNet: [Art√≠culo Oficial](https://arxiv.org/abs/1708.02002)
   - [Implementaci√≥n en PyTorch en Torchvision](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Implementaci√≥n en Keras](https://github.com/fizyr/keras-retinanet)
   - [Detecci√≥n de Objetos con RetinaNet](https://keras.io/examples/vision/retinanet/) en ejemplos de Keras.
* SSD (Single Shot Detector): [Art√≠culo Oficial](https://arxiv.org/abs/1512.02325)

## ‚úçÔ∏è Ejercicios: Detecci√≥n de Objetos

Contin√∫a tu aprendizaje en el siguiente cuaderno:

[ObjectDetection.ipynb](ObjectDetection.ipynb)

## Conclusi√≥n

En esta lecci√≥n hiciste un recorrido r√°pido por las diversas formas en que se puede lograr la detecci√≥n de objetos.

## üöÄ Desaf√≠o

Lee estos art√≠culos y cuadernos sobre YOLO y pru√©balos por ti mismo:

* [Buen art√≠culo](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/) que describe YOLO.
 * [Sitio oficial](https://pjreddie.com/darknet/yolo/)
 * YOLO: [Implementaci√≥n en Keras](https://github.com/experiencor/keras-yolo2), [cuaderno paso a paso](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * YOLO v2: [Implementaci√≥n en Keras](https://github.com/experiencor/keras-yolo2), [cuaderno paso a paso](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## Revisi√≥n y Autoestudio

* [Detecci√≥n de Objetos](https://tjmachinelearning.com/lectures/1718/obj/) por Nikhil Sardana.
* [Una buena comparaci√≥n de algoritmos de detecci√≥n de objetos](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html).
* [Revisi√≥n de algoritmos de aprendizaje profundo para la detecci√≥n de objetos](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852).
* [Introducci√≥n paso a paso a los algoritmos b√°sicos de detecci√≥n de objetos](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/).
* [Implementaci√≥n de Faster R-CNN en Python para la detecci√≥n de objetos](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/).

## [Asignaci√≥n: Detecci√≥n de Objetos](lab/README.md)

---

