# Autoencoders

Al entrenar CNNs, uno de los problemas es que necesitamos una gran cantidad de datos etiquetados. En el caso de la clasificaci√≥n de im√°genes, debemos separar las im√°genes en diferentes clases, lo cual requiere un esfuerzo manual.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/17)

Sin embargo, podr√≠amos querer usar datos sin procesar (no etiquetados) para entrenar extractores de caracter√≠sticas de CNN, lo que se llama **aprendizaje auto-supervisado**. En lugar de etiquetas, utilizaremos las im√°genes de entrenamiento como entrada y salida de la red. La idea principal de un **autoencoder** es que tendremos una **red codificadora** que convierte la imagen de entrada en alg√∫n **espacio latente** (normalmente es solo un vector de menor tama√±o), y luego una **red decodificadora**, cuyo objetivo ser√° reconstruir la imagen original.

> ‚úÖ Un [autoencoder](https://wikipedia.org/wiki/Autoencoder) es "un tipo de red neuronal artificial utilizada para aprender codificaciones eficientes de datos no etiquetados."

Dado que estamos entrenando un autoencoder para capturar la mayor cantidad de informaci√≥n posible de la imagen original para una reconstrucci√≥n precisa, la red intenta encontrar la mejor **representaci√≥n** de las im√°genes de entrada para capturar su significado.

![Diagrama de AutoEncoder](../../../../../translated_images/es/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> Imagen de [Keras blog](https://blog.keras.io/building-autoencoders-in-keras.html)

## Escenarios para usar Autoencoders

Aunque reconstruir im√°genes originales no parece √∫til por s√≠ mismo, hay algunos escenarios donde los autoencoders son especialmente √∫tiles:

* **Reducir la dimensi√≥n de las im√°genes para visualizaci√≥n** o **entrenar representaciones de im√°genes**. Generalmente, los autoencoders ofrecen mejores resultados que PCA, porque tienen en cuenta la naturaleza espacial de las im√°genes y las caracter√≠sticas jer√°rquicas.
* **Eliminaci√≥n de ruido**, es decir, eliminar el ruido de la imagen. Como el ruido contiene mucha informaci√≥n in√∫til, el autoencoder no puede ajustarlo todo en un espacio latente relativamente peque√±o, y por lo tanto captura solo la parte importante de la imagen. Al entrenar eliminadores de ruido, comenzamos con im√°genes originales y usamos im√°genes con ruido artificial a√±adido como entrada para el autoencoder.
* **Super-resoluci√≥n**, aumentar la resoluci√≥n de las im√°genes. Comenzamos con im√°genes de alta resoluci√≥n y usamos la imagen de menor resoluci√≥n como entrada del autoencoder.
* **Modelos generativos**. Una vez que entrenamos el autoencoder, la parte decodificadora puede usarse para crear nuevos objetos a partir de vectores latentes aleatorios.

## Autoencoders Variacionales (VAE)

Los autoencoders tradicionales reducen la dimensi√≥n de los datos de entrada de alguna manera, identificando las caracter√≠sticas importantes de las im√°genes de entrada. Sin embargo, los vectores latentes a menudo no tienen mucho sentido. En otras palabras, tomando como ejemplo el conjunto de datos MNIST, identificar qu√© d√≠gitos corresponden a diferentes vectores latentes no es una tarea f√°cil, porque los vectores latentes cercanos no necesariamente corresponden a los mismos d√≠gitos.

Por otro lado, para entrenar modelos *generativos* es mejor tener cierta comprensi√≥n del espacio latente. Esta idea nos lleva al **autoencoder variacional** (VAE).

El VAE es un autoencoder que aprende a predecir la *distribuci√≥n estad√≠stica* de los par√°metros latentes, llamada **distribuci√≥n latente**. Por ejemplo, podr√≠amos querer que los vectores latentes se distribuyan normalmente con una media z<sub>mean</sub> y una desviaci√≥n est√°ndar z<sub>sigma</sub> (tanto la media como la desviaci√≥n est√°ndar son vectores de alguna dimensionalidad d). El codificador en el VAE aprende a predecir esos par√°metros, y luego el decodificador toma un vector aleatorio de esta distribuci√≥n para reconstruir el objeto.

En resumen:

 * A partir del vector de entrada, predecimos `z_mean` y `z_log_sigma` (en lugar de predecir la desviaci√≥n est√°ndar directamente, predecimos su logaritmo).
 * Muestreamos un vector `sample` de la distribuci√≥n N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>)).
 * El decodificador intenta decodificar la imagen original usando `sample` como vector de entrada.

 <img src="../../../../../translated_images/es/vae.464c465a5b6a9e25.webp" width="50%">

> Imagen de [este blog](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) por Isaak Dykeman

Los autoencoders variacionales utilizan una funci√≥n de p√©rdida compleja que consta de dos partes:

* **P√©rdida de reconstrucci√≥n**, que es la funci√≥n de p√©rdida que muestra qu√© tan cerca est√° una imagen reconstruida del objetivo (puede ser el Error Cuadr√°tico Medio, o MSE). Es la misma funci√≥n de p√©rdida que en los autoencoders normales.
* **P√©rdida KL**, que asegura que las distribuciones de las variables latentes se mantengan cercanas a una distribuci√≥n normal. Se basa en la noci√≥n de [divergencia de Kullback-Leibler](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained), una m√©trica para estimar qu√© tan similares son dos distribuciones estad√≠sticas.

Una ventaja importante de los VAEs es que nos permiten generar nuevas im√°genes de manera relativamente sencilla, porque sabemos de qu√© distribuci√≥n muestrear los vectores latentes. Por ejemplo, si entrenamos un VAE con un vector latente 2D en MNIST, luego podemos variar los componentes del vector latente para obtener diferentes d√≠gitos:

<img alt="vaemnist" src="../../../../../translated_images/es/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> Imagen por [Dmitry Soshnikov](http://soshnikov.com)

Observa c√≥mo las im√°genes se mezclan entre s√≠, a medida que comenzamos a obtener vectores latentes de diferentes partes del espacio de par√°metros latentes. Tambi√©n podemos visualizar este espacio en 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/es/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> Imagen por [Dmitry Soshnikov](http://soshnikov.com)

## ‚úçÔ∏è Ejercicios: Autoencoders

Aprende m√°s sobre autoencoders en estos notebooks correspondientes:

* [Autoencoders en TensorFlow](AutoencodersTF.ipynb)
* [Autoencoders en PyTorch](AutoEncodersPyTorch.ipynb)

## Propiedades de los Autoencoders

* **Espec√≠ficos de los datos** - solo funcionan bien con el tipo de im√°genes con las que han sido entrenados. Por ejemplo, si entrenamos una red de super-resoluci√≥n en flores, no funcionar√° bien en retratos. Esto se debe a que la red puede producir im√°genes de mayor resoluci√≥n tomando detalles finos de las caracter√≠sticas aprendidas del conjunto de datos de entrenamiento.
* **Con p√©rdida** - la imagen reconstruida no es igual a la imagen original. La naturaleza de la p√©rdida est√° definida por la *funci√≥n de p√©rdida* utilizada durante el entrenamiento.
* Funciona con **datos no etiquetados**.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## Conclusi√≥n

En esta lecci√≥n, aprendiste sobre los diferentes tipos de autoencoders disponibles para el cient√≠fico de IA. Aprendiste c√≥mo construirlos y c√≥mo usarlos para reconstruir im√°genes. Tambi√©n aprendiste sobre el VAE y c√≥mo usarlo para generar nuevas im√°genes.

## üöÄ Desaf√≠o

En esta lecci√≥n, aprendiste sobre el uso de autoencoders para im√°genes. ¬°Pero tambi√©n pueden usarse para m√∫sica! Explora el proyecto [MusicVAE](https://magenta.tensorflow.org/music-vae) de Magenta, que utiliza autoencoders para aprender a reconstruir m√∫sica. Realiza algunos [experimentos](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) con esta biblioteca para ver qu√© puedes crear.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Revisi√≥n y Autoestudio

Para referencia, lee m√°s sobre autoencoders en estos recursos:

* [Construyendo Autoencoders en Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Publicaci√≥n en el blog de NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Autoencoders Variacionales Explicados](https://kvfrans.com/variational-autoencoders-explained/)
* [Autoencoders Variacionales Condicionales](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Tarea

Al final de [este notebook usando TensorFlow](AutoencodersTF.ipynb), encontrar√°s una 'tarea': √∫sala como tu asignaci√≥n.

---

