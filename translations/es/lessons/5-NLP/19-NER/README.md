# Reconocimiento de Entidades Nombradas

Hasta ahora, nos hemos concentrado principalmente en una tarea de PLN: la clasificaci√≥n. Sin embargo, existen otras tareas de PLN que pueden realizarse con redes neuronales. Una de esas tareas es **[Reconocimiento de Entidades Nombradas](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), que se ocupa de identificar entidades espec√≠ficas dentro del texto, como lugares, nombres de personas, intervalos de tiempo, f√≥rmulas qu√≠micas, entre otros.

## [Cuestionario previo a la clase](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Ejemplo de Uso de NER

Supongamos que quieres desarrollar un chatbot de lenguaje natural, similar a Amazon Alexa o Google Assistant. La forma en que funcionan los chatbots inteligentes es *entendiendo* lo que el usuario quiere mediante la clasificaci√≥n de texto en la frase de entrada. El resultado de esta clasificaci√≥n es el llamado **intento**, que determina lo que el chatbot debe hacer.

<img alt="Bot NER" src="../../../../../translated_images/es/bot-ner.4b09235dbb0ad275.webp" width="50%"/>

> Imagen del autor

Sin embargo, un usuario puede proporcionar algunos par√°metros como parte de la frase. Por ejemplo, al preguntar por el clima, puede especificar una ubicaci√≥n o una fecha. Un bot deber√≠a ser capaz de entender esas entidades y completar los espacios de los par√°metros antes de realizar la acci√≥n. Aqu√≠ es donde entra en juego NER.

> ‚úÖ Otro ejemplo ser√≠a [analizar art√≠culos cient√≠ficos m√©dicos](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Una de las principales cosas que necesitamos buscar son t√©rminos m√©dicos espec√≠ficos, como enfermedades y sustancias m√©dicas. Mientras que un peque√±o n√∫mero de enfermedades probablemente se pueda extraer mediante b√∫squeda de subcadenas, entidades m√°s complejas, como compuestos qu√≠micos y nombres de medicamentos, requieren un enfoque m√°s sofisticado.

## NER como Clasificaci√≥n de Tokens

Los modelos NER son esencialmente **modelos de clasificaci√≥n de tokens**, porque para cada uno de los tokens de entrada debemos decidir si pertenece a una entidad o no, y si lo hace, a qu√© clase de entidad pertenece.

Considera el siguiente t√≠tulo de un art√≠culo:

**Regurgitaci√≥n de la v√°lvula tric√∫spide** y **carbonato de litio** **toxicidad** en un reci√©n nacido.

Las entidades aqu√≠ son:

* Regurgitaci√≥n de la v√°lvula tric√∫spide es una enfermedad (`DIS`)
* Carbonato de litio es una sustancia qu√≠mica (`CHEM`)
* Toxicidad tambi√©n es una enfermedad (`DIS`)

Nota que una entidad puede abarcar varios tokens. Y, como en este caso, necesitamos distinguir entre dos entidades consecutivas. Por lo tanto, es com√∫n usar dos clases para cada entidad: una que especifica el primer token de la entidad (a menudo se usa el prefijo `B-`, para **b**eginning, inicio) y otra para la continuaci√≥n de una entidad (`I-`, para **i**nner token, interno). Tambi√©n usamos `O` como clase para representar todos los tokens **o**tros. Este etiquetado de tokens se llama [etiquetado BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (o IOB). Cuando se etiqueta, nuestro t√≠tulo se ver√° as√≠:

Token | Etiqueta
------|---------
Tricuspid | B-DIS
valve | I-DIS
regurgitation | I-DIS
and | O
lithium | B-CHEM
carbonate | I-CHEM
toxicity | B-DIS
in | O
a | O
newborn | O
infant | O
. | O

Dado que necesitamos construir una correspondencia uno a uno entre tokens y clases, podemos entrenar un modelo neuronal **muchos a muchos** como el que se muestra en esta imagen:

![Imagen que muestra patrones comunes de redes neuronales recurrentes.](../../../../../translated_images/es/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> *Imagen tomada de [este art√≠culo](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) de [Andrej Karpathy](http://karpathy.github.io/). Los modelos de clasificaci√≥n de tokens NER corresponden a la arquitectura de red m√°s a la derecha en esta imagen.*

## Entrenamiento de Modelos NER

Dado que un modelo NER es esencialmente un modelo de clasificaci√≥n de tokens, podemos usar RNNs, con las que ya estamos familiarizados, para esta tarea. En este caso, cada bloque de la red recurrente devolver√° el ID del token. El siguiente cuaderno de ejemplo muestra c√≥mo entrenar un LSTM para la clasificaci√≥n de tokens.

## ‚úçÔ∏è Cuadernos de Ejemplo: NER

Contin√∫a tu aprendizaje en el siguiente cuaderno:

* [NER con TensorFlow](NER-TF.ipynb)

## Conclusi√≥n

Un modelo NER es un **modelo de clasificaci√≥n de tokens**, lo que significa que puede usarse para realizar clasificaci√≥n de tokens. Esta es una tarea muy com√∫n en PLN, que ayuda a reconocer entidades espec√≠ficas dentro del texto, incluyendo lugares, nombres, fechas y m√°s.

## üöÄ Desaf√≠o

Completa la tarea vinculada a continuaci√≥n para entrenar un modelo de reconocimiento de entidades nombradas para t√©rminos m√©dicos, y luego pru√©balo en un conjunto de datos diferente.

## [Cuestionario posterior a la clase](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## Revisi√≥n y Autoestudio

Lee el blog [La Efectividad Inesperada de las Redes Neuronales Recurrentes](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) y sigue la secci√≥n de Lecturas Adicionales en ese art√≠culo para profundizar tu conocimiento.

## [Tarea](lab/README.md)

En la tarea de esta lecci√≥n, tendr√°s que entrenar un modelo de reconocimiento de entidades m√©dicas. Puedes comenzar entrenando un modelo LSTM como se describe en esta lecci√≥n y luego avanzar a usar el modelo transformador BERT. Lee [las instrucciones](lab/README.md) para obtener todos los detalles.

---

