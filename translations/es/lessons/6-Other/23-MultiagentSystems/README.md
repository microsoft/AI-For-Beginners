# Sistemas Multi-Agente

Una de las formas posibles de alcanzar la inteligencia es el llamado enfoque **emergente** (o **siner√©tico**), que se basa en el hecho de que el comportamiento combinado de muchos agentes relativamente simples puede resultar en un comportamiento general m√°s complejo (o inteligente) del sistema en su conjunto. Te√≥ricamente, esto se basa en los principios de la [Inteligencia Colectiva](https://en.wikipedia.org/wiki/Collective_intelligence), el [Emergentismo](https://en.wikipedia.org/wiki/Global_brain) y la [Cibern√©tica Evolutiva](https://en.wikipedia.org/wiki/Global_brain), que afirman que los sistemas de nivel superior obtienen alg√∫n tipo de valor a√±adido cuando se combinan adecuadamente a partir de sistemas de nivel inferior (el llamado *principio de transici√≥n de metasistema*).

## [Cuestionario previo a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/123)

La direcci√≥n de los **Sistemas Multi-Agente** ha surgido en IA en la d√©cada de 1990 como respuesta al crecimiento de Internet y los sistemas distribuidos. Uno de los libros de texto cl√°sicos de IA, [Inteligencia Artificial: Un Enfoque Moderno](https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach), se centra en la visi√≥n de la IA cl√°sica desde el punto de vista de los sistemas multi-agente.

Central al enfoque multi-agente es la noci√≥n de **Agente** - una entidad que vive en alg√∫n **entorno**, que puede percibir y actuar sobre √©l. Esta es una definici√≥n muy amplia, y podr√≠a haber muchos tipos y clasificaciones diferentes de agentes:

* Por su capacidad de razonar:
   - Los agentes **reactivos** generalmente tienen un comportamiento simple de tipo solicitud-respuesta.
   - Los agentes **deliberativos** emplean alg√∫n tipo de razonamiento l√≥gico y/o capacidades de planificaci√≥n.
* Por el lugar donde el agente ejecuta su c√≥digo:
   - Los agentes **est√°ticos** trabajan en un nodo de red dedicado.
   - Los agentes **m√≥viles** pueden mover su c√≥digo entre nodos de red.
* Por su comportamiento:
   - Los **agentes pasivos** no tienen objetivos espec√≠ficos. Tales agentes pueden reaccionar a est√≠mulos externos, pero no iniciar√°n acciones por s√≠ mismos.
   - Los **agentes activos** tienen objetivos que persiguen.
   - Los **agentes cognitivos** involucran planificaci√≥n y razonamiento complejos.

Los sistemas multi-agente se utilizan hoy en d√≠a en una serie de aplicaciones:

* En los juegos, muchos personajes no jugadores emplean alg√∫n tipo de IA y pueden considerarse agentes inteligentes.
* En la producci√≥n de video, renderizar escenas 3D complejas que involucran multitudes se realiza t√≠picamente utilizando simulaci√≥n multi-agente.
* En modelado de sistemas, el enfoque multi-agente se utiliza para simular el comportamiento de un modelo complejo. Por ejemplo, se ha utilizado con √©xito el enfoque multi-agente para predecir la propagaci√≥n de la enfermedad COVID-19 en todo el mundo. Un enfoque similar puede usarse para modelar el tr√°fico en la ciudad y ver c√≥mo reacciona a los cambios en las normas de tr√°fico.
* En sistemas de automatizaci√≥n complejos, cada dispositivo puede actuar como un agente independiente, lo que hace que todo el sistema sea menos monol√≠tico y m√°s robusto.

No vamos a dedicar mucho tiempo a profundizar en los sistemas multi-agente, pero consideremos un ejemplo de **Modelado Multi-Agente**.

## NetLogo

[NetLogo](https://ccl.northwestern.edu/netlogo/) es un entorno de modelado multi-agente basado en una versi√≥n modificada del lenguaje de programaci√≥n [Logo](https://en.wikipedia.org/wiki/Logo_(programming_language)). Este lenguaje fue desarrollado para ense√±ar conceptos de programaci√≥n a ni√±os, y permite controlar un agente llamado **tortuga**, que puede moverse, dejando un rastro detr√°s. Esto permite crear figuras geom√©tricas complejas, lo que es una forma muy visual de entender el comportamiento de un agente.

En NetLogo, podemos crear muchas tortugas utilizando el comando `create-turtles`. Luego podemos ordenar a todas las tortugas que realicen algunas acciones (en el ejemplo a continuaci√≥n - avanzar 10 puntos hacia adelante):

```
create-turtles 10
ask turtles [
  forward 10
]
```

Por supuesto, no es interesante cuando todas las tortugas hacen lo mismo, as√≠ que podemos `ask` groups of turtles, eg. those who are in the vicinity of a certain point. We can also create turtles of different *breeds* using `breed [cats cat]` command. Here `cat` es el nombre de una raza, y necesitamos especificar tanto la palabra en singular como en plural, porque diferentes comandos utilizan diferentes formas para mayor claridad.

> ‚úÖ No vamos a entrar en aprender el lenguaje NetLogo en s√≠; puedes visitar el brillante [Diccionario Interactivo para Principiantes de NetLogo](https://ccl.northwestern.edu/netlogo/bind/) si est√°s interesado en aprender m√°s.

Puedes [descargar](https://ccl.northwestern.edu/netlogo/download.shtml) e instalar NetLogo para probarlo.

### Biblioteca de Modelos

Una gran ventaja de NetLogo es que contiene una biblioteca de modelos funcionales que puedes probar. Ve a **Archivo ‚Üí Biblioteca de Modelos**, y tienes muchas categor√≠as de modelos para elegir.

<img alt="Biblioteca de Modelos de NetLogo" src="images/NetLogo-ModelLib.png" width="60%"/>

> Una captura de pantalla de la biblioteca de modelos por Dmitry Soshnikov

Puedes abrir uno de los modelos, por ejemplo **Biolog√≠a ‚Üí Reba√±o**.

### Principios Principales

Despu√©s de abrir el modelo, se te lleva a la pantalla principal de NetLogo. Aqu√≠ hay un modelo de ejemplo que describe la poblaci√≥n de lobos y ovejas, dados recursos finitos (hierba).

![Pantalla Principal de NetLogo](../../../../../translated_images/NetLogo-Main.32653711ec1a01b3cab22ec0b148e64193d0b979b055285bef329d5e3d6958c5.es.png)

> Captura de pantalla por Dmitry Soshnikov

En esta pantalla, puedes ver:

* La secci√≥n de **Interfaz** que contiene:
  - El campo principal, donde viven todos los agentes.
  - Diferentes controles: botones, deslizadores, etc.
  - Gr√°ficos que puedes usar para mostrar par√°metros de la simulaci√≥n.
* La pesta√±a de **C√≥digo** que contiene el editor, donde puedes escribir el programa NetLogo.

En la mayor√≠a de los casos, la interfaz tendr√≠a un bot√≥n de **Configuraci√≥n**, que inicializa el estado de la simulaci√≥n, y un bot√≥n de **Ejecutar** que inicia la ejecuci√≥n. Estos son manejados por controladores correspondientes en el c√≥digo que lucen as√≠:

```
to go [
...
]
```

El mundo de NetLogo consiste en los siguientes objetos:

* **Agentes** (tortugas) que pueden moverse por el campo y hacer algo. Ordenas a los agentes usando `ask turtles [...]` syntax, and the code in brackets is executed by all agents in *turtle mode*.
* **Patches** are square areas of the field, on which agents live. You can refer to all agents on the same patch, or you can change patch colors and some other properties. You can also `ask patches` para hacer algo.
* **Observador** es un agente √∫nico que controla el mundo. Todos los controladores de botones se ejecutan en *modo observador*.

> ‚úÖ La belleza de un entorno multi-agente es que el c√≥digo que se ejecuta en modo tortuga o en modo parche se ejecuta al mismo tiempo por todos los agentes en paralelo. As√≠, al escribir un poco de c√≥digo y programar el comportamiento de un agente individual, puedes crear un comportamiento complejo del sistema de simulaci√≥n en su conjunto.

### Reba√±o

Como ejemplo de comportamiento multi-agente, consideremos **[Reba√±o](https://en.wikipedia.org/wiki/Flocking_(behavior))**. El reba√±o es un patr√≥n complejo que es muy similar a c√≥mo vuelan los bandadas de aves. Al observarlas volar, puedes pensar que siguen alg√∫n tipo de algoritmo colectivo, o que poseen alguna forma de *inteligencia colectiva*. Sin embargo, este comportamiento complejo surge cuando cada agente individual (en este caso, un *p√°jaro*) solo observa a otros agentes a una corta distancia de √©l, y sigue tres reglas simples:

* **Alineaci√≥n** - se dirige hacia la direcci√≥n promedio de los agentes vecinos.
* **Cohesi√≥n** - intenta dirigirse hacia la posici√≥n promedio de los vecinos (*atracci√≥n a largo alcance*).
* **Separaci√≥n** - cuando se acerca demasiado a otros p√°jaros, intenta alejarse (*repulsi√≥n a corto alcance*).

Puedes ejecutar el ejemplo de reba√±o y observar el comportamiento. Tambi√©n puedes ajustar par√°metros, como el *grado de separaci√≥n*, o el *rango de visi√≥n*, que define cu√°n lejos puede ver cada p√°jaro. Ten en cuenta que si reduces el rango de visi√≥n a 0, todos los p√°jaros se vuelven ciegos y el reba√±o se detiene. Si reduces la separaci√≥n a 0, todos los p√°jaros se agrupan en una l√≠nea recta.

> ‚úÖ Cambia a la pesta√±a de **C√≥digo** y observa d√≥nde se implementan las tres reglas del reba√±o (alineaci√≥n, cohesi√≥n y separaci√≥n) en el c√≥digo. Nota c√≥mo nos referimos solo a aquellos agentes que est√°n a la vista.

### Otros Modelos para Ver

Hay algunos modelos m√°s interesantes con los que puedes experimentar:

* **Arte ‚Üí Fuegos Artificiales** muestra c√≥mo un fuego artificial puede considerarse un comportamiento colectivo de flujos individuales de fuego.
* **Ciencias Sociales ‚Üí Tr√°fico B√°sico** y **Ciencias Sociales ‚Üí Tr√°fico en Rejilla** muestran el modelo del tr√°fico de la ciudad en una rejilla 1D y 2D con o sin sem√°foros. Cada coche en la simulaci√≥n sigue las siguientes reglas:
   - Si el espacio frente a √©l est√° vac√≠o - acelera (hasta una cierta velocidad m√°xima).
   - Si ve un obst√°culo frente a √©l - frena (y puedes ajustar cu√°n lejos puede ver un conductor).
* **Ciencias Sociales ‚Üí Fiesta** muestra c√≥mo las personas se agrupan durante una fiesta de c√≥cteles. Puedes encontrar la combinaci√≥n de par√°metros que lleva al aumento m√°s r√°pido de la felicidad del grupo.

Como puedes ver en estos ejemplos, las simulaciones multi-agente pueden ser una forma bastante √∫til de entender el comportamiento de un sistema complejo que consiste en individuos que siguen la misma l√≥gica o l√≥gica similar. Tambi√©n puede utilizarse para controlar agentes virtuales, como [NPCs](https://en.wikipedia.org/wiki/NPC) en videojuegos, o agentes en mundos animados en 3D.

## Agentes Deliberativos

Los agentes descritos anteriormente son muy simples, reaccionando a los cambios en el entorno utilizando alg√∫n tipo de algoritmo. Como tales, son **agentes reactivos**. Sin embargo, a veces los agentes pueden razonar y planificar sus acciones, en cuyo caso se les llama **deliberativos**.

Un ejemplo t√≠pico ser√≠a un agente personal que recibe instrucciones de un humano para reservar un tour de vacaciones. Supongamos que hay muchos agentes que viven en Internet, que pueden ayudarlo. Entonces deber√≠a contactar a otros agentes para ver qu√© vuelos est√°n disponibles, cu√°les son los precios de los hoteles para diferentes fechas y tratar de negociar el mejor precio. Cuando el plan de vacaciones est√© completo y confirmado por el propietario, puede proceder con la reserva.

Para hacer eso, los agentes necesitan **comunicarse**. Para una comunicaci√≥n exitosa, necesitan:

* Algunos **lenguajes est√°ndar para intercambiar conocimiento**, como [Knowledge Interchange Format](https://en.wikipedia.org/wiki/Knowledge_Interchange_Format) (KIF) y [Knowledge Query and Manipulation Language](https://en.wikipedia.org/wiki/Knowledge_Query_and_Manipulation_Language) (KQML). Estos lenguajes est√°n dise√±ados en base a la [teor√≠a del acto de habla](https://en.wikipedia.org/wiki/Speech_act).
* Estos lenguajes tambi√©n deben incluir algunos **protocolos para negociaciones**, basados en diferentes **tipos de subastas**.
* Una **ontolog√≠a com√∫n** para usar, para que se refieran a los mismos conceptos conociendo su sem√°ntica.
* Una forma de **descubrir** qu√© pueden hacer los diferentes agentes, tambi√©n basada en alg√∫n tipo de ontolog√≠a.

Los agentes deliberativos son mucho m√°s complejos que los reactivos, porque no solo reaccionan a los cambios en el entorno, sino que tambi√©n deben ser capaces de *iniciar* acciones. Una de las arquitecturas propuestas para agentes deliberativos es el llamado agente de Creencias-Deseos-Intenciones (BDI):

* **Creencias** forman un conjunto de conocimientos sobre el entorno de un agente. Puede estructurarse como una base de conocimientos o un conjunto de reglas que un agente puede aplicar a una situaci√≥n espec√≠fica en el entorno.
* **Deseos** definen lo que un agente quiere hacer, es decir, sus objetivos. Por ejemplo, el objetivo del agente asistente personal mencionado anteriormente es reservar un tour, y el objetivo de un agente hotelero es maximizar las ganancias.
* **Intenciones** son acciones espec√≠ficas que un agente planea realizar para alcanzar sus objetivos. Las acciones cambian t√≠picamente el entorno y causan comunicaci√≥n con otros agentes.

Hay algunas plataformas disponibles para construir sistemas multi-agente, como [JADE](https://jade.tilab.com/). [Este documento](https://arxiv.org/ftp/arxiv/papers/2007/2007.08961.pdf) contiene una revisi√≥n de plataformas multi-agente, junto con una breve historia de los sistemas multi-agente y sus diferentes escenarios de uso.

## Conclusi√≥n

Los sistemas multi-agente pueden adoptar formas muy diferentes y utilizarse en muchas aplicaciones distintas. 
Todos tienden a centrarse en el comportamiento m√°s simple de un agente individual y lograr un comportamiento m√°s complejo del sistema general debido al **efecto sin√©rgico**.

## üöÄ Desaf√≠o

Lleva esta lecci√≥n al mundo real e intenta conceptualizar un sistema multi-agente que pueda resolver un problema. ¬øQu√©, por ejemplo, necesitar√≠a hacer un sistema multi-agente para optimizar una ruta de autob√∫s escolar? ¬øC√≥mo podr√≠a funcionar en una panader√≠a?

## [Cuestionario posterior a la clase](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/223)

## Revisi√≥n y Autoestudio

Revisa el uso de este tipo de sistema en la industria. Elige un dominio como la fabricaci√≥n o la industria de los videojuegos y descubre c√≥mo los sistemas multi-agente pueden utilizarse para resolver problemas √∫nicos.

## [Tarea de NetLogo](assignment.md)

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en inteligencia artificial. Si bien nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional humana. No somos responsables de malentendidos o malas interpretaciones que surjan del uso de esta traducci√≥n.