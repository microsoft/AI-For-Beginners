# Sinir AÄŸÄ± Ã‡erÃ§eveleri

Zaten Ã¶ÄŸrendiÄŸimiz gibi, sinir aÄŸlarÄ±nÄ± verimli bir ÅŸekilde eÄŸitebilmek iÃ§in iki ÅŸey yapmamÄ±z gerekiyor:

* TensÃ¶rler Ã¼zerinde iÅŸlem yapmak, Ã¶rneÄŸin Ã§arpma, toplama ve sigmoid veya softmax gibi bazÄ± fonksiyonlarÄ± hesaplama
* TÃ¼m ifadelerin gradyanlarÄ±nÄ± hesaplamak, bÃ¶ylece gradyan iniÅŸi optimizasyonu gerÃ§ekleÅŸtirebilmek

## [Ã–n-ders sÄ±navÄ±](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/105)

`numpy` kÃ¼tÃ¼phanesi ilk kÄ±smÄ± yapabilse de, gradyanlarÄ± hesaplamak iÃ§in bir mekanizmaya ihtiyacÄ±mÄ±z var. Ã–nceki bÃ¶lÃ¼mde geliÅŸtirdiÄŸimiz [Ã§erÃ§evemizde](../../../../../lessons/3-NeuralNetworks/04-OwnFramework/OwnFramework.ipynb), `backward` yÃ¶nteminin iÃ§inde tÃ¼m tÃ¼rev fonksiyonlarÄ±nÄ± manuel olarak programlamak zorunda kaldÄ±k. Ä°deal olarak, bir Ã§erÃ§eve, tanÄ±mlayabileceÄŸimiz *herhangi bir ifadenin* gradyanlarÄ±nÄ± hesaplama fÄ±rsatÄ±nÄ± bize vermelidir.

BaÅŸka Ã¶nemli bir ÅŸey de GPU veya diÄŸer Ã¶zel hesaplama birimleri, Ã¶rneÄŸin [TPU](https://en.wikipedia.org/wiki/Tensor_Processing_Unit) Ã¼zerinde hesaplamalar yapabilmektir. Derin sinir aÄŸÄ± eÄŸitimi *Ã§ok fazla* hesaplama gerektirir ve bu hesaplamalarÄ± GPU'larda paralelleÅŸtirebilmek Ã§ok Ã¶nemlidir.

> âœ… 'ParalelleÅŸtirme' terimi, hesaplamalarÄ± birden fazla cihaz arasÄ±nda daÄŸÄ±tmak anlamÄ±na gelir.

Åu anda, en popÃ¼ler iki sinir aÄŸÄ± Ã§erÃ§evesi: [TensorFlow](http://TensorFlow.org) ve [PyTorch](https://pytorch.org/). Her ikisi de CPU ve GPU Ã¼zerinde tensÃ¶rlerle Ã§alÄ±ÅŸmak iÃ§in dÃ¼ÅŸÃ¼k seviyeli bir API saÄŸlar. DÃ¼ÅŸÃ¼k seviyeli API'nin Ã¼stÃ¼nde, sÄ±rasÄ±yla [Keras](https://keras.io/) ve [PyTorch Lightning](https://pytorchlightning.ai/) adÄ±nda daha yÃ¼ksek seviyeli API'ler de bulunmaktadÄ±r.

DÃ¼ÅŸÃ¼k Seviye API | [TensorFlow](http://TensorFlow.org) | [PyTorch](https://pytorch.org/)
-----------------|-------------------------------------|--------------------------------
YÃ¼ksek Seviye API | [Keras](https://keras.io/) | [PyTorch Lightning](https://pytorchlightning.ai/)

**DÃ¼ÅŸÃ¼k seviye API'ler**, her iki Ã§erÃ§evede de **hesaplama grafikleri** adÄ± verilen yapÄ±lar oluÅŸturmanÄ±za olanak tanÄ±r. Bu grafik, belirli giriÅŸ parametreleriyle Ã§Ä±ktÄ±yÄ± (genellikle kayÄ±p fonksiyonu) nasÄ±l hesaplayacaÄŸÄ±nÄ±zÄ± tanÄ±mlar ve mevcutsa GPU Ã¼zerinde hesaplama iÃ§in itilebilir. Bu hesaplama grafiÄŸini farklÄ±laÅŸtÄ±rmak ve gradyanlarÄ± hesaplamak iÃ§in iÅŸlevler vardÄ±r; bu gradyanlar daha sonra model parametrelerini optimize etmek iÃ§in kullanÄ±labilir.

**YÃ¼ksek seviye API'ler**, sinir aÄŸlarÄ±nÄ± **katmanlar dizisi** olarak dÃ¼ÅŸÃ¼nÃ¼r ve Ã§oÄŸu sinir aÄŸÄ±nÄ± inÅŸa etmeyi Ã§ok daha kolay hale getirir. Modeli eÄŸitmek genellikle verileri hazÄ±rlamayÄ± ve ardÄ±ndan iÅŸi yapmak iÃ§in `fit` fonksiyonunu Ã§aÄŸÄ±rmayÄ± gerektirir.

YÃ¼ksek seviye API, tipik sinir aÄŸlarÄ±nÄ± Ã§ok hÄ±zlÄ± bir ÅŸekilde inÅŸa etmenize olanak tanÄ±r; birÃ§ok detay hakkÄ±nda endiÅŸelenmenize gerek kalmaz. AynÄ± zamanda, dÃ¼ÅŸÃ¼k seviye API, eÄŸitim sÃ¼reci Ã¼zerinde Ã§ok daha fazla kontrol saÄŸlar, bu nedenle yeni sinir aÄŸÄ± mimarileriyle Ã§alÄ±ÅŸÄ±rken araÅŸtÄ±rmalarda sÄ±klÄ±kla kullanÄ±lÄ±r.

Her iki API'yi bir arada kullanabileceÄŸinizi de anlamak Ã¶nemlidir; Ã¶rneÄŸin, dÃ¼ÅŸÃ¼k seviye API kullanarak kendi aÄŸ katmanÄ± mimarinizi geliÅŸtirebilir ve ardÄ±ndan yÃ¼ksek seviye API ile inÅŸa edilen ve eÄŸitilen daha bÃ¼yÃ¼k bir aÄŸÄ±n iÃ§inde kullanabilirsiniz. Ya da yÃ¼ksek seviye API'yi katmanlar dizisi olarak kullanarak bir aÄŸ tanÄ±mlayabilir ve ardÄ±ndan optimizasyon yapmak iÃ§in kendi dÃ¼ÅŸÃ¼k seviye eÄŸitim dÃ¶ngÃ¼nÃ¼zÃ¼ kullanabilirsiniz. Her iki API de aynÄ± temel kavramlarÄ± kullanÄ±r ve birlikte iyi Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

## Ã–ÄŸrenme

Bu kursta, iÃ§eriÄŸin Ã§oÄŸunu hem PyTorch hem de TensorFlow iÃ§in sunuyoruz. Tercih ettiÄŸiniz Ã§erÃ§eveyi seÃ§ebilir ve yalnÄ±zca ilgili not defterlerini inceleyebilirsiniz. Hangi Ã§erÃ§eveyi seÃ§eceÄŸinizden emin deÄŸilseniz, **PyTorch ve TensorFlow** ile ilgili internette bazÄ± tartÄ±ÅŸmalarÄ± okuyabilirsiniz. Daha iyi bir anlayÄ±ÅŸ elde etmek iÃ§in her iki Ã§erÃ§eveye de gÃ¶z atabilirsiniz.

MÃ¼mkÃ¼n olduÄŸunda, basitlik iÃ§in YÃ¼ksek Seviye API'leri kullanacaÄŸÄ±z. Ancak, sinir aÄŸlarÄ±nÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± en baÅŸtan anlamanÄ±n Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yoruz, bu nedenle baÅŸlangÄ±Ã§ta dÃ¼ÅŸÃ¼k seviye API ve tensÃ¶rlerle Ã§alÄ±ÅŸmaya baÅŸlÄ±yoruz. Ancak, hÄ±zlÄ± bir ÅŸekilde ilerlemek istiyorsanÄ±z ve bu detaylarÄ± Ã¶ÄŸrenmek iÃ§in Ã§ok fazla zaman harcamak istemiyorsanÄ±z, bunlarÄ± atlayabilir ve doÄŸrudan yÃ¼ksek seviye API not defterlerine geÃ§ebilirsiniz.

## âœï¸ AlÄ±ÅŸtÄ±rmalar: Ã‡erÃ§eveler

AÅŸaÄŸÄ±daki not defterlerinde Ã¶ÄŸreniminize devam edin:

DÃ¼ÅŸÃ¼k Seviye API | [TensorFlow+Keras Not Defteri](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKerasTF.ipynb) | [PyTorch](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroPyTorch.ipynb)
-----------------|-------------------------------------|--------------------------------
YÃ¼ksek Seviye API | [Keras](../../../../../lessons/3-NeuralNetworks/05-Frameworks/IntroKeras.ipynb) | *PyTorch Lightning*

Ã‡erÃ§eveleri Ã¶ÄŸrendikten sonra, aÅŸÄ±rÄ± uyum kavramÄ±nÄ± gÃ¶zden geÃ§irelim.

# AÅŸÄ±rÄ± Uyum

AÅŸÄ±rÄ± uyum, makine Ã¶ÄŸreniminde son derece Ã¶nemli bir kavramdÄ±r ve doÄŸru bir ÅŸekilde anlamak Ã§ok Ã¶nemlidir!

AÅŸaÄŸÄ±daki 5 noktayÄ± (aÅŸaÄŸÄ±daki grafiklerde `x` ile temsil edilmiÅŸtir) yaklaÅŸÄ±k olarak Ã§Ã¶zme sorununu dÃ¼ÅŸÃ¼nÃ¼n:

![linear](../../../../../translated_images/overfit1.f24b71c6f652e59e6bed7245ffbeaecc3ba320e16e2221f6832b432052c4da43.tr.jpg) | ![overfit](../../../../../translated_images/overfit2.131f5800ae10ca5e41d12a411f5f705d9ee38b1b10916f284b787028dd55cc1c.tr.jpg)
-------------------------|--------------------------
**DoÄŸrusal model, 2 parametre** | **DoÄŸrusal olmayan model, 7 parametre**
EÄŸitim hatasÄ± = 5.3 | EÄŸitim hatasÄ± = 0
DoÄŸrulama hatasÄ± = 5.1 | DoÄŸrulama hatasÄ± = 20

* Solda, iyi bir doÄŸru Ã§izgi yaklaÅŸÄ±k olarak gÃ¶rÃ¼yoruz. Parametre sayÄ±sÄ± uygun olduÄŸundan, model nokta daÄŸÄ±lÄ±mÄ±nÄ±n arkasÄ±ndaki fikri doÄŸru anlÄ±yor.
* SaÄŸda, model Ã§ok gÃ¼Ã§lÃ¼. Sadece 5 noktamÄ±z olduÄŸu iÃ§in ve modelin 7 parametresi olduÄŸu iÃ§in, tÃ¼m noktalarÄ±n Ã¼zerinden geÃ§ecek ÅŸekilde ayarlanabilir, bu da eÄŸitim hatasÄ±nÄ±n 0 olmasÄ±na neden olur. Ancak, bu modelin verilerin arkasÄ±ndaki doÄŸru deseni anlamasÄ±nÄ± engeller, bu nedenle doÄŸrulama hatasÄ± Ã§ok yÃ¼ksektir.

Modelin zenginliÄŸi (parametre sayÄ±sÄ±) ile eÄŸitim Ã¶rneklerinin sayÄ±sÄ± arasÄ±nda doÄŸru bir denge kurmak Ã§ok Ã¶nemlidir.

## AÅŸÄ±rÄ± Uyumun Nedenleri

  * Yeterince eÄŸitim verisi olmamasÄ±
  * Ã‡ok gÃ¼Ã§lÃ¼ model
  * GiriÅŸ verilerinde fazla gÃ¼rÃ¼ltÃ¼

## AÅŸÄ±rÄ± Uyumun Tespit Edilmesi

YukarÄ±daki grafikten gÃ¶rebileceÄŸiniz gibi, aÅŸÄ±rÄ± uyum, Ã§ok dÃ¼ÅŸÃ¼k bir eÄŸitim hatasÄ± ve yÃ¼ksek bir doÄŸrulama hatasÄ± ile tespit edilebilir. Genellikle eÄŸitim sÄ±rasÄ±nda hem eÄŸitim hem de doÄŸrulama hatalarÄ±nÄ±n azalmaya baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼rÃ¼z, ve sonra bir noktada doÄŸrulama hatasÄ± azalmayÄ± durdurup artmaya baÅŸlayabilir. Bu, aÅŸÄ±rÄ± uyumun bir iÅŸareti olacak ve muhtemelen bu noktada eÄŸitimi durdurmamÄ±z gerektiÄŸini (veya en azÄ±ndan modelin bir anlÄ±k gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ almamÄ±z gerektiÄŸini) gÃ¶sterir.

![overfitting](../../../../../translated_images/Overfitting.408ad91cd90b4371d0a81f4287e1409c359751adeb1ae450332af50e84f08c3e.tr.png)

## AÅŸÄ±rÄ± Uyumun Ã–nlenmesi

AÅŸÄ±rÄ± uyumun meydana geldiÄŸini gÃ¶rÃ¼yorsanÄ±z, aÅŸaÄŸÄ±dakilerden birini yapabilirsiniz:

 * EÄŸitim verisi miktarÄ±nÄ± artÄ±rÄ±n
 * Modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltÄ±n
 * Daha sonra ele alacaÄŸÄ±mÄ±z [dÃ¼zenleme tekniklerinden](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md) birini kullanÄ±n, Ã¶rneÄŸin [Dropout](../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout).

## AÅŸÄ±rÄ± Uyum ve Bias-Variance Ticaret Dengesi

AÅŸÄ±rÄ± uyum aslÄ±nda istatistikte daha genel bir problem olan [Bias-Variance Tradeoff](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) durumudur. Modelimizdeki hata kaynaklarÄ±nÄ± dikkate aldÄ±ÄŸÄ±mÄ±zda, iki tÃ¼r hata gÃ¶rebiliriz:

* **Bias hatalarÄ±**, algoritmamÄ±zÄ±n eÄŸitim verileri arasÄ±ndaki iliÅŸkiyi doÄŸru bir ÅŸekilde yakalayamamasÄ±ndan kaynaklanÄ±r. Bu, modelimizin yeterince gÃ¼Ã§lÃ¼ olmamasÄ±ndan kaynaklanabilir (**aÅŸÄ±rÄ± uyum**).
* **Variance hatalarÄ±**, modelin gÃ¼rÃ¼ltÃ¼yÃ¼ verilerdeki anlamlÄ± iliÅŸki yerine yaklaÅŸÄ±k olarak deÄŸerlendirmesinden kaynaklanÄ±r (**aÅŸÄ±rÄ± uyum**).

EÄŸitim sÄ±rasÄ±nda, bias hatasÄ± azalÄ±r (modelimiz verileri yaklaÅŸÄ±k olarak Ã¶ÄŸrenirken) ve variance hatasÄ± artar. AÅŸÄ±rÄ± uyumu Ã¶nlemek iÃ§in eÄŸitimi durdurmak Ã¶nemlidir - ya manuel olarak (aÅŸÄ±rÄ± uyumu tespit ettiÄŸimizde) ya da otomatik olarak (dÃ¼zenleme yaparak).

## SonuÃ§

Bu derste, en popÃ¼ler iki AI Ã§erÃ§evesi olan TensorFlow ve PyTorch iÃ§in Ã§eÅŸitli API'ler arasÄ±ndaki farklarÄ± Ã¶ÄŸrendiniz. AyrÄ±ca, Ã§ok Ã¶nemli bir konu olan aÅŸÄ±rÄ± uyumu da Ã¶ÄŸrendiniz.

## ğŸš€ Zorluk

EÅŸlik eden not defterlerinde, en altta 'gÃ¶revler' bulacaksÄ±nÄ±z; not defterlerini inceleyin ve gÃ¶revleri tamamlayÄ±n.

## [Ders sonrasÄ± sÄ±nav](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/205)

## GÃ¶zden GeÃ§irme & Kendi Kendine Ã‡alÄ±ÅŸma

AÅŸaÄŸÄ±daki konular hakkÄ±nda biraz araÅŸtÄ±rma yapÄ±n:

- TensorFlow
- PyTorch
- AÅŸÄ±rÄ± uyum

Kendinize ÅŸu sorularÄ± sorun:

- TensorFlow ve PyTorch arasÄ±ndaki fark nedir?
- AÅŸÄ±rÄ± uyum ve yetersiz uyum arasÄ±ndaki fark nedir?

## [Ã–dev](lab/README.md)

Bu laboratuvar Ã§alÄ±ÅŸmasÄ±nda, PyTorch veya TensorFlow kullanarak tek ve Ã§ok katmanlÄ± tam baÄŸlÄ± aÄŸlar ile iki sÄ±nÄ±flandÄ±rma problemini Ã§Ã¶zmeniz isteniyor.

* [Talimatlar](lab/README.md)
* [Not Defteri](../../../../../lessons/3-NeuralNetworks/05-Frameworks/lab/LabFrameworks.ipynb)

**AÃ§Ä±klama**:  
Bu belge, makine tabanlÄ± AI Ã§eviri hizmetleri kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluÄŸa Ã¶zen gÃ¶stersek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belge, ana dilinde, otoriter kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilmektedir. Bu Ã§evirinin kullanÄ±mÄ± sonucunda ortaya Ã§Ä±kabilecek yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.