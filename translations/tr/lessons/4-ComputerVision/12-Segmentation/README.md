<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d7f8a25ff13cfe9f4cd671cc23351fad",
  "translation_date": "2025-08-26T07:25:49+00:00",
  "source_file": "lessons/4-ComputerVision/12-Segmentation/README.md",
  "language_code": "tr"
}
-->
# Segmentasyon

Daha Ã¶nce, nesneleri *bounding box* tahminiyle gÃ¶rÃ¼ntÃ¼de bulmamÄ±zÄ± saÄŸlayan Nesne Tespiti hakkÄ±nda bilgi edinmiÅŸtik. Ancak, bazÄ± gÃ¶revlerde yalnÄ±zca bounding box'lara deÄŸil, daha hassas nesne konumlandÄ±rmasÄ±na da ihtiyaÃ§ duyarÄ±z. Bu gÃ¶reve **segmentasyon** denir.

## [Ders Ã–ncesi Test](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/112)

Segmentasyon, **piksel sÄ±nÄ±flandÄ±rmasÄ±** olarak gÃ¶rÃ¼lebilir; burada gÃ¶rÃ¼ntÃ¼nÃ¼n **her bir** pikseli iÃ§in sÄ±nÄ±fÄ±nÄ± tahmin etmemiz gerekir (*arka plan* da sÄ±nÄ±flardan biri olarak kabul edilir). Ä°ki ana segmentasyon algoritmasÄ± vardÄ±r:

* **Semantik segmentasyon**, yalnÄ±zca piksel sÄ±nÄ±fÄ±nÄ± belirtir ve aynÄ± sÄ±nÄ±fa ait farklÄ± nesneler arasÄ±nda ayrÄ±m yapmaz.
* **Ã–rnek segmentasyonu**, sÄ±nÄ±flarÄ± farklÄ± Ã¶rneklere ayÄ±rÄ±r.

Ã–rneÄŸin, Ã¶rnek segmentasyon iÃ§in bu koyunlar farklÄ± nesneler olarak kabul edilir, ancak semantik segmentasyon iÃ§in tÃ¼m koyunlar tek bir sÄ±nÄ±f olarak temsil edilir.

<img src="images/instance_vs_semantic.jpeg" width="50%">

> GÃ¶rsel [bu blog yazÄ±sÄ±ndan](https://nirmalamurali.medium.com/image-classification-vs-semantic-segmentation-vs-instance-segmentation-625c33a08d50) alÄ±nmÄ±ÅŸtÄ±r.

Segmentasyon iÃ§in farklÄ± sinir aÄŸÄ± mimarileri vardÄ±r, ancak hepsi aynÄ± yapÄ±ya sahiptir. Bir bakÄ±ma, daha Ã¶nce Ã¶ÄŸrendiÄŸiniz otomatik kodlayÄ±cÄ±ya (autoencoder) benzer, ancak burada amacÄ±mÄ±z orijinal gÃ¶rÃ¼ntÃ¼yÃ¼ yeniden oluÅŸturmak yerine bir **maske**yi yeniden oluÅŸturmaktÄ±r. Bu nedenle, bir segmentasyon aÄŸÄ± ÅŸu parÃ§alardan oluÅŸur:

* **KodlayÄ±cÄ± (Encoder)** giriÅŸ gÃ¶rÃ¼ntÃ¼sÃ¼nden Ã¶zellikler Ã§Ä±karÄ±r.
* **Kod Ã‡Ã¶zÃ¼cÃ¼ (Decoder)** bu Ã¶zellikleri, sÄ±nÄ±f sayÄ±sÄ±na karÅŸÄ±lÄ±k gelen kanal sayÄ±sÄ± ve aynÄ± boyutta bir **maske gÃ¶rÃ¼ntÃ¼sÃ¼ne** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

<img src="images/segm.png" width="80%">

> GÃ¶rsel [bu yayÄ±ndan](https://arxiv.org/pdf/2001.05566.pdf) alÄ±nmÄ±ÅŸtÄ±r.

Segmentasyon iÃ§in kullanÄ±lan kayÄ±p fonksiyonundan Ã¶zellikle bahsetmeliyiz. Klasik otomatik kodlayÄ±cÄ±lar kullanÄ±ldÄ±ÄŸÄ±nda, iki gÃ¶rÃ¼ntÃ¼ arasÄ±ndaki benzerliÄŸi Ã¶lÃ§memiz gerekir ve bunu yapmak iÃ§in ortalama kare hatasÄ± (MSE) kullanÄ±labilir. Segmentasyonda, hedef maske gÃ¶rÃ¼ntÃ¼sÃ¼ndeki her piksel sÄ±nÄ±f numarasÄ±nÄ± (Ã¼Ã§Ã¼ncÃ¼ boyut boyunca tekil kodlama ile) temsil eder, bu nedenle sÄ±nÄ±flandÄ±rma iÃ§in Ã¶zel kayÄ±p fonksiyonlarÄ± kullanmamÄ±z gerekir - tÃ¼m pikseller Ã¼zerinde ortalamasÄ± alÄ±nan Ã§apraz entropi kaybÄ±. EÄŸer maske ikili ise - **ikili Ã§apraz entropi kaybÄ±** (BCE) kullanÄ±lÄ±r.

> âœ… Tekil kodlama, bir sÄ±nÄ±f etiketini, sÄ±nÄ±f sayÄ±sÄ±na eÅŸit uzunlukta bir vektÃ¶re kodlamanÄ±n bir yoludur. Bu teknik hakkÄ±nda daha fazla bilgi iÃ§in [bu makaleye](https://datagy.io/sklearn-one-hot-encode/) gÃ¶z atÄ±n.

## TÄ±bbi GÃ¶rÃ¼ntÃ¼leme iÃ§in Segmentasyon

Bu derste, tÄ±bbi gÃ¶rÃ¼ntÃ¼lerde insan nevÃ¼slerini (benler olarak da bilinir) tanÄ±mak iÃ§in aÄŸÄ± eÄŸiterek segmentasyonu uygulamada gÃ¶receÄŸiz. GÃ¶rÃ¼ntÃ¼ kaynaÄŸÄ± olarak <a href="https://www.fc.up.pt/addi/ph2%20database.html">PH<sup>2</sup> VeritabanÄ±</a>'nÄ± kullanacaÄŸÄ±z. Bu veri seti, Ã¼Ã§ sÄ±nÄ±fa ait 200 gÃ¶rÃ¼ntÃ¼ iÃ§erir: tipik nevÃ¼s, atipik nevÃ¼s ve melanom. TÃ¼m gÃ¶rÃ¼ntÃ¼ler ayrÄ±ca nevÃ¼sÃ¼ Ã§evreleyen bir **maske** iÃ§erir.

> âœ… Bu teknik Ã¶zellikle bu tÃ¼r tÄ±bbi gÃ¶rÃ¼ntÃ¼leme iÃ§in uygundur, ancak baÅŸka hangi gerÃ§ek dÃ¼nya uygulamalarÄ±nÄ± hayal edebilirsiniz?

<img alt="navi" src="images/navi.png"/>

> GÃ¶rsel PH<sup>2</sup> VeritabanÄ±ndan alÄ±nmÄ±ÅŸtÄ±r.

Modelimizi, herhangi bir nevÃ¼sÃ¼ arka plandan ayÄ±rmak iÃ§in eÄŸiteceÄŸiz.

## âœï¸ AlÄ±ÅŸtÄ±rmalar: Semantik Segmentasyon

AÅŸaÄŸÄ±daki defterleri aÃ§arak farklÄ± semantik segmentasyon mimarileri hakkÄ±nda daha fazla bilgi edinin, bunlarla Ã§alÄ±ÅŸmayÄ± pratik yapÄ±n ve bunlarÄ± uygulamada gÃ¶rÃ¼n.

* [Semantik Segmentasyon Pytorch](../../../../../lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb)
* [Semantik Segmentasyon TensorFlow](../../../../../lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb)

## [Ders SonrasÄ± Test](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/212)

## SonuÃ§

Segmentasyon, gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ± iÃ§in Ã§ok gÃ¼Ã§lÃ¼ bir tekniktir ve bounding box'lardan piksel dÃ¼zeyinde sÄ±nÄ±flandÄ±rmaya geÃ§iÅŸ yapar. Bu teknik, tÄ±bbi gÃ¶rÃ¼ntÃ¼leme gibi birÃ§ok uygulamada kullanÄ±lÄ±r.

## ğŸš€ Zorluk

VÃ¼cut segmentasyonu, insan gÃ¶rÃ¼ntÃ¼leriyle yapabileceÄŸimiz yaygÄ±n gÃ¶revlerden sadece biridir. DiÄŸer Ã¶nemli gÃ¶revler arasÄ±nda **iskelet tespiti** ve **poz tespiti** bulunur. [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) kÃ¼tÃ¼phanesini deneyerek poz tespitinin nasÄ±l kullanÄ±labileceÄŸini gÃ¶rÃ¼n.

## Ä°nceleme ve Kendi Kendine Ã‡alÄ±ÅŸma

Bu [Vikipedi makalesi](https://wikipedia.org/wiki/Image_segmentation), bu tekniÄŸin Ã§eÅŸitli uygulamalarÄ± hakkÄ±nda iyi bir genel bakÄ±ÅŸ sunar. Bu alandaki Ã–rnek segmentasyonu ve Panoptik segmentasyon alt alanlarÄ± hakkÄ±nda kendi baÅŸÄ±nÄ±za daha fazla bilgi edinin.

## [Ã–dev](lab/README.md)

Bu laboratuvarda, Kaggle'dan [Segmentation Full Body MADS Dataset](https://www.kaggle.com/datasets/tapakah68/segmentation-full-body-mads-dataset) kullanarak **insan vÃ¼cudu segmentasyonu** yapmayÄ± deneyin.

**Feragatname**:  
Bu belge, [Co-op Translator](https://github.com/Azure/co-op-translator) adlÄ± yapay zeka Ã§eviri hizmeti kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belgenin kendi dilindeki hali, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.