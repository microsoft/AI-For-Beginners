# Ãœretici Ã‡ekiÅŸmeli AÄŸlar

Ã–nceki bÃ¶lÃ¼mde **Ã¼retici modelleri** Ã¶ÄŸrendik: eÄŸitim veri setindeki gÃ¶rÃ¼ntÃ¼lere benzer yeni gÃ¶rÃ¼ntÃ¼ler Ã¼retebilen modeller. VAE, Ã¼retici model iÃ§in iyi bir Ã¶rnekti.

## [Ders Ã–ncesi Test](https://ff-quizzes.netlify.app/en/ai/quiz/19)

Ancak, VAE ile makul bir Ã§Ã¶zÃ¼nÃ¼rlÃ¼kte anlamlÄ± bir ÅŸey, Ã¶rneÄŸin bir tablo Ã¼retmeye Ã§alÄ±ÅŸÄ±rsak, eÄŸitimin iyi bir ÅŸekilde yakÄ±nsamadÄ±ÄŸÄ±nÄ± gÃ¶receÄŸiz. Bu kullanÄ±m durumu iÃ§in, Ã¼retici modellere Ã¶zel olarak tasarlanmÄ±ÅŸ baÅŸka bir mimariyi Ã¶ÄŸrenmeliyiz - **Ãœretici Ã‡ekiÅŸmeli AÄŸlar**, veya GAN'lar.

GAN'Ä±n temel fikri, birbirine karÅŸÄ± eÄŸitilecek iki sinir aÄŸÄ±na sahip olmaktÄ±r:

<img src="../../../../../translated_images/tr/gan_architecture.8f3a5ab62b8d5d69.webp" width="70%"/>

> GÃ¶rsel: [Dmitry Soshnikov](http://soshnikov.com)

> âœ… KÃ¼Ã§Ã¼k bir sÃ¶zlÃ¼k:
> * **Generator** (Ãœretici), rastgele bir vektÃ¶r alÄ±r ve sonuÃ§ olarak bir gÃ¶rÃ¼ntÃ¼ Ã¼retir.
> * **Discriminator** (AyÄ±rt Edici), bir gÃ¶rÃ¼ntÃ¼ alÄ±r ve bunun gerÃ§ek bir gÃ¶rÃ¼ntÃ¼ (eÄŸitim veri setinden) mi yoksa Ã¼retici tarafÄ±ndan Ã¼retilmiÅŸ bir gÃ¶rÃ¼ntÃ¼ mÃ¼ olduÄŸunu sÃ¶ylemelidir. Temelde bir gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rÄ±cÄ±dÄ±r.

### AyÄ±rt Edici

AyÄ±rt edicinin mimarisi, sÄ±radan bir gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma aÄŸÄ±ndan farklÄ± deÄŸildir. En basit durumda tamamen baÄŸlÄ± bir sÄ±nÄ±flandÄ±rÄ±cÄ± olabilir, ancak bÃ¼yÃ¼k olasÄ±lÄ±kla bir [konvolÃ¼syonel aÄŸ](../07-ConvNets/README.md) olacaktÄ±r.

> âœ… KonvolÃ¼syonel aÄŸlara dayalÄ± bir GAN, [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) olarak adlandÄ±rÄ±lÄ±r.

Bir CNN ayÄ±rt edici ÅŸu katmanlardan oluÅŸur: birkaÃ§ konvolÃ¼syon+havuzlama (azalan uzaysal boyutlarla) ve bir veya daha fazla tamamen baÄŸlÄ± katman, "Ã¶zellik vektÃ¶rÃ¼" elde etmek iÃ§in son ikili sÄ±nÄ±flandÄ±rÄ±cÄ±.

> âœ… 'Havuzlama' bu baÄŸlamda gÃ¶rÃ¼ntÃ¼nÃ¼n boyutunu kÃ¼Ã§Ã¼ltme tekniÄŸidir. "Havuzlama katmanlarÄ±, bir katmandaki nÃ¶ron kÃ¼melerinin Ã§Ä±ktÄ±sÄ±nÄ± bir sonraki katmandaki tek bir nÃ¶ronda birleÅŸtirerek verilerin boyutlarÄ±nÄ± azaltÄ±r." - [kaynak](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Ãœretici

Ãœretici biraz daha karmaÅŸÄ±ktÄ±r. Bunu ters bir ayÄ±rt edici olarak dÃ¼ÅŸÃ¼nebilirsiniz. Bir Ã¶zellik vektÃ¶rÃ¼nÃ¼n yerine bir gizli vektÃ¶rden baÅŸlayarak, gerekli boyut/ÅŸekle dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in tamamen baÄŸlÄ± bir katmana sahiptir, ardÄ±ndan dekonvolÃ¼syon+Ã¶lÃ§ek bÃ¼yÃ¼tme iÅŸlemleri gelir. Bu, [otoenkoder](../09-Autoencoders/README.md)'in *kod Ã§Ã¶zÃ¼cÃ¼* kÄ±smÄ±na benzer.

> âœ… KonvolÃ¼syon katmanÄ± bir gÃ¶rÃ¼ntÃ¼ Ã¼zerinde doÄŸrusal bir filtre olarak uygulandÄ±ÄŸÄ±ndan, dekonvolÃ¼syon temelde konvolÃ¼syona benzer ve aynÄ± katman mantÄ±ÄŸÄ± kullanÄ±larak uygulanabilir.

<img src="../../../../../translated_images/tr/gan_arch_detail.46b95fd366f8e543.webp" width="70%"/>

> GÃ¶rsel: [Dmitry Soshnikov](http://soshnikov.com)

### GAN'Ä± EÄŸitmek

GAN'lar **Ã§ekiÅŸmeli** olarak adlandÄ±rÄ±lÄ±r Ã§Ã¼nkÃ¼ Ã¼retici ve ayÄ±rt edici arasÄ±nda sÃ¼rekli bir rekabet vardÄ±r. Bu rekabet sÄ±rasÄ±nda hem Ã¼retici hem de ayÄ±rt edici geliÅŸir, bÃ¶ylece aÄŸ daha iyi ve daha iyi gÃ¶rÃ¼ntÃ¼ler Ã¼retmeyi Ã¶ÄŸrenir.

EÄŸitim iki aÅŸamada gerÃ§ekleÅŸir:

* **AyÄ±rt ediciyi eÄŸitmek**. Bu gÃ¶rev oldukÃ§a basittir: Ã¼retici tarafÄ±ndan bir gÃ¶rÃ¼ntÃ¼ grubu oluÅŸtururuz, bunlarÄ± sahte gÃ¶rÃ¼ntÃ¼ anlamÄ±na gelen 0 ile etiketleriz ve giriÅŸ veri setinden bir grup gÃ¶rÃ¼ntÃ¼ alÄ±rÄ±z (etiket 1, gerÃ§ek gÃ¶rÃ¼ntÃ¼). Bir *ayÄ±rt edici kaybÄ±* elde ederiz ve geri yayÄ±lÄ±m yaparÄ±z.
* **Ãœreticiyi eÄŸitmek**. Bu biraz daha karmaÅŸÄ±ktÄ±r Ã§Ã¼nkÃ¼ Ã¼retici iÃ§in beklenen Ã§Ä±ktÄ±yÄ± doÄŸrudan bilmiyoruz. Ãœretici ve ayÄ±rt ediciden oluÅŸan tÃ¼m GAN aÄŸÄ±nÄ± alÄ±rÄ±z, rastgele vektÃ¶rlerle besleriz ve sonucun 1 olmasÄ±nÄ± bekleriz (gerÃ§ek gÃ¶rÃ¼ntÃ¼lere karÅŸÄ±lÄ±k gelir). AyÄ±rt edicinin parametrelerini dondururuz (bu adÄ±mda eÄŸitilmesini istemiyoruz) ve geri yayÄ±lÄ±m yaparÄ±z.

Bu sÃ¼reÃ§ sÄ±rasÄ±nda hem Ã¼retici hem de ayÄ±rt edici kayÄ±plarÄ± Ã¶nemli Ã¶lÃ§Ã¼de dÃ¼ÅŸmez. Ä°deal durumda, her iki aÄŸÄ±n performansÄ±nÄ± geliÅŸtirdiÄŸini gÃ¶steren bir salÄ±nÄ±m yapmalÄ±dÄ±rlar.

## âœï¸ AlÄ±ÅŸtÄ±rmalar: GAN'lar

* [TensorFlow/Keras ile GAN Not Defteri](GANTF.ipynb)
* [PyTorch ile GAN Not Defteri](GANPyTorch.ipynb)

### GAN EÄŸitimindeki Sorunlar

GAN'larÄ±n eÄŸitilmesi Ã¶zellikle zor olduÄŸu bilinir. Ä°ÅŸte birkaÃ§ sorun:

* **Mod Ã‡Ã¶kmesi**. Bu terimle, Ã¼reticinin ayÄ±rt ediciyi kandÄ±ran tek bir baÅŸarÄ±lÄ± gÃ¶rÃ¼ntÃ¼ Ã¼retmeyi Ã¶ÄŸrenmesi ve farklÄ± gÃ¶rÃ¼ntÃ¼ler Ã§eÅŸitliliÄŸi Ã¼retmemesi kastedilir.
* **Hiperparametrelere duyarlÄ±lÄ±k**. Ã‡oÄŸu zaman bir GAN'Ä±n hiÃ§ yakÄ±nsamadÄ±ÄŸÄ±nÄ± ve ardÄ±ndan Ã¶ÄŸrenme oranÄ±ndaki ani bir dÃ¼ÅŸÃ¼ÅŸle yakÄ±nsamaya baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶rebilirsiniz.
* Ãœretici ve ayÄ±rt edici arasÄ±nda **dengeyi korumak**. Ã‡oÄŸu durumda ayÄ±rt edici kaybÄ± nispeten hÄ±zlÄ± bir ÅŸekilde sÄ±fÄ±ra dÃ¼ÅŸebilir, bu da Ã¼reticinin daha fazla eÄŸitim yapamamasÄ±na neden olur. Bunu aÅŸmak iÃ§in Ã¼retici ve ayÄ±rt edici iÃ§in farklÄ± Ã¶ÄŸrenme oranlarÄ± ayarlamayÄ± veya kayÄ±p zaten Ã§ok dÃ¼ÅŸÃ¼kse ayÄ±rt edici eÄŸitimi atlamayÄ± deneyebiliriz.
* **YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k** iÃ§in eÄŸitim. Otoenkoderlerde olduÄŸu gibi aynÄ± sorunu yansÄ±tan bu sorun, konvolÃ¼syonel aÄŸÄ±n Ã§ok fazla katmanÄ±nÄ± yeniden oluÅŸturmanÄ±n artefaktlara yol aÃ§masÄ± nedeniyle tetiklenir. Bu sorun genellikle **aÅŸamalÄ± bÃ¼yÃ¼me** ile Ã§Ã¶zÃ¼lÃ¼r; Ã¶nce birkaÃ§ katman dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rÃ¼ntÃ¼lerde eÄŸitilir, ardÄ±ndan katmanlar "aÃ§Ä±lÄ±r" veya eklenir. Bir diÄŸer Ã§Ã¶zÃ¼m ise katmanlar arasÄ±nda ekstra baÄŸlantÄ±lar eklemek ve birden fazla Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ aynÄ± anda eÄŸitmek olabilir - detaylar iÃ§in bu [Multi-Scale Gradient GANs makalesine](https://arxiv.org/abs/1903.06048) bakabilirsiniz.

## Stil Transferi

GAN'lar sanatsal gÃ¶rÃ¼ntÃ¼ler Ã¼retmek iÃ§in harika bir yÃ¶ntemdir. Bir diÄŸer ilginÃ§ teknik ise **stil transferi** olarak adlandÄ±rÄ±lÄ±r. Bu teknik, bir **iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼** alÄ±r ve onu farklÄ± bir tarzda yeniden Ã§izer, **stil gÃ¶rÃ¼ntÃ¼sÃ¼nden** filtreler uygular.

NasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ± ÅŸu ÅŸekildedir:
* Rastgele bir gÃ¼rÃ¼ltÃ¼ gÃ¶rÃ¼ntÃ¼sÃ¼yle baÅŸlarÄ±z (veya iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼yle, ancak anlamak iÃ§in rastgele gÃ¼rÃ¼ltÃ¼yle baÅŸlamak daha kolaydÄ±r)
* AmacÄ±mÄ±z, hem iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼ne hem de stil gÃ¶rÃ¼ntÃ¼sÃ¼ne yakÄ±n olacak bir gÃ¶rÃ¼ntÃ¼ oluÅŸturmaktÄ±r. Bu, iki kayÄ±p fonksiyonu ile belirlenir:
   - **Ä°Ã§erik kaybÄ±**, mevcut gÃ¶rÃ¼ntÃ¼ ve iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼nden CNN tarafÄ±ndan bazÄ± katmanlarda Ã§Ä±karÄ±lan Ã¶zelliklere dayanarak hesaplanÄ±r.
   - **Stil kaybÄ±**, mevcut gÃ¶rÃ¼ntÃ¼ ve stil gÃ¶rÃ¼ntÃ¼sÃ¼ arasÄ±nda Gram matrisleri kullanÄ±larak akÄ±llÄ±ca hesaplanÄ±r (daha fazla bilgi iÃ§in [Ã¶rnek not defteri](StyleTransfer.ipynb)).
* GÃ¶rÃ¼ntÃ¼yÃ¼ daha dÃ¼zgÃ¼n hale getirmek ve gÃ¼rÃ¼ltÃ¼yÃ¼ kaldÄ±rmak iÃ§in **Varyasyon kaybÄ±** da ekleriz, bu komÅŸu pikseller arasÄ±ndaki ortalama mesafeyi hesaplar.
* Ana optimizasyon dÃ¶ngÃ¼sÃ¼, toplam kaybÄ± minimize etmek iÃ§in mevcut gÃ¶rÃ¼ntÃ¼yÃ¼ gradyan iniÅŸi (veya baÅŸka bir optimizasyon algoritmasÄ±) kullanarak ayarlar. Toplam kayÄ±p, tÃ¼m kayÄ±plarÄ±n aÄŸÄ±rlÄ±klÄ± bir toplamÄ±dÄ±r.

## âœï¸ Ã–rnek: [Stil Transferi](StyleTransfer.ipynb)

## [Ders SonrasÄ± Test](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## SonuÃ§

Bu derste GAN'larÄ± ve nasÄ±l eÄŸitileceÄŸini Ã¶ÄŸrendiniz. AyrÄ±ca bu tÃ¼r Sinir AÄŸlarÄ±nÄ±n karÅŸÄ±laÅŸabileceÄŸi Ã¶zel zorluklarÄ± ve bunlarÄ± aÅŸmak iÃ§in bazÄ± stratejileri Ã¶ÄŸrendiniz.

## ğŸš€ Meydan Okuma

Kendi gÃ¶rÃ¼ntÃ¼lerinizi kullanarak [Stil Transferi not defterini](StyleTransfer.ipynb) Ã§alÄ±ÅŸtÄ±rÄ±n.

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Referans iÃ§in, GAN'lar hakkÄ±nda daha fazla bilgi edinmek iÃ§in ÅŸu kaynaklara gÃ¶z atÄ±n:

* Marco Pasini, [Bir YÄ±l Boyunca GAN EÄŸitimiyle Ã–ÄŸrendiÄŸim 10 Ders](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), dikkate alÄ±nmasÄ± gereken bir *de facto* GAN mimarisi
* [Azure ML'de GAN'lar Kullanarak Ãœretici Sanat OluÅŸturma](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Ã–dev

Bu derse ait iki not defterinden birini tekrar ziyaret edin ve GAN'Ä± kendi gÃ¶rÃ¼ntÃ¼leriniz Ã¼zerinde yeniden eÄŸitin. Neler yaratabilirsiniz?

---

