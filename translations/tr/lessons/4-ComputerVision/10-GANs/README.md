# Ãœretken Ã‡atÄ±ÅŸmalÄ± AÄŸlar

Ã–nceki bÃ¶lÃ¼mde **Ã¼retken modeller** hakkÄ±nda bilgi edindik: eÄŸitim veri setindeki gÃ¶rÃ¼ntÃ¼lere benzer yeni gÃ¶rÃ¼ntÃ¼ler Ã¼retebilen modeller. VAE, bir Ã¼retken modelin iyi bir Ã¶rneÄŸiydi.

## [Ders Ã¶ncesi quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

Ancak, VAE ile gerÃ§ekten anlamlÄ± bir ÅŸey, Ã¶rneÄŸin makul bir Ã§Ã¶zÃ¼nÃ¼rlÃ¼kte bir resim Ã¼retmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±zda, eÄŸitimin iyi bir ÅŸekilde yakÄ±nsadÄ±ÄŸÄ±nÄ± gÃ¶remeyiz. Bu kullanÄ±m durumu iÃ§in, Ã¼retken modellere Ã¶zel olarak hedeflenmiÅŸ baÅŸka bir mimari hakkÄ±nda bilgi edinmemiz gerekir - **Ãœretken Ã‡atÄ±ÅŸmalÄ± AÄŸlar**, veya kÄ±saca GAN'lar.

GAN'Ä±n ana fikri, birbirine karÅŸÄ± eÄŸitilecek iki sinir aÄŸÄ±na sahip olmaktÄ±r:

<img src="images/gan_architecture.png" width="70%"/>

> Resim [Dmitry Soshnikov](http://soshnikov.com) tarafÄ±ndan

> âœ… KÃ¼Ã§Ã¼k bir kelime bilgisi:
> * **Ãœretici** (Generator), rastgele bir vektÃ¶r alÄ±p, sonuÃ§ olarak bir gÃ¶rÃ¼ntÃ¼ Ã¼reten bir aÄŸdÄ±r.
> * **AyrÄ±ÅŸtÄ±rÄ±cÄ±** (Discriminator), bir gÃ¶rÃ¼ntÃ¼ alÄ±r ve bunun gerÃ§ek bir gÃ¶rÃ¼ntÃ¼ olup olmadÄ±ÄŸÄ±nÄ± (eÄŸitim veri setinden) ya da bir Ã¼retici tarafÄ±ndan Ã¼retilip Ã¼retilmediÄŸini belirtmelidir. Temelde bir gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flayÄ±cÄ±sÄ±dÄ±r.

### AyrÄ±ÅŸtÄ±rÄ±cÄ±

AyrÄ±ÅŸtÄ±rÄ±cÄ±nÄ±n mimarisi, sÄ±radan bir gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flama aÄŸÄ±ndan farklÄ± deÄŸildir. En basit durumda, tamamen baÄŸlÄ± bir sÄ±nÄ±flayÄ±cÄ± olabilir, ancak bÃ¼yÃ¼k ihtimalle bir [konvolÃ¼syonel aÄŸ](../07-ConvNets/README.md) olacaktÄ±r.

> âœ… KonvolÃ¼syonel aÄŸlara dayanan bir GAN'a [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) denir.

Bir CNN ayrÄ±ÅŸtÄ±rÄ±cÄ±sÄ±, aÅŸaÄŸÄ±daki katmanlardan oluÅŸur: birkaÃ§ konvolÃ¼syon+havuzlama (azalan mekansal boyutlarla) ve "Ã¶zellik vektÃ¶rÃ¼" elde etmek iÃ§in bir veya daha fazla tamamen baÄŸlÄ± katman, son ikili sÄ±nÄ±flayÄ±cÄ±.

> âœ… Bu baÄŸlamda 'havuzlama', gÃ¶rÃ¼ntÃ¼nÃ¼n boyutunu azaltan bir tekniktir. "Havuzlama katmanlarÄ±, bir katmandaki nÃ¶ron kÃ¼melerinin Ã§Ä±ktÄ±sÄ±nÄ± bir sonraki katmandaki tek bir nÃ¶rona birleÅŸtirerek verinin boyutunu azaltÄ±r." - [kaynak](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Ãœretici

Ãœretici biraz daha karmaÅŸÄ±ktÄ±r. Bunu tersine Ã§evrilmiÅŸ bir ayrÄ±ÅŸtÄ±rÄ±cÄ± olarak dÃ¼ÅŸÃ¼nebilirsiniz. Gizli bir vektÃ¶rden (Ã¶zellik vektÃ¶rÃ¼nÃ¼n yerinde) baÅŸlar, gerekli boyut/ÅŸekle dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in bir tamamen baÄŸlÄ± katmana sahiptir ve ardÄ±ndan dekonvolÃ¼syonlar+Ã¶lÃ§ekleme yapÄ±lÄ±r. Bu, [oto kodlayÄ±cÄ±](../09-Autoencoders/README.md) kÄ±smÄ±nÄ±n *Ã§Ã¶zÃ¼cÃ¼* bÃ¶lÃ¼mÃ¼ne benzerdir.

> âœ… KonvolÃ¼syon katmanÄ± gÃ¶rÃ¼ntÃ¼yÃ¼ tarayan bir lineer filtre olarak uygulandÄ±ÄŸÄ± iÃ§in, dekonvolÃ¼syon temelde konvolÃ¼syona benzer ve aynÄ± katman mantÄ±ÄŸÄ± kullanÄ±larak uygulanabilir.

<img src="images/gan_arch_detail.png" width="70%"/>

> Resim [Dmitry Soshnikov](http://soshnikov.com) tarafÄ±ndan

### GAN'Ä± EÄŸitmek

GAN'lar **Ã§atÄ±ÅŸmalÄ±** olarak adlandÄ±rÄ±lÄ±r Ã§Ã¼nkÃ¼ Ã¼retici ile ayrÄ±ÅŸtÄ±rÄ±cÄ± arasÄ±nda sÃ¼rekli bir rekabet vardÄ±r. Bu rekabet sÄ±rasÄ±nda, hem Ã¼retici hem de ayrÄ±ÅŸtÄ±rÄ±cÄ± geliÅŸir, bÃ¶ylece aÄŸ daha iyi ve daha iyi resimler Ã¼retmeyi Ã¶ÄŸrenir.

EÄŸitim iki aÅŸamada gerÃ§ekleÅŸir:

* **AyrÄ±ÅŸtÄ±rÄ±cÄ±yÄ± EÄŸitmek**. Bu gÃ¶rev oldukÃ§a basittir: Ã¼retici tarafÄ±ndan bir gÃ¶rÃ¼ntÃ¼ partisi Ã¼retiyoruz, bunlarÄ± sahte gÃ¶rÃ¼ntÃ¼ iÃ§in 0 olarak etiketliyoruz ve giriÅŸ veri setinden (gerÃ§ek gÃ¶rÃ¼ntÃ¼ iÃ§in etiket 1) bir gÃ¶rÃ¼ntÃ¼ partisi alÄ±yoruz. BazÄ± *ayrÄ±ÅŸtÄ±rÄ±cÄ± kaybÄ±* elde ediyoruz ve geri yayÄ±lÄ±m yapÄ±yoruz.
* **Ãœreticiyi EÄŸitmek**. Bu biraz daha karmaÅŸÄ±ktÄ±r, Ã§Ã¼nkÃ¼ Ã¼retici iÃ§in beklenen Ã§Ä±ktÄ±yÄ± doÄŸrudan bilmiyoruz. Bir Ã¼retici ve ardÄ±ndan ayrÄ±ÅŸtÄ±rÄ±cÄ±dan oluÅŸan tÃ¼m GAN aÄŸÄ±nÄ± alÄ±yoruz, bazÄ± rastgele vektÃ¶rlerle besliyoruz ve sonucun 1 (gerÃ§ek gÃ¶rÃ¼ntÃ¼lere karÅŸÄ±lÄ±k gelen) olmasÄ±nÄ± bekliyoruz. ArdÄ±ndan, ayrÄ±ÅŸtÄ±rÄ±cÄ±nÄ±n parametrelerini donduruyoruz (bu adÄ±mda eÄŸitilmesini istemiyoruz) ve geri yayÄ±lÄ±m yapÄ±yoruz.

Bu sÃ¼reÃ§te, hem Ã¼retici hem de ayrÄ±ÅŸtÄ±rÄ±cÄ± kayÄ±plarÄ± Ã¶nemli Ã¶lÃ§Ã¼de dÃ¼ÅŸmez. Ä°deal durumda, her iki aÄŸÄ±n performanslarÄ±nÄ± geliÅŸtirmesine karÅŸÄ±lÄ±k olarak osilasyon gÃ¶stermelidirler.

## âœï¸ AlÄ±ÅŸtÄ±rmalar: GAN'lar

* [TensorFlow/Keras'ta GAN Not Defteri](../../../../../lessons/4-ComputerVision/10-GANs/GANTF.ipynb)
* [PyTorch'ta GAN Not Defteri](../../../../../lessons/4-ComputerVision/10-GANs/GANPyTorch.ipynb)

### GAN eÄŸitimindeki problemler

GAN'larÄ±n eÄŸitiminin Ã¶zellikle zor olduÄŸu bilinmektedir. Ä°ÅŸte birkaÃ§ problem:

* **Mod Ã‡Ã¶kmesi**. Bu terim, Ã¼reticinin bir baÅŸarÄ±lÄ± gÃ¶rÃ¼ntÃ¼ Ã¼retmeyi Ã¶ÄŸrenmesi ve farklÄ± gÃ¶rÃ¼ntÃ¼ Ã§eÅŸitliliÄŸi Ã¼retmemesi anlamÄ±na gelir.
* **Hiperparametrelere duyarlÄ±lÄ±k**. Genellikle bir GAN'Ä±n hiÃ§ yakÄ±nsama gÃ¶stermediÄŸini gÃ¶rebilirsiniz ve ardÄ±ndan Ã¶ÄŸrenme oranÄ±nda ani bir dÃ¼ÅŸÃ¼ÅŸ ile yakÄ±nsama sÃ¼recine girebilir.
* Ãœretici ve ayrÄ±ÅŸtÄ±rÄ±cÄ± arasÄ±nda bir **denge** saÄŸlamak. BirÃ§ok durumda ayrÄ±ÅŸtÄ±rÄ±cÄ± kaybÄ± oldukÃ§a hÄ±zlÄ± bir ÅŸekilde sÄ±fÄ±ra dÃ¼ÅŸebilir, bu da Ã¼reticinin daha fazla eÄŸitim yapamamasÄ±na neden olur. Bunu aÅŸmak iÃ§in, Ã¼retici ve ayrÄ±ÅŸtÄ±rÄ±cÄ± iÃ§in farklÄ± Ã¶ÄŸrenme oranlarÄ± belirlemeyi deneyebiliriz veya kayÄ±p zaten Ã§ok dÃ¼ÅŸÃ¼kse ayrÄ±ÅŸtÄ±rÄ±cÄ± eÄŸitimini atlayabiliriz.
* **YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼k** iÃ§in eÄŸitim. Oto kodlayÄ±cÄ±larla benzer bir sorunu yansÄ±tarak, Ã§ok sayÄ±da konvolÃ¼syonel aÄŸ katmanÄ±nÄ± yeniden yapÄ±landÄ±rmanÄ±n artefaktlara yol aÃ§masÄ± nedeniyle bu problem tetiklenir. Bu problem genellikle ilk olarak birkaÃ§ katmanÄ±n dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼kteki gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde eÄŸitilmesi ve ardÄ±ndan katmanlarÄ±n "aÃ§Ä±lmasÄ±" veya eklenmesiyle Ã§Ã¶zÃ¼len **ilerlemeli bÃ¼yÃ¼me** ile Ã§Ã¶zÃ¼lÃ¼r. DiÄŸer bir Ã§Ã¶zÃ¼m, katmanlar arasÄ±nda ekstra baÄŸlantÄ±lar eklemek ve birden fazla Ã§Ã¶zÃ¼nÃ¼rlÃ¼kte eÄŸitim yapmaktÄ±r - detaylar iÃ§in bu [Ã‡ok Ã–lÃ§ekli Gradyan GAN'lar makalesine](https://arxiv.org/abs/1903.06048) bakÄ±n.

## Stil AktarÄ±mÄ±

GAN'lar sanatsal gÃ¶rÃ¼ntÃ¼ler oluÅŸturmak iÃ§in harika bir yoldur. DiÄŸer ilginÃ§ bir teknik ise **stil aktarÄ±mÄ±** olarak adlandÄ±rÄ±lÄ±r; bu teknik, bir **iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼** alÄ±r ve bunu farklÄ± bir stil ile yeniden Ã§izer, **stil gÃ¶rÃ¼ntÃ¼sÃ¼nden** filtreler uygulayarak.

Bu iÅŸlem ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r:
* Rastgele bir gÃ¼rÃ¼ltÃ¼ gÃ¶rÃ¼ntÃ¼sÃ¼ ile baÅŸlarÄ±z (veya bir iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼ ile, ancak anlamak aÃ§Ä±sÄ±ndan rastgele gÃ¼rÃ¼ltÃ¼ ile baÅŸlamak daha kolaydÄ±r).
* AmacÄ±mÄ±z, hem iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼ne hem de stil gÃ¶rÃ¼ntÃ¼sÃ¼ne yakÄ±n bir gÃ¶rÃ¼ntÃ¼ oluÅŸturmaktÄ±r. Bu, iki kayÄ±p fonksiyonu ile belirlenir:
   - **Ä°Ã§erik kaybÄ±**, mevcut gÃ¶rÃ¼ntÃ¼ ve iÃ§erik gÃ¶rÃ¼ntÃ¼sÃ¼nden Ã§Ä±karÄ±lan Ã¶zellikler kullanÄ±larak hesaplanÄ±r.
   - **Stil kaybÄ±**, mevcut gÃ¶rÃ¼ntÃ¼ ve stil gÃ¶rÃ¼ntÃ¼sÃ¼ arasÄ±ndaki iliÅŸkiyi akÄ±llÄ±ca Gram matrisleri kullanarak hesaplar (daha fazla detay iÃ§in [Ã¶rnek not defterine](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) bakÄ±n).
* GÃ¶rÃ¼ntÃ¼yÃ¼ daha pÃ¼rÃ¼zsÃ¼z hale getirmek ve gÃ¼rÃ¼ltÃ¼yÃ¼ kaldÄ±rmak iÃ§in, ayrÄ±ca komÅŸu pikseller arasÄ±ndaki ortalama mesafeyi hesaplayan **Varyasyon kaybÄ±** da tanÄ±tÄ±yoruz.
* Ana optimizasyon dÃ¶ngÃ¼sÃ¼, toplam kaybÄ± minimize etmek iÃ§in mevcut gÃ¶rÃ¼ntÃ¼yÃ¼ gradyan iniÅŸi (veya baÅŸka bir optimizasyon algoritmasÄ±) kullanarak ayarlamaktadÄ±r; bu, Ã¼Ã§ kaybÄ±n aÄŸÄ±rlÄ±klÄ± toplamÄ±dÄ±r.

## âœï¸ Ã–rnek: [Stil AktarÄ±mÄ±](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb)

## [Ders sonrasÄ± quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## SonuÃ§

Bu derste, GAN'lar ve bunlarÄ± nasÄ±l eÄŸiteceÄŸiniz hakkÄ±nda bilgi edindiniz. AyrÄ±ca, bu tÃ¼r bir Sinir AÄŸÄ±'nÄ±n karÅŸÄ±laÅŸabileceÄŸi Ã¶zel zorluklar ve bunlarÄ± aÅŸmanÄ±n bazÄ± stratejileri hakkÄ±nda bilgi edindiniz.

## ğŸš€ Meydan Okuma

Kendi gÃ¶rÃ¼ntÃ¼lerinizi kullanarak [Stil AktarÄ±mÄ± not defterini](../../../../../lessons/4-ComputerVision/10-GANs/StyleTransfer.ipynb) Ã§alÄ±ÅŸtÄ±rÄ±n.

## Ä°nceleme & Kendi Kendine Ã‡alÄ±ÅŸma

Referans olarak, GAN'lar hakkÄ±nda daha fazla bilgi edinmek iÃ§in bu kaynaklarÄ± okuyun:

* Marco Pasini, [Bir YÄ±l Boyunca GAN EÄŸitimiyle Ä°lgili Ã–ÄŸrendiÄŸim 10 Ders](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* Dikkate alÄ±nmasÄ± gereken bir *de facto* GAN mimarisi olan [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN)
* [Azure ML'de GAN'lar kullanarak Ãœretken Sanat OluÅŸturma](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## GÃ¶rev

Bu derse baÄŸlÄ± iki not defterinden birini gÃ¶zden geÃ§irin ve GAN'Ä± kendi gÃ¶rÃ¼ntÃ¼leriniz Ã¼zerinde yeniden eÄŸitin. Ne yaratabilirsiniz?

**AÃ§Ä±klama**:  
Bu belge, makine tabanlÄ± yapay zeka Ã§eviri hizmetleri kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belge, kendi dilinde otoriter bir kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilmektedir. Bu Ã§evirinin kullanÄ±lmasÄ± sonucunda ortaya Ã§Ä±kan herhangi bir yanlÄ±ÅŸ anlama veya yanlÄ±ÅŸ yorumlama iÃ§in sorumluluk kabul etmiyoruz.