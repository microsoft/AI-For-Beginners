# Nesne Tespiti

Åimdiye kadar ele aldÄ±ÄŸÄ±mÄ±z gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma modelleri, bir gÃ¶rÃ¼ntÃ¼ alÄ±r ve MNIST probleminde 'sayÄ±' sÄ±nÄ±fÄ± gibi kategorik bir sonuÃ§ Ã¼retir. Ancak birÃ§ok durumda, bir resmin nesneleri tasvir ettiÄŸini bilmekle yetinmek istemiyoruz - bu nesnelerin kesin konumunu belirleyebilme yeteneÄŸine sahip olmak istiyoruz. Ä°ÅŸte bu, **nesne tespiti**nin tam anlamÄ±dÄ±r.

## [Ã–n-derse Quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/111)

![Nesne Tespiti](../../../../../translated_images/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be1b905373ed9c858102c054b16e4595c76ec3f7bba0feb549.tr.png)

> [YOLO v2 web sitesi](https://pjreddie.com/darknet/yolov2/) kaynaklÄ± gÃ¶rÃ¼ntÃ¼

## Nesne Tespiti iÃ§in Naif Bir YaklaÅŸÄ±m

Bir resimde bir kediyi bulmak istediÄŸimizi varsayalÄ±m, nesne tespiti iÃ§in Ã§ok naif bir yaklaÅŸÄ±m aÅŸaÄŸÄ±daki gibi olacaktÄ±r:

1. Resmi bir dizi kareye bÃ¶l
2. Her bir kare Ã¼zerinde gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ± yap.
3. Yeterince yÃ¼ksek aktivasyon sonucu veren kareler, sÃ¶z konusu nesneyi iÃ§eriyor olarak kabul edilebilir.

![Naif Nesne Tespiti](../../../../../translated_images/naive-detection.e7f1ba220ccd08c68a2ea8e06a7ed75c3fcc738c2372f9e00b7f4299a8659c01.tr.png)

> *[AlÄ±ÅŸtÄ±rma Defteri](../../../../../lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection-TF.ipynb)* kaynaÄŸÄ±ndan gÃ¶rÃ¼ntÃ¼

Ancak bu yaklaÅŸÄ±m, algoritmanÄ±n nesnenin sÄ±nÄ±rlayÄ±cÄ± kutusunu oldukÃ§a belirsiz bir ÅŸekilde yerleÅŸtirmesine olanak tanÄ±dÄ±ÄŸÄ± iÃ§in ideal deÄŸildir. Daha kesin bir konum iÃ§in, sÄ±nÄ±rlayÄ±cÄ± kutularÄ±n koordinatlarÄ±nÄ± tahmin etmek Ã¼zere bir tÃ¼r **regresyon** uygulamamÄ±z gerekiyor - ve bunun iÃ§in belirli veri setlerine ihtiyacÄ±mÄ±z var.

## Nesne Tespiti iÃ§in Regresyon

[Bu blog yazÄ±sÄ±](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491), ÅŸekil tespiti iÃ§in harika bir giriÅŸ sunmaktadÄ±r.

## Nesne Tespiti iÃ§in Veri Setleri

Bu gÃ¶rev iÃ§in aÅŸaÄŸÄ±daki veri setleriyle karÅŸÄ±laÅŸabilirsiniz:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) - 20 sÄ±nÄ±f
* [COCO](http://cocodataset.org/#home) - BaÄŸlamda Ortak Nesneler. 80 sÄ±nÄ±f, sÄ±nÄ±rlayÄ±cÄ± kutular ve segmentasyon maskeleri

![COCO](../../../../../translated_images/coco-examples.71bc60380fa6cceb7caad48bd09e35b6028caabd363aa04fee89c414e0870e86.tr.jpg)

## Nesne Tespiti Metrikleri

### Kesim Ãœzerine Birlik

GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rmasÄ± iÃ§in algoritmanÄ±n ne kadar iyi performans gÃ¶sterdiÄŸini Ã¶lÃ§mek kolaydÄ±r, ancak nesne tespiti iÃ§in hem sÄ±nÄ±fÄ±n doÄŸruluÄŸunu hem de Ã§Ä±karÄ±lan sÄ±nÄ±rlayÄ±cÄ± kutu konumunun doÄŸruluÄŸunu Ã¶lÃ§memiz gerekiyor. Ä°kincisi iÃ§in, iki kutunun (veya iki rastgele alanÄ±n) ne kadar Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ Ã¶lÃ§en **Kesim Ãœzerine Birlik** (IoU) adÄ± verilen bir Ã¶lÃ§Ã¼m kullanÄ±yoruz.

![IoU](../../../../../translated_images/iou_equation.9a4751d40fff4e119ecd0a7bcca4e71ab1dc83e0d4f2a0d66ff0859736f593cf.tr.png)

> *[Bu mÃ¼kemmel IoU blog yazÄ±sÄ±nÄ±n](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/) 2. ÅemasÄ±*

Fikir basit - iki ÅŸekil arasÄ±ndaki kesiÅŸim alanÄ±nÄ±, bu ÅŸekillerin birleÅŸim alanÄ±na bÃ¶lÃ¼yoruz. Ä°ki Ã¶zdeÅŸ alan iÃ§in, IoU 1 olurken, tamamen ayrÄ± alanlar iÃ§in 0 olur. Aksi takdirde, 0 ile 1 arasÄ±nda deÄŸiÅŸecektir. Genellikle, IoU'nun belirli bir deÄŸerin Ã¼zerinde olduÄŸu sÄ±nÄ±rlayÄ±cÄ± kutularÄ± dikkate alÄ±yoruz.

### Ortalama DoÄŸruluk

Verilen bir nesne sÄ±nÄ±fÄ± $C$'nin ne kadar iyi tanÄ±ndÄ±ÄŸÄ±nÄ± Ã¶lÃ§mek istiyoruz. Bunu Ã¶lÃ§mek iÃ§in, **Ortalama DoÄŸruluk** metriklerini kullanÄ±yoruz, bu da aÅŸaÄŸÄ±daki gibi hesaplanÄ±r:

1. DoÄŸruluk eÅŸiÄŸine (0 ile 1 arasÄ±nda) baÄŸlÄ± olarak doÄŸruluk deÄŸerlerini gÃ¶steren DoÄŸruluk-HatÄ±rlama eÄŸrisini dikkate al.
2. EÅŸeÄŸe baÄŸlÄ± olarak, gÃ¶rÃ¼ntÃ¼de daha fazla veya daha az nesne tespit edeceÄŸiz ve farklÄ± doÄŸruluk ve hatÄ±rlama deÄŸerleri elde edeceÄŸiz.
3. EÄŸri ÅŸu ÅŸekilde gÃ¶rÃ¼necek:

> *[NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)* kaynaÄŸÄ±ndan gÃ¶rÃ¼ntÃ¼

Verilen bir sÄ±nÄ±f $C$ iÃ§in ortalama DoÄŸruluk, bu eÄŸrinin altÄ±ndaki alandÄ±r. Daha kesin olarak, HatÄ±rlama ekseni genellikle 10 parÃ§aya bÃ¶lÃ¼nÃ¼r ve DoÄŸruluk tÃ¼m bu noktalar Ã¼zerinde ortalanÄ±r:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{DoÄŸruluk}(\mbox{HatÄ±rlama}={i\over10})
$$

### AP ve IoU

Sadece IoU'nun belirli bir deÄŸerin Ã¼zerinde olduÄŸu tespitleri dikkate alacaÄŸÄ±z. Ã–rneÄŸin, PASCAL VOC veri setinde genellikle $\mbox{IoU EÅŸiÄŸi} = 0.5$ varsayÄ±lÄ±rken, COCO'da AP farklÄ± $\mbox{IoU EÅŸiÄŸi}$ deÄŸerleri iÃ§in Ã¶lÃ§Ã¼lmektedir. 

### Ortalama Ortalama DoÄŸruluk - mAP

Nesne Tespiti iÃ§in ana metrik **Ortalama Ortalama DoÄŸruluk** veya **mAP** olarak adlandÄ±rÄ±lÄ±r. Bu, TÃ¼m nesne sÄ±nÄ±flarÄ± Ã¼zerinden ortalama alÄ±nmÄ±ÅŸ Ortalama DoÄŸruluk deÄŸeridir ve bazen de $\mbox{IoU EÅŸiÄŸi}$ Ã¼zerinden ortalama alÄ±nÄ±r. **mAP** hesaplama sÃ¼reci daha ayrÄ±ntÄ±lÄ± olarak [bu blog yazÄ±sÄ±nda](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3) ve [burada kod Ã¶rnekleri ile](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734) aÃ§Ä±klanmaktadÄ±r.

## FarklÄ± Nesne Tespiti YaklaÅŸÄ±mlarÄ±

Nesne tespiti algoritmalarÄ±nÄ±n iki geniÅŸ sÄ±nÄ±fÄ± vardÄ±r:

* **BÃ¶lge Teklif AÄŸlarÄ±** (R-CNN, Fast R-CNN, Faster R-CNN). Ana fikir, **Ä°lgi AlanlarÄ±** (ROI) Ã¼retmek ve bunlar Ã¼zerinde maksimum aktivasyon aramak iÃ§in CNN Ã§alÄ±ÅŸtÄ±rmaktÄ±r. Bu, naif yaklaÅŸÄ±ma biraz benziyor, tek fark, ROI'lerin daha akÄ±llÄ± bir ÅŸekilde Ã¼retilmesidir. Bu tÃ¼r yÃ¶ntemlerin en bÃ¼yÃ¼k dezavantajlarÄ±ndan biri, gÃ¶rÃ¼ntÃ¼ Ã¼zerinde CNN sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ±n birÃ§ok geÃ§iÅŸini gerektirdiÄŸi iÃ§in yavaÅŸ olmalarÄ±dÄ±r.
* **Tek geÃ§iÅŸ** (YOLO, SSD, RetinaNet) yÃ¶ntemleri. Bu mimarilerde, aÄŸÄ± hem sÄ±nÄ±flarÄ± hem de ROI'leri tek bir geÃ§iÅŸte tahmin edecek ÅŸekilde tasarlÄ±yoruz.

### R-CNN: BÃ¶lge TabanlÄ± CNN

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf), ROI bÃ¶lgelerinin hiyerarÅŸik yapÄ±sÄ±nÄ± oluÅŸturmak iÃ§in [SeÃ§ici Arama](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) kullanÄ±r, bu bÃ¶lgeler daha sonra CNN Ã¶zellik Ã§Ä±karÄ±cÄ±larÄ± ve SVM sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± Ã¼zerinden geÃ§irilerek nesne sÄ±nÄ±fÄ± belirlenir ve *sÄ±nÄ±rlayÄ±cÄ± kutu* koordinatlarÄ±nÄ± belirlemek iÃ§in doÄŸrusal regresyon uygulanÄ±r. [Resmi Makale](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/rcnn1.cae407020dfb1d1fb572656e44f75cd6c512cc220591c116c506652c10e47f26.tr.png)

> *van de Sande et al. ICCVâ€™11 kaynaÄŸÄ±ndan gÃ¶rÃ¼ntÃ¼*

![RCNN-1](../../../../../translated_images/rcnn2.2d9530bb83516484ec65b250c22dbf37d3d23244f32864ebcb91d98fe7c3112c.tr.png)

> *[Bu blog](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) kaynaÄŸÄ±ndan gÃ¶rÃ¼ntÃ¼*

### F-RCNN - HÄ±zlÄ± R-CNN

Bu yaklaÅŸÄ±m R-CNN ile benzerdir, ancak bÃ¶lgeler, konvolÃ¼syon katmanlarÄ± uygulandÄ±ktan sonra tanÄ±mlanÄ±r.

![FRCNN](../../../../../translated_images/f-rcnn.3cda6d9bb41888754037d2d9763e2298a96de5d9bc2a21db3147357aa5da9b1a.tr.png)

> Resim [Resmi Makale](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Daha HÄ±zlÄ± R-CNN

Bu yaklaÅŸÄ±mÄ±n ana fikri, ROI'leri tahmin etmek iÃ§in bir sinir aÄŸÄ± kullanmaktÄ±r - bu, *BÃ¶lge Teklif AÄŸÄ±* olarak adlandÄ±rÄ±lÄ±r. [Makale](https://arxiv.org/pdf/1506.01497.pdf), 2016

![Daha HÄ±zlÄ±RCNN](../../../../../translated_images/faster-rcnn.8d46c099b87ef30ab2ea26dbc4bdd85b974a57ba8eb526f65dc4cd0a4711de30.tr.png)

> Resim [resmi makaleden](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: BÃ¶lge TabanlÄ± Tam KonvolÃ¼syonel AÄŸ

Bu algoritma, Daha HÄ±zlÄ± R-CNN'den bile daha hÄ±zlÄ±dÄ±r. Ana fikir aÅŸaÄŸÄ±daki gibidir:

1. Ã–zellikler ResNet-101 kullanÄ±larak Ã§Ä±karÄ±lÄ±r.
2. Ã–zellikler **Pozisyon-DuyarlÄ± Skor HaritasÄ±** tarafÄ±ndan iÅŸlenir. $C$ sÄ±nÄ±flarÄ±ndaki her nesne $k\times k$ bÃ¶lgeye ayrÄ±lÄ±r ve nesnelerin parÃ§alarÄ±nÄ± tahmin etmek iÃ§in eÄŸitim yapÄ±lÄ±r.
3. $k\times k$ bÃ¶lgelerden her bir parÃ§a iÃ§in tÃ¼m aÄŸlar nesne sÄ±nÄ±flarÄ± iÃ§in oy kullanÄ±r ve maksimum oy alan nesne sÄ±nÄ±fÄ± seÃ§ilir.

![r-fcn gÃ¶rÃ¼ntÃ¼sÃ¼](../../../../../translated_images/r-fcn.13eb88158b99a3da50fa2787a6be5cb310d47f0e9655cc93a1090dc7aab338d1.tr.png)

> Resim [resmi makaleden](https://arxiv.org/abs/1605.06409)

### YOLO - Bir Kez BakarsÄ±nÄ±z

YOLO, gerÃ§ek zamanlÄ± bir tek geÃ§iÅŸ algoritmasÄ±dÄ±r. Ana fikir aÅŸaÄŸÄ±daki gibidir:

 * GÃ¶rÃ¼ntÃ¼ $S\times S$ bÃ¶lgelere bÃ¶lÃ¼nÃ¼r.
 * Her bÃ¶lge iÃ§in, **CNN** $n$ olasÄ± nesneyi, *sÄ±nÄ±rlayÄ±cÄ± kutu* koordinatlarÄ±nÄ± ve *gÃ¼ven* = *olasÄ±lÄ±k* * IoU'yu tahmin eder.

 ![YOLO](../../../../../translated_images/yolo.a2648ec82ee8bb4ea27537677adb482fd4b733ca1705c561b6a24a85102dced5.tr.png)
> [Resmi makale](https://arxiv.org/abs/1506.02640) kaynaÄŸÄ±ndan gÃ¶rÃ¼ntÃ¼

### DiÄŸer Algoritmalar

* RetinaNet: [resmi makale](https://arxiv.org/abs/1708.02002)
   - [Torchvision'da PyTorch UygulamasÄ±](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Keras UygulamasÄ±](https://github.com/fizyr/keras-retinanet)
   - Keras Ã–rneklerinde [RetinaNet ile Nesne Tespiti](https://keras.io/examples/vision/retinanet/)
* SSD (Tek AtÄ±ÅŸ DedektÃ¶rÃ¼): [resmi makale](https://arxiv.org/abs/1512.02325)

## âœï¸ AlÄ±ÅŸtÄ±rmalar: Nesne Tespiti

AÅŸaÄŸÄ±daki not defterinde Ã¶ÄŸreniminize devam edin:

[ObjectDetection.ipynb](../../../../../lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb)

## SonuÃ§

Bu derste, nesne tespitinin gerÃ§ekleÅŸtirilebileceÄŸi Ã§eÅŸitli yollarÄ± hÄ±zlÄ± bir ÅŸekilde keÅŸfettiniz!

## ğŸš€ Zorluk

Bu makaleleri ve not defterlerini okuyun, YOLO hakkÄ±nda bilgi edinin ve kendiniz deneyin.

* YOLO'yu tanÄ±mlayan [iyi bir blog yazÄ±sÄ±](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/)
 * [Resmi site](https://pjreddie.com/darknet/yolo/)
 * Yolo: [Keras uygulamasÄ±](https://github.com/experiencor/keras-yolo2), [adÄ±m adÄ±m not defteri](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * Yolo v2: [Keras uygulamasÄ±](https://github.com/experiencor/keras-yolo2), [adÄ±m adÄ±m not defteri](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [Ders sonrasÄ± sÄ±nav](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/211)

## GÃ¶zden GeÃ§irme & Kendi Kendine Ã‡alÄ±ÅŸma

* Nikhil Sardana tarafÄ±ndan [Nesne Tespiti](https://tjmachinelearning.com/lectures/1718/obj/)
* [Nesne tespit algoritmalarÄ±nÄ±n iyi bir karÅŸÄ±laÅŸtÄ±rmasÄ±](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [Nesne Tespiti iÃ§in Derin Ã–ÄŸrenme AlgoritmalarÄ±nÄ±n GÃ¶zden GeÃ§irilmesi](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [Temel Nesne Tespit AlgoritmalarÄ±na AdÄ±m AdÄ±m GiriÅŸ](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Nesne Tespiti iÃ§in Python'da Daha HÄ±zlÄ± R-CNN UygulamasÄ±](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [GÃ¶rev: Nesne Tespiti](lab/README.md)

**AÃ§Ä±klama**:  
Bu belge, makine tabanlÄ± yapay zeka Ã§eviri hizmetleri kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belge, kendi dilinde otoriter kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilmektedir. Bu Ã§evirinin kullanÄ±lmasÄ± sonucunda ortaya Ã§Ä±kan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.