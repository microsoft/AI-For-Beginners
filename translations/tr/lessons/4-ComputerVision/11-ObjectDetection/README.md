# Nesne Tespiti

BugÃ¼ne kadar ele aldÄ±ÄŸÄ±mÄ±z gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma modelleri, bir gÃ¶rÃ¼ntÃ¼yÃ¼ alÄ±p MNIST problemindeki 'sayÄ±' sÄ±nÄ±fÄ± gibi kategorik bir sonuÃ§ Ã¼retiyordu. Ancak, birÃ§ok durumda bir resmin nesneleri tasvir ettiÄŸini bilmek yeterli deÄŸildir - nesnelerin tam konumlarÄ±nÄ± belirlemek isteriz. Ä°ÅŸte **nesne tespiti** tam olarak bu noktada devreye girer.

## [Ders Ã–ncesi Test](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![Nesne Tespiti](../../../../../translated_images/tr/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be.webp)

> GÃ¶rsel [YOLO v2 web sitesi](https://pjreddie.com/darknet/yolov2/) Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.

## Nesne Tespiti iÃ§in Naif Bir YaklaÅŸÄ±m

Bir resimde bir kediyi bulmak istediÄŸimizi varsayalÄ±m, nesne tespiti iÃ§in Ã§ok basit bir yaklaÅŸÄ±m ÅŸu ÅŸekilde olabilir:

1. Resmi bir dizi kareye ayÄ±rÄ±n.
2. Her bir karede gÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma iÅŸlemi gerÃ§ekleÅŸtirin.
3. Yeterince yÃ¼ksek aktivasyon veren kareler, ilgili nesneyi iÃ§eriyor olarak kabul edilebilir.

![Naif Nesne Tespiti](../../../../../translated_images/tr/naive-detection.e7f1ba220ccd08c6.webp)

> *GÃ¶rsel [Egzersiz Defteri](ObjectDetection-TF.ipynb) Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.*

Ancak, bu yaklaÅŸÄ±m ideal olmaktan uzaktÄ±r Ã§Ã¼nkÃ¼ algoritmanÄ±n nesnenin sÄ±nÄ±r kutusunu Ã§ok hassas bir ÅŸekilde belirlemesine izin vermez. Daha hassas bir konum belirlemek iÃ§in, sÄ±nÄ±r kutularÄ±nÄ±n koordinatlarÄ±nÄ± tahmin etmek Ã¼zere bir tÃ¼r **regresyon** Ã§alÄ±ÅŸtÄ±rmamÄ±z gerekir - ve bunun iÃ§in Ã¶zel veri setlerine ihtiyaÃ§ duyarÄ±z.

## Nesne Tespiti iÃ§in Regresyon

[Bu blog yazÄ±sÄ±](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491), ÅŸekilleri tespit etme konusunda harika bir giriÅŸ sunuyor.

## Nesne Tespiti iÃ§in Veri Setleri

Bu gÃ¶rev iÃ§in aÅŸaÄŸÄ±daki veri setleriyle karÅŸÄ±laÅŸabilirsiniz:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) - 20 sÄ±nÄ±f
* [COCO](http://cocodataset.org/#home) - BaÄŸlamdaki YaygÄ±n Nesneler. 80 sÄ±nÄ±f, sÄ±nÄ±r kutularÄ± ve segmentasyon maskeleri

![COCO](../../../../../translated_images/tr/coco-examples.71bc60380fa6cceb.webp)

## Nesne Tespiti Metrikleri

### KesiÅŸim BÃ¶lÃ¼ BirleÅŸim (IoU)

GÃ¶rÃ¼ntÃ¼ sÄ±nÄ±flandÄ±rma iÃ§in algoritmanÄ±n ne kadar iyi performans gÃ¶sterdiÄŸini Ã¶lÃ§mek kolaydÄ±r, ancak nesne tespiti iÃ§in hem sÄ±nÄ±fÄ±n doÄŸruluÄŸunu hem de tahmin edilen sÄ±nÄ±r kutusu konumunun hassasiyetini Ã¶lÃ§memiz gerekir. Ä°kincisi iÃ§in, **KesiÅŸim BÃ¶lÃ¼ BirleÅŸim** (IoU) adÄ± verilen bir Ã¶lÃ§Ã¼m kullanÄ±rÄ±z, bu iki kutunun (veya iki rastgele alanÄ±n) ne kadar iyi Ã¶rtÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼ Ã¶lÃ§er.

![IoU](../../../../../translated_images/tr/iou_equation.9a4751d40fff4e11.webp)

> *[Bu harika IoU blog yazÄ±sÄ±ndan](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/) alÄ±nan Åekil 2.*

Fikir basittir - iki ÅŸeklin kesiÅŸim alanÄ±nÄ± birleÅŸim alanÄ±na bÃ¶leriz. Ä°ki Ã¶zdeÅŸ alan iÃ§in IoU 1 olurken, tamamen ayrÄ±k alanlar iÃ§in 0 olur. DiÄŸer durumlarda 0 ile 1 arasÄ±nda deÄŸiÅŸir. Genellikle IoU belirli bir deÄŸerin Ã¼zerinde olan sÄ±nÄ±r kutularÄ±nÄ± dikkate alÄ±rÄ±z.

### Ortalama Hassasiyet (Average Precision)

Bir nesne sÄ±nÄ±fÄ± $C$'nin ne kadar iyi tanÄ±ndÄ±ÄŸÄ±nÄ± Ã¶lÃ§mek istediÄŸimizi varsayalÄ±m. Bunu Ã¶lÃ§mek iÃ§in **Ortalama Hassasiyet** metriÄŸini kullanÄ±rÄ±z, bu ÅŸu ÅŸekilde hesaplanÄ±r:

1. Hassasiyet-Tekrar Ã‡aÄŸÄ±rma eÄŸrisi, algÄ±lama eÅŸik deÄŸerine (0'dan 1'e kadar) baÄŸlÄ± olarak doÄŸruluÄŸu gÃ¶sterir.
2. EÅŸik deÄŸerine baÄŸlÄ± olarak, gÃ¶rÃ¼ntÃ¼de daha fazla veya daha az nesne algÄ±lanÄ±r ve farklÄ± hassasiyet ve tekrar Ã§aÄŸÄ±rma deÄŸerleri elde edilir.
3. EÄŸri ÅŸu ÅŸekilde gÃ¶rÃ¼nÃ¼r:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *GÃ¶rsel [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop) Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.*

Belirli bir sÄ±nÄ±f $C$ iÃ§in Ortalama Hassasiyet, bu eÄŸrinin altÄ±ndaki alandÄ±r. Daha spesifik olarak, Tekrar Ã‡aÄŸÄ±rma ekseni genellikle 10 parÃ§aya bÃ¶lÃ¼nÃ¼r ve Hassasiyet bu noktalarÄ±n tÃ¼mÃ¼ Ã¼zerinde ortalanÄ±r:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP ve IoU

Sadece IoU belirli bir deÄŸerin Ã¼zerinde olan algÄ±lamalarÄ± dikkate alacaÄŸÄ±z. Ã–rneÄŸin, PASCAL VOC veri setinde genellikle $\mbox{IoU Threshold} = 0.5$ varsayÄ±lÄ±rken, COCO'da AP farklÄ± $\mbox{IoU Threshold}$ deÄŸerleri iÃ§in Ã¶lÃ§Ã¼lÃ¼r.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *GÃ¶rsel [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop) Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.*

### Ortalama Ortalama Hassasiyet - mAP

Nesne Tespiti iÃ§in ana metrik **Ortalama Ortalama Hassasiyet** veya **mAP** olarak adlandÄ±rÄ±lÄ±r. Bu, tÃ¼m nesne sÄ±nÄ±flarÄ± ve bazen de $\mbox{IoU Threshold}$ Ã¼zerinde ortalanmÄ±ÅŸ Ortalama Hassasiyet deÄŸeridir. **mAP** hesaplama sÃ¼reci daha ayrÄ±ntÄ±lÄ± olarak
[bu blog yazÄ±sÄ±nda](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3)) ve ayrÄ±ca [kod Ã¶rnekleriyle burada](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734) aÃ§Ä±klanmÄ±ÅŸtÄ±r.

## FarklÄ± Nesne Tespiti YaklaÅŸÄ±mlarÄ±

Nesne tespiti algoritmalarÄ± iki geniÅŸ sÄ±nÄ±fa ayrÄ±lÄ±r:

* **BÃ¶lge Ã–neri AÄŸlarÄ±** (R-CNN, Fast R-CNN, Faster R-CNN). Ana fikir, **Ä°lgi AlanlarÄ±** (ROI) oluÅŸturmak ve maksimum aktivasyonu aramak iÃ§in CNN Ã§alÄ±ÅŸtÄ±rmaktÄ±r. Bu, naif yaklaÅŸÄ±ma biraz benzer, ancak ROI'ler daha akÄ±llÄ±ca oluÅŸturulur. Bu tÃ¼r yÃ¶ntemlerin en bÃ¼yÃ¼k dezavantajlarÄ±ndan biri, yavaÅŸ olmalarÄ±dÄ±r Ã§Ã¼nkÃ¼ gÃ¶rÃ¼ntÃ¼ Ã¼zerinde CNN sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±nÄ±n birÃ§ok geÃ§iÅŸine ihtiyaÃ§ duyarÄ±z.
* **Tek geÃ§iÅŸ** (YOLO, SSD, RetinaNet) yÃ¶ntemleri. Bu mimarilerde, aÄŸ hem sÄ±nÄ±flarÄ± hem de ROI'leri tek bir geÃ§iÅŸte tahmin edecek ÅŸekilde tasarlanÄ±r.

### R-CNN: BÃ¶lge TabanlÄ± CNN

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf), ROI bÃ¶lgelerinin hiyerarÅŸik yapÄ±sÄ±nÄ± oluÅŸturmak iÃ§in [Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) kullanÄ±r. Bu bÃ¶lgeler daha sonra CNN Ã¶zellik Ã§Ä±karÄ±cÄ±larÄ± ve SVM sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± aracÄ±lÄ±ÄŸÄ±yla nesne sÄ±nÄ±fÄ±nÄ± belirlemek ve *sÄ±nÄ±r kutusu* koordinatlarÄ±nÄ± belirlemek iÃ§in doÄŸrusal regresyon ile iÅŸlenir. [Resmi Makale](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/tr/rcnn1.cae407020dfb1d1f.webp)

> *GÃ¶rsel van de Sande ve ark. ICCVâ€™11'dan alÄ±nmÄ±ÅŸtÄ±r.*

![RCNN-1](../../../../../translated_images/tr/rcnn2.2d9530bb83516484.webp)

> *GÃ¶rseller [bu blogdan](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) alÄ±nmÄ±ÅŸtÄ±r.*

### F-RCNN - HÄ±zlÄ± R-CNN

Bu yaklaÅŸÄ±m R-CNN'e benzer, ancak bÃ¶lgeler konvolÃ¼syon katmanlarÄ± uygulandÄ±ktan sonra tanÄ±mlanÄ±r.

![FRCNN](../../../../../translated_images/tr/f-rcnn.3cda6d9bb4188875.webp)

> GÃ¶rsel [Resmi Makale](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015 Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.

### Daha HÄ±zlÄ± R-CNN

Bu yaklaÅŸÄ±mÄ±n ana fikri, ROI'leri tahmin etmek iÃ§in sinir aÄŸÄ± kullanmaktÄ±r - *BÃ¶lge Ã–neri AÄŸÄ±* olarak adlandÄ±rÄ±lÄ±r. [Makale](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../translated_images/tr/faster-rcnn.8d46c099b87ef30a.webp)

> GÃ¶rsel [Resmi Makale](https://arxiv.org/pdf/1506.01497.pdf) Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.

### R-FCN: BÃ¶lge TabanlÄ± Tam KonvolÃ¼syonel AÄŸ

Bu algoritma, Daha HÄ±zlÄ± R-CNN'den bile daha hÄ±zlÄ±dÄ±r. Ana fikir ÅŸu ÅŸekildedir:

1. Ã–zellikler ResNet-101 kullanÄ±larak Ã§Ä±karÄ±lÄ±r.
2. Ã–zellikler **Pozisyon-DuyarlÄ± Skor HaritasÄ±** tarafÄ±ndan iÅŸlenir. $C$ sÄ±nÄ±flarÄ±ndan her bir nesne $k\times k$ bÃ¶lgelere ayrÄ±lÄ±r ve nesne parÃ§alarÄ±nÄ± tahmin etmek iÃ§in eÄŸitim yapÄ±lÄ±r.
3. $k\times k$ bÃ¶lgelerden her bir parÃ§a iÃ§in tÃ¼m aÄŸlar nesne sÄ±nÄ±flarÄ± iÃ§in oy kullanÄ±r ve maksimum oyu alan nesne sÄ±nÄ±fÄ± seÃ§ilir.

![r-fcn image](../../../../../translated_images/tr/r-fcn.13eb88158b99a3da.webp)

> GÃ¶rsel [Resmi Makale](https://arxiv.org/abs/1605.06409) Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.

### YOLO - Sadece Bir Kez Bak

YOLO, gerÃ§ek zamanlÄ± tek geÃ§iÅŸli bir algoritmadÄ±r. Ana fikir ÅŸu ÅŸekildedir:

 * GÃ¶rÃ¼ntÃ¼ $S\times S$ bÃ¶lgelere ayrÄ±lÄ±r.
 * Her bÃ¶lge iÃ§in **CNN**, $n$ olasÄ± nesneleri, *sÄ±nÄ±r kutusu* koordinatlarÄ±nÄ± ve *gÃ¼ven* = *olasÄ±lÄ±k* * IoU tahmin eder.

 ![YOLO](../../../../../translated_images/tr/yolo.a2648ec82ee8bb4e.webp)

> GÃ¶rsel [Resmi Makale](https://arxiv.org/abs/1506.02640) Ã¼zerinden alÄ±nmÄ±ÅŸtÄ±r.

### DiÄŸer Algoritmalar

* RetinaNet: [Resmi Makale](https://arxiv.org/abs/1708.02002)
   - [Torchvision'da PyTorch UygulamasÄ±](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Keras UygulamasÄ±](https://github.com/fizyr/keras-retinanet)
   - [Keras Ã–rneklerinde RetinaNet ile Nesne Tespiti](https://keras.io/examples/vision/retinanet/)
* SSD (Tek AtÄ±ÅŸ DedektÃ¶rÃ¼): [Resmi Makale](https://arxiv.org/abs/1512.02325)

## âœï¸ Egzersizler: Nesne Tespiti

Ã–ÄŸreniminize aÅŸaÄŸÄ±daki defterde devam edin:

[ObjectDetection.ipynb](ObjectDetection.ipynb)

## SonuÃ§

Bu derste, nesne tespitinin Ã§eÅŸitli yollarÄ±nÄ± hÄ±zlÄ± bir ÅŸekilde gÃ¶zden geÃ§irdiniz!

## ğŸš€ Meydan Okuma

Bu makaleleri ve defterleri YOLO hakkÄ±nda okuyun ve kendiniz deneyin:

* [YOLO'yu aÃ§Ä±klayan iyi bir blog yazÄ±sÄ±](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/)
 * [Resmi site](https://pjreddie.com/darknet/yolo/)
 * Yolo: [Keras uygulamasÄ±](https://github.com/experiencor/keras-yolo2), [adÄ±m adÄ±m defter](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * Yolo v2: [Keras uygulamasÄ±](https://github.com/experiencor/keras-yolo2), [adÄ±m adÄ±m defter](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [Ders SonrasÄ± Test](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

* [Nesne Tespiti](https://tjmachinelearning.com/lectures/1718/obj/) - Nikhil Sardana
* [Nesne tespiti algoritmalarÄ±nÄ±n iyi bir karÅŸÄ±laÅŸtÄ±rmasÄ±](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [Nesne Tespiti iÃ§in Derin Ã–ÄŸrenme AlgoritmalarÄ±nÄ±n Ä°ncelemesi](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [Temel Nesne Tespiti AlgoritmalarÄ±na AdÄ±m AdÄ±m GiriÅŸ](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Python'da Nesne Tespiti iÃ§in Daha HÄ±zlÄ± R-CNN UygulamasÄ±](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [Ã–dev: Nesne Tespiti](lab/README.md)

---

