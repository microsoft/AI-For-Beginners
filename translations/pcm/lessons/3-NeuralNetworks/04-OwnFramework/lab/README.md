<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "48fdd704d483e19bc3d7464074c9fcbe",
  "translation_date": "2025-11-18T18:27:33+00:00",
  "source_file": "lessons/3-NeuralNetworks/04-OwnFramework/lab/README.md",
  "language_code": "pcm"
}
-->
# MNIST Classification wit Our Own Framework

Lab Assignment from [AI for Beginners Curriculum](https://github.com/microsoft/ai-for-beginners).

## Task

Solve di MNIST handwritten digit classification problem wit 1-, 2- and 3-layered perceptron. Use di neural network framework wey we don develop for di lesson.

## Stating Notebook

Start di lab by opening [MyFW_MNIST.ipynb](MyFW_MNIST.ipynb)

## Questions

As di result of dis lab, try answer di following questions:

- Di inter-layer activation function dey affect di network performance?
- We need 2- or 3-layered network for dis task?
- You experience any wahala to train di network? Especially as di number of layers increase.
- How di weights of di network dey behave during training? You fit plot di max abs value of weights vs. epoch to understand di relation.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Disclaimer**:  
Dis dokyument don use AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator) take translate am. Even though we dey try make sure say e correct, abeg sabi say automatic translation fit get mistake or no dey accurate well. Di original dokyument for im native language na di main correct source. For important information, e go beta make professional human translator check am. We no go fit hold responsibility for any misunderstanding or wrong interpretation wey fit happen because you use dis translation.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->