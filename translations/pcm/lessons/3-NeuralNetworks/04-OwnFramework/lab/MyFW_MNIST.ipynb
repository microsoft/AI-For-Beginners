{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification wit our own Framework\n",
    "\n",
    "Lab Assignment from [AI for Beginners Curriculum](https://github.com/microsoft/ai-for-beginners).\n",
    "\n",
    "### Reading the Dataset\n",
    "\n",
    "Dis code go download di dataset from di repository wey dey online. You fit also manually copy di dataset from `/data` directory for AI Curriculum repo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  9.9M  100  9.9M    0     0   9.9M      0  0:00:01 --:--:--  0:00:01 15.8M\n"
     ]
    }
   ],
   "source": [
    "!rm *.pkl\n",
    "!wget https://raw.githubusercontent.com/microsoft/AI-For-Beginners/main/data/mnist.pkl.gz\n",
    "!gzip -d mnist.pkl.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mnist.pkl','rb') as f:\n",
    "    MNIST = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = MNIST['Train']['Labels']\n",
    "data = MNIST['Train']['Features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make we see wetin be di shape of di data wey we get:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How we go take share di Data\n",
    "\n",
    "We go use Scikit Learn to share di data between training and test dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 33600, test samples: 8400\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(data,labels,test_size=0.2)\n",
    "\n",
    "print(f\"Train samples: {len(features_train)}, test samples: {len(features_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "1. Carry di framework code wey dey di lesson put for dis notebook, or (better sef) put am for separate Python module\n",
    "1. Define and train one-layered perceptron, dey look di training and validation accuracy as e dey train\n",
    "1. Try understand if overfitting happen, and adjust di layer parameters to make accuracy better\n",
    "1. Repeat di steps wey dey before for 2- and 3-layered perceptrons. Try experiment with different activation functions between di layers.\n",
    "1. Try answer di questions wey dey below:\n",
    "    - Di activation function wey dey between di layers, e dey affect di network performance?\n",
    "    - We need 2- or 3-layered network for dis task?\n",
    "    - You experience any wahala to train di network? Especially as di number of layers increase.\n",
    "    - How di weights of di network dey behave as e dey train? You fit plot di max abs value of weights vs. epoch to understand di relationship.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:  \nDis dokyument don use AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator) do di translation. Even as we dey try make am accurate, abeg sabi say automated translations fit get mistake or no dey correct well. Di original dokyument for im native language na di main source wey you go trust. For important information, e better make professional human translation dey use. We no go fit take blame for any misunderstanding or wrong interpretation wey fit happen because you use dis translation.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "coopTranslator": {
   "original_hash": "6fa055f484eb5d6bdf41166a356d3abf",
   "translation_date": "2025-11-18T19:13:16+00:00",
   "source_file": "lessons/3-NeuralNetworks/04-OwnFramework/lab/MyFW_MNIST.ipynb",
   "language_code": "pcm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}