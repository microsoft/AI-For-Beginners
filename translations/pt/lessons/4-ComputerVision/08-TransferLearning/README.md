# Redes Neurais Pr√©-treinadas e Aprendizado por Transfer√™ncia

Treinar CNNs pode levar muito tempo, e uma grande quantidade de dados √© necess√°ria para essa tarefa. No entanto, muito do tempo √© gasto aprendendo os melhores filtros de baixo n√≠vel que uma rede pode usar para extrair padr√µes de imagens. Surge uma pergunta natural - podemos usar uma rede neural treinada em um conjunto de dados e adapt√°-la para classificar diferentes imagens sem precisar de um processo de treinamento completo?

## [Quiz pr√©-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Essa abordagem √© chamada de **aprendizado por transfer√™ncia**, porque transferimos algum conhecimento de um modelo de rede neural para outro. No aprendizado por transfer√™ncia, normalmente come√ßamos com um modelo pr√©-treinado, que foi treinado em algum grande conjunto de dados de imagens, como **ImageNet**. Esses modelos j√° podem fazer um bom trabalho extraindo diferentes caracter√≠sticas de imagens gen√©ricas, e em muitos casos, apenas construir um classificador em cima dessas caracter√≠sticas extra√≠das pode resultar em um bom resultado.

> ‚úÖ Aprendizado por Transfer√™ncia √© um termo que voc√™ encontra em outros campos acad√™micos, como Educa√ß√£o. Refere-se ao processo de levar conhecimento de um dom√≠nio e aplic√°-lo a outro.

## Modelos Pr√©-Treinados como Extratores de Caracter√≠sticas

As redes convolucionais que discutimos na se√ß√£o anterior continham uma s√©rie de camadas, cada uma das quais deve extrair algumas caracter√≠sticas da imagem, come√ßando por combina√ß√µes de pixels de baixo n√≠vel (como linha horizontal/vertical ou tra√ßo), at√© combina√ß√µes de caracter√≠sticas de n√≠vel mais alto, correspondendo a coisas como o olho de uma chama. Se treinarmos uma CNN em um conjunto de dados suficientemente grande de imagens gen√©ricas e diversas, a rede deve aprender a extrair essas caracter√≠sticas comuns.

Tanto Keras quanto PyTorch cont√™m fun√ß√µes para carregar facilmente pesos de redes neurais pr√©-treinadas para algumas arquiteturas comuns, a maioria das quais foi treinada em imagens do ImageNet. As mais frequentemente usadas est√£o descritas na p√°gina de [Arquiteturas CNN](../07-ConvNets/CNN_Architectures.md) da li√ß√£o anterior. Em particular, voc√™ pode considerar usar uma das seguintes:

* **VGG-16/VGG-19**, que s√£o modelos relativamente simples que ainda oferecem boa precis√£o. Muitas vezes, usar VGG como uma primeira tentativa √© uma boa escolha para ver como o aprendizado por transfer√™ncia funciona.
* **ResNet** √© uma fam√≠lia de modelos proposta pela Microsoft Research em 2015. Eles t√™m mais camadas e, portanto, consomem mais recursos.
* **MobileNet** √© uma fam√≠lia de modelos com tamanho reduzido, adequada para dispositivos m√≥veis. Use-os se voc√™ estiver com recursos limitados e puder sacrificar um pouco de precis√£o.

Aqui est√£o amostras de caracter√≠sticas extra√≠das de uma imagem de um gato pela rede VGG-16:

![Caracter√≠sticas extra√≠das pela VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.pt.png)

## Conjunto de Dados de Gatos vs. Cachorros

Neste exemplo, usaremos um conjunto de dados de [Gatos e Cachorros](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), que √© muito pr√≥ximo de um cen√°rio real de classifica√ß√£o de imagens.

## ‚úçÔ∏è Exerc√≠cio: Aprendizado por Transfer√™ncia

Vamos ver o aprendizado por transfer√™ncia em a√ß√£o nos cadernos correspondentes:

* [Aprendizado por Transfer√™ncia - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Aprendizado por Transfer√™ncia - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Visualizando o Gato Adversarial

A rede neural pr√©-treinada cont√©m diferentes padr√µes dentro de seu *c√©rebro*, incluindo no√ß√µes de **gato ideal** (assim como cachorro ideal, zebra ideal, etc.). Seria interessante de alguma forma **visualizar essa imagem**. No entanto, n√£o √© simples, porque os padr√µes est√£o espalhados por todo o peso da rede e tamb√©m organizados em uma estrutura hier√°rquica.

Uma abordagem que podemos adotar √© come√ßar com uma imagem aleat√≥ria e, em seguida, tentar usar a t√©cnica de **otimiza√ß√£o por descida de gradiente** para ajustar essa imagem de tal forma que a rede comece a pensar que √© um gato.

![Loop de Otimiza√ß√£o de Imagem](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.pt.png)

No entanto, se fizermos isso, receberemos algo muito semelhante a um ru√≠do aleat√≥rio. Isso ocorre porque *existem muitas maneiras de fazer a rede pensar que a imagem de entrada √© um gato*, incluindo algumas que n√£o fazem sentido visualmente. Embora essas imagens contenham muitos padr√µes t√≠picos de um gato, n√£o h√° nada que as restrinja a serem visualmente distintas.

Para melhorar o resultado, podemos adicionar outro termo √† fun√ß√£o de perda, que √© chamado de **perda de varia√ß√£o**. √â uma m√©trica que mostra qu√£o semelhantes s√£o os pixels vizinhos da imagem. Minimizar a perda de varia√ß√£o torna a imagem mais suave e elimina o ru√≠do - revelando assim padr√µes visualmente mais agrad√°veis. Aqui est√° um exemplo de tais imagens "ideais", que s√£o classificadas como gato e como zebra com alta probabilidade:

![Gato Ideal](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.pt.png) | ![Zebra Ideal](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.pt.png)
-----|-----
 *Gato Ideal* | *Zebra Ideal*

Uma abordagem semelhante pode ser usada para realizar os chamados **ataques adversariais** em uma rede neural. Suponha que queiramos enganar uma rede neural e fazer um cachorro parecer um gato. Se pegarmos a imagem de um cachorro, que √© reconhecida pela rede como um cachorro, podemos ent√£o ajust√°-la um pouco usando otimiza√ß√£o por descida de gradiente, at√© que a rede comece a classific√°-la como um gato:

![Imagem de um Cachorro](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.pt.png) | ![Imagem de um cachorro classificada como gato](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.pt.png)
-----|-----
*Imagem original de um cachorro* | *Imagem de um cachorro classificada como gato*

Veja o c√≥digo para reproduzir os resultados acima no seguinte caderno:

* [Gato Ideal e Adversarial - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## Conclus√£o

Usando aprendizado por transfer√™ncia, voc√™ pode rapidamente montar um classificador para uma tarefa de classifica√ß√£o de objetos personalizada e alcan√ßar alta precis√£o. Voc√™ pode ver que tarefas mais complexas que estamos resolvendo agora requerem maior poder computacional e n√£o podem ser facilmente resolvidas na CPU. Na pr√≥xima unidade, tentaremos usar uma implementa√ß√£o mais leve para treinar o mesmo modelo usando recursos computacionais menores, o que resulta em uma precis√£o apenas ligeiramente inferior.

## üöÄ Desafio

Nos cadernos acompanhantes, h√° notas na parte inferior sobre como o conhecimento de transfer√™ncia funciona melhor com dados de treinamento um tanto semelhantes (um novo tipo de animal, talvez). Fa√ßa algumas experimenta√ß√µes com tipos de imagens completamente novos para ver qu√£o bem ou mal seus modelos de conhecimento de transfer√™ncia se saem.

## [Quiz p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Revis√£o & Autoestudo

Leia [TrainingTricks.md](TrainingTricks.md) para aprofundar seu conhecimento sobre algumas outras maneiras de treinar seus modelos.

## [Tarefa](lab/README.md)

Neste laborat√≥rio, usaremos um conjunto de dados de animais de estima√ß√£o da vida real [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) com 35 ra√ßas de gatos e cachorros, e construiremos um classificador de aprendizado por transfer√™ncia.

**Aviso Legal**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes do uso desta tradu√ß√£o.