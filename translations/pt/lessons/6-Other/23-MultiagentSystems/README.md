# Sistemas Multi-Agente

Uma das poss√≠veis maneiras de alcan√ßar intelig√™ncia √© a chamada abordagem **emergente** (ou **sinerg√©tica**), que se baseia no fato de que o comportamento combinado de muitos agentes relativamente simples pode resultar em um comportamento mais complexo (ou inteligente) do sistema como um todo. Teoricamente, isso se baseia nos princ√≠pios da [Intelig√™ncia Coletiva](https://en.wikipedia.org/wiki/Collective_intelligence), [Emergentismo](https://en.wikipedia.org/wiki/Global_brain) e [Cibern√©tica Evolutiva](https://en.wikipedia.org/wiki/Global_brain), que afirmam que sistemas de n√≠vel superior ganham algum tipo de valor agregado quando s√£o devidamente combinados a partir de sistemas de n√≠vel inferior (o chamado *princ√≠pio da transi√ß√£o de metasistema*).

## [Quiz pr√©-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/123)

A dire√ß√£o dos **Sistemas Multi-Agente** surgiu na IA na d√©cada de 1990 como uma resposta ao crescimento da Internet e de sistemas distribu√≠dos. Um dos cl√°ssicos livros did√°ticos de IA, [Intelig√™ncia Artificial: Uma Abordagem Moderna](https://en.wikipedia.org/wiki/Artificial_Intelligence:_A_Modern_Approach), foca na vis√£o da IA cl√°ssica sob a perspectiva dos sistemas multi-agente.

Central para a abordagem multi-agente √© a no√ß√£o de **Agente** - uma entidade que vive em algum **ambiente**, que pode perceber e agir sobre. Esta √© uma defini√ß√£o muito ampla, e pode haver muitos tipos e classifica√ß√µes de agentes:

* Pela sua capacidade de racioc√≠nio:
   - Agentes **Reativos** geralmente t√™m um comportamento simples do tipo solicita√ß√£o-resposta
   - Agentes **Deliberativos** empregam algum tipo de racioc√≠nio l√≥gico e/ou capacidades de planejamento
* Pelo local onde o agente executa seu c√≥digo:
   - Agentes **Est√°ticos** trabalham em um n√≥ de rede dedicado
   - Agentes **M√≥veis** podem mover seu c√≥digo entre n√≥s de rede
* Pelo seu comportamento:
   - Agentes **Passivos** n√£o t√™m objetivos espec√≠ficos. Esses agentes podem reagir a est√≠mulos externos, mas n√£o iniciar√£o a√ß√µes por conta pr√≥pria.
   - Agentes **Ativos** t√™m alguns objetivos que perseguem
   - Agentes **Cognitivos** envolvem planejamento e racioc√≠nio complexos

Os sistemas multi-agente s√£o hoje utilizados em uma s√©rie de aplica√ß√µes:

* Em jogos, muitos personagens n√£o jog√°veis empregam algum tipo de IA e podem ser considerados agentes inteligentes
* Na produ√ß√£o de v√≠deo, a renderiza√ß√£o de cenas 3D complexas que envolvem multid√µes √© tipicamente feita usando simula√ß√£o multi-agente
* Na modelagem de sistemas, a abordagem multi-agente √© utilizada para simular o comportamento de um modelo complexo. Por exemplo, a abordagem multi-agente foi usada com sucesso para prever a dissemina√ß√£o da doen√ßa COVID-19 em todo o mundo. Uma abordagem semelhante pode ser usada para modelar o tr√°fego na cidade e ver como ele reage a mudan√ßas nas regras de tr√¢nsito.
* Em sistemas de automa√ß√£o complexos, cada dispositivo pode agir como um agente independente, o que torna todo o sistema menos monol√≠tico e mais robusto.

N√£o vamos gastar muito tempo aprofundando em sistemas multi-agente, mas consideraremos um exemplo de **Modelagem Multi-Agente**.

## NetLogo

[NetLogo](https://ccl.northwestern.edu/netlogo/) √© um ambiente de modelagem multi-agente baseado em uma vers√£o modificada da linguagem de programa√ß√£o [Logo](https://en.wikipedia.org/wiki/Logo_(programming_language)). Esta linguagem foi desenvolvida para ensinar conceitos de programa√ß√£o para crian√ßas, e permite que voc√™ controle um agente chamado **tartaruga**, que pode se mover, deixando um rastro para tr√°s. Isso permite a cria√ß√£o de figuras geom√©tricas complexas, que √© uma maneira muito visual de entender o comportamento de um agente.

No NetLogo, podemos criar muitas tartarugas usando o comando `create-turtles`. Podemos ent√£o comandar todas as tartarugas a realizar algumas a√ß√µes (no exemplo abaixo - mais 10 pontos para frente):

```
create-turtles 10
ask turtles [
  forward 10
]
```

Claro, n√£o √© interessante quando todas as tartarugas fazem a mesma coisa, ent√£o podemos `ask ` groups of turtles, eg. those who are in the vicinity of a certain point. We can also create turtles of different *breeds* using `breed [cats cat]` command. Here `cat` √© o nome de uma ra√ßa, e precisamos especificar tanto a forma singular quanto a plural, porque diferentes comandos usam diferentes formas para clareza.

> ‚úÖ N√£o vamos nos aprofundar no aprendizado da linguagem NetLogo em si - voc√™ pode visitar o brilhante [Dicion√°rio Interativo para Iniciantes do NetLogo](https://ccl.northwestern.edu/netlogo/bind/) se estiver interessado em aprender mais.

Voc√™ pode [baixar](https://ccl.northwestern.edu/netlogo/download.shtml) e instalar o NetLogo para experimentar.

### Biblioteca de Modelos

Uma grande coisa sobre o NetLogo √© que ele cont√©m uma biblioteca de modelos funcionais que voc√™ pode experimentar. V√° para **Arquivo ‚Üí Biblioteca de Modelos**, e voc√™ ter√° muitas categorias de modelos para escolher.

<img alt="Biblioteca de Modelos do NetLogo" src="images/NetLogo-ModelLib.png" width="60%"/>

> Uma captura de tela da biblioteca de modelos por Dmitry Soshnikov

Voc√™ pode abrir um dos modelos, por exemplo **Biologia ‚Üí Flocking**.

### Princ√≠pios Principais

Ap√≥s abrir o modelo, voc√™ √© levado √† tela principal do NetLogo. Aqui est√° um modelo de exemplo que descreve a popula√ß√£o de lobos e ovelhas, dado recursos finitos (grama).

![Tela Principal do NetLogo](../../../../../translated_images/NetLogo-Main.32653711ec1a01b3cab22ec0b148e64193d0b979b055285bef329d5e3d6958c5.pt.png)

> Captura de tela por Dmitry Soshnikov

Nesta tela, voc√™ pode ver:

* A se√ß√£o **Interface** que cont√©m:
  - O campo principal, onde todos os agentes vivem
  - Diferentes controles: bot√µes, deslizadores, etc.
  - Gr√°ficos que voc√™ pode usar para exibir par√¢metros da simula√ß√£o
* A aba **C√≥digo** que cont√©m o editor, onde voc√™ pode digitar o programa NetLogo

Na maioria dos casos, a interface teria um bot√£o **Configurar**, que inicializa o estado da simula√ß√£o, e um bot√£o **Executar** que inicia a execu√ß√£o. Esses s√£o gerenciados pelos manipuladores correspondentes no c√≥digo que se parecem com isso:

```
to go [
...
]
```

O mundo do NetLogo consiste nos seguintes objetos:

* **Agentes** (tartarugas) que podem se mover pelo campo e fazer algo. Voc√™ comanda os agentes usando `ask turtles [...]` syntax, and the code in brackets is executed by all agents in *turtle mode*.
* **Patches** are square areas of the field, on which agents live. You can refer to all agents on the same patch, or you can change patch colors and some other properties. You can also `ask patches` para fazer algo.
* **Observador** √© um agente √∫nico que controla o mundo. Todos os manipuladores de bot√µes s√£o executados no *modo observador*.

> ‚úÖ A beleza de um ambiente multi-agente √© que o c√≥digo que √© executado no modo tartaruga ou no modo patch √© executado ao mesmo tempo por todos os agentes em paralelo. Assim, ao escrever um pouco de c√≥digo e programar o comportamento de um agente individual, voc√™ pode criar um comportamento complexo do sistema de simula√ß√£o como um todo.

### Flocking

Como um exemplo de comportamento multi-agente, vamos considerar **[Flocking](https://en.wikipedia.org/wiki/Flocking_(behavior))**. O Flocking √© um padr√£o complexo que √© muito semelhante a como bandos de p√°ssaros voam. Ao observ√°-los voar, voc√™ pode pensar que eles seguem algum tipo de algoritmo coletivo ou que possuem alguma forma de *intelig√™ncia coletiva*. No entanto, esse comportamento complexo surge quando cada agente individual (neste caso, um *p√°ssaro*) apenas observa alguns outros agentes a uma curta dist√¢ncia dele e segue tr√™s regras simples:

* **Alinhamento** - ele se dirige para a m√©dia da dire√ß√£o dos agentes vizinhos
* **Coes√£o** - ele tenta se dirigir para a posi√ß√£o m√©dia dos vizinhos (*atra√ß√£o de longo alcance*)
* **Separa√ß√£o** - ao se aproximar demais de outros p√°ssaros, ele tenta se afastar (*repuls√£o de curto alcance*)

Voc√™ pode executar o exemplo de flocking e observar o comportamento. Voc√™ tamb√©m pode ajustar par√¢metros, como *grau de separa√ß√£o* ou *alcance de vis√£o*, que define qu√£o longe cada p√°ssaro pode ver. Observe que, se voc√™ diminuir o alcance de vis√£o para 0, todos os p√°ssaros ficam cegos, e o flocking para. Se voc√™ diminuir a separa√ß√£o para 0, todos os p√°ssaros se re√∫nem em uma linha reta.

> ‚úÖ Mude para a aba **C√≥digo** e veja onde as tr√™s regras de flocking (alinhamento, coes√£o e separa√ß√£o) est√£o implementadas no c√≥digo. Observe como nos referimos apenas √†queles agentes que est√£o √† vista.

### Outros Modelos para Ver

Existem mais alguns modelos interessantes que voc√™ pode experimentar:

* **Arte ‚Üí Fogos de Artif√≠cio** mostra como um fogo de artif√≠cio pode ser considerado um comportamento coletivo de fluxos individuais de fogo
* **Ci√™ncia Social ‚Üí Tr√°fego B√°sico** e **Ci√™ncia Social ‚Üí Grade de Tr√°fego** mostram o modelo de tr√°fego urbano em Grade 1D e 2D com ou sem sem√°foros. Cada carro na simula√ß√£o segue as seguintes regras:
   - Se o espa√ßo √† sua frente estiver vazio - acelere (at√© uma certa velocidade m√°xima)
   - Se ele v√™ um obst√°culo √† frente - freie (e voc√™ pode ajustar qu√£o longe um motorista pode ver)
* **Ci√™ncia Social ‚Üí Festa** mostra como as pessoas se agrupam durante uma festa de coquetel. Voc√™ pode encontrar a combina√ß√£o de par√¢metros que leva ao aumento mais r√°pido da felicidade do grupo.

Como voc√™ pode ver por esses exemplos, simula√ß√µes multi-agente podem ser uma maneira bastante √∫til de entender o comportamento de um sistema complexo composto por indiv√≠duos que seguem a mesma l√≥gica ou l√≥gica semelhante. Tamb√©m pode ser usado para controlar agentes virtuais, como [NPCs](https://en.wikipedia.org/wiki/NPC) em jogos de computador, ou agentes em mundos animados em 3D.

## Agentes Deliberativos

Os agentes descritos acima s√£o muito simples, reagindo a mudan√ßas no ambiente usando algum tipo de algoritmo. Como tal, eles s√£o **agentes reativos**. No entanto, √†s vezes os agentes podem raciocinar e planejar suas a√ß√µes, caso em que s√£o chamados de **deliberativos**.

Um exemplo t√≠pico seria um agente pessoal que recebe uma instru√ß√£o de um humano para reservar uma viagem de f√©rias. Suponha que existam muitos agentes que vivem na internet, que podem ajud√°-lo. Ele deve ent√£o entrar em contato com outros agentes para ver quais voos est√£o dispon√≠veis, quais s√£o os pre√ßos dos hot√©is para diferentes datas e tentar negociar o melhor pre√ßo. Quando o plano de f√©rias estiver completo e confirmado pelo propriet√°rio, ele pode prosseguir com a reserva.

Para fazer isso, os agentes precisam **se comunicar**. Para uma comunica√ß√£o bem-sucedida, eles precisam de:

* Algumas **l√≠nguas padr√£o para trocar conhecimento**, como [Formato de Interc√¢mbio de Conhecimento](https://en.wikipedia.org/wiki/Knowledge_Interchange_Format) (KIF) e [Linguagem de Consulta e Manipula√ß√£o de Conhecimento](https://en.wikipedia.org/wiki/Knowledge_Query_and_Manipulation_Language) (KQML). Essas linguagens s√£o projetadas com base na [Teoria do Ato de Fala](https://en.wikipedia.org/wiki/Speech_act).
* Essas linguagens tamb√©m devem incluir alguns **protocolos para negocia√ß√µes**, baseados em diferentes **tipos de leil√£o**.
* Uma **ontologia comum** para usar, para que eles se refiram aos mesmos conceitos conhecendo sua sem√¢ntica
* Uma maneira de **descobrir** o que diferentes agentes podem fazer, tamb√©m baseada em algum tipo de ontologia

Agentes deliberativos s√£o muito mais complexos do que reativos, porque eles n√£o apenas reagem a mudan√ßas no ambiente, mas tamb√©m devem ser capazes de *iniciar* a√ß√µes. Uma das arquiteturas propostas para agentes deliberativos √© a chamada agente de Cren√ßa-Desejo-Inten√ß√£o (BDI):

* **Cren√ßas** formam um conjunto de conhecimentos sobre o ambiente de um agente. Pode ser estruturado como uma base de conhecimento ou um conjunto de regras que um agente pode aplicar a uma situa√ß√£o espec√≠fica no ambiente.
* **Desejos** definem o que um agente quer fazer, ou seja, seus objetivos. Por exemplo, o objetivo do agente assistente pessoal acima √© reservar uma viagem, e o objetivo de um agente de hotel √© maximizar o lucro.
* **Inten√ß√µes** s√£o a√ß√µes espec√≠ficas que um agente planeja realizar para alcan√ßar seus objetivos. As a√ß√µes normalmente mudam o ambiente e causam comunica√ß√£o com outros agentes.

Existem algumas plataformas dispon√≠veis para construir sistemas multi-agente, como [JADE](https://jade.tilab.com/). [Este artigo](https://arxiv.org/ftp/arxiv/papers/2007/2007.08961.pdf) cont√©m uma revis√£o das plataformas multi-agente, juntamente com uma breve hist√≥ria dos sistemas multi-agente e seus diferentes cen√°rios de uso.

## Conclus√£o

Os sistemas multi-agente podem assumir formas muito diferentes e ser usados em muitas aplica√ß√µes diferentes. 
Todos tendem a focar no comportamento mais simples de um agente individual e alcan√ßar um comportamento mais complexo do sistema geral devido ao **efeito sin√©rgico**.

## üöÄ Desafio

Leve esta li√ß√£o para o mundo real e tente conceituar um sistema multi-agente que possa resolver um problema. O que, por exemplo, um sistema multi-agente precisaria fazer para otimizar a rota de um √¥nibus escolar? Como ele poderia funcionar em uma padaria?

## [Quiz p√≥s-aula](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/223)

## Revis√£o e Autoestudo

Revise o uso desse tipo de sistema na ind√∫stria. Escolha um dom√≠nio como fabrica√ß√£o ou a ind√∫stria de videogames e descubra como os sistemas multi-agente podem ser usados para resolver problemas √∫nicos.

## [Tarefa NetLogo](assignment.md)

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.