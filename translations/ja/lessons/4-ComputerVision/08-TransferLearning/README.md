# 事前学習済みネットワークと転移学習

CNNのトレーニングには多くの時間がかかり、また大量のデータが必要です。しかし、ネットワークが画像からパターンを抽出するための最適な低レベルフィルターを学習することに多くの時間が費やされています。そこで自然に生じる疑問は、あるデータセットでトレーニングされたニューラルネットワークを使って、完全なトレーニングプロセスを必要とせずに異なる画像を分類することができるかということです。

## [事前講義クイズ](https://ff-quizzes.netlify.app/en/ai/quiz/15)

このアプローチは**転移学習**と呼ばれます。これは、あるニューラルネットワークモデルから別のモデルへ知識を転移することを指します。転移学習では、通常、**ImageNet**のような大規模な画像データセットでトレーニングされた事前学習済みモデルを使用します。これらのモデルはすでに一般的な画像からさまざまな特徴を抽出する能力を持っており、多くの場合、それらの抽出された特徴の上に分類器を構築するだけで良い結果が得られます。

> ✅ 転移学習は教育学など他の学問分野でも見られる用語です。ある領域で得た知識を別の領域に応用するプロセスを指します。

## 事前学習済みモデルを特徴抽出器として使用する

前のセクションで説明した畳み込みネットワークは、画像から特徴を抽出するための複数の層を含んでいます。これらの層は、低レベルのピクセルの組み合わせ（水平線や垂直線、ストロークなど）から始まり、最終的には炎の目のような高レベルの特徴の組み合わせに至ります。十分に大きく多様な画像データセットでCNNをトレーニングすれば、ネットワークはこれらの共通の特徴を抽出する能力を学習します。

KerasとPyTorchには、一般的なアーキテクチャの事前学習済みニューラルネットワークの重みを簡単にロードするための関数が含まれています。これらの多くはImageNet画像でトレーニングされています。よく使用されるものは、前のレッスンの[CNNアーキテクチャ](../07-ConvNets/CNN_Architectures.md)ページで説明されています。特に以下のモデルを検討する価値があります：

* **VGG-16/VGG-19**：比較的シンプルなモデルでありながら良い精度を提供します。転移学習の動作を確認するための最初の試みとしてVGGを使用するのは良い選択です。
* **ResNet**：Microsoft Researchが2015年に提案したモデルファミリーです。層が多いため、より多くのリソースを必要とします。
* **MobileNet**：サイズが小さく、モバイルデバイスに適したモデルファミリーです。リソースが限られていて、多少の精度を犠牲にしても良い場合に使用します。

以下は、VGG-16ネットワークによって猫の画像から抽出された特徴の例です：

![VGG-16による特徴抽出](../../../../../translated_images/ja/features.6291f9c7ba3a0b95.webp)

## 猫 vs 犬データセット

この例では、[Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste)データセットを使用します。これは実際の画像分類シナリオに非常に近いものです。

## ✍️ 演習：転移学習

対応するノートブックで転移学習の実際の動作を確認してみましょう：

* [転移学習 - PyTorch](TransferLearningPyTorch.ipynb)
* [転移学習 - TensorFlow](TransferLearningTF.ipynb)

## 理想的な猫の可視化

事前学習済みニューラルネットワークには、その「脳」の中にさまざまなパターンが含まれています。これには**理想的な猫**（理想的な犬、理想的なシマウマなど）も含まれます。この画像を**可視化**することができれば面白いでしょう。しかし、これは簡単ではありません。なぜなら、パターンはネットワークの重み全体に広がっており、また階層的に組織されているからです。

一つのアプローチとして、ランダムな画像から始めて、**勾配降下法**を使用してその画像を調整し、ネットワークがそれを猫だと認識するようにする方法があります。

![画像最適化ループ](../../../../../translated_images/ja/ideal-cat-loop.999fbb8ff306e044.webp)

しかし、この方法ではランダムノイズに非常に近いものが得られます。これは、*ネットワークが入力画像を猫だと認識する方法が多数存在する*ためであり、その中には視覚的に意味をなさないものも含まれます。これらの画像には猫に典型的な多くのパターンが含まれていますが、視覚的に特徴的であるように制約するものはありません。

結果を改善するために、**変動損失**と呼ばれる項を損失関数に追加することができます。これは、画像の隣接するピクセルがどれだけ似ているかを示す指標です。変動損失を最小化することで画像が滑らかになり、ノイズが除去され、より視覚的に魅力的なパターンが現れます。以下は、猫とシマウマとして高い確率で分類される「理想的な」画像の例です：

![理想的な猫](../../../../../translated_images/ja/ideal-cat.203dd4597643d6b0.webp) | ![理想的なシマウマ](../../../../../translated_images/ja/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *理想的な猫* | *理想的なシマウマ*

同様のアプローチを使用して、いわゆる**敵対的攻撃**をニューラルネットワークに対して行うことができます。例えば、犬を猫のように見せてネットワークを欺きたい場合、ネットワークが犬として認識する犬の画像を取り、それを少し調整してネットワークがそれを猫として分類するようにすることができます：

![犬の画像](../../../../../translated_images/ja/original-dog.8f68a67d2fe0911f.webp) | ![猫として分類される犬の画像](../../../../../translated_images/ja/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*元の犬の画像* | *猫として分類される犬の画像*

上記の結果を再現するコードは以下のノートブックで確認できます：

* [理想的な猫と敵対的猫 - TensorFlow](AdversarialCat_TF.ipynb)

## 結論

転移学習を使用することで、カスタムオブジェクト分類タスクのための分類器を迅速に構築し、高い精度を達成することができます。現在解決しているより複雑なタスクは、より高い計算能力を必要とし、CPUでは簡単に解決できないことがわかります。次のユニットでは、同じモデルを低い計算リソースでトレーニングするための軽量な実装を使用し、わずかに精度が低下する結果を試してみます。

## 🚀 チャレンジ

付属のノートブックの下部には、転移学習がある程度似たトレーニングデータ（例えば新しい種類の動物）で最も効果的に機能するというメモがあります。完全に新しい種類の画像で実験を行い、転移学習モデルがどれほど良く、または悪く機能するかを確認してください。

## [講義後クイズ](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## 復習と自己学習

[TrainingTricks.md](TrainingTricks.md)を読み、モデルをトレーニングする他の方法についての知識を深めてください。

## [課題](lab/README.md)

このラボでは、35種類の猫と犬の品種を含む実際の[Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/)ペットデータセットを使用し、転移学習分類器を構築します。

---

