# Eelnevalt treenitud v√µrgud ja √ºlekande√µpe

CNN-ide treenimine v√µib v√µtta palju aega ja n√µuda suurt hulka andmeid. Suur osa ajast kulub aga parimate madala taseme filtrite √µppimisele, mida v√µrk saab kasutada mustrite tuvastamiseks piltidelt. Tekib loomulik k√ºsimus ‚Äì kas saaksime kasutada √ºhel andmestikul treenitud n√§rviv√µrku ja kohandada seda erinevate piltide klassifitseerimiseks ilma t√§ieliku treenimisprotsessita?

## [Eelloengu viktoriin](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Seda l√§henemist nimetatakse **√ºlekande√µppeks**, kuna me kanname osa teadmistest √ºhest n√§rviv√µrgumudelist teise. √úlekande√µppes alustame tavaliselt eelnevalt treenitud mudeliga, mis on treenitud m√µnel suurel pildianmestikul, n√§iteks **ImageNet**. Need mudelid suudavad juba h√§sti tuvastada erinevaid omadusi √ºldistest piltidest, ja paljudel juhtudel v√µib nende tuvastatud omaduste peale ehitatud klassifikaator anda h√§id tulemusi.

> ‚úÖ √úlekande√µpe on termin, mida leidub ka teistes akadeemilistes valdkondades, n√§iteks hariduses. See viitab protsessile, kus teadmisi √ºhest valdkonnast rakendatakse teises.

## Eelnevalt treenitud mudelid kui omaduste tuvastajad

Konvolutsiooniv√µrgud, millest r√§√§kisime eelmises osas, sisaldavad mitmeid kihte, millest iga√ºks peaks tuvastama pildilt teatud omadusi, alustades madala taseme pikslikombinatsioonidest (n√§iteks horisontaalne/vertikaalne joon v√µi joonistus), kuni k√µrgema taseme omaduste kombinatsioonideni, mis vastavad n√§iteks leegisilmale. Kui treenime CNN-i piisavalt suurel √ºldiste ja mitmekesiste piltide andmestikul, peaks v√µrk √µppima tuvastama neid √ºhiseid omadusi.

Nii Keras kui PyTorch sisaldavad funktsioone, mis v√µimaldavad h√µlpsalt laadida eelnevalt treenitud n√§rviv√µrgu kaalusid m√µnele levinud arhitektuurile, millest enamik on treenitud ImageNet piltidel. K√µige sagedamini kasutatavad mudelid on kirjeldatud eelmise √µppetunni [CNN arhitektuuride](../07-ConvNets/CNN_Architectures.md) lehel. Eelk√µige v√µiksite kaaluda √ºhe j√§rgmistest kasutamist:

* **VGG-16/VGG-19**, mis on suhteliselt lihtsad mudelid, kuid annavad siiski head t√§psust. Sageli on VGG kasutamine esimese katse jaoks hea valik, et n√§ha, kuidas √ºlekande√µpe t√∂√∂tab.
* **ResNet** on mudelite perekond, mille Microsoft Research esitas 2015. aastal. Neil on rohkem kihte ja seet√µttu vajavad nad rohkem ressursse.
* **MobileNet** on mudelite perekond, mille suurus on v√§hendatud, sobides mobiilseadmetele. Kasutage neid, kui teil on ressursipuudus ja saate ohverdada veidi t√§psust.

Siin on n√§ide omadustest, mille VGG-16 v√µrk kassipildilt tuvastas:

![VGG-16 tuvastatud omadused](../../../../../translated_images/et/features.6291f9c7ba3a0b95.webp)

## Kasside ja koerte andmestik

Selles n√§ites kasutame [Kasside ja koerte](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste) andmestikku, mis on v√§ga l√§hedane p√§riselulisele pildiklassifikatsiooni stsenaariumile.

## ‚úçÔ∏è Harjutus: √úlekande√µpe

Vaatame √ºlekande√µpet tegevuses vastavates m√§rkmikes:

* [√úlekande√µpe - PyTorch](TransferLearningPyTorch.ipynb)
* [√úlekande√µpe - TensorFlow](TransferLearningTF.ipynb)

## Adversariaalse kassi visualiseerimine

Eelnevalt treenitud n√§rviv√µrk sisaldab oma *ajus* erinevaid mustreid, sealhulgas **ideaalse kassi** (samuti ideaalse koera, ideaalse sebra jne) m√µisteid. Oleks huvitav kuidagi **visualiseerida seda pilti**. Kuid see pole lihtne, kuna mustrid on hajutatud √ºle v√µrgu kaalude ja organiseeritud hierarhilises struktuuris.

√úks l√§henemine, mida saame kasutada, on alustada juhuslikust pildist ja seej√§rel proovida kasutada **gradientide optimeerimise** tehnikat, et kohandada seda pilti nii, et v√µrk hakkaks arvama, et see on kass.

![Pildi optimeerimise ts√ºkkel](../../../../../translated_images/et/ideal-cat-loop.999fbb8ff306e044.webp)

Kui me seda teeme, saame tulemuseks midagi, mis on v√§ga sarnane juhusliku m√ºraga. See on tingitud sellest, et *on palju viise, kuidas panna v√µrk arvama, et sisendpilt on kass*, sealhulgas m√µned, mis visuaalselt ei ole m√µistlikud. Kuigi need pildid sisaldavad palju kassile t√º√ºpilisi mustreid, pole midagi, mis sunniks neid olema visuaalselt eristatavad.

Tulemuse parandamiseks saame lisada kaotuse funktsiooni teise termini, mida nimetatakse **variatsioonikaotuseks**. See on m√µ√µdik, mis n√§itab, kui sarnased on pildi naaberpikslid. Variatsioonikaotuse minimeerimine muudab pildi sujuvamaks ja eemaldab m√ºra ‚Äì paljastades visuaalselt meeldivamad mustrid. Siin on n√§ide sellistest "ideaalse" piltidest, mis klassifitseeritakse suure t√µen√§osusega kassiks ja sebraks:

![Ideaalne kass](../../../../../translated_images/et/ideal-cat.203dd4597643d6b0.webp) | ![Ideaalne sebra](../../../../../translated_images/et/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Ideaalne kass* | *Ideaalne sebra*

Sarnast l√§henemist saab kasutada nn **adversariaalsete r√ºnnakute** l√§biviimiseks n√§rviv√µrgule. Oletame, et tahame petta n√§rviv√µrku ja panna koera v√§lja n√§gema nagu kass. Kui v√µtame koera pildi, mida v√µrk tuvastab koerana, saame seda veidi kohandada, kasutades gradientide optimeerimist, kuni v√µrk hakkab seda klassifitseerima kassina:

![Koera pilt](../../../../../translated_images/et/original-dog.8f68a67d2fe0911f.webp) | ![Koera pilt, mis klassifitseeritakse kassina](../../../../../translated_images/et/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Originaalne koera pilt* | *Koera pilt, mis klassifitseeritakse kassina*

Vaadake koodi, et √ºlaltoodud tulemusi reprodutseerida, j√§rgmises m√§rkmikus:

* [Ideaalne ja adversariaalne kass - TensorFlow](AdversarialCat_TF.ipynb)

## Kokkuv√µte

√úlekande√µppe abil saate kiiresti kokku panna klassifikaatori kohandatud objektide klassifitseerimise √ºlesande jaoks ja saavutada k√µrge t√§psuse. N√§ete, et keerukamad √ºlesanded, mida me n√º√ºd lahendame, n√µuavad suuremat arvutusv√µimsust ja neid ei saa lihtsalt lahendada CPU-l. J√§rgmises osas proovime kasutada kergemat rakendust, et treenida sama mudelit madalamate arvutusressurssidega, mis toob kaasa vaid veidi madalama t√§psuse.

## üöÄ V√§ljakutse

Kaasaolevates m√§rkmikes on m√§rkused selle kohta, kuidas √ºlekande teadmised toimivad k√µige paremini sarnaste treeningandmetega (n√§iteks uus loomaliik). Katsetage t√§iesti uute pildit√º√ºpidega, et n√§ha, kui h√§sti v√µi halvasti teie √ºlekande teadmiste mudelid toimivad.

## [J√§relloengu viktoriin](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## √úlevaade ja iseseisev √µppimine

Lugege l√§bi [TrainingTricks.md](TrainingTricks.md), et s√ºvendada oma teadmisi mudelite treenimise muudest viisidest.

## [√úlesanne](lab/README.md)

Selles laboris kasutame p√§riselulist [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) lemmikloomade andmestikku, mis sisaldab 35 kassi- ja koerat√µugu, ning ehitame √ºlekande√µppe klassifikaatori.

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud, kasutades AI t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame tagada t√§psust, palun arvestage, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul on soovitatav kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valede t√µlgenduste eest.