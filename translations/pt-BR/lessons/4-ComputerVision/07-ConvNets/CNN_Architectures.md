# Arquiteturas Conhecidas de CNN

### VGG-16

VGG-16 √© uma rede que alcan√ßou 92,7% de precis√£o na classifica√ß√£o top-5 do ImageNet em 2014. Ela possui a seguinte estrutura de camadas:

![Camadas do ImageNet](../../../../../translated_images/pt-BR/vgg-16-arch1.d901a5583b3a51ba.webp)

Como voc√™ pode ver, a VGG segue uma arquitetura tradicional em forma de pir√¢mide, que √© uma sequ√™ncia de camadas de convolu√ß√£o e pooling.

![Pir√¢mide do ImageNet](../../../../../translated_images/pt-BR/vgg-16-arch.64ff2137f50dd49f.webp)

> Imagem de [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet √© uma fam√≠lia de modelos proposta pela Microsoft Research em 2015. A ideia principal da ResNet √© usar **blocos residuais**:

<img src="../../../../../translated_images/pt-BR/resnet-block.aba4ccbcc0944434.webp" width="300"/>

> Imagem deste [artigo](https://arxiv.org/pdf/1512.03385.pdf)

A raz√£o para usar a passagem de identidade √© fazer com que nossa camada preveja **a diferen√ßa** entre o resultado de uma camada anterior e a sa√≠da do bloco residual - da√≠ o nome *residual*. Esses blocos s√£o muito mais f√°ceis de treinar, e √© poss√≠vel construir redes com centenas desses blocos (as variantes mais comuns s√£o ResNet-52, ResNet-101 e ResNet-152).

Voc√™ tamb√©m pode pensar nessa rede como sendo capaz de ajustar sua complexidade ao conjunto de dados. Inicialmente, quando voc√™ come√ßa a treinar a rede, os valores dos pesos s√£o pequenos, e a maior parte do sinal passa pelas camadas de identidade. √Ä medida que o treinamento avan√ßa e os pesos se tornam maiores, a import√¢ncia dos par√¢metros da rede cresce, e a rede se ajusta para acomodar o poder expressivo necess√°rio para classificar corretamente as imagens de treinamento.

### Google Inception

A arquitetura Google Inception leva essa ideia um passo adiante e constr√≥i cada camada da rede como uma combina√ß√£o de v√°rios caminhos diferentes:

<img src="../../../../../translated_images/pt-BR/inception.a6605b85bcbc6f52.webp" width="400"/>

> Imagem de [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Aqui, precisamos enfatizar o papel das convolu√ß√µes 1x1, porque, √† primeira vista, elas n√£o fazem sentido. Por que precisar√≠amos passar pela imagem com um filtro 1x1? No entanto, √© importante lembrar que os filtros de convolu√ß√£o tamb√©m trabalham com v√°rios canais de profundidade (originalmente - cores RGB, em camadas subsequentes - canais para diferentes filtros), e a convolu√ß√£o 1x1 √© usada para misturar esses canais de entrada usando diferentes pesos trein√°veis. Ela tamb√©m pode ser vista como uma redu√ß√£o de dimens√£o (pooling) sobre a dimens√£o dos canais.

Aqui est√° [um bom post de blog](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) sobre o assunto, e [o artigo original](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet √© uma fam√≠lia de modelos com tamanho reduzido, adequada para dispositivos m√≥veis. Use-os se voc√™ tiver poucos recursos e puder sacrificar um pouco de precis√£o. A ideia principal por tr√°s deles √© a chamada **convolu√ß√£o separ√°vel por profundidade**, que permite representar filtros de convolu√ß√£o por uma composi√ß√£o de convolu√ß√µes espaciais e convolu√ß√£o 1x1 sobre canais de profundidade. Isso reduz significativamente o n√∫mero de par√¢metros, tornando a rede menor em tamanho e tamb√©m mais f√°cil de treinar com menos dados.

Aqui est√° [um bom post de blog sobre MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Conclus√£o

Nesta unidade, voc√™ aprendeu o conceito principal por tr√°s das redes neurais de vis√£o computacional - redes convolucionais. Arquiteturas reais que alimentam classifica√ß√£o de imagens, detec√ß√£o de objetos e at√© redes de gera√ß√£o de imagens s√£o todas baseadas em CNNs, apenas com mais camadas e alguns truques adicionais de treinamento.

## üöÄ Desafio

Nos notebooks que acompanham, h√° notas no final sobre como obter maior precis√£o. Fa√ßa alguns experimentos para ver se voc√™ consegue alcan√ßar maior precis√£o.

## [Quiz p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Revis√£o e Autoestudo

Embora as CNNs sejam mais frequentemente usadas para tarefas de Vis√£o Computacional, elas s√£o geralmente boas para extrair padr√µes de tamanho fixo. Por exemplo, se estivermos lidando com sons, tamb√©m podemos querer usar CNNs para procurar padr√µes espec√≠ficos no sinal de √°udio - nesse caso, os filtros seriam unidimensionais (e essa CNN seria chamada de 1D-CNN). Al√©m disso, √†s vezes 3D-CNN √© usada para extrair caracter√≠sticas em espa√ßo multidimensional, como certos eventos ocorrendo em v√≠deos - a CNN pode capturar certos padr√µes de mudan√ßa de caracter√≠sticas ao longo do tempo. Fa√ßa uma revis√£o e autoestudo sobre outras tarefas que podem ser realizadas com CNNs.

## [Tarefa](lab/README.md)

Neste laborat√≥rio, voc√™ ser√° encarregado de classificar diferentes ra√ßas de gatos e c√£es. Essas imagens s√£o mais complexas do que o conjunto de dados MNIST, possuem dimens√µes maiores e h√° mais de 10 classes.

---

