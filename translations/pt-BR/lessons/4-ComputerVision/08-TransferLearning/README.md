# Redes Pr√©-treinadas e Aprendizado por Transfer√™ncia

Treinar CNNs pode levar muito tempo e exigir uma grande quantidade de dados. No entanto, grande parte do tempo √© gasto aprendendo os melhores filtros de baixo n√≠vel que uma rede pode usar para extrair padr√µes de imagens. Surge uma pergunta natural: podemos usar uma rede neural treinada em um conjunto de dados e adapt√°-la para classificar imagens diferentes sem precisar de um processo completo de treinamento?

## [Quiz pr√©-aula](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Essa abordagem √© chamada de **aprendizado por transfer√™ncia**, porque transferimos algum conhecimento de um modelo de rede neural para outro. No aprendizado por transfer√™ncia, normalmente come√ßamos com um modelo pr√©-treinado, que foi treinado em um grande conjunto de dados de imagens, como o **ImageNet**. Esses modelos j√° conseguem extrair diferentes caracter√≠sticas de imagens gen√©ricas, e, em muitos casos, apenas construir um classificador em cima dessas caracter√≠sticas extra√≠das pode gerar bons resultados.

> ‚úÖ Aprendizado por Transfer√™ncia √© um termo que voc√™ encontra em outros campos acad√™micos, como Educa√ß√£o. Ele se refere ao processo de levar conhecimento de um dom√≠nio e aplic√°-lo em outro.

## Modelos Pr√©-treinados como Extratores de Caracter√≠sticas

As redes convolucionais que discutimos na se√ß√£o anterior cont√™m v√°rias camadas, cada uma delas destinada a extrair caracter√≠sticas da imagem, come√ßando por combina√ß√µes de pixels de baixo n√≠vel (como linhas horizontais/verticais ou tra√ßos), at√© combina√ß√µes de caracter√≠sticas de n√≠vel mais alto, correspondendo a coisas como o olho de uma chama. Se treinarmos uma CNN em um conjunto de dados suficientemente grande de imagens gen√©ricas e diversas, a rede deve aprender a extrair essas caracter√≠sticas comuns.

Tanto o Keras quanto o PyTorch possuem fun√ß√µes para carregar facilmente pesos de redes neurais pr√©-treinadas para algumas arquiteturas comuns, a maioria das quais foi treinada em imagens do ImageNet. As mais utilizadas est√£o descritas na p√°gina [Arquiteturas de CNN](../07-ConvNets/CNN_Architectures.md) da li√ß√£o anterior. Em particular, voc√™ pode considerar usar uma das seguintes:

* **VGG-16/VGG-19**, que s√£o modelos relativamente simples, mas ainda oferecem boa precis√£o. Usar o VGG como uma primeira tentativa √© uma boa escolha para ver como o aprendizado por transfer√™ncia est√° funcionando.
* **ResNet** √© uma fam√≠lia de modelos proposta pela Microsoft Research em 2015. Eles possuem mais camadas e, portanto, exigem mais recursos.
* **MobileNet** √© uma fam√≠lia de modelos com tamanho reduzido, adequada para dispositivos m√≥veis. Use-os se voc√™ tiver poucos recursos e puder sacrificar um pouco de precis√£o.

Aqui est√£o caracter√≠sticas extra√≠das de uma imagem de um gato pela rede VGG-16:

![Caracter√≠sticas extra√≠das pelo VGG-16](../../../../../translated_images/pt-BR/features.6291f9c7ba3a0b95.webp)

## Conjunto de Dados de Gatos vs. Cachorros

Neste exemplo, usaremos um conjunto de dados de [Gatos e Cachorros](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), que √© muito pr√≥ximo de um cen√°rio real de classifica√ß√£o de imagens.

## ‚úçÔ∏è Exerc√≠cio: Aprendizado por Transfer√™ncia

Vamos ver o aprendizado por transfer√™ncia em a√ß√£o nos notebooks correspondentes:

* [Transfer Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](TransferLearningTF.ipynb)

## Visualizando o Gato Adversarial

Uma rede neural pr√©-treinada cont√©m diferentes padr√µes em seu *c√©rebro*, incluindo no√ß√µes de **gato ideal** (assim como cachorro ideal, zebra ideal, etc.). Seria interessante de alguma forma **visualizar essa imagem**. No entanto, isso n√£o √© simples, porque os padr√µes est√£o espalhados por todos os pesos da rede e organizados em uma estrutura hier√°rquica.

Uma abordagem que podemos adotar √© come√ßar com uma imagem aleat√≥ria e, em seguida, tentar usar a t√©cnica de **otimiza√ß√£o por descida de gradiente** para ajustar essa imagem de forma que a rede comece a pensar que √© um gato.

![Loop de Otimiza√ß√£o de Imagem](../../../../../translated_images/pt-BR/ideal-cat-loop.999fbb8ff306e044.webp)

No entanto, se fizermos isso, receberemos algo muito semelhante a um ru√≠do aleat√≥rio. Isso ocorre porque *existem muitas maneiras de fazer a rede pensar que a imagem de entrada √© um gato*, incluindo algumas que n√£o fazem sentido visualmente. Embora essas imagens contenham muitos padr√µes t√≠picos de um gato, n√£o h√° nada que as restrinja a serem visualmente distintas.

Para melhorar o resultado, podemos adicionar outro termo √† fun√ß√£o de perda, chamado de **perda de varia√ß√£o**. √â uma m√©trica que mostra qu√£o semelhantes s√£o os pixels vizinhos da imagem. Minimizar a perda de varia√ß√£o torna a imagem mais suave e elimina o ru√≠do, revelando padr√µes mais visualmente atraentes. Aqui est√° um exemplo de tais imagens "ideais", classificadas como gato e zebra com alta probabilidade:

![Gato Ideal](../../../../../translated_images/pt-BR/ideal-cat.203dd4597643d6b0.webp) | ![Zebra Ideal](../../../../../translated_images/pt-BR/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Gato Ideal* | *Zebra Ideal*

Uma abordagem semelhante pode ser usada para realizar os chamados **ataques adversariais** em uma rede neural. Suponha que queremos enganar uma rede neural e fazer um cachorro parecer um gato. Se pegarmos a imagem de um cachorro, que √© reconhecida pela rede como um cachorro, podemos ajust√°-la um pouco usando otimiza√ß√£o por descida de gradiente at√© que a rede comece a classific√°-la como um gato:

![Imagem de um Cachorro](../../../../../translated_images/pt-BR/original-dog.8f68a67d2fe0911f.webp) | ![Imagem de um cachorro classificada como gato](../../../../../translated_images/pt-BR/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Imagem original de um cachorro* | *Imagem de um cachorro classificada como gato*

Veja o c√≥digo para reproduzir os resultados acima no seguinte notebook:

* [Ideal e Adversarial Cat - TensorFlow](AdversarialCat_TF.ipynb)

## Conclus√£o

Usando aprendizado por transfer√™ncia, voc√™ pode montar rapidamente um classificador para uma tarefa de classifica√ß√£o de objetos personalizada e alcan√ßar alta precis√£o. Voc√™ pode perceber que tarefas mais complexas que estamos resolvendo agora exigem maior poder computacional e n√£o podem ser facilmente resolvidas no CPU. Na pr√≥xima unidade, tentaremos usar uma implementa√ß√£o mais leve para treinar o mesmo modelo usando menos recursos computacionais, o que resulta em uma precis√£o apenas ligeiramente menor.

## üöÄ Desafio

Nos notebooks que acompanham, h√° notas no final sobre como o aprendizado por transfer√™ncia funciona melhor com dados de treinamento um pouco semelhantes (um novo tipo de animal, talvez). Fa√ßa algumas experimenta√ß√µes com tipos completamente novos de imagens para ver como seus modelos de aprendizado por transfer√™ncia se saem.

## [Quiz p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Revis√£o e Autoestudo

Leia o arquivo [TrainingTricks.md](TrainingTricks.md) para aprofundar seu conhecimento sobre outras formas de treinar seus modelos.

## [Tarefa](lab/README.md)

Neste laborat√≥rio, usaremos o conjunto de dados real [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) de animais de estima√ß√£o, com 35 ra√ßas de gatos e cachorros, e construiremos um classificador de aprendizado por transfer√™ncia.

---

