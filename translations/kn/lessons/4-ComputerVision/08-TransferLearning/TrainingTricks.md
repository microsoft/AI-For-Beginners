# ಡೀಪ್ ಲರ್ನಿಂಗ್ ತರಬೇತಿ ತಂತ್ರಗಳು

ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳು ಆಳವಾಗುತ್ತಿರೋಂತೆ, ಅವುಗಳ ತರಬೇತಿ ಪ್ರಕ್ರಿಯೆ ಹೆಚ್ಚು ಮತ್ತು ಹೆಚ್ಚು ಸವಾಲಿನಾಯಕವಾಗುತ್ತದೆ. ಒಂದು ಪ್ರಮುಖ ಸಮಸ್ಯೆ ಎಂದರೆ [ವ್ಯಾನಿಶಿಂಗ್ ಗ್ರೇಡಿಯಂಟ್ಸ್](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) ಅಥವಾ [ಎಕ್ಸ್‌ಪ್ಲೋಡಿಂಗ್ ಗ್ರೇಡಿಯಂಟ್ಸ್](https://deepai.org/machine-learning-glossary-and-terms/exploding-gradient-problem#:~:text=Exploding%20gradients%20are%20a%20problem,updates%20are%20small%20and%20controlled.). [ಈ ಪೋಸ್ಟ್](https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11) ಆ ಸಮಸ್ಯೆಗಳ ಪರಿಚಯವನ್ನು ಚೆನ್ನಾಗಿ ನೀಡುತ್ತದೆ.

ಡೀಪ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳ ತರಬೇತಿಯನ್ನು ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಮಾಡಲು ಕೆಲವು ತಂತ್ರಗಳನ್ನು ಬಳಸಬಹುದು.

## ಮೌಲ್ಯಗಳನ್ನು ಯುಕ್ತಿಯುತ ಶ್ರೇಣಿಯಲ್ಲಿ ಇಡುವುದು

ಸಂಖ್ಯಾತ್ಮಕ ಗಣನೆಗಳನ್ನು ಸ್ಥಿರವಾಗಿರಿಸಲು, ನಮ್ಮ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ನ ಎಲ್ಲಾ ಮೌಲ್ಯಗಳು ಯುಕ್ತಿಯುತ ಪ್ರಮಾಣದಲ್ಲಿ ಇರಬೇಕು ಎಂದು ನಾವು ಬಯಸುತ್ತೇವೆ, ಸಾಮಾನ್ಯವಾಗಿ [-1..1] ಅಥವಾ [0..1]. ಇದು ಕಠಿಣ ನಿಯಮವಲ್ಲ, ಆದರೆ ಫ್ಲೋಟಿಂಗ್ ಪಾಯಿಂಟ್ ಗಣನೆಗಳ ಸ್ವಭಾವವೇ ಬೇರೆ ಬೇರೆ ಪ್ರಮಾಣದ ಮೌಲ್ಯಗಳನ್ನು ಸರಿಯಾಗಿ ಸಂಚಾಲಿಸಲು ಸಾಧ್ಯವಿಲ್ಲ. ಉದಾಹರಣೆಗೆ, 10<sup>-10</sup> ಮತ್ತು 10<sup>10</sup> ಅನ್ನು ಸೇರಿಸಿದರೆ, ನಾವು ಬಹುಶಃ 10<sup>10</sup> ಅನ್ನು ಪಡೆಯುತ್ತೇವೆ, ಏಕೆಂದರೆ ಸಣ್ಣ ಮೌಲ್ಯವನ್ನು ದೊಡ್ಡದಿನ ಸರಣಿಗೆ "ಪರಿವರ್ತಿಸಲಾಗುತ್ತದೆ" ಮತ್ತು ಮ್ಯಾಂಟಿಸ್ಸಾ ಕಳೆದುಹೋಗುತ್ತದೆ.

ಬಹುತೇಕ ಸಕ್ರಿಯತೆ ಕಾರ್ಯಗಳು [-1..1] ಸುತ್ತಲೂ ಅಸಮಾನತೆಗಳನ್ನು ಹೊಂದಿವೆ, ಆದ್ದರಿಂದ ಎಲ್ಲಾ ಇನ್‌ಪುಟ್ ಡೇಟಾವನ್ನು [-1..1] ಅಥವಾ [0..1] ಶ್ರೇಣಿಗೆ ಮಾಪನ ಮಾಡುವುದು ಸೂಕ್ತ.

## ಪ್ರಾಥಮಿಕ ತೂಕ ಆರಂಭಿಕೀಕರಣ

ಆದರ್ಶವಾಗಿ, ನೆಟ್‌ವರ್ಕ್ ಲೇಯರ್‌ಗಳ ಮೂಲಕ ಮೌಲ್ಯಗಳು ಒಂದೇ ಶ್ರೇಣಿಯಲ್ಲಿ ಇರಬೇಕು. ಆದ್ದರಿಂದ, ಮೌಲ್ಯಗಳ ವಿತರಣೆಯನ್ನು ಉಳಿಸುವಂತೆ ತೂಕಗಳನ್ನು ಆರಂಭಿಕೀಕರಿಸುವುದು ಮುಖ್ಯ.

ಸಾಮಾನ್ಯ ವಿತರಣೆಯಾದ **N(0,1)** ಉತ್ತಮ ಆಯ್ಕೆ ಅಲ್ಲ, ಏಕೆಂದರೆ *n* ಇನ್‌ಪುಟ್‌ಗಳಿದ್ದರೆ, ಔಟ್‌ಪುಟ್‌ನ ಸ್ಟ್ಯಾಂಡರ್ಡ್ ಡಿವಿಯೇಶನ್ *n* ಆಗುತ್ತದೆ ಮತ್ತು ಮೌಲ್ಯಗಳು [0..1] ಶ್ರೇಣಿಯಿಂದ ಹೊರಗೆ ಹೋಗಬಹುದು.

ಕೆಳಗಿನ ಆರಂಭಿಕೀಕರಣಗಳು ಸಾಮಾನ್ಯವಾಗಿ ಬಳಸಲಾಗುತ್ತವೆ:

 * ಸಮವಿತರಣಾ ವಿತರಣೆ -- `uniform`
 * **N(0,1/n)** -- `gaussian`
 * **N(0,1/&radic;n_in)** ಇದು ಶೂನ್ಯ ಸರಾಸರಿ ಮತ್ತು 1 ಸ್ಟ್ಯಾಂಡರ್ಡ್ ಡಿವಿಯೇಶನ್ ಇರುವ ಇನ್‌ಪುಟ್‌ಗಳಿಗೆ ಅದೇ ಸರಾಸರಿ/ಸ್ಟ್ಯಾಂಡರ್ಡ್ ಡಿವಿಯೇಶನ್ ಉಳಿಸುವುದನ್ನು ಖಚಿತಪಡಿಸುತ್ತದೆ
 * **N(0,&radic;2/(n_in+n_out))** -- ಇದನ್ನು **Xavier ಆರಂಭಿಕೀಕರಣ** (`glorot`) ಎಂದು ಕರೆಯುತ್ತಾರೆ, ಇದು ಫಾರ್ವರ್ಡ್ ಮತ್ತು ಬ್ಯಾಕ್ವರ್ಡ್ ಪ್ರೋಪಗೇಶನ್ ಸಮಯದಲ್ಲಿ ಸಿಗ್ನಲ್‌ಗಳನ್ನು ಶ್ರೇಣಿಯಲ್ಲಿ ಇಡಲು ಸಹಾಯ ಮಾಡುತ್ತದೆ

## ಬ್ಯಾಚ್ ನಾರ್ಮಲೈಜೆಷನ್

ಸರಿಯಾದ ತೂಕ ಆರಂಭಿಕೀಕರಣ ಇದ್ದರೂ, ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ತೂಕಗಳು ಅನಿಯಂತ್ರಿತವಾಗಿ ದೊಡ್ಡದಾಗಬಹುದು ಅಥವಾ ಚಿಕ್ಕದಾಗಬಹುದು, ಮತ್ತು ಅವು ಸಿಗ್ನಲ್‌ಗಳನ್ನು ಸರಿಯಾದ ಶ್ರೇಣಿಯಿಂದ ಹೊರಗೆ ತರುತ್ತವೆ. ನಾವು ಸಿಗ್ನಲ್‌ಗಳನ್ನು ಹಿಂತಿರುಗಿಸಲು **ನಾರ್ಮಲೈಜೆಷನ್** ತಂತ್ರಗಳನ್ನು ಬಳಸಬಹುದು. ಹಲವಾರು ವಿಧಾನಗಳಿದ್ದರೂ (ತೂಕ ನಾರ್ಮಲೈಜೆಷನ್, ಲೇಯರ್ ನಾರ್ಮಲೈಜೆಷನ್), ಅತ್ಯಂತ ಸಾಮಾನ್ಯವಾಗಿ ಬಳಸುವದು ಬ್ಯಾಚ್ ನಾರ್ಮಲೈಜೆಷನ್.

**ಬ್ಯಾಚ್ ನಾರ್ಮಲೈಜೆಷನ್** ಯೋಚನೆ ಎಂದರೆ, ಮಿನಿಬ್ಯಾಚ್‌ನ ಎಲ್ಲಾ ಮೌಲ್ಯಗಳನ್ನು ಪರಿಗಣಿಸಿ, ಅವುಗಳ ಆಧಾರದ ಮೇಲೆ ನಾರ್ಮಲೈಜೆಷನ್ (ಅಂದರೆ ಸರಾಸರಿಯನ್ನು ಕಡಿತಮಾಡಿ ಮತ್ತು ಸ್ಟ್ಯಾಂಡರ್ಡ್ ಡಿವಿಯೇಶನ್ ಮೂಲಕ ಭಾಗಿಸಿ) ಮಾಡುವುದು. ಇದು ತೂಕಗಳನ್ನು ಅನ್ವಯಿಸಿದ ನಂತರ, ಆದರೆ ಸಕ್ರಿಯತೆ ಕಾರ್ಯದ ಮೊದಲು ಈ ನಾರ್ಮಲೈಜೆಷನ್ ಮಾಡುವ ಲೇಯರ್ ಆಗಿ ಅನುಷ್ಠಾನಗೊಳ್ಳುತ್ತದೆ. ಇದರಿಂದ ಅಂತಿಮ ಶುದ್ಧತೆ ಹೆಚ್ಚಾಗುತ್ತದೆ ಮತ್ತು ತರಬೇತಿ ವೇಗವೂ ಹೆಚ್ಚಾಗುತ್ತದೆ.

ಇದು ಬ್ಯಾಚ್ ನಾರ್ಮಲೈಜೆಷನ್ ಕುರಿತು [ಮೂಲ ಪೇಪರ್](https://arxiv.org/pdf/1502.03167.pdf), [ವಿಕಿಪೀಡಿಯ上的 ವಿವರಣೆ](https://en.wikipedia.org/wiki/Batch_normalization), ಮತ್ತು [ಒಂದು ಉತ್ತಮ ಪರಿಚಯಾತ್ಮಕ ಬ್ಲಾಗ್ ಪೋಸ್ಟ್](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338) (ಮತ್ತು [ರಷ್ಯನ್‌ನಲ್ಲಿ](https://habrahabr.ru/post/309302/)).

## ಡ್ರಾಪೌಟ್

**ಡ್ರಾಪೌಟ್** ಒಂದು ಆಸಕ್ತಿದಾಯಕ ತಂತ್ರ, ಇದು ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ನಿರ್ದಿಷ್ಟ ಪ್ರಮಾಣದ ಯಾದೃಚ್ಛಿಕ ನ್ಯೂರಾನ್ಗಳನ್ನು ತೆಗೆದುಹಾಕುತ್ತದೆ. ಇದು ಒಂದು ಲೇಯರ್ ಆಗಿ ಅನುಷ್ಠಾನಗೊಳ್ಳುತ್ತದೆ, ಇದರಲ್ಲಿ ಒಂದು ಪ್ಯಾರಾಮೀಟರ್ (ತೆಗೆದುಹಾಕುವ ನ್ಯೂರಾನ್ಗಳ ಶೇಕಡಾವಾರು, ಸಾಮಾನ್ಯವಾಗಿ 10%-50%) ಇರುತ್ತದೆ, ಮತ್ತು ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ಇನ್‌ಪುಟ್ ವೆಕ್ಟರ್‌ನ ಯಾದೃಚ್ಛಿಕ ಅಂಶಗಳನ್ನು ಶೂನ್ಯಗೊಳಿಸುತ್ತದೆ, ನಂತರ ಮುಂದಿನ ಲೇಯರ್‌ಗೆ ಕಳುಹಿಸುತ್ತದೆ.

ಇದು ವಿಚಿತ್ರವಾದ ಯೋಚನೆ ಎಂದು ತೋರುತ್ತಿದ್ದರೂ, ನೀವು [`Dropout.ipynb`](Dropout.ipynb) ನೋಟ್ಬುಕ್‌ನಲ್ಲಿ MNIST ಅಂಕಿ ವರ್ಗೀಕರಣದ ತರಬೇತಿಯಲ್ಲಿ ಡ್ರಾಪೌಟ್ ಪರಿಣಾಮವನ್ನು ನೋಡಬಹುದು. ಇದು ತರಬೇತಿಯನ್ನು ವೇಗಗೊಳಿಸುತ್ತದೆ ಮತ್ತು ಕಡಿಮೆ ತರಬೇತಿ ಯುಗಗಳಲ್ಲಿ ಹೆಚ್ಚಿನ ಶುದ್ಧತೆಯನ್ನು ಸಾಧಿಸಲು ಸಹಾಯ ಮಾಡುತ್ತದೆ.

ಈ ಪರಿಣಾಮವನ್ನು ಹಲವಾರು ರೀತಿಯಲ್ಲಿ ವಿವರಿಸಬಹುದು:

 * ಇದು ಮಾದರಿಗಾಗಿ ಯಾದೃಚ್ಛಿಕ ಶಾಕ್ ಆಗಿದ್ದು, ಆಪ್ಟಿಮೈಜೆಷನ್ ಅನ್ನು ಸ್ಥಳೀಯ ಕನಿಷ್ಠದಿಂದ ಹೊರಗೆ ತರುತ್ತದೆ
 * ಇದು *ಅನೈಕ್ಯ ಮಾದರಿ ಸರಾಸರಿ* ಎಂದು ಪರಿಗಣಿಸಬಹುದು, ಏಕೆಂದರೆ ಡ್ರಾಪೌಟ್ ಸಮಯದಲ್ಲಿ ನಾವು ಸ್ವಲ್ಪ ವಿಭಿನ್ನ ಮಾದರಿಯನ್ನು ತರಬೇತಿಸುತ್ತಿದ್ದೇವೆ ಎಂದು ಹೇಳಬಹುದು

> *ಕೆಲವರು ಹೇಳುತ್ತಾರೆ, ಮದ್ಯಪಾನ ಮಾಡಿದ ವ್ಯಕ್ತಿ ಏನಾದರೂ ಕಲಿಯಲು ಪ್ರಯತ್ನಿಸಿದಾಗ, ಅವನು ಮುಂದಿನ ಬೆಳಿಗ್ಗೆ ಅದನ್ನು ಹೆಚ್ಚು ನೆನಪಿಡುತ್ತಾನೆ, ಏಕೆಂದರೆ ಕೆಲವು ನ್ಯೂರಾನ್ಗಳು ಸರಿಯಾಗಿ ಕಾರ್ಯನಿರ್ವಹಿಸದಿದ್ದಾಗ ಮೆದುಳು ಅರ್ಥವನ್ನು ಹಿಡಿಯಲು ಉತ್ತಮವಾಗಿ ಹೊಂದಿಕೊಳ್ಳಲು ಪ್ರಯತ್ನಿಸುತ್ತದೆ. ನಾವು ಇದನ್ನು ಪರೀಕ್ಷಿಸಿಲ್ಲ, ಇದು ಸತ್ಯವೇ ಇಲ್ಲವೇ ಎಂದು.*

## ಓವರ್‌ಫಿಟಿಂಗ್ ತಡೆಯುವುದು

ಡೀಪ್ ಲರ್ನಿಂಗ್‌ನ ಅತ್ಯಂತ ಪ್ರಮುಖ ಅಂಶಗಳಲ್ಲಿ ಒಂದಾಗಿದೆ [ಓವರ್‌ಫಿಟಿಂಗ್](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) ತಡೆಯುವ ಸಾಮರ್ಥ್ಯ. ಬಹುಶಃ ಬಹುಶಕ್ತಿಶಾಲಿ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್ ಮಾದರಿಯನ್ನು ಬಳಸಲು ಆಕರ್ಷಣೆಯಿದ್ದರೂ, ನಾವು ಯಾವಾಗಲೂ ಮಾದರಿ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳ ಸಂಖ್ಯೆಯನ್ನು ತರಬೇತಿ ಮಾದರಿಗಳ ಸಂಖ್ಯೆಯೊಂದಿಗೆ ಸಮತೋಲನ ಮಾಡಬೇಕು.

> ನಾವು ಮೊದಲು ಪರಿಚಯಿಸಿದ [ಓವರ್‌ಫಿಟಿಂಗ್](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) ಸಂಜ್ಞೆಯನ್ನು ನೀವು ಖಚಿತವಾಗಿ ಅರ್ಥಮಾಡಿಕೊಂಡಿರಬೇಕು!

ಓವರ್‌ಫಿಟಿಂಗ್ ತಡೆಯಲು ಹಲವಾರು ವಿಧಾನಗಳಿವೆ:

 * ಆರಂಭಿಕ ನಿಲ್ಲಿಕೆ -- ಮಾನ್ಯತೆ ಸೆಟ್‌ನಲ್ಲಿ ದೋಷವನ್ನು ನಿರಂತರವಾಗಿ ಗಮನಿಸಿ, ಮಾನ್ಯತೆ ದೋಷ ಹೆಚ್ಚಾಗಲು ಪ್ರಾರಂಭಿಸಿದಾಗ ತರಬೇತಿಯನ್ನು ನಿಲ್ಲಿಸುವುದು.
 * ಸ್ಪಷ್ಟ ತೂಕ ಕ್ಷಯ / ನಿಯಮಿತೀಕರಣ -- ತೂಕಗಳ ಹೆಚ್ಚಿನ ಪರಮಾಣು ಮೌಲ್ಯಗಳಿಗೆ ಲಾಸ್ ಫಂಕ್ಷನ್‌ಗೆ ಹೆಚ್ಚುವರಿ ದಂಡನೆಯನ್ನು ಸೇರಿಸುವುದು, ಇದು ಮಾದರಿಯನ್ನು ಅಸ್ಥಿರ ಫಲಿತಾಂಶಗಳಿಂದ ತಡೆಯುತ್ತದೆ
 * ಮಾದರಿ ಸರಾಸರಿ -- ಹಲವಾರು ಮಾದರಿಗಳನ್ನು ತರಬೇತಿಸಿ ನಂತರ ಫಲಿತಾಂಶವನ್ನು ಸರಾಸರಿಮಾಡುವುದು. ಇದು ವ್ಯತ್ಯಾಸವನ್ನು ಕಡಿಮೆ ಮಾಡಲು ಸಹಾಯ ಮಾಡುತ್ತದೆ.
 * ಡ್ರಾಪೌಟ್ (ಅನೈಕ್ಯ ಮಾದರಿ ಸರಾಸರಿ)

## ಆಪ್ಟಿಮೈಜರ್‌ಗಳು / ತರಬೇತಿ ಆಲ್ಗಾರಿದಮ್ಗಳು

ತರಬೇತಿಯ ಮತ್ತೊಂದು ಪ್ರಮುಖ ಅಂಶವೆಂದರೆ ಉತ್ತಮ ತರಬೇತಿ ಆಲ್ಗಾರಿದಮ್ನ್ನು ಆಯ್ಕೆ ಮಾಡುವುದು. ಸಾಂಪ್ರದಾಯಿಕ **ಗ್ರೇಡಿಯಂಟ್ ಡಿಸೆಂಟ್** ಒಳ್ಳೆಯ ಆಯ್ಕೆ ಆಗಿದ್ದರೂ, ಅದು ಕೆಲವೊಮ್ಮೆ ನಿಧಾನವಾಗಬಹುದು ಅಥವಾ ಇತರ ಸಮಸ್ಯೆಗಳನ್ನುಂಟುಮಾಡಬಹುದು.

ಡೀಪ್ ಲರ್ನಿಂಗ್‌ನಲ್ಲಿ, ನಾವು **ಸ್ಟೋಚಾಸ್ಟಿಕ್ ಗ್ರೇಡಿಯಂಟ್ ಡಿಸೆಂಟ್** (SGD) ಅನ್ನು ಬಳಸುತ್ತೇವೆ, ಇದು ತರಬೇತಿ ಸೆಟ್‌ನಿಂದ ಯಾದೃಚ್ಛಿಕವಾಗಿ ಆಯ್ದ ಮಿನಿಬ್ಯಾಚ್‌ಗಳಿಗೆ ಅನ್ವಯಿಸುವ ಗ್ರೇಡಿಯಂಟ್ ಡಿಸೆಂಟ್ ಆಗಿದೆ. ತೂಕಗಳನ್ನು ಈ ಸೂತ್ರದಿಂದ ಸರಿಹೊಂದಿಸಲಾಗುತ್ತದೆ:

w<sup>t+1</sup> = w<sup>t</sup> - &eta;&nabla;&lagran;

### ಮೊಮೆಂಟಮ್

**ಮೊಮೆಂಟಮ್ SGD** ನಲ್ಲಿ, ನಾವು ಹಿಂದಿನ ಹಂತಗಳ ಗ್ರೇಡಿಯಂಟ್‌ನ ಒಂದು ಭಾಗವನ್ನು ಉಳಿಸಿಕೊಂಡಿರುತ್ತೇವೆ. ಇದು ನಾವು ಜಡತೆಯಿಂದ ಎಲ್ಲಿ ಹೋಗುತ್ತಿದ್ದೇವೆ ಮತ್ತು ಬೇರೊಂದು ದಿಕ್ಕಿನಲ್ಲಿ ಹೊಡೆತ ಬಂದಾಗ, ನಮ್ಮ ಮಾರ್ಗ ತಕ್ಷಣ ಬದಲಾಗದೆ ಮೂಲ ಚಲನೆಯ ಕೆಲವು ಭಾಗವನ್ನು ಉಳಿಸುವಂತಿದೆ. ಇಲ್ಲಿ ನಾವು *ವೇಗ* ಅನ್ನು ಪ್ರತಿನಿಧಿಸಲು ಮತ್ತೊಂದು ವೆಕ್ಟರ್ v ಅನ್ನು ಪರಿಚಯಿಸುತ್ತೇವೆ:

* v<sup>t+1</sup> = &gamma; v<sup>t</sup> - &eta;&nabla;&lagran;
* w<sup>t+1</sup> = w<sup>t</sup>+v<sup>t+1</sup>

ಇಲ್ಲಿ ಪ್ಯಾರಾಮೀಟರ್ &gamma; ನಮ್ಮ inertia ಅನ್ನು ಎಷ್ಟು ಪರಿಗಣಿಸುವುದನ್ನು ಸೂಚಿಸುತ್ತದೆ: &gamma;=0 ಎಂದರೆ ಸಾಂಪ್ರದಾಯಿಕ SGD; &gamma;=1 ಎಂದರೆ ಶುದ್ಧ ಚಲನೆಯ ಸಮೀಕರಣ.

### Adam, Adagrad, ಇತ್ಯಾದಿ

ಪ್ರತಿ ಲೇಯರ್‌ನಲ್ಲಿ ನಾವು ಕೆಲವು ಮ್ಯಾಟ್ರಿಕ್ಸ್ W<sub>i</sub> ಮೂಲಕ ಸಿಗ್ನಲ್‌ಗಳನ್ನು ಗುಣಿಸುತ್ತೇವೆ, ||W<sub>i</sub>|| ಮೇಲೆ ಅವಲಂಬಿಸಿ, ಗ್ರೇಡಿಯಂಟ್ ಶೂನ್ಯಕ್ಕೆ ಹತ್ತಿರವಾಗಬಹುದು ಅಥವಾ ಅನಿಯಮಿತವಾಗಿ ಏರಬಹುದು. ಇದು ಎಕ್ಸ್‌ಪ್ಲೋಡಿಂಗ್/ವ್ಯಾನಿಶಿಂಗ್ ಗ್ರೇಡಿಯಂಟ್ಸ್ ಸಮಸ್ಯೆಯ ಮೂಲ.

ಈ ಸಮಸ್ಯೆಗೆ ಒಂದು ಪರಿಹಾರವೆಂದರೆ ಸಮೀಕರಣದಲ್ಲಿ ಗ್ರೇಡಿಯಂಟ್ ದಿಕ್ಕನ್ನು ಮಾತ್ರ ಬಳಸುವುದು, ಪರಮಾಣು ಮೌಲ್ಯವನ್ನು ನಿರ್ಲಕ್ಷಿಸುವುದು, ಅಂದರೆ

w<sup>t+1</sup> = w<sup>t</sup> - &eta;(&nabla;&lagran;/||&nabla;&lagran;||), ಇಲ್ಲಿ ||&nabla;&lagran;|| = &radic;&sum;(&nabla;&lagran;)<sup>2</sup>

ಈ ಆಲ್ಗಾರಿದಮ್ ಅನ್ನು **Adagrad** ಎಂದು ಕರೆಯುತ್ತಾರೆ. ಇದೇ ಯೋಚನೆಯನ್ನು ಬಳಸುವ ಇತರ ಆಲ್ಗಾರಿದಮ್‌ಗಳು: **RMSProp**, **Adam**

> **Adam** ಅನ್ನು ಅನೇಕ ಅನ್ವಯಿಕೆಗಳಿಗೆ ಅತ್ಯಂತ ಪರಿಣಾಮಕಾರಿ ಆಲ್ಗಾರಿದಮ್ ಎಂದು ಪರಿಗಣಿಸಲಾಗುತ್ತದೆ, ಆದ್ದರಿಂದ ನೀವು ಯಾವದನ್ನು ಬಳಸಬೇಕೆಂದು ಖಚಿತವಾಗದಿದ್ದರೆ - Adam ಅನ್ನು ಬಳಸಿ.

### ಗ್ರೇಡಿಯಂಟ್ ಕ್ಲಿಪ್ಪಿಂಗ್

ಗ್ರೇಡಿಯಂಟ್ ಕ್ಲಿಪ್ಪಿಂಗ್ ಮೇಲಿನ ಯೋಚನೆಯ ವಿಸ್ತರಣೆ. ||&nabla;&lagran;|| &le; &theta; ಇದ್ದಾಗ, ನಾವು ಮೂಲ ಗ್ರೇಡಿಯಂಟ್ ಅನ್ನು ತೂಕ ಆಪ್ಟಿಮೈಜೇಶನ್‌ನಲ್ಲಿ ಪರಿಗಣಿಸುತ್ತೇವೆ, ಮತ್ತು ||&nabla;&lagran;|| > &theta; ಇದ್ದಾಗ - ಗ್ರೇಡಿಯಂಟ್ ಅನ್ನು ಅದರ ನಾರ್ಮ್ ಮೂಲಕ ಭಾಗಿಸುತ್ತೇವೆ. ಇಲ್ಲಿ &theta; ಒಂದು ಪ್ಯಾರಾಮೀಟರ್, ಬಹುತೇಕ ಸಂದರ್ಭಗಳಲ್ಲಿ ನಾವು &theta;=1 ಅಥವಾ &theta;=10 ಅನ್ನು ತೆಗೆದುಕೊಳ್ಳಬಹುದು.

### ಲರ್ನಿಂಗ್ ರೇಟ್ ಡಿಕೇ

ತರಬೇತಿ ಯಶಸ್ಸು ಬಹುಶಃ ಲರ್ನಿಂಗ್ ರೇಟ್ ಪ್ಯಾರಾಮೀಟರ್ &eta; ಮೇಲೆ ಅವಲಂಬಿತವಾಗಿದೆ. ದೊಡ್ಡ &eta; ಮೌಲ್ಯಗಳು ವೇಗವಾದ ತರಬೇತಿಗೆ ಕಾರಣವಾಗುತ್ತವೆ, ಇದು ಸಾಮಾನ್ಯವಾಗಿ ತರಬೇತಿಯ ಆರಂಭದಲ್ಲಿ ಬೇಕಾಗುತ್ತದೆ, ನಂತರ ಚಿಕ್ಕ &eta; ಮೌಲ್ಯಗಳು ನೆಟ್‌ವರ್ಕ್ ಅನ್ನು ಸೂಕ್ಷ್ಮವಾಗಿ ಹೊಂದಿಸಲು ಸಹಾಯ ಮಾಡುತ್ತವೆ. ಆದ್ದರಿಂದ, ಬಹುತೇಕ ಸಂದರ್ಭಗಳಲ್ಲಿ ತರಬೇತಿ ಪ್ರಕ್ರಿಯೆಯಲ್ಲಿ &eta; ಅನ್ನು ಕಡಿಮೆ ಮಾಡಬೇಕಾಗುತ್ತದೆ.

ಇದು ಪ್ರತಿ ತರಬೇತಿ ಯುಗದ ನಂತರ &eta; ಅನ್ನು ಕೆಲವು ಸಂಖ್ಯೆಯಿಂದ (ಉದಾ. 0.98) ಗುಣಿಸುವ ಮೂಲಕ ಅಥವಾ ಹೆಚ್ಚು ಸಂಕೀರ್ಣ **ಲರ್ನಿಂಗ್ ರೇಟ್ ಶೆಡ್ಯೂಲ್** ಬಳಸಿ ಮಾಡಬಹುದು.

## ವಿಭಿನ್ನ ನೆಟ್‌ವರ್ಕ್ ವಾಸ್ತುಶಿಲ್ಪಗಳು

ನಿಮ್ಮ ಸಮಸ್ಯೆಗೆ ಸರಿಯಾದ ನೆಟ್‌ವರ್ಕ್ ವಾಸ್ತುಶಿಲ್ಪವನ್ನು ಆಯ್ಕೆ ಮಾಡುವುದು ಕಷ್ಟಕರವಾಗಬಹುದು. ಸಾಮಾನ್ಯವಾಗಿ, ನಾವು ನಮ್ಮ ನಿರ್ದಿಷ್ಟ ಕಾರ್ಯಕ್ಕೆ (ಅಥವಾ ಸಮಾನ ಕಾರ್ಯಕ್ಕೆ) ಕಾರ್ಯನಿರ್ವಹಿಸಿದ ವಾಸ್ತುಶಿಲ್ಪವನ್ನು ತೆಗೆದುಕೊಳ್ಳುತ್ತೇವೆ. ಇಲ್ಲಿ ಕಂಪ್ಯೂಟರ್ ವೀಷನ್‌ಗೆ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್ ವಾಸ್ತುಶಿಲ್ಪಗಳ [ಒಂದು ಉತ್ತಮ ಅವಲೋಕನ](https://www.topbots.com/a-brief-history-of-neural-network-architectures/) ಇದೆ.

> ನಾವು ಹೊಂದಿರುವ ತರಬೇತಿ ಮಾದರಿಗಳ ಸಂಖ್ಯೆಗೆ ತಕ್ಕಷ್ಟು ಶಕ್ತಿಶಾಲಿ ವಾಸ್ತುಶಿಲ್ಪವನ್ನು ಆಯ್ಕೆ ಮಾಡುವುದು ಮುಖ್ಯ. ತುಂಬಾ ಶಕ್ತಿಶಾಲಿ ಮಾದರಿಯನ್ನು ಆಯ್ಕೆ ಮಾಡುವುದು [ಓವರ್‌ಫಿಟಿಂಗ್](../../3-NeuralNetworks/05-Frameworks/Overfitting.md) ಗೆ ಕಾರಣವಾಗಬಹುದು.

ಮತ್ತೊಂದು ಉತ್ತಮ ವಿಧಾನವೆಂದರೆ ಅಗತ್ಯವಿರುವ ಸಂಕೀರ್ಣತೆಗೆ ಸ್ವಯಂಚಾಲಿತವಾಗಿ ಹೊಂದಿಕೊಳ್ಳುವ ವಾಸ್ತುಶಿಲ್ಪವನ್ನು ಬಳಸುವುದು. ಕೆಲವು ಮಟ್ಟಿಗೆ, **ResNet** ವಾಸ್ತುಶಿಲ್ಪ ಮತ್ತು **Inception** ಸ್ವಯಂ ಹೊಂದಿಕೊಳ್ಳುವವು. [ಕಂಪ್ಯೂಟರ್ ವೀಷನ್ ವಾಸ್ತುಶಿಲ್ಪಗಳ ಬಗ್ಗೆ ಇನ್ನಷ್ಟು](../07-ConvNets/CNN_Architectures.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ಅಸ್ವೀಕರಣ**:  
ಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ತಪ್ಪುಗಳು ಅಥವಾ ಅಸತ್ಯತೆಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವಾಗಿ ಪರಿಗಣಿಸಬೇಕು. ಮಹತ್ವದ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->