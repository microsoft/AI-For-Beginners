# ನೈಸರ್ಗಿಕ ಭಾಷಾ ಪ್ರಕ್ರಿಯೆ

![NLP ಕಾರ್ಯಗಳ ಸಾರಾಂಶವನ್ನು ಡೂಡಲ್‌ನಲ್ಲಿ](../../../../translated_images/kn/ai-nlp.b22dcb8ca4707cea.webp)

ಈ ವಿಭಾಗದಲ್ಲಿ, ನಾವು ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳನ್ನು ಬಳಸಿಕೊಂಡು **ನೈಸರ್ಗಿಕ ಭಾಷಾ ಪ್ರಕ್ರಿಯೆ (NLP)** ಸಂಬಂಧಿತ ಕಾರ್ಯಗಳನ್ನು ನಿರ್ವಹಿಸುವುದರ ಮೇಲೆ ಗಮನಹರಿಸುವೆವು. ಕಂಪ್ಯೂಟರ್‌ಗಳು ಪರಿಹರಿಸಬೇಕಾದ ಅನೇಕ NLP ಸಮಸ್ಯೆಗಳಿವೆ:

* **ಪಠ್ಯ ವರ್ಗೀಕರಣ** ಎಂದರೆ ಪಠ್ಯ ಕ್ರಮಗಳ ಸಂಬಂಧಿಸಿದ ಸಾಮಾನ್ಯ ವರ್ಗೀಕರಣ ಸಮಸ್ಯೆ. ಉದಾಹರಣೆಗೆ, ಇಮೇಲ್ ಸಂದೇಶಗಳನ್ನು ಸ್ಪ್ಯಾಮ್ ಅಥವಾ ಸ್ಪ್ಯಾಮ್ ಅಲ್ಲ ಎಂದು ವರ್ಗೀಕರಿಸುವುದು, ಅಥವಾ ಲೇಖನಗಳನ್ನು ಕ್ರೀಡೆ, ವ್ಯವಹಾರ, ರಾಜಕಾರಣ ಇತ್ಯಾದಿಯಾಗಿ ವರ್ಗೀಕರಿಸುವುದು. ಚಾಟ್ ಬಾಟ್‌ಗಳನ್ನು ಅಭಿವೃದ್ಧಿಪಡಿಸುವಾಗ, ಬಳಕೆದಾರನು ಏನು ಹೇಳಲು ಬಯಸಿದನು ಎಂಬುದನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳಬೇಕಾಗುತ್ತದೆ — ಇದನ್ನು **ಉದ್ದೇಶ ವರ್ಗೀಕರಣ** ಎಂದು ಕರೆಯುತ್ತಾರೆ. ಉದ್ದೇಶ ವರ್ಗೀಕರಣದಲ್ಲಿ ಸಾಮಾನ್ಯವಾಗಿ ಅನೇಕ ವರ್ಗಗಳನ್ನು ನಿರ್ವಹಿಸಬೇಕಾಗುತ್ತದೆ.
* **ಭಾವನಾತ್ಮಕ ವಿಶ್ಲೇಷಣೆ** ಎಂದರೆ ಒಂದು ವಾಕ್ಯದ ಅರ್ಥವು ಎಷ್ಟು ಧನಾತ್ಮಕ ಅಥವಾ ಋಣಾತ್ಮಕ ಎಂಬುದನ್ನು ಸೂಚಿಸುವ ಸಂಖ್ಯೆಯನ್ನು (ಭಾವನೆಯನ್ನು) ನೀಡುವ ಸಾಮಾನ್ಯ ರಿಗ್ರೆಷನ್ ಸಮಸ್ಯೆ. ಭಾವನಾತ್ಮಕ ವಿಶ್ಲೇಷಣೆಯ ಹೆಚ್ಚು ಪ್ರಗತಿಶೀಲ ಆವೃತ್ತಿ **ಅಂಶಾಧಾರಿತ ಭಾವನಾತ್ಮಕ ವಿಶ್ಲೇಷಣೆ** (ABSA), ಇದರಲ್ಲಿ ಭಾವನೆ ಸಂಪೂರ್ಣ ವಾಕ್ಯಕ್ಕೆ ಅಲ್ಲದೆ ಅದರ ವಿಭಿನ್ನ ಭಾಗಗಳಿಗೆ (ಅಂಶಗಳಿಗೆ) ನೀಡಲಾಗುತ್ತದೆ, ಉದಾ. *ಈ ರೆಸ್ಟೋರೆಂಟ್‌ನಲ್ಲಿ, ನನಗೆ ಆಹಾರ ಇಷ್ಟವಾಯಿತು, ಆದರೆ ವಾತಾವರಣ ಭಯಂಕರವಾಗಿತ್ತು*.
* **ನಾಮಿತ ಘಟಕ ಗುರುತಿಸುವಿಕೆ** (NER) ಎಂದರೆ ಪಠ್ಯದಿಂದ ನಿರ್ದಿಷ್ಟ ಘಟಕಗಳನ್ನು ಹೊರತೆಗೆಯುವ ಸಮಸ್ಯೆ. ಉದಾಹರಣೆಗೆ, *ನಾನು ನಾಳೆ ಪ್ಯಾರಿಸ್‌ಗೆ ಹಾರಬೇಕಾಗಿದೆ* ಎಂಬ ವಾಕ್ಯದಲ್ಲಿ *ನಾಳೆ* ಎಂಬ ಪದವು ದಿನಾಂಕವನ್ನು ಸೂಚಿಸುತ್ತದೆ ಮತ್ತು *ಪ್ಯಾರಿಸ್* ಸ್ಥಳವನ್ನು ಸೂಚಿಸುತ್ತದೆ ಎಂದು ಅರ್ಥಮಾಡಿಕೊಳ್ಳಬೇಕಾಗುತ್ತದೆ.
* **ಕೀವರ್ಡ್ ಹೊರತೆಗೆಯುವಿಕೆ** NER ಗೆ ಸಮಾನವಾಗಿದೆ, ಆದರೆ ನಾವು ನಿರ್ದಿಷ್ಟ ಘಟಕ ಪ್ರಕಾರಗಳಿಗೆ ಪೂರ್ವ-ಪ್ರಶಿಕ್ಷಣವಿಲ್ಲದೆ ಸ್ವಯಂಚಾಲಿತವಾಗಿ ವಾಕ್ಯದ ಅರ್ಥಕ್ಕೆ ಮುಖ್ಯವಾದ ಪದಗಳನ್ನು ಹೊರತೆಗೆಯಬೇಕಾಗುತ್ತದೆ.
* **ಪಠ್ಯ ಗುಂಪುಮಾಡುವಿಕೆ** ಸಮಾನವಾದ ವಾಕ್ಯಗಳನ್ನು ಗುಂಪುಮಾಡಲು ಉಪಯುಕ್ತವಾಗಬಹುದು, ಉದಾಹರಣೆಗೆ ತಾಂತ್ರಿಕ ಬೆಂಬಲ ಸಂಭಾಷಣೆಗಳಲ್ಲಿ ಸಮಾನ ವಿನಂತಿಗಳನ್ನು ಗುಂಪುಮಾಡುವುದು.
* **ಪ್ರಶ್ನೆ ಉತ್ತರಿಸುವಿಕೆ** ಎಂದರೆ ಮಾದರಿ ನಿರ್ದಿಷ್ಟ ಪ್ರಶ್ನೆಗೆ ಉತ್ತರ ನೀಡುವ ಸಾಮರ್ಥ್ಯ. ಮಾದರಿ ಪಠ್ಯ ಭಾಗ ಮತ್ತು ಪ್ರಶ್ನೆಯನ್ನು ಇನ್‌ಪುಟ್ ಆಗಿ ಪಡೆಯುತ್ತದೆ ಮತ್ತು ಪ್ರಶ್ನೆಗೆ ಉತ್ತರ ಇರುವ ಪಠ್ಯದ ಸ್ಥಳವನ್ನು ನೀಡಬೇಕಾಗುತ್ತದೆ (ಅಥವಾ ಕೆಲವೊಮ್ಮೆ ಉತ್ತರ ಪಠ್ಯವನ್ನು ರಚಿಸಬೇಕಾಗುತ್ತದೆ).
* **ಪಠ್ಯ ರಚನೆ** ಎಂದರೆ ಮಾದರಿ ಹೊಸ ಪಠ್ಯವನ್ನು ರಚಿಸುವ ಸಾಮರ್ಥ್ಯ. ಇದನ್ನು ಕೆಲವು *ಪಠ್ಯ ಪ್ರಾಂಪ್ಟ್* ಆಧರಿಸಿ ಮುಂದಿನ ಅಕ್ಷರ/ಪದವನ್ನು ಭವಿಷ್ಯವಾಣಿ ಮಾಡುವ ವರ್ಗೀಕರಣ ಕಾರ್ಯವೆಂದು ಪರಿಗಣಿಸಬಹುದು. GPT-3 ಮುಂತಾದ ಪ್ರಗತಿಶೀಲ ಪಠ್ಯ ರಚನೆ ಮಾದರಿಗಳು [prompt programming](https://towardsdatascience.com/software-3-0-how-prompting-will-change-the-rules-of-the-game-a982fbfe1e0) ಅಥವಾ [prompt engineering](https://medium.com/swlh/openai-gpt-3-and-prompt-engineering-dcdc2c5fcd29) ಎಂಬ ತಂತ್ರಗಳನ್ನು ಬಳಸಿ ಇತರ NLP ಕಾರ್ಯಗಳನ್ನು ಸಹ ಪರಿಹರಿಸಬಹುದು.
* **ಪಠ್ಯ ಸಾರಾಂಶ** ಎಂದರೆ ಕಂಪ್ಯೂಟರ್‌ನ್ನು ದೀರ್ಘ ಪಠ್ಯವನ್ನು "ಓದಿ" ಅದನ್ನು ಕೆಲವು ವಾಕ್ಯಗಳಲ್ಲಿ ಸಾರಾಂಶಗೊಳಿಸುವ ತಂತ್ರ.
* **ಯಂತ್ರ ಅನುವಾದ** ಒಂದು ಭಾಷೆಯ ಪಠ್ಯ ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಮತ್ತು ಮತ್ತೊಂದು ಭಾಷೆಯಲ್ಲಿ ಪಠ್ಯ ರಚನೆಯ ಸಂಯೋಜನೆಯಾಗಿ ಪರಿಗಣಿಸಬಹುದು.

ಆರಂಭದಲ್ಲಿ, ಹೆಚ್ಚಿನ NLP ಕಾರ್ಯಗಳನ್ನು ವ್ಯಾಕರಣಗಳಂತಹ ಪರಂಪರাগত ವಿಧಾನಗಳಿಂದ ಪರಿಹರಿಸಲಾಗುತ್ತಿತ್ತು. ಉದಾಹರಣೆಗೆ, ಯಂತ್ರ ಅನುವಾದದಲ್ಲಿ ಪ್ರಾರಂಭಿಕ ವಾಕ್ಯವನ್ನು ವ್ಯಾಕರಣ ವೃಕ್ಷಕ್ಕೆ ಪರಿವರ್ತಿಸಲು ಪಾರ್ಸರ್‌ಗಳನ್ನು ಬಳಸಲಾಗುತ್ತಿತ್ತು, ನಂತರ ವಾಕ್ಯದ ಅರ್ಥವನ್ನು ಪ್ರತಿನಿಧಿಸುವ ಉನ್ನತ ಮಟ್ಟದ ಅರ್ಥಾತ್ಮಕ ರಚನೆಗಳನ್ನು ಹೊರತೆಗೆಯಲಾಗುತ್ತಿತ್ತು, ಮತ್ತು ಈ ಅರ್ಥ ಮತ್ತು ಗುರಿ ಭಾಷೆಯ ವ್ಯಾಕರಣ ಆಧರಿಸಿ ಫಲಿತಾಂಶವನ್ನು ರಚಿಸಲಾಗುತ್ತಿತ್ತು. ಇಂದಿನ ದಿನಗಳಲ್ಲಿ, ಅನೇಕ NLP ಕಾರ್ಯಗಳನ್ನು ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳ ಮೂಲಕ ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಪರಿಹರಿಸಲಾಗುತ್ತಿದೆ.

> ಅನೇಕ ಶ್ರೇಷ್ಟ NLP ವಿಧಾನಗಳು [Natural Language Processing Toolkit (NLTK)](https://www.nltk.org) ಪೈಥಾನ್ ಗ್ರಂಥಾಲಯದಲ್ಲಿ ಅನುಷ್ಠಾನಗೊಳ್ಳುತ್ತವೆ. ವಿವಿಧ NLP ಕಾರ್ಯಗಳನ್ನು NLTK ಬಳಸಿ ಹೇಗೆ ಪರಿಹರಿಸಬಹುದು ಎಂಬುದನ್ನು ವಿವರಿಸುವ [NLTK ಪುಸ್ತಕ](https://www.nltk.org/book/) ಆನ್‌ಲೈನ್‌ನಲ್ಲಿ ಲಭ್ಯವಿದೆ.

ನಮ್ಮ ಕೋರ್ಸ್‌ನಲ್ಲಿ, ನಾವು ಮುಖ್ಯವಾಗಿ NLP ಗಾಗಿ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳನ್ನು ಬಳಸುವುದರ ಮೇಲೆ ಗಮನಹರಿಸುವೆವು ಮತ್ತು ಅಗತ್ಯವಿದ್ದಲ್ಲಿ NLTK ಅನ್ನು ಬಳಸುವೆವು.

ನಾವು ಈಗಾಗಲೇ ಟೇಬ್ಯುಲರ್ ಡೇಟಾ ಮತ್ತು ಚಿತ್ರಗಳೊಂದಿಗೆ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳನ್ನು ಬಳಸುವುದನ್ನು ಕಲಿತಿದ್ದೇವೆ. ಆ ಡೇಟಾ ಪ್ರಕಾರಗಳ ಮತ್ತು ಪಠ್ಯದ ನಡುವಿನ ಮುಖ್ಯ ವ್ಯತ್ಯಾಸವೆಂದರೆ ಪಠ್ಯವು ಬದಲಾಗುವ ಉದ್ದದ ಕ್ರಮವಾಗಿದ್ದು, ಚಿತ್ರಗಳ ಇನ್‌ಪುಟ್ ಗಾತ್ರ ಮುಂಚಿತವಾಗಿ ತಿಳಿದಿರುತ್ತದೆ. ಸಂವೇದಿ ನೆಟ್‌ವರ್ಕ್‌ಗಳು ಇನ್‌ಪುಟ್ ಡೇಟಾದಿಂದ ಮಾದರಿಗಳನ್ನು ಹೊರತೆಗೆಯಬಹುದು, ಆದರೆ ಪಠ್ಯದ ಮಾದರಿಗಳು ಹೆಚ್ಚು ಸಂಕೀರ್ಣವಾಗಿವೆ. ಉದಾ., ನಕಾರಾತ್ಮಕತೆ ವಿಷಯದಿಂದ ದೂರವಿರುವ ಪದಗಳ ನಡುವೆ ಇರಬಹುದು (ಉದಾ. *ನನಗೆ ಕಿತ್ತಳೆಗಳು ಇಷ್ಟವಿಲ್ಲ*, ಮತ್ತು *ನನಗೆ ಆ ದೊಡ್ಡ ಬಣ್ಣಬರಹದ ರುಚಿಕರ ಕಿತ್ತಳೆಗಳು ಇಷ್ಟವಿಲ್ಲ*), ಮತ್ತು ಅದನ್ನು ಒಂದೇ ಮಾದರಿಯಾಗಿ ಅರ್ಥಮಾಡಿಕೊಳ್ಳಬೇಕು. ಆದ್ದರಿಂದ, ಭಾಷೆಯನ್ನು ನಿರ್ವಹಿಸಲು ನಾವು ಹೊಸ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್ ಪ್ರಕಾರಗಳನ್ನು ಪರಿಚಯಿಸಬೇಕಾಗುತ್ತದೆ, ಉದಾ. *ಪುನರಾವರ್ತಿತ ನೆಟ್‌ವರ್ಕ್‌ಗಳು* ಮತ್ತು *ಟ್ರಾನ್ಸ್‌ಫಾರ್ಮರ್‌ಗಳು*.

## ಗ್ರಂಥಾಲಯಗಳನ್ನು ಸ್ಥಾಪಿಸಿ

ನೀವು ಈ ಕೋರ್ಸ್ ಅನ್ನು ಸ್ಥಳೀಯ ಪೈಥಾನ್ ಸ್ಥಾಪನೆಯೊಂದಿಗೆ ನಡೆಸುತ್ತಿದ್ದರೆ, ಕೆಳಗಿನ ಆಜ್ಞೆಗಳನ್ನು ಬಳಸಿ NLP ಗಾಗಿ ಅಗತ್ಯವಿರುವ ಎಲ್ಲಾ ಗ್ರಂಥಾಲಯಗಳನ್ನು ಸ್ಥಾಪಿಸಬೇಕಾಗಬಹುದು:

**ಪೈಟಾರ್ಚ್ ಗಾಗಿ**
```bash
pip install -r requirements-torch.txt
```
**ಟೆನ್ಸರ್‌ಫ್ಲೋ ಗಾಗಿ**
```bash
pip install -r requirements-tf.txt
```

> ನೀವು [Microsoft Learn](https://docs.microsoft.com/learn/modules/intro-natural-language-processing-tensorflow/?WT.mc_id=academic-77998-cacaste) ನಲ್ಲಿ ಟೆನ್ಸರ್‌ಫ್ಲೋ ಬಳಸಿ NLP ಪ್ರಯತ್ನಿಸಬಹುದು

## GPU ಎಚ್ಚರಿಕೆ

ಈ ವಿಭಾಗದಲ್ಲಿ, ಕೆಲವು ಉದಾಹರಣೆಗಳಲ್ಲಿ ನಾವು ಬಹಳ ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು ತರಬೇತುಗೊಳಿಸುವೆವು.
* **GPU-ಸಕ್ರಿಯ ಕಂಪ್ಯೂಟರ್ ಬಳಸಿ**: ದೊಡ್ಡ ಮಾದರಿಗಳೊಂದಿಗೆ ಕೆಲಸ ಮಾಡುವಾಗ ಕಾಯುವ ಸಮಯವನ್ನು ಕಡಿಮೆ ಮಾಡಲು ನಿಮ್ಮ ನೋಟ್ಬುಕ್‌ಗಳನ್ನು GPU-ಸಕ್ರಿಯ ಕಂಪ್ಯೂಟರ್‌ನಲ್ಲಿ ನಡೆಸುವುದು ಶಿಫಾರಸು ಮಾಡಲಾಗಿದೆ.
* **GPU ಮೆಮೊರಿ ಮಿತಿಗಳು**: ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು ತರಬೇತುಗೊಳಿಸುವಾಗ GPU ಮೆಮೊರಿ ಮುಗಿಯುವ ಪರಿಸ್ಥಿತಿಗಳು ಸಂಭವಿಸಬಹುದು.
* **GPU ಮೆಮೊರಿ ಬಳಕೆ**: ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ಬಳಕೆಯಾದ GPU ಮೆಮೊರಿ ಪ್ರಮಾಣವು ವಿವಿಧ ಅಂಶಗಳ ಮೇಲೆ ಅವಲಂಬಿತವಾಗಿರುತ್ತದೆ, ಅದರಲ್ಲಿ ಮಿನಿಬ್ಯಾಚ್ ಗಾತ್ರವೂ ಸೇರಿದೆ.
* **ಮಿನಿಬ್ಯಾಚ್ ಗಾತ್ರವನ್ನು ಕಡಿಮೆ ಮಾಡಿ**: GPU ಮೆಮೊರಿ ಸಮಸ್ಯೆ ಎದುರಾದರೆ, ನಿಮ್ಮ ಕೋಡ್‌ನಲ್ಲಿ ಮಿನಿಬ್ಯಾಚ್ ಗಾತ್ರವನ್ನು ಕಡಿಮೆ ಮಾಡುವುದನ್ನು ಪರಿಗಣಿಸಿ.
* **ಟೆನ್ಸರ್‌ಫ್ಲೋ GPU ಮೆಮೊರಿ ಬಿಡುಗಡೆ**: ಹಳೆಯ ಟೆನ್ಸರ್‌ಫ್ಲೋ ಆವೃತ್ತಿಗಳು ಒಂದೇ ಪೈಥಾನ್ ಕರ್ಣಲ್‌ನಲ್ಲಿ ಅನೇಕ ಮಾದರಿಗಳನ್ನು ತರಬೇತುಗೊಳಿಸುವಾಗ GPU ಮೆಮೊರಿಯನ್ನು ಸರಿಯಾಗಿ ಬಿಡುಗಡೆ ಮಾಡದಿರಬಹುದು. GPU ಮೆಮೊರಿ ಬಳಕೆಯನ್ನು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ನಿರ್ವಹಿಸಲು, ಟೆನ್ಸರ್‌ಫ್ಲೋವನ್ನು ಅಗತ್ಯವಿರುವಷ್ಟೇ GPU ಮೆಮೊರಿ ಹಂಚಿಕೊಳ್ಳುವಂತೆ ಸಂರಚಿಸಬಹುದು.
* **ಕೋಡ್ ಸೇರಿಸುವಿಕೆ**: ಟೆನ್ಸರ್‌ಫ್ಲೋವನ್ನು ಅಗತ್ಯವಿರುವಾಗ ಮಾತ್ರ GPU ಮೆಮೊರಿ ಹಂಚಿಕೊಳ್ಳುವಂತೆ ಹೊಂದಿಸಲು, ನಿಮ್ಮ ನೋಟ್ಬುಕ್‌ಗಳಲ್ಲಿ ಕೆಳಗಿನ ಕೋಡ್ ಸೇರಿಸಿ:

```python
physical_devices = tf.config.list_physical_devices('GPU') 
if len(physical_devices)>0:
    tf.config.experimental.set_memory_growth(physical_devices[0], True) 
```

ನೀವು ಶ್ರೇಷ್ಟ ML ದೃಷ್ಟಿಕೋನದಿಂದ NLP ಕಲಿಯಲು ಆಸಕ್ತರಾಗಿದ್ದರೆ, [ಈ ಪಾಠಗಳ ಸರಣಿಯನ್ನು](https://github.com/microsoft/ML-For-Beginners/tree/main/6-NLP) ಭೇಟಿ ನೀಡಿ

## ಈ ವಿಭಾಗದಲ್ಲಿ
ಈ ವಿಭಾಗದಲ್ಲಿ ನಾವು ಕಲಿಯುವ ವಿಷಯಗಳು:

* [ಪಠ್ಯವನ್ನು ಟೆನ್ಸರ್‌ಗಳಾಗಿ ಪ್ರತಿನಿಧಿಸುವುದು](13-TextRep/README.md)
* [ಪದ ನುಡಿಗಳು](14-Emdeddings/README.md)
* [ಭಾಷಾ ಮಾದರೀಕರಣ](15-LanguageModeling/README.md)
* [ಪುನರಾವರ್ತಿತ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳು](16-RNN/README.md)
* [ಜನರೇಟಿವ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳು](17-GenerativeNetworks/README.md)
* [ಟ್ರಾನ್ಸ್‌ಫಾರ್ಮರ್‌ಗಳು](18-Transformers/README.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ಅಸ್ವೀಕರಣ**:  
ಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ತಪ್ಪುಗಳು ಅಥವಾ ಅಸತ್ಯತೆಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಪ್ರಮುಖ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->