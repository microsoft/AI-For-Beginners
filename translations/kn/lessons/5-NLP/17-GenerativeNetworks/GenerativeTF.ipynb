{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ಜನರೇಟಿವ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳು\n",
    "\n",
    "ರಿಕರೆಂಟ್ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್‌ಗಳು (RNNಗಳು) ಮತ್ತು ಅವುಗಳ ಗೇಟೆಡ್ ಸೆಲ್ ರೂಪಾಂತರಗಳು, ಉದಾಹರಣೆಗೆ ಲಾಂಗ್ ಶಾರ್ಟ್ ಟರ್ಮ್ ಮೆಮೊರಿ ಸೆಲ್ಸ್ (LSTMs) ಮತ್ತು ಗೇಟೆಡ್ ರಿಕರೆಂಟ್ ಯುನಿಟ್ಸ್ (GRUs), ಭಾಷಾ ಮಾದರೀಕರಣಕ್ಕೆ ಒಂದು ಯಂತ್ರವಿಧಾನವನ್ನು ಒದಗಿಸುತ್ತವೆ, ಅಂದರೆ ಅವು ಪದಗಳ ಕ್ರಮವನ್ನು ಕಲಿಯಬಹುದು ಮತ್ತು ಸರಣಿಯಲ್ಲಿ ಮುಂದಿನ ಪದದ ಭವಿಷ್ಯವಾಣಿ ಮಾಡಬಹುದು. ಇದರಿಂದ ನಾವು RNNಗಳನ್ನು **ಜನರೇಟಿವ್ ಕಾರ್ಯಗಳಿಗೆ** ಬಳಸಬಹುದು, ಉದಾಹರಣೆಗೆ ಸಾಮಾನ್ಯ ಪಠ್ಯ ರಚನೆ, ಯಂತ್ರ ಅನುವಾದ ಮತ್ತು ಚಿತ್ರ ಶೀರ್ಷಿಕೆ ರಚನೆ.\n",
    "\n",
    "ನಾವು ಹಿಂದಿನ ಘಟಕದಲ್ಲಿ ಚರ್ಚಿಸಿದ RNN ವಾಸ್ತುಶಿಲ್ಪದಲ್ಲಿ, ಪ್ರತಿ RNN ಘಟಕವು ಮುಂದಿನ ಹಿಡ್‌ನ್ ಸ್ಥಿತಿಯನ್ನು ಔಟ್‌ಪುಟ್ ಆಗಿ ನೀಡುತ್ತಿತ್ತು. ಆದರೆ, ನಾವು ಪ್ರತಿ ರಿಕರೆಂಟ್ ಘಟಕಕ್ಕೆ ಮತ್ತೊಂದು ಔಟ್‌ಪುಟ್ ಅನ್ನು ಸೇರಿಸಬಹುದು, ಇದು ನಮಗೆ **ಸರಣಿ** (ಮೂಲ ಸರಣಿಯ ಉದ್ದಕ್ಕೆ ಸಮಾನ) ಅನ್ನು ಔಟ್‌ಪುಟ್ ಮಾಡಲು ಅವಕಾಶ ನೀಡುತ್ತದೆ. ಜೊತೆಗೆ, ನಾವು ಪ್ರತಿ ಹಂತದಲ್ಲಿ ಇನ್‌ಪುಟ್ ಸ್ವೀಕರಿಸದ RNN ಘಟಕಗಳನ್ನು ಬಳಸಬಹುದು, ಮತ್ತು ಕೇವಲ ಕೆಲವು ಪ್ರಾರಂಭಿಕ ಸ್ಥಿತಿ ವೆಕ್ಟರ್ ಅನ್ನು ತೆಗೆದುಕೊಂಡು, ನಂತರ ಔಟ್‌ಪುಟ್ ಸರಣಿಯನ್ನು ಉತ್ಪಾದಿಸಬಹುದು.\n",
    "\n",
    "ಈ ನೋಟ್ಬುಕ್‌ನಲ್ಲಿ, ನಾವು ಪಠ್ಯವನ್ನು ರಚಿಸಲು ಸಹಾಯ ಮಾಡುವ ಸರಳ ಜನರೇಟಿವ್ ಮಾದರಿಗಳ ಮೇಲೆ ಗಮನಹರಿಸುವೆವು. ಸರಳತೆಗೆ, ನಾವು **ಅಕ್ಷರ ಮಟ್ಟದ ನೆಟ್‌ವರ್ಕ್** ಅನ್ನು ನಿರ್ಮಿಸೋಣ, ಇದು ಅಕ್ಷರದಿಂದ ಅಕ್ಷರಕ್ಕೆ ಪಠ್ಯವನ್ನು ರಚಿಸುತ್ತದೆ. ತರಬೇತಿಯ ಸಮಯದಲ್ಲಿ, ನಮಗೆ ಕೆಲವು ಪಠ್ಯ ಸಂಗ್ರಹವನ್ನು ತೆಗೆದು, ಅದನ್ನು ಅಕ್ಷರ ಸರಣಿಗಳಾಗಿ ವಿಭಜಿಸಬೇಕಾಗುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "ds_train, ds_test = tfds.load('ag_news_subset').values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಅಕ್ಷರ ಶಬ್ದಕೋಶ ನಿರ್ಮಾಣ\n",
    "\n",
    "ಅಕ್ಷರ ಮಟ್ಟದ ಜನರೇಟಿವ್ ನೆಟ್‌ವರ್ಕ್ ನಿರ್ಮಿಸಲು, ನಮಗೆ ಪಠ್ಯವನ್ನು ಪದಗಳ ಬದಲು ಪ್ರತ್ಯೇಕ ಅಕ್ಷರಗಳಾಗಿ ವಿಭಜಿಸಬೇಕಾಗುತ್ತದೆ. ನಾವು ಮೊದಲು ಬಳಸುತ್ತಿದ್ದ `TextVectorization` ಲೇಯರ್ ಅದನ್ನು ಮಾಡಲು ಸಾಧ್ಯವಿಲ್ಲ, ಆದ್ದರಿಂದ ನಮಗೆ ಎರಡು ಆಯ್ಕೆಗಳು ಇವೆ:\n",
    "\n",
    "* ಕೈಯಿಂದ ಪಠ್ಯವನ್ನು ಲೋಡ್ ಮಾಡಿ ಟೋಕನೈಜೇಶನ್ ಮಾಡುವುದು, [ಈ ಅಧಿಕೃತ Keras ಉದಾಹರಣೆಯ](https://keras.io/examples/generative/lstm_character_level_text_generation/)ಂತೆ\n",
    "* ಅಕ್ಷರ ಮಟ್ಟದ ಟೋಕನೈಜೇಶನ್ ಮಾಡಲು `Tokenizer` ಕ್ಲಾಸ್ ಬಳಸುವುದು.\n",
    "\n",
    "ನಾವು ಎರಡನೇ ಆಯ್ಕೆಯನ್ನು ತೆಗೆದುಕೊಳ್ಳುತ್ತೇವೆ. `Tokenizer` ಅನ್ನು ಪದಗಳಾಗಿ ಟೋಕನೈಜ್ ಮಾಡಲು ಸಹ ಬಳಸಬಹುದು, ಆದ್ದರಿಂದ ಅಕ್ಷರ ಮಟ್ಟದಿಂದ ಪದ ಮಟ್ಟದ ಟೋಕನೈಜೇಶನ್‌ಗೆ ಸುಲಭವಾಗಿ ಬದಲಾಯಿಸಬಹುದು.\n",
    "\n",
    "ಅಕ್ಷರ ಮಟ್ಟದ ಟೋಕನೈಜೇಶನ್ ಮಾಡಲು, `char_level=True` ಪರಾಮೀಟರ್ ಅನ್ನು ಪಾಸ್ ಮಾಡಬೇಕು:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(x):\n",
    "    return x['title']+' '+x['description']\n",
    "\n",
    "def tupelize(x):\n",
    "    return (extract_text(x),x['label'])\n",
    "\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True,lower=False)\n",
    "tokenizer.fit_on_texts([x['title'].numpy().decode('utf-8') for x in ds_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ನಾವು ಕ್ರಮದ ಅಂತ್ಯವನ್ನು ಸೂಚಿಸಲು ಒಂದು ವಿಶೇಷ ಟೋಕನ್ ಅನ್ನು ಬಳಸಲು ಬಯಸುತ್ತೇವೆ, ಅದನ್ನು ನಾವು `<eos>` ಎಂದು ಕರೆಯುತ್ತೇವೆ. ಅದನ್ನು ಶಬ್ದಕೋಶಕ್ಕೆ ಕೈಯಿಂದ ಸೇರಿಸೋಣ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = len(tokenizer.word_index)+1\n",
    "tokenizer.word_index['<eos>'] = eos_token\n",
    "\n",
    "vocab_size = eos_token + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈಗ, ಪಠ್ಯವನ್ನು ಸಂಖ್ಯೆಗಳ ಸರಣಿಗಳಾಗಿ ಎನ್‌ಕೋಡ್ ಮಾಡಲು, ನಾವು ಬಳಸಬಹುದು:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[48, 2, 10, 10, 5, 44, 1, 25, 5, 8, 10, 13, 78]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(['Hello, world!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಶೀರ್ಷಿಕೆಗಳನ್ನು ರಚಿಸಲು ಜನರೇಟಿವ್ RNN ತರಬೇತಿ\n",
    "\n",
    "ನಾವು ಸುದ್ದಿಯ ಶೀರ್ಷಿಕೆಗಳನ್ನು ರಚಿಸಲು RNN ಅನ್ನು ತರಬೇತಿಗೊಳಿಸುವ ವಿಧಾನ ಹೀಗಿದೆ. ಪ್ರತಿ ಹಂತದಲ್ಲಿ, ನಾವು ಒಂದು ಶೀರ್ಷಿಕೆಯನ್ನು ತೆಗೆದುಕೊಳ್ಳುತ್ತೇವೆ, ಅದನ್ನು RNN ಗೆ ನೀಡಲಾಗುತ್ತದೆ, ಮತ್ತು ಪ್ರತಿ ಇನ್‌ಪುಟ್ ಅಕ್ಷರಕ್ಕೆ ನೆಟ್‌ವರ್ಕ್ ಮುಂದಿನ ಔಟ್‌ಪುಟ್ ಅಕ್ಷರವನ್ನು ರಚಿಸಲು ಕೇಳಲಾಗುತ್ತದೆ:\n",
    "\n",
    "!['HELLO' ಎಂಬ ಪದದ ಉದಾಹರಣೆಯಾಗಿ RNN ರಚನೆಯನ್ನು ತೋರಿಸುವ ಚಿತ್ರ.](../../../../../translated_images/kn/rnn-generate.56c54afb52f9781d.webp)\n",
    "\n",
    "ನಮ್ಮ ಕ್ರಮದ ಕೊನೆಯ ಅಕ್ಷರಕ್ಕೆ, ನಾವು ನೆಟ್‌ವರ್ಕ್ `<eos>` ಟೋಕನ್ ರಚಿಸಲು ಕೇಳುತ್ತೇವೆ.\n",
    "\n",
    "ನಾವು ಇಲ್ಲಿ ಬಳಸುತ್ತಿರುವ ಜನರೇಟಿವ್ RNN ನ ಪ್ರಮುಖ ವ್ಯತ್ಯಾಸವೆಂದರೆ, ನಾವು RNN ನ ಪ್ರತಿ ಹಂತದಿಂದ ಔಟ್‌ಪುಟ್ ತೆಗೆದುಕೊಳ್ಳುತ್ತೇವೆ, ಕೇವಲ ಕೊನೆಯ ಸೆಲ್‌ನಿಂದ ಮಾತ್ರವಲ್ಲ. ಇದನ್ನು RNN ಸೆಲ್‌ಗೆ `return_sequences` ಪರಿಮಾಣವನ್ನು ಸೂಚಿಸುವ ಮೂಲಕ ಸಾಧಿಸಬಹುದು.\n",
    "\n",
    "ಹೀಗಾಗಿ, ತರಬೇತಿಯ ಸಮಯದಲ್ಲಿ, ನೆಟ್‌ವರ್ಕ್‌ಗೆ ಇನ್‌ಪುಟ್ ಆಗಿರುವುದು ಕೆಲವು ಉದ್ದದ ಎನ್‌ಕೋಡ್ ಮಾಡಿದ ಅಕ್ಷರಗಳ ಕ್ರಮವಾಗಿದ್ದು, ಔಟ್‌ಪುಟ್ ಅದೇ ಉದ್ದದ ಕ್ರಮವಾಗಿದ್ದು, ಆದರೆ ಒಂದು ಅಂಶದಿಂದ ಸರಿದೂಗಿಸಿ `<eos>` ಟೋಕನ್‌ನಿಂದ ಮುಕ್ತಾಯಗೊಳ್ಳುತ್ತದೆ. ಮಿನಿಬ್ಯಾಚ್ ಹಲವಾರು ಇಂತಹ ಕ್ರಮಗಳನ್ನು ಒಳಗೊಂಡಿರುತ್ತದೆ, ಮತ್ತು ಎಲ್ಲಾ ಕ್ರಮಗಳನ್ನು ಸರಿಹೊಂದಿಸಲು **padding** ಬಳಸಬೇಕಾಗುತ್ತದೆ.\n",
    "\n",
    "ನಮ್ಮಿಗಾಗಿ ಡೇಟಾಸೆಟ್ ಅನ್ನು ಪರಿವರ್ತಿಸಲು ಫಂಕ್ಷನ್‌ಗಳನ್ನು ರಚಿಸೋಣ. ನಾವು ಮಿನಿಬ್ಯಾಚ್ ಮಟ್ಟದಲ್ಲಿ ಕ್ರಮಗಳನ್ನು ಪ್ಯಾಡ್ ಮಾಡಬೇಕಾಗಿರುವುದರಿಂದ, ಮೊದಲು `.batch()` ಅನ್ನು ಕರೆದು ಡೇಟಾಸೆಟ್ ಅನ್ನು ಬ್ಯಾಚ್ ಮಾಡುತ್ತೇವೆ, ನಂತರ `map` ಅನ್ನು ಕರೆದು ಪರಿವರ್ತನೆ ಮಾಡುತ್ತೇವೆ. ಆದ್ದರಿಂದ, ಪರಿವರ್ತನೆ ಫಂಕ್ಷನ್ ಸಂಪೂರ್ಣ ಮಿನಿಬ್ಯಾಚ್ ಅನ್ನು ಪ್ಯಾರಾಮೀಟರ್ ಆಗಿ ತೆಗೆದುಕೊಳ್ಳುತ್ತದೆ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_batch(x):\n",
    "    x = [t.numpy().decode('utf-8') for t in x]\n",
    "    z = tokenizer.texts_to_sequences(x)\n",
    "    z = tf.keras.preprocessing.sequence.pad_sequences(z)\n",
    "    return tf.one_hot(z,vocab_size), tf.one_hot(tf.concat([z[:,1:],tf.constant(eos_token,shape=(len(z),1))],axis=1),vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ನಾವು ಇಲ್ಲಿ ಮಾಡುವ ಕೆಲವು ಪ್ರಮುಖ ವಿಷಯಗಳು:\n",
    "* ಮೊದಲು ನಾವು ಸ್ಟ್ರಿಂಗ್ ಟೆನ್ಸರ್‌ನಿಂದ ನಿಜವಾದ ಪಠ್ಯವನ್ನು ಹೊರತೆಗೆಯುತ್ತೇವೆ\n",
    "* `text_to_sequences` ಸ್ಟ್ರಿಂಗ್‌ಗಳ ಪಟ್ಟಿಯನ್ನು ಪೂರ್ಣಾಂಕ ಟೆನ್ಸರ್‌ಗಳ ಪಟ್ಟಿಯಾಗಿ ಪರಿವರ್ತಿಸುತ್ತದೆ\n",
    "* `pad_sequences` ಆ ಟೆನ್ಸರ್‌ಗಳನ್ನು ಅವುಗಳ ಗರಿಷ್ಠ ಉದ್ದಕ್ಕೆ ಪ್ಯಾಡ್ ಮಾಡುತ್ತದೆ\n",
    "* ಕೊನೆಗೆ ನಾವು ಎಲ್ಲಾ ಅಕ್ಷರಗಳನ್ನು ಒನ್-ಹಾಟ್ ಎನ್‌ಕೋಡ್ ಮಾಡುತ್ತೇವೆ, ಮತ್ತು ಶಿಫ್ಟಿಂಗ್ ಮತ್ತು `<eos>` ಸೇರಿಸುವುದನ್ನೂ ಮಾಡುತ್ತೇವೆ. ನಾವು ಶೀಘ್ರದಲ್ಲೇ ಒನ್-ಹಾಟ್ ಎನ್‌ಕೋಡ್ ಮಾಡಿದ ಅಕ್ಷರಗಳು ಏಕೆ ಬೇಕು ಎಂಬುದನ್ನು ನೋಡುತ್ತೇವೆ\n",
    "\n",
    "ಆದರೆ, ಈ ಫಂಕ್ಷನ್ **Pythonic** ಆಗಿದೆ, ಅಂದರೆ ಇದನ್ನು ಸ್ವಯಂಚಾಲಿತವಾಗಿ Tensorflow ಗಣನಾತ್ಮಕ ಗ್ರಾಫ್‌ಗೆ ಅನುವಾದಿಸಲಾಗುವುದಿಲ್ಲ. ನಾವು ಈ ಫಂಕ್ಷನ್ ಅನ್ನು ನೇರವಾಗಿ `Dataset.map` ಫಂಕ್ಷನ್‌ನಲ್ಲಿ ಬಳಸಲು ಪ್ರಯತ್ನಿಸಿದರೆ ದೋಷಗಳು ಬರುತ್ತವೆ. ನಾವು ಈ Pythonic ಕರೆ ಅನ್ನು `py_function` ರ್ಯಾಪರ್ ಬಳಸಿ ಒಳಗೊಳಿಸಬೇಕಾಗುತ್ತದೆ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_batch_fn(x):\n",
    "    x = x['title']\n",
    "    a,b = tf.py_function(title_batch,inp=[x],Tout=(tf.float32,tf.float32))\n",
    "    return a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ಗಮನಿಸಿ**: Pythonic ಮತ್ತು Tensorflow ಪರಿವರ್ತನೆ ಕಾರ್ಯಗಳನ್ನು ವಿಭಿನ್ನಗೊಳಿಸುವುದು ಸ್ವಲ್ಪ ಜಟಿಲವಾಗಬಹುದು, ಮತ್ತು ನೀವು ಯಾಕೆ ನಾವು ಡೇಟಾಸೆಟ್ ಅನ್ನು ಸಾಮಾನ್ಯ Python ಕಾರ್ಯಗಳನ್ನು ಬಳಸಿ ಪರಿವರ್ತನೆ ಮಾಡದೆ `fit` ಗೆ ಹಂಚುವುದಿಲ್ಲ ಎಂದು ಪ್ರಶ್ನಿಸುತ್ತಿರಬಹುದು. ಇದನ್ನು ನಿಶ್ಚಿತವಾಗಿ ಮಾಡಬಹುದು, ಆದರೆ `Dataset.map` ಬಳಕೆ ಮಾಡುವುದಕ್ಕೆ ದೊಡ್ಡ ಲಾಭವಿದೆ, ಏಕೆಂದರೆ ಡೇಟಾ ಪರಿವರ್ತನೆ ಪೈಪ್‌ಲೈನ್ Tensorflow ಗಣನಾತ್ಮಕ ಗ್ರಾಫ್ ಬಳಸಿ ಕಾರ್ಯಗತಗೊಳ್ಳುತ್ತದೆ, ಇದು GPU ಗಣನೆಗಳ ಲಾಭವನ್ನು ಪಡೆಯುತ್ತದೆ ಮತ್ತು CPU/GPU ನಡುವೆ ಡೇಟಾ ಹಂಚಿಕೆಯನ್ನು ಕಡಿಮೆ ಮಾಡುತ್ತದೆ.\n",
    "\n",
    "ಈಗ ನಾವು ನಮ್ಮ ಜನರೇಟರ್ ನೆಟ್‌ವರ್ಕ್ ನಿರ್ಮಿಸಿ ತರಬೇತಿ ಪ್ರಾರಂಭಿಸಬಹುದು. ಇದು ಹಿಂದಿನ ಘಟಕದಲ್ಲಿ ಚರ್ಚಿಸಿದ ಯಾವುದೇ ಪುನರಾವರ್ತಿತ ಸೆಲ್ (ಸರಳ, LSTM ಅಥವಾ GRU) ಆಧಾರಿತವಾಗಿರಬಹುದು. ನಮ್ಮ ಉದಾಹರಣೆಯಲ್ಲಿ ನಾವು LSTM ಬಳಸುತ್ತೇವೆ.\n",
    "\n",
    "ನೆಟ್‌ವರ್ಕ್ ಅಕ್ಷರಗಳನ್ನು ಇನ್‌ಪುಟ್ ಆಗಿ ತೆಗೆದುಕೊಳ್ಳುತ್ತದೆ ಮತ್ತು ಶಬ್ದಕೋಶದ ಗಾತ್ರ ತುಂಬಾ ಸಣ್ಣದಾಗಿರುವುದರಿಂದ, ನಮಗೆ embedding ಲೇಯರ್ ಅಗತ್ಯವಿಲ್ಲ, one-hot-encoded ಇನ್‌ಪುಟ್ ನೇರವಾಗಿ LSTM ಸೆಲ್‌ಗೆ ಹೋಗಬಹುದು. ಔಟ್‌ಪುಟ್ ಲೇಯರ್ ಒಂದು `Dense` ವರ್ಗೀಕರಿಸುವಿಕೆಯಾಗಿ ಇರುತ್ತದೆ, ಇದು LSTM ಔಟ್‌ಪುಟ್ ಅನ್ನು one-hot-encoded ಟೋಕನ್ ಸಂಖ್ಯೆಗಳಾಗಿ ಪರಿವರ್ತಿಸುತ್ತದೆ.\n",
    "\n",
    "ಇನ್ನೂ, ನಾವು ಬದಲಾಗುವ ಉದ್ದದ ಕ್ರಮಗಳೊಂದಿಗೆ ಕೆಲಸ ಮಾಡುತ್ತಿದ್ದೇವೆ, ಆದ್ದರಿಂದ ನಾವು `Masking` ಲೇಯರ್ ಬಳಸಿ ಸ್ಟ್ರಿಂಗ್‌ನ ಪ್ಯಾಡ್ ಮಾಡಿದ ಭಾಗವನ್ನು ನಿರ್ಲಕ್ಷಿಸುವ ಮಾಸ್ಕ್ ರಚಿಸಬಹುದು. ಇದು ಕಡ್ಡಾಯವಲ್ಲ, ಏಕೆಂದರೆ ನಾವು `<eos>` ಟೋಕನ್ ನಂತರದ ಎಲ್ಲವನ್ನೂ ಹೆಚ್ಚು ಆಸಕ್ತರಾಗಿಲ್ಲ, ಆದರೆ ಈ ಲೇಯರ್ ಪ್ರಕಾರದ ಅನುಭವ ಪಡೆಯಲು ನಾವು ಇದನ್ನು ಬಳಸುತ್ತೇವೆ. `input_shape` ಆಗಿದ್ದು `(None, vocab_size)`, ಇಲ್ಲಿ `None` ಬದಲಾಗುವ ಉದ್ದದ ಕ್ರಮವನ್ನು ಸೂಚಿಸುತ್ತದೆ, ಮತ್ತು ಔಟ್‌ಪುಟ್ ಆಕಾರವೂ `(None, vocab_size)` ಆಗಿದೆ, ನೀವು `summary` ನಿಂದ ನೋಡಬಹುದು:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, None, 84)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         109056    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 84)          10836     \n",
      "=================================================================\n",
      "Total params: 119,892\n",
      "Trainable params: 119,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "15000/15000 [==============================] - 229s 15ms/step - loss: 1.5385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa40c1245e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Masking(input_shape=(None,vocab_size)),\n",
    "    keras.layers.LSTM(128,return_sequences=True),\n",
    "    keras.layers.Dense(vocab_size,activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(ds_train.batch(8).map(title_batch_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಔಟ್‌ಪುಟ್ ರಚನೆ\n",
    "\n",
    "ನಾವು ಮಾದರಿಯನ್ನು ತರಬೇತುಗೊಳಿಸಿದ್ದರಿಂದ, ಈಗ ಅದನ್ನು ಬಳಸಿಕೊಂಡು ಕೆಲವು ಔಟ್‌ಪುಟ್ ರಚಿಸಲು ಬಯಸುತ್ತೇವೆ. ಮೊದಲು, ಟೋಕನ್ ಸಂಖ್ಯೆಗಳ ಸರಣಿಯಿಂದ ಪ್ರತಿನಿಧಿಸಲಾದ ಪಠ್ಯವನ್ನು ಡಿಕೋಡ್ ಮಾಡುವ ವಿಧಾನ ಬೇಕಾಗುತ್ತದೆ. ಇದಕ್ಕಾಗಿ, ನಾವು `tokenizer.sequences_to_texts` ಫಂಕ್ಷನ್ ಅನ್ನು ಬಳಸಬಹುದು; ಆದರೆ, ಇದು ಅಕ್ಷರ ಮಟ್ಟದ ಟೋಕನೈಜೇಶನ್‌ಗೆ ಚೆನ್ನಾಗಿ ಕೆಲಸ ಮಾಡದು. ಆದ್ದರಿಂದ, ನಾವು ಟೋಕನೈಜರ್‌ನಿಂದ ಟೋಕನ್‌ಗಳ ಡಿಕ್ಷನರಿ (ಹೆಸರಿಸಲಾಗಿದೆ `word_index`) ತೆಗೆದು, ಅದರಿಂದ ರಿವರ್ಸ್ ಮ್ಯಾಪ್ ರಚಿಸಿ, ನಮ್ಮದೇ ಡಿಕೋಡಿಂಗ್ ಫಂಕ್ಷನ್ ಬರೆಯುತ್ತೇವೆ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_map = {val:key for key, val in tokenizer.word_index.items()}\n",
    "\n",
    "def decode(x):\n",
    "    return ''.join([reverse_map[t] for t in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈಗ, ನಾವು ಜನರೇಶನ್ ಮಾಡೋಣ. ನಾವು ಕೆಲವು ಸ್ಟ್ರಿಂಗ್ `start` ನಿಂದ ಪ್ರಾರಂಭಿಸಿ, ಅದನ್ನು ಸರಣಿಯಾಗಿ `inp` ಗೆ ಎನ್‌ಕೋಡ್ ಮಾಡುತ್ತೇವೆ, ಮತ್ತು ನಂತರ ಪ್ರತಿ ಹಂತದಲ್ಲಿ ನಮ್ಮ ನೆಟ್‌ವರ್ಕ್ ಅನ್ನು ಕರೆಸಿ ಮುಂದಿನ ಅಕ್ಷರವನ್ನು ಊಹಿಸುತ್ತೇವೆ.\n",
    "\n",
    "ನೆಟ್‌ವರ್ಕ್‌ನ ಔಟ್‌ಪುಟ್ `out` ಎಂಬುದು `vocab_size` ಅಂಶಗಳ ವೆಕ್ಟರ್ ಆಗಿದ್ದು, ಪ್ರತಿ ಟೋಕನ್‌ನ ಸಂಭವನೀಯತೆಯನ್ನು ಪ್ರತಿನಿಧಿಸುತ್ತದೆ, ಮತ್ತು ನಾವು `argmax` ಬಳಸಿ ಅತ್ಯಂತ ಸಾಧ್ಯತೆ ಇರುವ ಟೋಕನ್ ಸಂಖ್ಯೆಯನ್ನು ಕಂಡುಹಿಡಿಯಬಹುದು. ನಂತರ ನಾವು ಆ ಅಕ್ಷರವನ್ನು ಜನರೇಟು ಮಾಡಿದ ಟೋಕನ್‌ಗಳ ಪಟ್ಟಿಗೆ ಸೇರಿಸಿ, ಜನರೇಶನ್ ಮುಂದುವರಿಸುತ್ತೇವೆ. ಒಂದು ಅಕ್ಷರವನ್ನು ಜನರೇಟ್ ಮಾಡುವ ಈ ಪ್ರಕ್ರಿಯೆಯನ್ನು `size` ಬಾರಿ ಪುನರಾವರ್ತಿಸಲಾಗುತ್ತದೆ ಅಗತ್ಯವಾದ ಅಕ್ಷರಗಳ ಸಂಖ್ಯೆಯನ್ನು ಜನರೇಟ್ ಮಾಡಲು, ಮತ್ತು `eos_token` ಕಂಡುಬಂದಾಗ ಮುಂಚಿತವಾಗಿ ನಿಲ್ಲಿಸಲಾಗುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today #39;s lead to strike for the strike for the strike for the strike (AFP)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(model,size=100,start='Today '):\n",
    "        inp = tokenizer.texts_to_sequences([start])[0]\n",
    "        chars = inp\n",
    "        for i in range(size):\n",
    "            out = model(tf.expand_dims(tf.one_hot(inp,vocab_size),0))[0][-1]\n",
    "            nc = tf.argmax(out)\n",
    "            if nc==eos_token:\n",
    "                break\n",
    "            chars.append(nc.numpy())\n",
    "            inp = inp+[nc]\n",
    "        return decode(chars)\n",
    "    \n",
    "generate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ಮಾದರಿ ಉತ್ಪಾದನೆ \n",
    "\n",
    "ನಮಗೆ *ನಿಖರತೆ* ಮುಂತಾದ ಯಾವುದೇ ಉಪಯುಕ್ತ ಅಳೆಯುವಿಕೆಗಳಿಲ್ಲದ ಕಾರಣ, ನಮ್ಮ ಮಾದರಿ ಉತ್ತಮವಾಗುತ್ತಿದೆಯೆಂದು ನೋಡಲು ಏಕಮಾತ್ರ ಮಾರ್ಗವೆಂದರೆ ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ಉತ್ಪಾದಿತ ಸ್ಟ್ರಿಂಗ್ ಅನ್ನು **ಮಾದರಿ ಉತ್ಪಾದನೆ** ಮಾಡುವುದು. ಇದಕ್ಕಾಗಿ ನಾವು **ಕಾಲ್‌ಬ್ಯಾಕ್‌ಗಳು** ಅನ್ನು ಬಳಸುತ್ತೇವೆ, ಅಂದರೆ `fit` ಫಂಕ್ಷನ್‌ಗೆ ನೀಡಬಹುದಾದ ಮತ್ತು ತರಬೇತಿ ಸಮಯದಲ್ಲಿ ನಿಯಮಿತವಾಗಿ ಕರೆಮಾಡಲಾಗುವ ಫಂಕ್ಷನ್‌ಗಳು.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15000/15000 [==============================] - 226s 15ms/step - loss: 1.2703\n",
      "Today #39;s a lead in the company for the strike\n",
      "Epoch 2/3\n",
      "15000/15000 [==============================] - 227s 15ms/step - loss: 1.2057\n",
      "Today #39;s the Market Service on Security Start (AP)\n",
      "Epoch 3/3\n",
      "15000/15000 [==============================] - 226s 15ms/step - loss: 1.1752\n",
      "Today #39;s a line on the strike to start for the start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa40c74e3d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_callback = keras.callbacks.LambdaCallback(\n",
    "  on_epoch_end = lambda batch, logs: print(generate(model))\n",
    ")\n",
    "\n",
    "model.fit(ds_train.batch(8).map(title_batch_fn),callbacks=[sampling_callback],epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈ ಉದಾಹರಣೆ ಈಗಾಗಲೇ ಕೆಲವು ಚೆನ್ನಾದ ಪಠ್ಯವನ್ನು ರಚಿಸುತ್ತದೆ, ಆದರೆ ಇದನ್ನು ಹಲವಾರು ರೀತಿಗಳಲ್ಲಿ ಇನ್ನಷ್ಟು ಸುಧಾರಿಸಬಹುದು:\n",
    "* **ಹೆಚ್ಚಿನ ಪಠ್ಯ**. ನಾವು ನಮ್ಮ ಕಾರ್ಯಕ್ಕಾಗಿ ಶೀರ್ಷಿಕೆಗಳನ್ನು ಮಾತ್ರ ಬಳಸಿದ್ದೇವೆ, ಆದರೆ ನೀವು ಸಂಪೂರ್ಣ ಪಠ್ಯವನ್ನು ಪ್ರಯೋಗಿಸಲು ಬಯಸಬಹುದು. RNN ಗಳು ದೀರ್ಘ ಕ್ರಮಗಳನ್ನು ನಿರ್ವಹಿಸುವಲ್ಲಿ ತುಂಬಾ ಉತ್ತಮವಲ್ಲವೆಂದು ನೆನಪಿಡಿ, ಆದ್ದರಿಂದ ಅವುಗಳನ್ನು ಚಿಕ್ಕ ವಾಕ್ಯಗಳಾಗಿ ವಿಭಜಿಸುವುದು ಅಥವಾ ಯಾವಾಗಲೂ ನಿಗದಿತ ಕ್ರಮದ ಉದ್ದ `num_chars` (ಉದಾಹರಣೆಗೆ, 256) ಮೇಲೆ ತರಬೇತಿ ನೀಡುವುದು ಅರ್ಥಪೂರ್ಣ. ಮೇಲಿನ ಉದಾಹರಣೆಯನ್ನು ಇಂತಹ ವಾಸ್ತುಶಿಲ್ಪಕ್ಕೆ ಬದಲಾಯಿಸಲು ನೀವು ಪ್ರಯತ್ನಿಸಬಹುದು, [ಅಧಿಕೃತ Keras ಟ್ಯುಟೋರಿಯಲ್](https://keras.io/examples/generative/lstm_character_level_text_generation/) ಅನ್ನು ಪ್ರೇರಣೆಯಾಗಿ ಬಳಸಿಕೊಂಡು.\n",
    "* **ಬಹುಮಟ್ಟದ LSTM**. 2 ಅಥವಾ 3 LSTM ಸೆಲ್‌ಗಳ ಮಟ್ಟಗಳನ್ನು ಪ್ರಯತ್ನಿಸುವುದು ಅರ್ಥಪೂರ್ಣ. ಹಿಂದಿನ ಘಟಕದಲ್ಲಿ ನಾವು ಉಲ್ಲೇಖಿಸಿದಂತೆ, ಪ್ರತಿ LSTM ಮಟ್ಟವು ಪಠ್ಯದಿಂದ ನಿರ್ದಿಷ್ಟ ಮಾದರಿಗಳನ್ನು ಹೊರತೆಗೆಯುತ್ತದೆ, ಮತ್ತು ಅಕ್ಷರ ಮಟ್ಟದ ಜನರೇಟರ್‌ನ ಸಂದರ್ಭದಲ್ಲಿ ಕೆಳಗಿನ LSTM ಮಟ್ಟವು ಸಿಲಬಲ್ಗಳನ್ನು ಹೊರತೆಗೆಯಲು ಜವಾಬ್ದಾರಿಯಾಗಿರಬಹುದು, ಮತ್ತು ಮೇಲಿನ ಮಟ್ಟಗಳು ಪದಗಳು ಮತ್ತು ಪದ ಸಂಯೋಜನೆಗಳಿಗೆ. ಇದನ್ನು LSTM ನಿರ್ಮಾಪಕಕ್ಕೆ ಮಟ್ಟಗಳ ಸಂಖ್ಯೆಯ ಪರಿಮಾಣವನ್ನು ನೀಡುವ ಮೂಲಕ ಸುಲಭವಾಗಿ ಅನುಷ್ಠಾನಗೊಳಿಸಬಹುದು.\n",
    "* ನೀವು **GRU ಘಟಕಗಳ**ೊಂದಿಗೆ ಪ್ರಯೋಗಿಸಲು ಮತ್ತು ಯಾವವು ಉತ್ತಮವಾಗಿ ಕಾರ್ಯನಿರ್ವಹಿಸುತ್ತವೆ ಎಂದು ನೋಡಲು ಬಯಸಬಹುದು, ಮತ್ತು **ವಿಭಿನ್ನ ಗುಪ್ತ ಮಟ್ಟದ ಗಾತ್ರಗಳ**ೊಂದಿಗೆ ಕೂಡ. ತುಂಬಾ ದೊಡ್ಡ ಗುಪ್ತ ಮಟ್ಟವು ಅತಿವೈಯಕ್ತೀಕರಣಕ್ಕೆ ಕಾರಣವಾಗಬಹುದು (ಉದಾ: ಜಾಲವು ನಿಖರ ಪಠ್ಯವನ್ನು ಕಲಿಯುತ್ತದೆ), ಮತ್ತು ಚಿಕ್ಕ ಗಾತ್ರವು ಉತ್ತಮ ಫಲಿತಾಂಶ ನೀಡದಿರಬಹುದು.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಸಾಫ್ಟ್ ಪಠ್ಯ ಉತ್ಪಾದನೆ ಮತ್ತು ತಾಪಮಾನ\n",
    "\n",
    "ಹಿಂದಿನ `generate` ವ್ಯಾಖ್ಯಾನದಲ್ಲಿ, ನಾವು ಯಾವಾಗಲೂ ಅತ್ಯಧಿಕ ಸಾಧ್ಯತೆಯಿರುವ ಅಕ್ಷರವನ್ನು ಮುಂದಿನ ಅಕ್ಷರವಾಗಿ ತೆಗೆದುಕೊಂಡಿದ್ದೇವೆ. ಇದರಿಂದ ಪಠ್ಯವು ಬಹುಶಃ ಒಂದೇ ಅಕ್ಷರ ಸರಣಿಗಳನ್ನು ಮರುಕಳಿಸುವಂತೆ ಆಗುತ್ತಿತ್ತು, ಉದಾಹರಣೆಗೆ ಈ ಕೆಳಗಿನಂತಿದೆ:\n",
    "```\n",
    "today of the second the company and a second the company ...\n",
    "```\n",
    "\n",
    "ಆದರೆ, ಮುಂದಿನ ಅಕ್ಷರದ ಸಾಧ್ಯತೆ ವಿತರಣೆಯನ್ನು ನೋಡಿದರೆ, ಕೆಲವು ಅತ್ಯಧಿಕ ಸಾಧ್ಯತೆಗಳ ನಡುವಿನ ವ್ಯತ್ಯಾಸ ದೊಡ್ಡದಾಗಿರದಿರಬಹುದು, ಉದಾಹರಣೆಗೆ ಒಂದು ಅಕ್ಷರಕ್ಕೆ 0.2 ಸಾಧ್ಯತೆ ಇದ್ದರೆ, ಇನ್ನೊಂದು ಅಕ್ಷರಕ್ಕೆ 0.19 ಸಾಧ್ಯತೆ ಇರಬಹುದು. ಉದಾಹರಣೆಗೆ, '*play*' ಸರಣಿಯಲ್ಲಿ ಮುಂದಿನ ಅಕ್ಷರವನ್ನು ಹುಡುಕುವಾಗ, ಮುಂದಿನ ಅಕ್ಷರವಾಗಿ ಸ್ಪೇಸ್ ಅಥವಾ **e** (ಪದ *player* ನಲ್ಲಿ ಇದ್ದಂತೆ) ಎರಡೂ ಸಮಾನವಾಗಿ ಸಾಧ್ಯವಾಗಬಹುದು.\n",
    "\n",
    "ಇದರಿಂದ ನಮಗೆ ತಿಳಿಯುತ್ತದೆ, ಯಾವಾಗಲೂ ಹೆಚ್ಚಿನ ಸಾಧ್ಯತೆಯ ಅಕ್ಷರವನ್ನು ಆಯ್ಕೆ ಮಾಡುವುದು \"ನ್ಯಾಯಸಮ್ಮತ\" ಅಲ್ಲ, ಏಕೆಂದರೆ ಎರಡನೇ ಅತ್ಯಧಿಕ ಅಕ್ಷರವನ್ನು ಆಯ್ಕೆ ಮಾಡುವುದು ಸಹ ಅರ್ಥಪೂರ್ಣ ಪಠ್ಯಕ್ಕೆ ದಾರಿ ಮಾಡಿಕೊಡಬಹುದು. ಆದ್ದರಿಂದ, ನೆಟ್‌ವರ್ಕ್ ಔಟ್‌ಪುಟ್ ನೀಡುವ ಸಾಧ್ಯತೆ ವಿತರಣೆಯಿಂದ ಅಕ್ಷರಗಳನ್ನು **ನಮೂದಿಸುವುದು** (sample) ಹೆಚ್ಚು ಜ್ಞಾನವಂತಿಕೆಯಾಗಿದೆ.\n",
    "\n",
    "ಈ ನಮೂದಿಸುವಿಕೆಯನ್ನು `np.multinomial` ಫಂಕ್ಷನ್ ಬಳಸಿ ಮಾಡಬಹುದು, ಇದು **ಮಲ್ಟಿನೋಮಿಯಲ್ ವಿತರಣೆಯನ್ನು** ಅನುಷ್ಠಾನಗೊಳಿಸುತ್ತದೆ. ಈ **ಸಾಫ್ಟ್** ಪಠ್ಯ ಉತ್ಪಾದನೆಯನ್ನು ಅನುಷ್ಠಾನಗೊಳಿಸುವ ಫಂಕ್ಷನ್ ಕೆಳಗೆ ನೀಡಲಾಗಿದೆ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Temperature = 0.3\n",
      "Today #39;s strike #39; to start at the store return\n",
      "On Sunday PO to Be Data Profit Up (Reuters)\n",
      "Moscow, SP wins straight to the Microsoft #39;s control of the space start\n",
      "President olding of the blast start for the strike to pay &lt;b&gt;...&lt;/b&gt;\n",
      "Little red riding hood ficed to the spam countered in European &lt;b&gt;...&lt;/b&gt;\n",
      "\n",
      "--- Temperature = 0.8\n",
      "Today countie strikes ryder missile faces food market blut\n",
      "On Sunday collores lose-toppy of sale of Bullment in &lt;b&gt;...&lt;/b&gt;\n",
      "Moscow, IBM Diffeiting in Afghan Software Hotels (Reuters)\n",
      "President Ol Luster for Profit Peaced Raised (AP)\n",
      "Little red riding hood dace on depart talks #39; bank up\n",
      "\n",
      "--- Temperature = 1.0\n",
      "Today wits House buiting debate fixes #39; supervice stake again\n",
      "On Sunday arling digital poaching In for level\n",
      "Moscow, DS Up 7, Top Proble Protest Caprey Mamarian Strike\n",
      "President teps help of roubler stepted lessabul-Dhalitics (AFP)\n",
      "Little red riding hood signs on cash in Carter-youb\n",
      "\n",
      "--- Temperature = 1.3\n",
      "Today wits flawer ro, pSIA figat's co DroftwavesIs Talo up\n",
      "On Sunday hround elitwing wint EU Powerburlinetien\n",
      "Moscow, Bazz #39;s sentries olymen winnelds' next for Olympite Huc?\n",
      "President lost securitys from power Elections in Smiltrials\n",
      "Little red riding hood vides profit, exponituity, profitmainalist-at said listers\n",
      "\n",
      "--- Temperature = 1.8\n",
      "Today #39;It: He deat: N.KA Asside\n",
      "On Sunday i arry Par aldeup patient Wo stele1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-db32367a0feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Temperature = {i}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_soft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-db32367a0feb>\u001b[0m in \u001b[0;36mgenerate_soft\u001b[0;34m(model, size, start, temperature)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mchars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Today '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'On Sunday '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Moscow, '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'President '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Little red riding hood '\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3f5fa6130b1d>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3f5fa6130b1d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreverse_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def generate_soft(model,size=100,start='Today ',temperature=1.0):\n",
    "        inp = tokenizer.texts_to_sequences([start])[0]\n",
    "        chars = inp\n",
    "        for i in range(size):\n",
    "            out = model(tf.expand_dims(tf.one_hot(inp,vocab_size),0))[0][-1]\n",
    "            probs = tf.exp(tf.math.log(out)/temperature).numpy().astype(np.float64)\n",
    "            probs = probs/np.sum(probs)\n",
    "            nc = np.argmax(np.random.multinomial(1,probs,1))\n",
    "            if nc==eos_token:\n",
    "                break\n",
    "            chars.append(nc)\n",
    "            inp = inp+[nc]\n",
    "        return decode(chars)\n",
    "\n",
    "words = ['Today ','On Sunday ','Moscow, ','President ','Little red riding hood ']\n",
    "    \n",
    "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
    "    print(f\"\\n--- Temperature = {i}\")\n",
    "    for j in range(5):\n",
    "        print(generate_soft(model,size=300,start=words[j],temperature=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ನಾವು ಇನ್ನೊಂದು ಪರಿಮಾಣವನ್ನು ಪರಿಚಯಿಸಿದ್ದೇವೆ ಅದನ್ನು **ತಾಪಮಾನ** ಎಂದು ಕರೆಯಲಾಗುತ್ತದೆ, ಇದು ನಾವು ಎಷ್ಟು ಕಠಿಣವಾಗಿ ಅತ್ಯಧಿಕ ಸಾಧ್ಯತೆಯನ್ನು ಅನುಸರಿಸಬೇಕು ಎಂಬುದನ್ನು ಸೂಚಿಸಲು ಬಳಸಲಾಗುತ್ತದೆ. ತಾಪಮಾನ 1.0 ಆಗಿದ್ದರೆ, ನಾವು ನ್ಯಾಯಸಮ್ಮತ ಬಹುಪದೀಯ ಮಾದರಿಯನ್ನು ಮಾಡುತ್ತೇವೆ, ಮತ್ತು ತಾಪಮಾನ ಅನಂತಕ್ಕೆ ಹೋಗುವಾಗ - ಎಲ್ಲಾ ಸಾಧ್ಯತೆಗಳು ಸಮಾನವಾಗುತ್ತವೆ, ಮತ್ತು ನಾವು ಯಾದೃಚ್ಛಿಕವಾಗಿ ಮುಂದಿನ ಅಕ್ಷರವನ್ನು ಆಯ್ಕೆಮಾಡುತ್ತೇವೆ. ಕೆಳಗಿನ ಉದಾಹರಣೆಯಲ್ಲಿ ನಾವು ಗಮನಿಸಬಹುದು, ತಾಪಮಾನವನ್ನು ತುಂಬಾ ಹೆಚ್ಚಿಸಿದಾಗ ಪಠ್ಯ ಅರ್ಥವಿಲ್ಲದಂತೆ ಆಗುತ್ತದೆ, ಮತ್ತು ಅದು 0ಕ್ಕೆ ಹತ್ತಿರವಾಗುವಾಗ \"ಚಕ್ರಾಕೃತ\" ಕಠಿಣ-ಉತ್ಪಾದಿತ ಪಠ್ಯವನ್ನು ಹೋಲುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**ಅಸ್ವೀಕರಣ**:  \nಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ತಪ್ಪುಗಳು ಅಥವಾ ಅಸತ್ಯತೆಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಮಹತ್ವದ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16af2a8bbb083ea23e5e41c7f5787656b2ce26968575d8763f2c4b17f9cd711f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "coopTranslator": {
   "original_hash": "9fbb7d5fda708537649f71f5f646fcde",
   "translation_date": "2025-11-26T02:18:08+00:00",
   "source_file": "lessons/5-NLP/17-GenerativeNetworks/GenerativeTF.ipynb",
   "language_code": "kn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}