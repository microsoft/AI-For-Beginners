# Vorgefertigte Netzwerke und Transfer-Learning

Das Training von CNNs kann viel Zeit in Anspruch nehmen, und es wird eine gro√üe Menge an Daten daf√ºr ben√∂tigt. Ein Gro√üteil der Zeit wird jedoch darauf verwendet, die besten Low-Level-Filter zu lernen, die ein Netzwerk nutzen kann, um Muster aus Bildern zu extrahieren. Eine nat√ºrliche Frage stellt sich: K√∂nnen wir ein neuronales Netzwerk, das auf einem Datensatz trainiert wurde, verwenden und anpassen, um andere Bilder zu klassifizieren, ohne den gesamten Trainingsprozess erneut durchlaufen zu m√ºssen?

## [Quiz vor der Vorlesung](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Dieser Ansatz wird als **Transfer-Learning** bezeichnet, da wir Wissen von einem neuronalen Netzwerkmodell auf ein anderes √ºbertragen. Beim Transfer-Learning beginnen wir typischerweise mit einem vortrainierten Modell, das auf einem gro√üen Bilddatensatz wie **ImageNet** trainiert wurde. Diese Modelle k√∂nnen bereits verschiedene Merkmale aus generischen Bildern gut extrahieren, und in vielen F√§llen reicht es aus, einen Klassifikator auf diesen extrahierten Merkmalen aufzubauen, um gute Ergebnisse zu erzielen.

> ‚úÖ Transfer-Learning ist ein Begriff, den man auch in anderen akademischen Bereichen wie der P√§dagogik findet. Er bezieht sich auf den Prozess, Wissen aus einem Bereich zu nehmen und in einem anderen anzuwenden.

## Vorgefertigte Modelle als Merkmalsextraktoren

Die in der vorherigen Sektion besprochenen Convolutional Networks enthalten eine Reihe von Schichten, die jeweils Merkmale aus dem Bild extrahieren sollen ‚Äì angefangen bei Low-Level-Pixelkombinationen (wie horizontalen/vertikalen Linien oder Strichen) bis hin zu h√∂herwertigen Kombinationen von Merkmalen, die beispielsweise einem Auge oder einer Flamme entsprechen. Wenn wir ein CNN auf einem ausreichend gro√üen Datensatz mit generischen und vielf√§ltigen Bildern trainieren, sollte das Netzwerk lernen, diese allgemeinen Merkmale zu extrahieren.

Sowohl Keras als auch PyTorch enthalten Funktionen, um vortrainierte neuronale Netzwerkgewichte f√ºr einige g√§ngige Architekturen einfach zu laden, von denen die meisten auf ImageNet-Bildern trainiert wurden. Die am h√§ufigsten verwendeten Architekturen sind auf der Seite [CNN Architectures](../07-ConvNets/CNN_Architectures.md) aus der vorherigen Lektion beschrieben. Insbesondere k√∂nnten Sie eine der folgenden in Betracht ziehen:

* **VGG-16/VGG-19**, relativ einfache Modelle, die dennoch gute Genauigkeit liefern. Oft ist es eine gute Wahl, VGG als ersten Versuch zu verwenden, um zu sehen, wie Transfer-Learning funktioniert.
* **ResNet**, eine Modellfamilie, die 2015 von Microsoft Research vorgeschlagen wurde. Sie haben mehr Schichten und ben√∂tigen daher mehr Ressourcen.
* **MobileNet**, eine Modellfamilie mit reduzierter Gr√∂√üe, geeignet f√ºr mobile Ger√§te. Verwenden Sie sie, wenn Sie wenig Ressourcen haben und bereit sind, ein wenig Genauigkeit zu opfern.

Hier sind Beispielmerkmale, die von einem Bild einer Katze durch das VGG-16-Netzwerk extrahiert wurden:

![Merkmale extrahiert von VGG-16](../../../../../translated_images/de/features.6291f9c7ba3a0b95.webp)

## Cats vs. Dogs Datensatz

In diesem Beispiel verwenden wir einen Datensatz von [Cats and Dogs](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), der einem realen Szenario der Bildklassifikation sehr nahe kommt.

## ‚úçÔ∏è √úbung: Transfer-Learning

Lassen Sie uns Transfer-Learning in Aktion in den entsprechenden Notebooks sehen:

* [Transfer-Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer-Learning - TensorFlow](TransferLearningTF.ipynb)

## Visualisierung einer adversarialen Katze

Ein vortrainiertes neuronales Netzwerk enth√§lt verschiedene Muster in seinem *Gehirn*, einschlie√ülich Vorstellungen von einer **idealen Katze** (sowie einem idealen Hund, idealen Zebra usw.). Es w√§re interessant, dieses Bild irgendwie **zu visualisieren**. Allerdings ist das nicht einfach, da die Muster √ºber die Netzwerkgewichte verteilt sind und in einer hierarchischen Struktur organisiert sind.

Ein Ansatz, den wir verfolgen k√∂nnen, besteht darin, mit einem zuf√§lligen Bild zu beginnen und dann die Technik der **Gradientenabstiegsoptimierung** zu verwenden, um dieses Bild so anzupassen, dass das Netzwerk denkt, es sei eine Katze.

![Bildoptimierungsschleife](../../../../../translated_images/de/ideal-cat-loop.999fbb8ff306e044.webp)

Wenn wir dies jedoch tun, erhalten wir etwas, das einem zuf√§lligen Rauschen sehr √§hnlich ist. Dies liegt daran, dass *es viele M√∂glichkeiten gibt, das Netzwerk glauben zu lassen, dass das Eingabebild eine Katze ist*, einschlie√ülich solcher, die visuell keinen Sinn ergeben. W√§hrend diese Bilder viele f√ºr eine Katze typische Muster enthalten, gibt es nichts, das sie visuell unterscheidbar macht.

Um das Ergebnis zu verbessern, k√∂nnen wir einen weiteren Term in die Verlustfunktion einf√ºgen, der als **Variationsverlust** bezeichnet wird. Dies ist eine Metrik, die zeigt, wie √§hnlich benachbarte Pixel des Bildes sind. Die Minimierung des Variationsverlusts macht das Bild glatter und beseitigt Rauschen ‚Äì wodurch visuell ansprechendere Muster sichtbar werden. Hier ist ein Beispiel f√ºr solche "idealen" Bilder, die mit hoher Wahrscheinlichkeit als Katze bzw. Zebra klassifiziert werden:

![Ideale Katze](../../../../../translated_images/de/ideal-cat.203dd4597643d6b0.webp) | ![Ideales Zebra](../../../../../translated_images/de/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
*Ideale Katze* | *Ideales Zebra*

Ein √§hnlicher Ansatz kann verwendet werden, um sogenannte **adversariale Angriffe** auf ein neuronales Netzwerk durchzuf√ºhren. Angenommen, wir m√∂chten ein neuronales Netzwerk t√§uschen und einen Hund wie eine Katze aussehen lassen. Wenn wir das Bild eines Hundes nehmen, das vom Netzwerk als Hund erkannt wird, k√∂nnen wir es mit Hilfe der Gradientenabstiegsoptimierung so lange leicht anpassen, bis das Netzwerk es als Katze klassifiziert:

![Bild eines Hundes](../../../../../translated_images/de/original-dog.8f68a67d2fe0911f.webp) | ![Bild eines Hundes, der als Katze klassifiziert wird](../../../../../translated_images/de/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Originalbild eines Hundes* | *Bild eines Hundes, der als Katze klassifiziert wird*

Sehen Sie sich den Code an, um die oben genannten Ergebnisse in folgendem Notebook zu reproduzieren:

* [Ideale und adversariale Katze - TensorFlow](AdversarialCat_TF.ipynb)

## Fazit

Mit Transfer-Learning k√∂nnen Sie schnell einen Klassifikator f√ºr eine benutzerdefinierte Objektklassifikationsaufgabe zusammenstellen und eine hohe Genauigkeit erzielen. Sie sehen, dass komplexere Aufgaben, die wir jetzt l√∂sen, eine h√∂here Rechenleistung erfordern und nicht einfach auf der CPU gel√∂st werden k√∂nnen. In der n√§chsten Einheit werden wir versuchen, eine leichtere Implementierung zu verwenden, um dasselbe Modell mit geringeren Rechenressourcen zu trainieren, was nur zu einer geringf√ºgig niedrigeren Genauigkeit f√ºhrt.

## üöÄ Herausforderung

In den begleitenden Notebooks gibt es am Ende Hinweise darauf, dass Transfer-Wissen am besten mit einigerma√üen √§hnlichen Trainingsdaten funktioniert (z. B. eine neue Tierart). Experimentieren Sie mit v√∂llig neuen Bildtypen, um zu sehen, wie gut oder schlecht Ihre Transfer-Wissen-Modelle abschneiden.

## [Quiz nach der Vorlesung](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## R√ºckblick & Selbststudium

Lesen Sie [TrainingTricks.md](TrainingTricks.md), um Ihr Wissen √ºber andere M√∂glichkeiten zur Modellschulung zu vertiefen.

## [Aufgabe](lab/README.md)

In diesem Labor verwenden wir den realen [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) Haustierdatensatz mit 35 Katzen- und Hunderassen und erstellen einen Transfer-Learning-Klassifikator.

---

