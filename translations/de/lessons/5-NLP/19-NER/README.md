# Named Entity Recognition

Bis jetzt haben wir uns haupts√§chlich auf eine NLP-Aufgabe konzentriert ‚Äì die Klassifikation. Es gibt jedoch auch andere NLP-Aufgaben, die mit neuronalen Netzwerken gel√∂st werden k√∂nnen. Eine dieser Aufgaben ist **[Named Entity Recognition](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), die sich mit der Erkennung spezifischer Entit√§ten im Text befasst, wie Orte, Personennamen, Zeitintervalle, chemische Formeln und vieles mehr.

## [Quiz vor der Vorlesung](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Beispiel f√ºr die Verwendung von NER

Angenommen, Sie m√∂chten einen nat√ºrlichen Sprach-Chatbot entwickeln, √§hnlich wie Amazon Alexa oder Google Assistant. Intelligente Chatbots funktionieren, indem sie *verstehen*, was der Benutzer m√∂chte, indem sie eine Textklassifikation auf den Eingabesatz anwenden. Das Ergebnis dieser Klassifikation ist die sogenannte **Intent**, die bestimmt, was der Chatbot tun soll.

<img alt="Bot NER" src="../../../../../translated_images/de/bot-ner.4b09235dbb0ad275.webp" width="50%"/>

> Bild vom Autor

Ein Benutzer k√∂nnte jedoch einige Parameter als Teil des Satzes angeben. Wenn er beispielsweise nach dem Wetter fragt, k√∂nnte er einen Ort oder ein Datum angeben. Ein Bot sollte in der Lage sein, diese Entit√§ten zu verstehen und die Parameter entsprechend auszuf√ºllen, bevor er die Aktion ausf√ºhrt. Genau hier kommt NER ins Spiel.

> ‚úÖ Ein weiteres Beispiel w√§re [die Analyse wissenschaftlicher medizinischer Artikel](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). Eine der Hauptaufgaben besteht darin, spezifische medizinische Begriffe wie Krankheiten und medizinische Substanzen zu identifizieren. W√§hrend eine kleine Anzahl von Krankheiten wahrscheinlich durch Substring-Suche extrahiert werden kann, erfordern komplexere Entit√§ten wie chemische Verbindungen und Medikamentennamen einen komplexeren Ansatz.

## NER als Token-Klassifikation

NER-Modelle sind im Wesentlichen **Token-Klassifikationsmodelle**, da wir f√ºr jedes der Eingabetokens entscheiden m√ºssen, ob es zu einer Entit√§t geh√∂rt oder nicht, und falls ja ‚Äì zu welcher Entit√§tsklasse.

Betrachten Sie den folgenden Titel eines Artikels:

**Trikuspidalklappeninsuffizienz** und **Lithiumcarbonat**-**Toxizit√§t** bei einem neugeborenen S√§ugling.

Die Entit√§ten hier sind:

* Trikuspidalklappeninsuffizienz ist eine Krankheit (`DIS`)
* Lithiumcarbonat ist eine chemische Substanz (`CHEM`)
* Toxizit√§t ist ebenfalls eine Krankheit (`DIS`)

Beachten Sie, dass eine Entit√§t aus mehreren Tokens bestehen kann. Und wie in diesem Fall m√ºssen wir zwischen zwei aufeinanderfolgenden Entit√§ten unterscheiden. Daher ist es √ºblich, zwei Klassen f√ºr jede Entit√§t zu verwenden ‚Äì eine, die das erste Token der Entit√§t angibt (oft wird das Pr√§fix `B-` f√ºr **b**eginning verwendet), und eine andere f√ºr die Fortsetzung einer Entit√§t (`I-`, f√ºr **i**nner Token). Wir verwenden auch `O` als Klasse, um alle **o**ther Tokens darzustellen. Eine solche Token-Kennzeichnung wird [BIO-Tagging](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (oder IOB) genannt. Nach der Kennzeichnung sieht unser Titel so aus:

Token | Tag
------|-----
Trikuspidalklappen | B-DIS
insuffizienz | I-DIS
und | O
Lithium | B-CHEM
carbonat | I-CHEM
Toxizit√§t | B-DIS
bei | O
einem | O
neugeborenen | O
S√§ugling | O
. | O

Da wir eine Eins-zu-Eins-Korrespondenz zwischen Tokens und Klassen herstellen m√ºssen, k√∂nnen wir ein rechtsbasiertes **Many-to-Many**-Neuralnetzwerkmodell aus diesem Bild trainieren:

![Bild zeigt g√§ngige Muster von rekurrenten neuronalen Netzwerken.](../../../../../translated_images/de/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> *Bild aus [diesem Blogbeitrag](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) von [Andrej Karpathy](http://karpathy.github.io/). NER-Token-Klassifikationsmodelle entsprechen der rechtsbasierten Netzwerkarchitektur auf diesem Bild.*

## Training von NER-Modellen

Da ein NER-Modell im Wesentlichen ein Token-Klassifikationsmodell ist, k√∂nnen wir RNNs, die wir bereits kennen, f√ºr diese Aufgabe verwenden. In diesem Fall gibt jeder Block des rekurrenten Netzwerks die Token-ID zur√ºck. Das folgende Beispiel-Notebook zeigt, wie man LSTM f√ºr die Token-Klassifikation trainiert.

## ‚úçÔ∏è Beispiel-Notebooks: NER

Setzen Sie Ihr Lernen mit dem folgenden Notebook fort:

* [NER mit TensorFlow](NER-TF.ipynb)

## Fazit

Ein NER-Modell ist ein **Token-Klassifikationsmodell**, was bedeutet, dass es zur Token-Klassifikation verwendet werden kann. Dies ist eine sehr h√§ufige Aufgabe in der NLP, die hilft, spezifische Entit√§ten im Text zu erkennen, einschlie√ülich Orte, Namen, Daten und mehr.

## üöÄ Herausforderung

Bearbeiten Sie die unten verlinkte Aufgabe, um ein Named Entity Recognition-Modell f√ºr medizinische Begriffe zu trainieren, und testen Sie es anschlie√üend mit einem anderen Datensatz.

## [Quiz nach der Vorlesung](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## √úberpr√ºfung & Selbststudium

Lesen Sie den Blog [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) und folgen Sie dem Abschnitt "Weiterf√ºhrende Literatur" in diesem Artikel, um Ihr Wissen zu vertiefen.

## [Aufgabe](lab/README.md)

In der Aufgabe zu dieser Lektion m√ºssen Sie ein Modell zur Erkennung medizinischer Entit√§ten trainieren. Sie k√∂nnen mit dem Training eines LSTM-Modells beginnen, wie in dieser Lektion beschrieben, und anschlie√üend das BERT-Transformer-Modell verwenden. Lesen Sie [die Anweisungen](lab/README.md), um alle Details zu erhalten.

---

