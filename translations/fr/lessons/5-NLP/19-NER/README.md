# Reconnaissance d'entit√©s nomm√©es

Jusqu'√† pr√©sent, nous nous sommes principalement concentr√©s sur une t√¢che de traitement du langage naturel (NLP) : la classification. Cependant, il existe d'autres t√¢ches NLP qui peuvent √™tre r√©alis√©es avec des r√©seaux neuronaux. L'une de ces t√¢ches est la **[Reconnaissance d'entit√©s nomm√©es](https://wikipedia.org/wiki/Named-entity_recognition)** (NER), qui consiste √† identifier des entit√©s sp√©cifiques dans un texte, telles que des lieux, des noms de personnes, des intervalles de date-heure, des formules chimiques, etc.

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ai/quiz/37)

## Exemple d'utilisation de la NER

Supposons que vous souhaitiez d√©velopper un chatbot en langage naturel, similaire √† Amazon Alexa ou Google Assistant. Les chatbots intelligents fonctionnent en *comprenant* ce que l'utilisateur veut gr√¢ce √† la classification de texte sur la phrase d'entr√©e. Le r√©sultat de cette classification est ce qu'on appelle **l'intention**, qui d√©termine ce que le chatbot doit faire.

<img alt="Bot NER" src="../../../../../translated_images/fr/bot-ner.4b09235dbb0ad275.webp" width="50%"/>

> Image par l'auteur

Cependant, un utilisateur peut fournir certains param√®tres dans sa phrase. Par exemple, en demandant la m√©t√©o, il peut sp√©cifier un lieu ou une date. Un bot doit √™tre capable de comprendre ces entit√©s et de remplir les param√®tres correspondants avant d'ex√©cuter l'action. C'est pr√©cis√©ment l√† que la NER intervient.

> ‚úÖ Un autre exemple serait [l'analyse de publications scientifiques m√©dicales](https://soshnikov.com/science/analyzing-medical-papers-with-azure-and-text-analytics-for-health/). L'un des principaux objectifs est de rechercher des termes m√©dicaux sp√©cifiques, tels que des maladies et des substances m√©dicales. Alors qu'un petit nombre de maladies peut probablement √™tre extrait par recherche de sous-cha√Ænes, des entit√©s plus complexes, comme des compos√©s chimiques et des noms de m√©dicaments, n√©cessitent une approche plus sophistiqu√©e.

## NER comme classification de tokens

Les mod√®les NER sont essentiellement des **mod√®les de classification de tokens**, car pour chaque token d'entr√©e, nous devons d√©terminer s'il appartient √† une entit√© ou non, et si oui, √† quelle classe d'entit√©.

Prenons le titre d'article suivant :

**R√©gurgitation de la valve tricuspide** et **carbonate de lithium** **toxicit√©** chez un nouveau-n√©.

Les entit√©s ici sont :

* R√©gurgitation de la valve tricuspide est une maladie (`DIS`)
* Carbonate de lithium est une substance chimique (`CHEM`)
* Toxicit√© est √©galement une maladie (`DIS`)

Notez qu'une entit√© peut s'√©tendre sur plusieurs tokens. Et, comme dans ce cas, nous devons distinguer entre deux entit√©s cons√©cutives. Ainsi, il est courant d'utiliser deux classes pour chaque entit√© : une pour sp√©cifier le premier token de l'entit√© (souvent avec le pr√©fixe `B-` pour **d√©but**), et une autre pour la continuation de l'entit√© (`I-`, pour **int√©rieur**). Nous utilisons √©galement `O` comme classe pour repr√©senter tous les autres tokens (**autres**). Ce type de balisage de tokens est appel√© [balisage BIO](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (ou IOB). Une fois balis√©, notre titre ressemblera √† ceci :

Token | Tag
------|-----
R√©gurgitation | B-DIS
de | I-DIS
la | I-DIS
valve | I-DIS
tricuspide | I-DIS
et | O
carbonate | B-CHEM
de | I-CHEM
lithium | I-CHEM
toxicit√© | B-DIS
chez | O
un | O
nouveau-n√© | O
. | O

Puisque nous devons √©tablir une correspondance un-√†-un entre les tokens et les classes, nous pouvons entra√Æner un mod√®le neuronal **many-to-many** (plusieurs-√†-plusieurs) √† partir de cette image :

![Image montrant les architectures courantes des r√©seaux neuronaux r√©currents.](../../../../../translated_images/fr/unreasonable-effectiveness-of-rnn.541ead816778f42d.webp)

> *Image tir√©e de [cet article de blog](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) par [Andrej Karpathy](http://karpathy.github.io/). Les mod√®les de classification de tokens NER correspondent √† l'architecture de r√©seau situ√©e √† l'extr√™me droite de cette image.*

## Entra√Ænement des mod√®les NER

√âtant donn√© qu'un mod√®le NER est essentiellement un mod√®le de classification de tokens, nous pouvons utiliser les RNN que nous connaissons d√©j√† pour cette t√¢che. Dans ce cas, chaque bloc du r√©seau r√©current renverra l'ID du token. L'exemple de notebook suivant montre comment entra√Æner un LSTM pour la classification de tokens.

## ‚úçÔ∏è Notebooks d'exemple : NER

Poursuivez votre apprentissage avec le notebook suivant :

* [NER avec TensorFlow](NER-TF.ipynb)

## Conclusion

Un mod√®le NER est un **mod√®le de classification de tokens**, ce qui signifie qu'il peut √™tre utilis√© pour effectuer la classification de tokens. C'est une t√¢che tr√®s courante en NLP, permettant de reconna√Ætre des entit√©s sp√©cifiques dans un texte, notamment des lieux, des noms, des dates, et bien plus.

## üöÄ D√©fi

R√©alisez l'exercice ci-dessous pour entra√Æner un mod√®le de reconnaissance d'entit√©s nomm√©es pour les termes m√©dicaux, puis testez-le sur un autre ensemble de donn√©es.

## [Quiz apr√®s le cours](https://ff-quizzes.netlify.app/en/ai/quiz/38)

## R√©vision et √©tude personnelle

Lisez l'article de blog [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) et explorez la section "Further Reading" de cet article pour approfondir vos connaissances.

## [Exercice](lab/README.md)

Dans l'exercice de cette le√ßon, vous devrez entra√Æner un mod√®le de reconnaissance d'entit√©s m√©dicales. Vous pouvez commencer par entra√Æner un mod√®le LSTM comme d√©crit dans cette le√ßon, puis passer √† l'utilisation du mod√®le transformateur BERT. Consultez [les instructions](lab/README.md) pour obtenir tous les d√©tails.

---

