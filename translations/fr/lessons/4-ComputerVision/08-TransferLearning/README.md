# R√©seaux pr√©-entra√Æn√©s et apprentissage par transfert

L'entra√Ænement des CNN peut prendre beaucoup de temps et n√©cessite une grande quantit√© de donn√©es. Cependant, une grande partie du temps est consacr√©e √† l'apprentissage des meilleurs filtres de bas niveau qu'un r√©seau peut utiliser pour extraire des motifs √† partir d'images. Une question naturelle se pose : peut-on utiliser un r√©seau neuronal entra√Æn√© sur un ensemble de donn√©es et l'adapter pour classifier d'autres images sans n√©cessiter un processus d'entra√Ænement complet ?

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Cette approche est appel√©e **apprentissage par transfert**, car nous transf√©rons une partie des connaissances d'un mod√®le de r√©seau neuronal √† un autre. Dans l'apprentissage par transfert, nous commen√ßons g√©n√©ralement par un mod√®le pr√©-entra√Æn√©, qui a √©t√© entra√Æn√© sur un grand ensemble de donn√©es d'images, comme **ImageNet**. Ces mod√®les sont d√©j√† capables d'extraire efficacement diff√©rentes caract√©ristiques d'images g√©n√©riques, et dans de nombreux cas, construire simplement un classificateur sur ces caract√©ristiques extraites peut donner de bons r√©sultats.

> ‚úÖ L'apprentissage par transfert est un terme que l'on retrouve dans d'autres domaines acad√©miques, comme l'√©ducation. Il fait r√©f√©rence au processus consistant √† appliquer des connaissances d'un domaine √† un autre.

## Mod√®les pr√©-entra√Æn√©s comme extracteurs de caract√©ristiques

Les r√©seaux convolutionnels que nous avons abord√©s dans la section pr√©c√©dente contiennent plusieurs couches, chacune √©tant cens√©e extraire des caract√©ristiques de l'image, en commen√ßant par des combinaisons de pixels de bas niveau (comme des lignes horizontales/verticales ou des traits), jusqu'√† des combinaisons de caract√©ristiques de niveau sup√©rieur, correspondant √† des √©l√©ments comme un ≈ìil ou une flamme. Si nous entra√Ænons un CNN sur un ensemble de donn√©es suffisamment large et diversifi√©, le r√©seau devrait apprendre √† extraire ces caract√©ristiques communes.

Keras et PyTorch proposent des fonctions permettant de charger facilement les poids de r√©seaux neuronaux pr√©-entra√Æn√©s pour certaines architectures courantes, dont la plupart ont √©t√© entra√Æn√©es sur des images d'ImageNet. Les mod√®les les plus utilis√©s sont d√©crits sur la page [Architectures CNN](../07-ConvNets/CNN_Architectures.md) de la le√ßon pr√©c√©dente. En particulier, vous pourriez envisager d'utiliser l'un des mod√®les suivants :

* **VGG-16/VGG-19**, qui sont des mod√®les relativement simples offrant une bonne pr√©cision. Utiliser VGG comme premi√®re tentative est souvent un bon choix pour voir comment fonctionne l'apprentissage par transfert.
* **ResNet**, une famille de mod√®les propos√©e par Microsoft Research en 2015. Ces mod√®les ont plus de couches et n√©cessitent donc davantage de ressources.
* **MobileNet**, une famille de mod√®les de taille r√©duite, adapt√©e aux appareils mobiles. Utilisez-les si vous disposez de ressources limit√©es et pouvez sacrifier un peu de pr√©cision.

Voici des exemples de caract√©ristiques extraites d'une image de chat par le r√©seau VGG-16 :

![Caract√©ristiques extraites par VGG-16](../../../../../translated_images/fr/features.6291f9c7ba3a0b95.webp)

## Ensemble de donn√©es "Chats vs. Chiens"

Dans cet exemple, nous utiliserons un ensemble de donn√©es de [Chats et Chiens](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), qui est tr√®s proche d'un sc√©nario r√©el de classification d'images.

## ‚úçÔ∏è Exercice : Apprentissage par transfert

Voyons l'apprentissage par transfert en action dans les notebooks correspondants :

* [Apprentissage par transfert - PyTorch](TransferLearningPyTorch.ipynb)
* [Apprentissage par transfert - TensorFlow](TransferLearningTF.ipynb)

## Visualisation du chat adversarial

Un r√©seau neuronal pr√©-entra√Æn√© contient diff√©rents motifs dans son *cerveau*, y compris des notions de **chat id√©al** (ainsi que de chien id√©al, de z√®bre id√©al, etc.). Il serait int√©ressant de **visualiser cette image**. Cependant, ce n'est pas simple, car les motifs sont r√©partis dans les poids du r√©seau et organis√©s dans une structure hi√©rarchique.

Une approche consiste √† partir d'une image al√©atoire et √† utiliser une technique d'optimisation par **descente de gradient** pour ajuster cette image de mani√®re √† ce que le r√©seau commence √† penser qu'il s'agit d'un chat.

![Boucle d'optimisation d'image](../../../../../translated_images/fr/ideal-cat-loop.999fbb8ff306e044.webp)

Cependant, si nous faisons cela, nous obtiendrons quelque chose qui ressemble beaucoup √† un bruit al√©atoire. Cela s'explique par le fait qu'*il existe de nombreuses fa√ßons de faire croire au r√©seau que l'image d'entr√©e est un chat*, y compris certaines qui n'ont aucun sens visuel. Bien que ces images contiennent de nombreux motifs typiques d'un chat, rien ne les contraint √† √™tre visuellement distinctives.

Pour am√©liorer le r√©sultat, nous pouvons ajouter un autre terme √† la fonction de perte, appel√© **perte de variation**. Il s'agit d'une m√©trique qui montre √† quel point les pixels voisins de l'image sont similaires. Minimiser la perte de variation rend l'image plus lisse et √©limine le bruit, r√©v√©lant ainsi des motifs plus visuellement attrayants. Voici un exemple de telles images "id√©ales", class√©es comme chat et comme z√®bre avec une forte probabilit√© :

![Chat id√©al](../../../../../translated_images/fr/ideal-cat.203dd4597643d6b0.webp) | ![Z√®bre id√©al](../../../../../translated_images/fr/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Chat id√©al* | *Z√®bre id√©al*

Une approche similaire peut √™tre utilis√©e pour effectuer des **attaques adversariales** sur un r√©seau neuronal. Supposons que nous souhaitons tromper un r√©seau neuronal et faire en sorte qu'un chien ressemble √† un chat. Si nous prenons une image de chien, reconnue par le r√©seau comme un chien, nous pouvons la modifier l√©g√®rement en utilisant l'optimisation par descente de gradient, jusqu'√† ce que le r√©seau commence √† la classer comme un chat :

![Image d'un chien](../../../../../translated_images/fr/original-dog.8f68a67d2fe0911f.webp) | ![Image d'un chien class√©e comme un chat](../../../../../translated_images/fr/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Image originale d'un chien* | *Image d'un chien class√©e comme un chat*

Consultez le code pour reproduire les r√©sultats ci-dessus dans le notebook suivant :

* [Chat id√©al et adversarial - TensorFlow](AdversarialCat_TF.ipynb)

## Conclusion

Gr√¢ce √† l'apprentissage par transfert, vous pouvez rapidement cr√©er un classificateur pour une t√¢che de classification d'objets personnalis√©e et obtenir une grande pr√©cision. Vous pouvez constater que les t√¢ches plus complexes que nous r√©solvons maintenant n√©cessitent une puissance de calcul plus √©lev√©e et ne peuvent pas √™tre facilement ex√©cut√©es sur un CPU. Dans la prochaine unit√©, nous essayerons d'utiliser une impl√©mentation plus l√©g√®re pour entra√Æner le m√™me mod√®le en utilisant moins de ressources de calcul, ce qui entra√Æne une pr√©cision l√©g√®rement inf√©rieure.

## üöÄ D√©fi

Dans les notebooks associ√©s, des notes en bas expliquent que l'apprentissage par transfert fonctionne mieux avec des donn√©es d'entra√Ænement quelque peu similaires (par exemple, un nouveau type d'animal). Faites des exp√©rimentations avec des types d'images compl√®tement nouveaux pour voir √† quel point vos mod√®les d'apprentissage par transfert fonctionnent bien ou mal.

## [Quiz apr√®s le cours](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## R√©vision et auto-apprentissage

Lisez [TrainingTricks.md](TrainingTricks.md) pour approfondir vos connaissances sur d'autres fa√ßons d'entra√Æner vos mod√®les.

## [Devoir](lab/README.md)

Dans ce laboratoire, nous utiliserons l'ensemble de donn√©es r√©el [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) sur les animaux de compagnie, comprenant 35 races de chats et de chiens, et nous construirons un classificateur bas√© sur l'apprentissage par transfert.

---

