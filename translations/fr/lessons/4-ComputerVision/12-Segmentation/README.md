<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d7f8a25ff13cfe9f4cd671cc23351fad",
  "translation_date": "2025-08-24T20:49:58+00:00",
  "source_file": "lessons/4-ComputerVision/12-Segmentation/README.md",
  "language_code": "fr"
}
-->
# Segmentation

Nous avons pr√©c√©demment appris la d√©tection d'objets, qui nous permet de localiser des objets dans une image en pr√©disant leurs *bo√Ætes englobantes*. Cependant, pour certaines t√¢ches, nous avons besoin d'une localisation d'objets plus pr√©cise que les simples bo√Ætes englobantes. Cette t√¢che s'appelle **segmentation**.

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ai/quiz/23)

La segmentation peut √™tre vue comme une **classification de pixels**, o√π pour **chaque** pixel de l'image, nous devons pr√©dire sa classe (*le fond* √©tant l'une des classes). Il existe deux principaux algorithmes de segmentation :

* La **segmentation s√©mantique** indique uniquement la classe du pixel, sans distinguer les diff√©rents objets appartenant √† la m√™me classe.
* La **segmentation par instance** divise les classes en diff√©rentes instances.

Pour la segmentation par instance, ces moutons sont des objets diff√©rents, mais pour la segmentation s√©mantique, tous les moutons sont repr√©sent√©s par une seule classe.

<img src="images/instance_vs_semantic.jpeg" width="50%">

> Image tir√©e de [cet article de blog](https://nirmalamurali.medium.com/image-classification-vs-semantic-segmentation-vs-instance-segmentation-625c33a08d50)

Il existe diff√©rentes architectures neuronales pour la segmentation, mais elles ont toutes la m√™me structure. D'une certaine mani√®re, cela ressemble √† l'autoencodeur que vous avez appris pr√©c√©demment, mais au lieu de d√©construire l'image originale, notre objectif est de d√©construire un **masque**. Ainsi, un r√©seau de segmentation comporte les parties suivantes :

* **Encodeur** : extrait les caract√©ristiques de l'image d'entr√©e.
* **D√©codeur** : transforme ces caract√©ristiques en une **image de masque**, avec la m√™me taille et un nombre de canaux correspondant au nombre de classes.

<img src="images/segm.png" width="80%">

> Image tir√©e de [cette publication](https://arxiv.org/pdf/2001.05566.pdf)

Il est particuli√®rement important de mentionner la fonction de perte utilis√©e pour la segmentation. Lors de l'utilisation d'autoencodeurs classiques, nous devons mesurer la similarit√© entre deux images, et nous pouvons utiliser l'erreur quadratique moyenne (MSE) pour cela. En segmentation, chaque pixel de l'image cible du masque repr√©sente le num√©ro de classe (encod√© en one-hot le long de la troisi√®me dimension), nous devons donc utiliser des fonctions de perte sp√©cifiques √† la classification - la perte par entropie crois√©e, moyenn√©e sur tous les pixels. Si le masque est binaire, on utilise la **perte par entropie crois√©e binaire** (BCE).

> ‚úÖ L'encodage one-hot est une m√©thode pour encoder une √©tiquette de classe en un vecteur de longueur √©gale au nombre de classes. Consultez [cet article](https://datagy.io/sklearn-one-hot-encode/) pour en savoir plus sur cette technique.

## Segmentation pour l'imagerie m√©dicale

Dans cette le√ßon, nous verrons la segmentation en action en entra√Ænant un r√©seau √† reconna√Ætre des n√¶vus humains (√©galement appel√©s grains de beaut√©) sur des images m√©dicales. Nous utiliserons la <a href="https://www.fc.up.pt/addi/ph2%20database.html">base de donn√©es PH<sup>2</sup></a> d'images de dermoscopie comme source d'images. Ce jeu de donn√©es contient 200 images de trois classes : n√¶vus typique, n√¶vus atypique et m√©lanome. Toutes les images contiennent √©galement un **masque** correspondant qui d√©limite le n√¶vus.

> ‚úÖ Cette technique est particuli√®rement adapt√©e √† ce type d'imagerie m√©dicale, mais quelles autres applications r√©elles pourriez-vous envisager ?

<img alt="navi" src="images/navi.png"/>

> Image tir√©e de la base de donn√©es PH<sup>2</sup>

Nous entra√Ænerons un mod√®le √† segmenter tout n√¶vus de son arri√®re-plan.

## ‚úçÔ∏è Exercices : Segmentation s√©mantique

Ouvrez les notebooks ci-dessous pour en apprendre davantage sur diff√©rentes architectures de segmentation s√©mantique, pratiquer leur utilisation et les voir en action.

* [Segmentation s√©mantique avec Pytorch](../../../../../lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationPytorch.ipynb)
* [Segmentation s√©mantique avec TensorFlow](../../../../../lessons/4-ComputerVision/12-Segmentation/SemanticSegmentationTF.ipynb)

## [Quiz apr√®s le cours](https://ff-quizzes.netlify.app/en/ai/quiz/24)

## Conclusion

La segmentation est une technique tr√®s puissante pour la classification d'images, allant au-del√† des bo√Ætes englobantes pour une classification au niveau des pixels. C'est une technique utilis√©e en imagerie m√©dicale, entre autres applications.

## üöÄ D√©fi

La segmentation corporelle n'est qu'une des t√¢ches courantes que nous pouvons r√©aliser avec des images de personnes. D'autres t√¢ches importantes incluent la **d√©tection de squelette** et la **d√©tection de pose**. Essayez la biblioth√®que [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) pour voir comment la d√©tection de pose peut √™tre utilis√©e.

## R√©vision et √©tude personnelle

Cet [article Wikip√©dia](https://wikipedia.org/wiki/Image_segmentation) offre un bon aper√ßu des diverses applications de cette technique. Renseignez-vous davantage sur les sous-domaines de la segmentation par instance et de la segmentation panoptique dans ce domaine d'√©tude.

## [Devoir](lab/README.md)

Dans ce laboratoire, essayez la **segmentation du corps humain** en utilisant le [jeu de donn√©es Segmentation Full Body MADS](https://www.kaggle.com/datasets/tapakah68/segmentation-full-body-mads-dataset) disponible sur Kaggle.

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.