<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f7b97b375358cb51a1e098df306bf73",
  "translation_date": "2025-08-28T15:13:51+00:00",
  "source_file": "lessons/4-ComputerVision/07-ConvNets/CNN_Architectures.md",
  "language_code": "no"
}
-->
# Velkjente CNN-arkitekturer

### VGG-16

VGG-16 er et nettverk som oppn친dde 92,7 % n칮yaktighet i ImageNet top-5 klassifisering i 2014. Det har f칮lgende lagstruktur:

![ImageNet Layers](../../../../../translated_images/vgg-16-arch1.d901a5583b3a51baeaab3e768567d921e5d54befa46e1e642616c5458c934028.no.jpg)

Som du kan se, f칮lger VGG en tradisjonell pyramidearkitektur, som er en sekvens av konvolusjons- og pooling-lag.

![ImageNet Pyramid](../../../../../translated_images/vgg-16-arch.64ff2137f50dd49fdaa786e3f3a975b3f22615efd13efb19c5d22f12e01451a1.no.jpg)

> Bilde fra [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet er en familie av modeller foresl친tt av Microsoft Research i 2015. Hovedideen bak ResNet er 친 bruke **residualblokker**:

<img src="images/resnet-block.png" width="300"/>

> Bilde fra [denne artikkelen](https://arxiv.org/pdf/1512.03385.pdf)

Grunnen til 친 bruke identitets-pass-through er at laget skal forutsi **forskjellen** mellom resultatet fra et tidligere lag og utgangen fra residualblokken - derav navnet *residual*. Disse blokkene er mye enklere 친 trene, og man kan konstruere nettverk med flere hundre slike blokker (de vanligste variantene er ResNet-52, ResNet-101 og ResNet-152).

Du kan ogs친 tenke p친 dette nettverket som i stand til 친 justere kompleksiteten til datasettet. I starten, n친r du begynner 친 trene nettverket, er vektverdiene sm친, og mesteparten av signalet g친r gjennom identitetslagene. Etter hvert som treningen skrider frem og vektene blir st칮rre, 칮ker betydningen av nettverksparametrene, og nettverket tilpasser seg for 친 oppn친 n칮dvendig uttrykkskraft for 친 klassifisere treningsbildene korrekt.

### Google Inception

Google Inception-arkitekturen tar denne ideen et steg videre og bygger hvert nettverkslag som en kombinasjon av flere forskjellige veier:

<img src="images/inception.png" width="400"/>

> Bilde fra [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Her m친 vi fremheve rollen til 1x1-konvolusjoner, fordi de ved f칮rste 칮yekast ikke gir mening. Hvorfor skulle vi trenge 친 kj칮re gjennom bildet med et 1x1-filter? Men husk at konvolusjonsfiltre ogs친 fungerer med flere dybdekanaler (opprinnelig - RGB-farger, i p친f칮lgende lag - kanaler for forskjellige filtre), og 1x1-konvolusjon brukes til 친 blande disse inngangskanalene sammen ved hjelp av forskjellige trenbare vekter. Det kan ogs친 ses som nedsampling (pooling) over kanaldimensjonen.

Her er [en god bloggpost](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) om emnet, og [den originale artikkelen](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet er en familie av modeller med redusert st칮rrelse, egnet for mobile enheter. Bruk dem hvis du har begrensede ressurser og kan ofre litt n칮yaktighet. Hovedideen bak dem er s친kalt **depthwise separable convolution**, som gj칮r det mulig 친 representere konvolusjonsfiltre som en sammensetning av romlige konvolusjoner og 1x1-konvolusjon over dybdekanaler. Dette reduserer antall parametere betydelig, gj칮r nettverket mindre i st칮rrelse, og ogs친 enklere 친 trene med mindre data.

Her er [en god bloggpost om MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Konklusjon

I denne enheten har du l칝rt hovedkonseptet bak nevrale nettverk for datavisjon - konvolusjonsnettverk. Virkelige arkitekturer som driver bildegjenkjenning, objektdeteksjon og til og med bildegenerering er alle basert p친 CNN-er, bare med flere lag og noen ekstra treningstriks.

## 游 Utfordring

I de medf칮lgende notatb칮kene er det notater nederst om hvordan man kan oppn친 h칮yere n칮yaktighet. Gj칮r noen eksperimenter for 친 se om du kan oppn친 bedre resultater.

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Gjennomgang og selvstudium

Selv om CNN-er oftest brukes til oppgaver innen datavisjon, er de generelt gode til 친 trekke ut m칮nstre av fast st칮rrelse. For eksempel, hvis vi jobber med lyd, kan vi ogs친 bruke CNN-er til 친 lete etter spesifikke m칮nstre i lydsignalet - i s친 fall vil filtrene v칝re 1-dimensjonale (og dette CNN-et vil kalles 1D-CNN). Noen ganger brukes ogs친 3D-CNN til 친 trekke ut funksjoner i et flerdimensjonalt rom, som visse hendelser som skjer p친 video - CNN kan fange visse m칮nstre av funksjonsendringer over tid. Gj칮r litt gjennomgang og selvstudium om andre oppgaver som kan utf칮res med CNN-er.

## [Oppgave](lab/README.md)

I denne labben skal du klassifisere forskjellige katteraser og hunderaser. Disse bildene er mer komplekse enn MNIST-datasettet, har h칮yere dimensjoner, og det er mer enn 10 klasser.

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n칮yaktighet, v칝r oppmerksom p친 at automatiserte oversettelser kan inneholde feil eller un칮yaktigheter. Det originale dokumentet p친 sitt opprinnelige spr친k b칮r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.