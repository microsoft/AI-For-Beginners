# Velkjente CNN-arkitekturer

### VGG-16

VGG-16 er et nettverk som oppn친dde 92,7 % n칮yaktighet i ImageNet top-5 klassifisering i 2014. Det har f칮lgende lagstruktur:

![ImageNet Layers](../../../../../translated_images/no/vgg-16-arch1.d901a5583b3a51ba.webp)

Som du kan se, f칮lger VGG en tradisjonell pyramidearkitektur, som er en sekvens av konvolusjons- og pooling-lag.

![ImageNet Pyramid](../../../../../translated_images/no/vgg-16-arch.64ff2137f50dd49f.webp)

> Bilde fra [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet er en familie av modeller foresl친tt av Microsoft Research i 2015. Hovedideen bak ResNet er 친 bruke **residualblokker**:

<img src="../../../../../translated_images/no/resnet-block.aba4ccbcc0944434.webp" width="300"/>

> Bilde fra [denne artikkelen](https://arxiv.org/pdf/1512.03385.pdf)

Grunnen til 친 bruke identitets-passering er at laget skal forutsi **forskjellen** mellom resultatet fra et tidligere lag og utgangen fra residualblokken - derav navnet *residual*. Disse blokkene er mye enklere 친 trene, og man kan konstruere nettverk med flere hundre slike blokker (de vanligste variantene er ResNet-52, ResNet-101 og ResNet-152).

Du kan ogs친 tenke p친 dette nettverket som i stand til 친 justere kompleksiteten til datasettet. I starten, n친r du begynner 친 trene nettverket, er vektverdiene sm친, og mesteparten av signalet g친r gjennom identitetslagene. Etter hvert som treningen skrider frem og vektene blir st칮rre, 칮ker betydningen av nettverksparametrene, og nettverket tilpasser seg for 친 oppn친 n칮dvendig uttrykkskraft for 친 klassifisere treningsbildene korrekt.

### Google Inception

Google Inception-arkitekturen tar denne ideen et steg videre og bygger hvert nettverkslag som en kombinasjon av flere forskjellige veier:

<img src="../../../../../translated_images/no/inception.a6605b85bcbc6f52.webp" width="400"/>

> Bilde fra [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Her m친 vi fremheve rollen til 1x1-konvolusjoner, fordi de ved f칮rste 칮yekast ikke gir mening. Hvorfor skulle vi trenge 친 kj칮re gjennom bildet med et 1x1-filter? Men du m친 huske at konvolusjonsfiltre ogs친 fungerer med flere dybdekanaler (opprinnelig - RGB-farger, i p친f칮lgende lag - kanaler for forskjellige filtre), og 1x1-konvolusjon brukes til 친 blande disse inngangskanalene sammen ved hjelp av forskjellige trenbare vekter. Det kan ogs친 ses som nedsampling (pooling) over kanaldimensjonen.

Her er [en god bloggpost](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) om emnet, og [den originale artikkelen](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet er en familie av modeller med redusert st칮rrelse, egnet for mobile enheter. Bruk dem hvis du har begrensede ressurser og kan ofre litt n칮yaktighet. Hovedideen bak dem er s친kalte **depthwise separable convolution**, som gj칮r det mulig 친 representere konvolusjonsfiltre som en sammensetning av romlige konvolusjoner og 1x1-konvolusjon over dybdekanaler. Dette reduserer antall parametere betydelig, noe som gj칮r nettverket mindre i st칮rrelse og ogs친 enklere 친 trene med mindre data.

Her er [en god bloggpost om MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Konklusjon

I denne enheten har du l칝rt hovedkonseptet bak nevrale nettverk for datamaskinsyn - konvolusjonsnettverk. Virkelige arkitekturer som driver bildeklassifisering, objektdeteksjon og til og med bildegenereringsnettverk er alle basert p친 CNN-er, bare med flere lag og noen ekstra treningsmetoder.

## 游 Utfordring

I de medf칮lgende notatb칮kene er det notater nederst om hvordan man kan oppn친 h칮yere n칮yaktighet. Gj칮r noen eksperimenter for 친 se om du kan oppn친 bedre resultater.

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Gjennomgang og selvstudium

Selv om CNN-er oftest brukes til oppgaver innen datamaskinsyn, er de generelt gode til 친 trekke ut m칮nstre av fast st칮rrelse. For eksempel, hvis vi jobber med lyd, kan vi ogs친 bruke CNN-er til 친 lete etter spesifikke m칮nstre i lydsignalet - i s친 fall vil filtrene v칝re 1-dimensjonale (og dette CNN-et vil kalles 1D-CNN). Noen ganger brukes ogs친 3D-CNN til 친 trekke ut funksjoner i et multidimensjonalt rom, som visse hendelser som skjer p친 video - CNN kan fange visse m칮nstre av funksjonsendringer over tid. Gj칮r litt gjennomgang og selvstudium om andre oppgaver som kan utf칮res med CNN-er.

## [Oppgave](lab/README.md)

I denne laben skal du klassifisere forskjellige katteraser og hunderaser. Disse bildene er mer komplekse enn MNIST-datasettet og har h칮yere dimensjoner, og det er mer enn 10 klasser.

---

