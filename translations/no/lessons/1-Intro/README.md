# Introduksjon til AI

![Oppsummering av innholdet i Introduksjon til AI i en tegning](../../../../translated_images/no/ai-intro.bf28d1ac4235881c.webp)

> Tegning av [Tomomi Imura](https://twitter.com/girlie_mac)

## [Quiz f√∏r forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/1)

**Kunstig intelligens** er en spennende vitenskapelig disiplin som studerer hvordan vi kan f√• datamaskiner til √• vise intelligent atferd, f.eks. gj√∏re de tingene som mennesker er gode til √• gj√∏re.

Opprinnelig ble datamaskiner oppfunnet av [Charles Babbage](https://en.wikipedia.org/wiki/Charles_Babbage) for √• operere p√• tall ved √• f√∏lge en veldefinert prosedyre ‚Äì en algoritme. Moderne datamaskiner, selv om de er betydelig mer avanserte enn den opprinnelige modellen foresl√•tt p√• 1800-tallet, f√∏lger fortsatt samme id√© om kontrollerte beregninger. Dermed er det mulig √• programmere en datamaskin til √• gj√∏re noe hvis vi kjenner den n√∏yaktige sekvensen av trinn som m√• utf√∏res for √• oppn√• m√•let.

![Bilde av en person](../../../../translated_images/no/dsh_age.d212a30d4e54fb5f.webp)

> Foto av [Vickie Soshnikova](http://twitter.com/vickievalerie)

> ‚úÖ √Ö definere alderen til en person ut fra et fotografi er en oppgave som ikke kan programmeres eksplisitt, fordi vi ikke vet hvordan vi kommer frem til et tall i hodet v√•rt n√•r vi gj√∏r det.

---

Det finnes imidlertid noen oppgaver som vi ikke eksplisitt vet hvordan vi skal l√∏se. Tenk p√• det √• bestemme alderen til en person ut fra et fotografi. Vi l√¶rer oss dette p√• en eller annen m√•te, fordi vi har sett mange eksempler p√• mennesker i ulike aldre, men vi kan ikke eksplisitt forklare hvordan vi gj√∏r det, og heller ikke programmere en datamaskin til √• gj√∏re det. Dette er akkurat den typen oppgaver som er interessante for **kunstig intelligens** (forkortet AI).

‚úÖ Tenk p√• noen oppgaver du kunne overlate til en datamaskin som ville dra nytte av AI. Tenk p√• omr√•der som finans, medisin og kunst ‚Äì hvordan drar disse omr√•dene nytte av AI i dag?

## Svak AI vs. Sterk AI

Svak AI | Sterk AI
---------------------------------------|-------------------------------------
Svak AI refererer til AI-systemer som er designet og trent for en spesifikk oppgave eller et smalt sett av oppgaver.|Sterk AI, eller kunstig generell intelligens (AGI), refererer til AI-systemer med menneskelig niv√• av intelligens og forst√•else.
Disse AI-systemene er ikke generelt intelligente; de utmerker seg i √• utf√∏re en forh√•ndsdefinert oppgave, men mangler ekte forst√•else eller bevissthet.|Disse AI-systemene har evnen til √• utf√∏re enhver intellektuell oppgave som et menneske kan gj√∏re, tilpasse seg ulike domener og besitte en form for bevissthet eller selvforst√•else.
Eksempler p√• svak AI inkluderer virtuelle assistenter som Siri eller Alexa, anbefalingsalgoritmer brukt av str√∏mmetjenester, og chatboter designet for spesifikke kundeserviceoppgaver.|√Ö oppn√• sterk AI er et langsiktig m√•l for AI-forskning og vil kreve utvikling av AI-systemer som kan resonnere, l√¶re, forst√• og tilpasse seg p√• tvers av et bredt spekter av oppgaver og kontekster.
Svak AI er h√∏yt spesialisert og har ikke menneskelignende kognitive evner eller generell probleml√∏sningsevne utenfor sitt smale domene.|Sterk AI er forel√∏pig et teoretisk konsept, og ingen AI-systemer har n√•dd dette niv√•et av generell intelligens.

For mer informasjon, se **[Artificial General Intelligence](https://en.wikipedia.org/wiki/Artificial_general_intelligence)** (AGI).

## Definisjonen av intelligens og Turing-testen

Et av problemene med begrepet **[intelligens](https://en.wikipedia.org/wiki/Intelligence)** er at det ikke finnes noen klar definisjon av dette begrepet. Man kan argumentere for at intelligens er knyttet til **abstrakt tenkning** eller **selvbevissthet**, men vi kan ikke definere det ordentlig.

![Bilde av en katt](../../../../translated_images/no/photo-cat.8c8e8fb760ffe457.webp)

> [Foto](https://unsplash.com/photos/75715CVEJhI) av [Amber Kipp](https://unsplash.com/@sadmax) fra Unsplash

For √• se hvor tvetydig begrepet *intelligens* er, pr√∏v √• svare p√• sp√∏rsm√•let: "Er en katt intelligent?". Ulike mennesker har en tendens til √• gi ulike svar p√• dette sp√∏rsm√•let, siden det ikke finnes noen universelt akseptert test for √• bevise om p√•standen er sann eller ikke. Og hvis du tror det finnes ‚Äì pr√∏v √• gi katten din en IQ-test...

‚úÖ Tenk et √∏yeblikk p√• hvordan du definerer intelligens. Er en kr√•ke som kan l√∏se en labyrint for √• f√• tak i mat intelligent? Er et barn intelligent?

---

N√•r vi snakker om AGI, trenger vi en m√•te √• avgj√∏re om vi har skapt et virkelig intelligent system. [Alan Turing](https://en.wikipedia.org/wiki/Alan_Turing) foreslo en metode kalt **[Turing-testen](https://en.wikipedia.org/wiki/Turing_test)**, som ogs√• fungerer som en definisjon av intelligens. Testen sammenligner et gitt system med noe som er iboende intelligent ‚Äì et ekte menneske, og fordi enhver automatisk sammenligning kan omg√•s av et dataprogram, bruker vi en menneskelig dommer. S√•, hvis et menneske ikke klarer √• skille mellom en ekte person og et datasystem i en tekstbasert dialog ‚Äì anses systemet som intelligent.

> En chatbot kalt [Eugene Goostman](https://en.wikipedia.org/wiki/Eugene_Goostman), utviklet i St. Petersburg, kom n√¶r √• best√• Turing-testen i 2014 ved √• bruke et smart personlighetstriks. Den annonserte p√• forh√•nd at den var en 13 √•r gammel ukrainsk gutt, noe som forklarte mangelen p√• kunnskap og noen uoverensstemmelser i teksten. Botten overbeviste 30 % av dommerne om at den var menneskelig etter en 5-minutters dialog, en metrikk som Turing trodde en maskin ville kunne oppn√• innen √•r 2000. Men man b√∏r forst√• at dette ikke indikerer at vi har skapt et intelligent system, eller at et datasystem har lurt den menneskelige dommeren ‚Äì systemet lurte ikke menneskene, men snarere bot-skaperne gjorde det!

‚úÖ Har du noen gang blitt lurt av en chatbot til √• tro at du snakker med et menneske? Hvordan overbeviste den deg?

## Ulike tiln√¶rminger til AI

Hvis vi vil at en datamaskin skal oppf√∏re seg som et menneske, m√• vi p√• en eller annen m√•te modellere v√•r m√•te √• tenke p√• inne i datamaskinen. F√∏lgelig m√• vi pr√∏ve √• forst√• hva som gj√∏r et menneske intelligent.

> For √• kunne programmere intelligens inn i en maskin, m√• vi forst√• hvordan v√•re egne beslutningsprosesser fungerer. Hvis du gj√∏r litt selvransakelse, vil du innse at det er noen prosesser som skjer underbevisst ‚Äì f.eks. vi kan skille en katt fra en hund uten √• tenke over det ‚Äì mens andre involverer resonnering.

Det finnes to mulige tiln√¶rminger til dette problemet:

Top-down-tiln√¶rming (symbolsk resonnering) | Bottom-up-tiln√¶rming (nevrale nettverk)
---------------------------------------|-------------------------------------
En top-down-tiln√¶rming modellerer m√•ten en person resonerer for √• l√∏se et problem. Det inneb√¶rer √• trekke ut **kunnskap** fra et menneske og representere det i en datamaskinlesbar form. Vi m√• ogs√• utvikle en m√•te √• modellere **resonnering** inne i en datamaskin.|En bottom-up-tiln√¶rming modellerer strukturen til en menneskelig hjerne, best√•ende av et stort antall enkle enheter kalt **nevroner**. Hvert nevron fungerer som et vektet gjennomsnitt av sine innganger, og vi kan trene et nettverk av nevroner til √• l√∏se nyttige problemer ved √• gi **treningsdata**.

Det finnes ogs√• noen andre mulige tiln√¶rminger til intelligens:

* En **Emergent**, **Synergetisk** eller **multi-agent tiln√¶rming** er basert p√• det faktum at kompleks intelligent atferd kan oppn√•s gjennom interaksjon mellom et stort antall enkle agenter. If√∏lge [evolusjon√¶r kybernetikk](https://en.wikipedia.org/wiki/Global_brain#Evolutionary_cybernetics) kan intelligens *oppst√•* fra enklere, reaktiv atferd i prosessen med *metasystemovergang*.

* En **Evolusjon√¶r tiln√¶rming**, eller **genetisk algoritme**, er en optimaliseringsprosess basert p√• prinsippene for evolusjon.

Vi vil se n√¶rmere p√• disse tiln√¶rmingene senere i kurset, men akkurat n√• vil vi fokusere p√• to hovedretninger: top-down og bottom-up.

### Top-Down-Tiln√¶rmingen

I en **top-down-tiln√¶rming** pr√∏ver vi √• modellere v√•r resonnering. Fordi vi kan f√∏lge tankene v√•re n√•r vi resonerer, kan vi pr√∏ve √• formalisere denne prosessen og programmere den inn i datamaskinen. Dette kalles **symbolsk resonnering**.

Folk har en tendens til √• ha noen regler i hodet som styrer deres beslutningsprosesser. For eksempel, n√•r en lege diagnostiserer en pasient, kan han eller hun innse at en person har feber, og dermed kan det v√¶re en betennelse i kroppen. Ved √• bruke et stort sett med regler p√• et spesifikt problem kan en lege komme frem til en endelig diagnose.

Denne tiln√¶rmingen er sterkt avhengig av **kunnskapsrepresentasjon** og **resonnering**. √Ö trekke ut kunnskap fra en menneskelig ekspert kan v√¶re den vanskeligste delen, fordi en lege i mange tilfeller ikke vet n√∏yaktig hvorfor han eller hun kommer frem til en bestemt diagnose. Noen ganger dukker l√∏sningen bare opp i hodet uten eksplisitt tenkning. Noen oppgaver, som √• bestemme alderen til en person ut fra et fotografi, kan overhodet ikke reduseres til √• manipulere kunnskap.

### Bottom-Up-Tiln√¶rmingen

Alternativt kan vi pr√∏ve √• modellere de enkleste elementene i hjernen v√•r ‚Äì et nevron. Vi kan konstruere et s√•kalt **kunstig nevralt nettverk** inne i en datamaskin, og deretter pr√∏ve √• l√¶re det √• l√∏se problemer ved √• gi det eksempler. Denne prosessen ligner p√• hvordan et nyf√∏dt barn l√¶rer om omgivelsene sine ved √• gj√∏re observasjoner.

‚úÖ Gj√∏r litt research p√• hvordan babyer l√¶rer. Hva er de grunnleggende elementene i en babys hjerne?

> | Hva med ML?         |      |
> |--------------|-----------|
> | En del av kunstig intelligens som er basert p√• at datamaskiner l√¶rer √• l√∏se et problem basert p√• noen data, kalles **maskinl√¶ring**. Vi vil ikke g√• inn p√• klassisk maskinl√¶ring i dette kurset ‚Äì vi henviser deg til et eget [Maskinl√¶ring for nybegynnere](http://aka.ms/ml-beginners)-pensum. |   ![ML for Beginners](../../../../translated_images/no/ml-for-beginners.9e4fed176fd5817d.webp)    |

## En Kort Historie om AI

Kunstig intelligens startet som et felt p√• midten av det tjuende √•rhundre. Opprinnelig var symbolsk resonnering en dominerende tiln√¶rming, og det f√∏rte til en rekke viktige suksesser, som ekspertsystemer ‚Äì dataprogrammer som kunne opptre som en ekspert innenfor noen begrensede problemomr√•der. Det ble imidlertid raskt klart at en slik tiln√¶rming ikke skalerer godt. √Ö trekke ut kunnskap fra en ekspert, representere det i en datamaskin og holde kunnskapsbasen n√∏yaktig viste seg √• v√¶re en sv√¶rt kompleks oppgave, og for kostbar til √• v√¶re praktisk i mange tilfeller. Dette f√∏rte til den s√•kalte [AI-vinteren](https://en.wikipedia.org/wiki/AI_winter) p√• 1970-tallet.

<img alt="Kort Historie om AI" src="../../../../translated_images/no/history-of-ai.7e83efa70b537f5a.webp" width="70%"/>

> Bilde av [Dmitry Soshnikov](http://soshnikov.com)

Etter hvert som tiden gikk, ble databehandlingsressurser billigere, og mer data ble tilgjengelig, slik at tiln√¶rminger med nevrale nettverk begynte √• vise stor ytelse i √• konkurrere med mennesker p√• mange omr√•der, som datamaskinsyn eller talegjenkjenning. I det siste ti√•ret har begrepet kunstig intelligens stort sett blitt brukt som et synonym for nevrale nettverk, fordi de fleste AI-suksessene vi h√∏rer om er basert p√• dem.

Vi kan observere hvordan tiln√¶rmingene har endret seg, for eksempel i utviklingen av et sjakkspillende dataprogram:

* Tidlige sjakkprogrammer var basert p√• s√∏k ‚Äì et program pr√∏vde eksplisitt √• estimere mulige trekk fra en motstander for et gitt antall fremtidige trekk, og valgte et optimalt trekk basert p√• den optimale posisjonen som kunne oppn√•s i l√∏pet av noen f√• trekk. Dette f√∏rte til utviklingen av den s√•kalte [alpha-beta pruning](https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning)-s√∏kealgoritmen.
* S√∏kesstrategier fungerer godt mot slutten av spillet, der s√∏keomr√•det er begrenset av et lite antall mulige trekk. Imidlertid, i begynnelsen av spillet, er s√∏keomr√•det enormt, og algoritmen kan forbedres ved √• l√¶re av eksisterende kamper mellom menneskelige spillere. P√•f√∏lgende eksperimenter brukte s√•kalt [case-based reasoning](https://en.wikipedia.org/wiki/Case-based_reasoning), der programmet lette etter tilfeller i kunnskapsbasen som lignet veldig p√• den n√•v√¶rende posisjonen i spillet.
* Moderne programmer som vinner over menneskelige spillere er basert p√• nevrale nettverk og [forsterkende l√¶ring](https://en.wikipedia.org/wiki/Reinforcement_learning), der programmene l√¶rer √• spille utelukkende ved √• spille lenge mot seg selv og l√¶re av sine egne feil ‚Äì omtrent som mennesker gj√∏r n√•r de l√¶rer √• spille sjakk. Imidlertid kan et dataprogram spille mange flere spill p√• mye kortere tid, og dermed l√¶re mye raskere.

‚úÖ Gj√∏r litt research p√• andre spill som har blitt spilt av AI.

P√• samme m√•te kan vi se hvordan tiln√¶rmingen til √• lage "snakkende programmer" (som kan best√• Turing-testen) har endret seg:

* Tidlige programmer av denne typen, som [Eliza](https://en.wikipedia.org/wiki/ELIZA), var basert p√• sv√¶rt enkle grammatiske regler og omformulering av inndata-setningen til et sp√∏rsm√•l.
* Moderne assistenter, som Cortana, Siri eller Google Assistant, er alle hybridsystemer som bruker nevrale nettverk for √• konvertere tale til tekst og gjenkjenne v√•r intensjon, og deretter benytter noe resonnering eller eksplisitte algoritmer for √• utf√∏re n√∏dvendige handlinger.
* I fremtiden kan vi forvente en komplett nevrale-basert modell som h√•ndterer dialog helt p√• egen h√•nd. De nylige GPT- og [Turing-NLG](https://www.microsoft.com/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft)-familiene av nevrale nettverk viser stor suksess i dette.

<img alt="Turing-testens utvikling" src="../../../../translated_images/no/turing-test-evol.4184696701293ead.webp" width="70%"/>
> Bilde av Dmitry Soshnikov, [foto](https://unsplash.com/photos/r8LmVbUKgns) av [Marina Abrosimova](https://unsplash.com/@abrosimova_marina_foto), Unsplash

## Nyere AI-forskning

Den enorme veksten i forskning p√• nevrale nettverk startet rundt 2010, da store offentlige datasett begynte √• bli tilgjengelige. En stor samling bilder kalt [ImageNet](https://en.wikipedia.org/wiki/ImageNet), som inneholder rundt 14 millioner annoterte bilder, ga opphav til [ImageNet Large Scale Visual Recognition Challenge](https://image-net.org/challenges/LSVRC/).

![ILSVRC N√∏yaktighet](../../../../lessons/1-Intro/images/ilsvrc.gif)

> Bilde av [Dmitry Soshnikov](http://soshnikov.com)

I 2012 ble [Convolutional Neural Networks](../4-ComputerVision/07-ConvNets/README.md) f√∏rst brukt i bildegjenkjenning, noe som f√∏rte til en betydelig reduksjon i klassifiseringsfeil (fra nesten 30 % til 16,4 %). I 2015 oppn√•dde ResNet-arkitekturen fra Microsoft Research [menneskelig niv√• av n√∏yaktighet](https://doi.org/10.1109/ICCV.2015.123).

Siden den gang har nevrale nettverk vist seg √• v√¶re sv√¶rt vellykkede i mange oppgaver:

---

√Ör | Menneskelig niv√• oppn√•dd
-----|--------
2015 | [Bildeklassifisering](https://doi.org/10.1109/ICCV.2015.123)
2016 | [Samtalebasert talegjenkjenning](https://arxiv.org/abs/1610.05256)
2018 | [Automatisk maskinoversettelse](https://arxiv.org/abs/1803.05567) (Kinesisk-til-engelsk)
2020 | [Bildebeskrivelse](https://arxiv.org/abs/2009.13682)

De siste √•rene har vi v√¶rt vitne til store suksesser med store spr√•kmodeller, som BERT og GPT-3. Dette skjedde hovedsakelig fordi det finnes mye generell tekstdata tilgjengelig som gj√∏r det mulig √• trene modeller til √• fange opp strukturen og meningen i tekster, forh√•ndstrene dem p√• generelle tekstsamlinger, og deretter spesialisere disse modellene for mer spesifikke oppgaver. Vi vil l√¶re mer om [Natural Language Processing](../5-NLP/README.md) senere i dette kurset.

## üöÄ Utfordring

Utforsk internett for √• finne ut hvor, etter din mening, AI brukes mest effektivt. Er det i en kartleggingsapp, eller en tale-til-tekst-tjeneste eller et videospill? Unders√∏k hvordan systemet ble bygget.

## [Quiz etter forelesning](https://ff-quizzes.netlify.app/en/ai/quiz/2)

## Gjennomgang & Selvstudium

G√• gjennom historien til AI og ML ved √• lese [denne leksjonen](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/2-history-of-ML). Ta et element fra sketchnoten √∏verst i den leksjonen eller denne, og unders√∏k det i st√∏rre dybde for √• forst√• den kulturelle konteksten som har p√•virket utviklingen.

**Oppgave**: [Game Jam](assignment.md)

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->