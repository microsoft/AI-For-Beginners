# Detec√ß√£o de Objetos

Os modelos de classifica√ß√£o de imagens que abord√°mos at√© agora recebiam uma imagem e produziam um resultado categ√≥rico, como a classe 'n√∫mero' num problema MNIST. No entanto, em muitos casos, n√£o queremos apenas saber que uma imagem retrata objetos - queremos determinar a sua localiza√ß√£o precisa. Este √© exatamente o objetivo da **detec√ß√£o de objetos**.

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![Detec√ß√£o de Objetos](../../../../../translated_images/pt-PT/Screen_Shot_2016-11-17_at_11.14.54_AM.b4bb3769353287be.webp)

> Imagem do [site YOLO v2](https://pjreddie.com/darknet/yolov2/)

## Uma Abordagem Ing√©nua para Detec√ß√£o de Objetos

Supondo que queremos encontrar um gato numa imagem, uma abordagem muito ing√©nua para detec√ß√£o de objetos seria a seguinte:

1. Dividir a imagem em v√°rios blocos.
2. Executar a classifica√ß√£o de imagem em cada bloco.
3. Os blocos que resultarem numa ativa√ß√£o suficientemente alta podem ser considerados como contendo o objeto em quest√£o.

![Detec√ß√£o Ing√©nua de Objetos](../../../../../translated_images/pt-PT/naive-detection.e7f1ba220ccd08c6.webp)

> *Imagem do [Caderno de Exerc√≠cios](ObjectDetection-TF.ipynb)*

No entanto, esta abordagem est√° longe de ser ideal, pois s√≥ permite ao algoritmo localizar a caixa delimitadora do objeto de forma muito imprecisa. Para uma localiza√ß√£o mais precisa, precisamos de executar algum tipo de **regress√£o** para prever as coordenadas das caixas delimitadoras - e, para isso, necessitamos de conjuntos de dados espec√≠ficos.

## Regress√£o para Detec√ß√£o de Objetos

[Este artigo](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491) oferece uma excelente introdu√ß√£o √† dete√ß√£o de formas.

## Conjuntos de Dados para Detec√ß√£o de Objetos

Poder√° encontrar os seguintes conjuntos de dados para esta tarefa:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) - 20 classes
* [COCO](http://cocodataset.org/#home) - Objetos Comuns em Contexto. 80 classes, caixas delimitadoras e m√°scaras de segmenta√ß√£o

![COCO](../../../../../translated_images/pt-PT/coco-examples.71bc60380fa6cceb.webp)

## M√©tricas de Detec√ß√£o de Objetos

### Interse√ß√£o sobre Uni√£o

Enquanto na classifica√ß√£o de imagens √© f√°cil medir o desempenho do algoritmo, na detec√ß√£o de objetos precisamos de medir tanto a corre√ß√£o da classe como a precis√£o da localiza√ß√£o da caixa delimitadora inferida. Para esta √∫ltima, utilizamos a chamada **Interse√ß√£o sobre Uni√£o** (IoU), que mede o qu√£o bem duas caixas (ou duas √°reas arbitr√°rias) se sobrep√µem.

![IoU](../../../../../translated_images/pt-PT/iou_equation.9a4751d40fff4e11.webp)

> *Figura 2 de [este excelente artigo sobre IoU](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)*

A ideia √© simples - dividimos a √°rea de interse√ß√£o entre duas figuras pela √°rea da sua uni√£o. Para duas √°reas id√™nticas, o IoU seria 1, enquanto para √°reas completamente disjuntas ser√° 0. Caso contr√°rio, variar√° entre 0 e 1. Normalmente, consideramos apenas as caixas delimitadoras para as quais o IoU est√° acima de um determinado valor.

### Precis√£o M√©dia

Suponha que queremos medir o qu√£o bem uma determinada classe de objetos $C$ √© reconhecida. Para medir isso, utilizamos a m√©trica de **Precis√£o M√©dia**, que √© calculada da seguinte forma:

1. Consideramos a curva de Precis√£o-Recall que mostra a precis√£o dependendo de um valor de limiar de dete√ß√£o (de 0 a 1).
2. Dependendo do limiar, obteremos mais ou menos objetos detetados na imagem e diferentes valores de precis√£o e recall.
3. A curva ter√° este aspeto:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *Imagem de [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

A Precis√£o M√©dia para uma classe $C$ √© a √°rea sob esta curva. Mais precisamente, o eixo Recall √© normalmente dividido em 10 partes, e a Precis√£o √© calculada como m√©dia em todos esses pontos:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP e IoU

Consideramos apenas as dete√ß√µes para as quais o IoU est√° acima de um determinado valor. Por exemplo, no conjunto de dados PASCAL VOC, normalmente $\mbox{IoU Threshold} = 0.5$ √© assumido, enquanto no COCO o AP √© medido para diferentes valores de $\mbox{IoU Threshold}$.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *Imagem de [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

### Precis√£o M√©dia Global - mAP

A principal m√©trica para Detec√ß√£o de Objetos √© chamada de **Precis√£o M√©dia Global**, ou **mAP**. √â o valor da Precis√£o M√©dia, calculado como m√©dia entre todas as classes de objetos, e √†s vezes tamb√©m sobre $\mbox{IoU Threshold}$. O processo de c√°lculo do **mAP** √© descrito em mais detalhe
[neste artigo](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3)), e tamb√©m [aqui com exemplos de c√≥digo](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734).

## Diferentes Abordagens para Detec√ß√£o de Objetos

Existem duas grandes classes de algoritmos de detec√ß√£o de objetos:

* **Redes de Proposta de Regi√£o** (R-CNN, Fast R-CNN, Faster R-CNN). A ideia principal √© gerar **Regi√µes de Interesse** (ROI) e executar CNN sobre elas, procurando a ativa√ß√£o m√°xima. √â um pouco semelhante √† abordagem ing√©nua, com a exce√ß√£o de que as ROIs s√£o geradas de forma mais inteligente. Uma das principais desvantagens desses m√©todos √© que s√£o lentos, pois necessitam de v√°rias passagens do classificador CNN sobre a imagem.
* M√©todos de **uma √∫nica passagem** (YOLO, SSD, RetinaNet). Nessas arquiteturas, projetamos a rede para prever tanto as classes como as ROIs numa √∫nica passagem.

### R-CNN: CNN Baseada em Regi√£o

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf) utiliza [Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) para gerar uma estrutura hier√°rquica de regi√µes ROI, que s√£o ent√£o passadas por extratores de caracter√≠sticas CNN e classificadores SVM para determinar a classe do objeto, e regress√£o linear para determinar as coordenadas da *caixa delimitadora*. [Artigo Oficial](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../translated_images/pt-PT/rcnn1.cae407020dfb1d1f.webp)

> *Imagem de van de Sande et al. ICCV‚Äô11*

![RCNN-1](../../../../../translated_images/pt-PT/rcnn2.2d9530bb83516484.webp)

> *Imagens de [este artigo](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)*

### F-RCNN - Fast R-CNN

Esta abordagem √© semelhante √† R-CNN, mas as regi√µes s√£o definidas ap√≥s as camadas de convolu√ß√£o terem sido aplicadas.

![FRCNN](../../../../../translated_images/pt-PT/f-rcnn.3cda6d9bb4188875.webp)

> Imagem do [Artigo Oficial](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Faster R-CNN

A ideia principal desta abordagem √© usar uma rede neural para prever ROIs - a chamada *Rede de Proposta de Regi√£o*. [Artigo](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../translated_images/pt-PT/faster-rcnn.8d46c099b87ef30a.webp)

> Imagem do [artigo oficial](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: Rede Totalmente Convolucional Baseada em Regi√£o

Este algoritmo √© ainda mais r√°pido que o Faster R-CNN. A ideia principal √© a seguinte:

1. Extra√≠mos caracter√≠sticas usando ResNet-101.
1. As caracter√≠sticas s√£o processadas por **Position-Sensitive Score Map**. Cada objeto das classes $C$ √© dividido em regi√µes $k\times k$, e treinamos para prever partes dos objetos.
1. Para cada parte das regi√µes $k\times k$, todas as redes votam pelas classes de objetos, e a classe de objeto com o voto m√°ximo √© selecionada.

![r-fcn image](../../../../../translated_images/pt-PT/r-fcn.13eb88158b99a3da.webp)

> Imagem do [artigo oficial](https://arxiv.org/abs/1605.06409)

### YOLO - You Only Look Once

YOLO √© um algoritmo de uma √∫nica passagem em tempo real. A ideia principal √© a seguinte:

 * A imagem √© dividida em regi√µes $S\times S$.
 * Para cada regi√£o, **CNN** prev√™ $n$ objetos poss√≠veis, coordenadas da *caixa delimitadora* e *confian√ßa*=*probabilidade* * IoU.

 ![YOLO](../../../../../translated_images/pt-PT/yolo.a2648ec82ee8bb4e.webp)

> Imagem do [artigo oficial](https://arxiv.org/abs/1506.02640)

### Outros Algoritmos

* RetinaNet: [artigo oficial](https://arxiv.org/abs/1708.02002)
   - [Implementa√ß√£o PyTorch em Torchvision](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Implementa√ß√£o Keras](https://github.com/fizyr/keras-retinanet)
   - [Detec√ß√£o de Objetos com RetinaNet](https://keras.io/examples/vision/retinanet/) em exemplos Keras
* SSD (Single Shot Detector): [artigo oficial](https://arxiv.org/abs/1512.02325)

## ‚úçÔ∏è Exerc√≠cios: Detec√ß√£o de Objetos

Continue a sua aprendizagem no seguinte caderno:

[ObjectDetection.ipynb](ObjectDetection.ipynb)

## Conclus√£o

Nesta li√ß√£o, fez uma r√°pida explora√ß√£o de todas as v√°rias formas de realizar detec√ß√£o de objetos!

## üöÄ Desafio

Leia estes artigos e cadernos sobre YOLO e experimente por si mesmo:

* [Bom artigo](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/) descrevendo YOLO
 * [Site oficial](https://pjreddie.com/darknet/yolo/)
 * YOLO: [Implementa√ß√£o Keras](https://github.com/experiencor/keras-yolo2), [caderno passo-a-passo](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * YOLO v2: [Implementa√ß√£o Keras](https://github.com/experiencor/keras-yolo2), [caderno passo-a-passo](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## Revis√£o e Autoestudo

* [Detec√ß√£o de Objetos](https://tjmachinelearning.com/lectures/1718/obj/) por Nikhil Sardana
* [Uma boa compara√ß√£o de algoritmos de detec√ß√£o de objetos](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [Revis√£o de Algoritmos de Aprendizagem Profunda para Detec√ß√£o de Objetos](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [Uma Introdu√ß√£o Passo-a-Passo aos Algoritmos B√°sicos de Detec√ß√£o de Objetos](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Implementa√ß√£o de Faster R-CNN em Python para Detec√ß√£o de Objetos](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [Tarefa: Detec√ß√£o de Objetos](lab/README.md)

---

