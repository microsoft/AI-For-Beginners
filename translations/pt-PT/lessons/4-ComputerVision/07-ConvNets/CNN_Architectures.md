# Arquiteturas Conhecidas de CNN

### VGG-16

VGG-16 √© uma rede que alcan√ßou 92,7% de precis√£o na classifica√ß√£o top-5 do ImageNet em 2014. Tem a seguinte estrutura de camadas:

![Camadas do ImageNet](../../../../../translated_images/pt-PT/vgg-16-arch1.d901a5583b3a51ba.webp)

Como pode ver, a VGG segue uma arquitetura tradicional em pir√¢mide, que consiste numa sequ√™ncia de camadas de convolu√ß√£o e pooling.

![Pir√¢mide do ImageNet](../../../../../translated_images/pt-PT/vgg-16-arch.64ff2137f50dd49f.webp)

> Imagem de [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet √© uma fam√≠lia de modelos proposta pela Microsoft Research em 2015. A ideia principal da ResNet √© utilizar **blocos residuais**:

<img src="../../../../../translated_images/pt-PT/resnet-block.aba4ccbcc0944434.webp" width="300"/>

> Imagem retirada [deste artigo](https://arxiv.org/pdf/1512.03385.pdf)

A raz√£o para usar a passagem de identidade √© fazer com que a camada preveja **a diferen√ßa** entre o resultado de uma camada anterior e a sa√≠da do bloco residual - da√≠ o nome *residual*. Estes blocos s√£o muito mais f√°ceis de treinar, e √© poss√≠vel construir redes com centenas destes blocos (as variantes mais comuns s√£o ResNet-52, ResNet-101 e ResNet-152).

Pode tamb√©m pensar nesta rede como sendo capaz de ajustar a sua complexidade ao conjunto de dados. Inicialmente, quando come√ßa a treinar a rede, os valores dos pesos s√£o pequenos, e a maior parte do sinal passa pelas camadas de identidade. √Ä medida que o treino avan√ßa e os pesos se tornam maiores, a import√¢ncia dos par√¢metros da rede cresce, e a rede ajusta-se para acomodar o poder expressivo necess√°rio para classificar corretamente as imagens de treino.

### Google Inception

A arquitetura Google Inception leva esta ideia um passo mais al√©m e constr√≥i cada camada da rede como uma combina√ß√£o de v√°rios caminhos diferentes:

<img src="../../../../../translated_images/pt-PT/inception.a6605b85bcbc6f52.webp" width="400"/>

> Imagem de [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Aqui, √© importante destacar o papel das convolu√ß√µes 1x1, porque √† primeira vista n√£o fazem sentido. Por que raz√£o precisar√≠amos de passar pela imagem com um filtro 1x1? No entanto, √© necess√°rio lembrar que os filtros de convolu√ß√£o tamb√©m trabalham com v√°rios canais de profundidade (originalmente - cores RGB, em camadas subsequentes - canais para diferentes filtros), e a convolu√ß√£o 1x1 √© usada para misturar esses canais de entrada utilizando diferentes pesos trein√°veis. Pode tamb√©m ser vista como uma redu√ß√£o dimensional (pooling) sobre a dimens√£o dos canais.

Aqui est√° [um bom artigo](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) sobre o assunto, e [o artigo original](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet √© uma fam√≠lia de modelos com tamanho reduzido, adequada para dispositivos m√≥veis. Utilize-os se tiver poucos recursos e puder sacrificar um pouco de precis√£o. A ideia principal por tr√°s destes modelos √© a chamada **convolu√ß√£o separ√°vel por profundidade**, que permite representar filtros de convolu√ß√£o atrav√©s de uma composi√ß√£o de convolu√ß√µes espaciais e convolu√ß√µes 1x1 sobre os canais de profundidade. Isto reduz significativamente o n√∫mero de par√¢metros, tornando a rede menor em tamanho e tamb√©m mais f√°cil de treinar com menos dados.

Aqui est√° [um bom artigo sobre MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Conclus√£o

Nesta unidade, aprendeu o conceito principal por tr√°s das redes neurais de vis√£o computacional - redes convolucionais. Arquiteturas reais que alimentam classifica√ß√£o de imagens, dete√ß√£o de objetos e at√© redes de gera√ß√£o de imagens s√£o todas baseadas em CNNs, apenas com mais camadas e alguns truques adicionais de treino.

## üöÄ Desafio

Nos notebooks que acompanham esta unidade, h√° notas no final sobre como obter maior precis√£o. Fa√ßa alguns experimentos para ver se consegue alcan√ßar uma precis√£o mais elevada.

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Revis√£o e Autoestudo

Embora as CNNs sejam mais frequentemente usadas para tarefas de Vis√£o Computacional, elas s√£o geralmente boas para extrair padr√µes de tamanho fixo. Por exemplo, se estivermos a lidar com sons, tamb√©m podemos querer usar CNNs para procurar padr√µes espec√≠ficos no sinal de √°udio - neste caso, os filtros seriam unidimensionais (e esta CNN seria chamada de 1D-CNN). Al√©m disso, √†s vezes utiliza-se 3D-CNN para extrair caracter√≠sticas em espa√ßo multidimensional, como certos eventos que ocorrem em v√≠deos - a CNN pode capturar certos padr√µes de mudan√ßa de caracter√≠sticas ao longo do tempo. Fa√ßa uma revis√£o e autoestudo sobre outras tarefas que podem ser realizadas com CNNs.

## [Tarefa](lab/README.md)

Neste laborat√≥rio, a sua tarefa √© classificar diferentes ra√ßas de gatos e c√£es. Estas imagens s√£o mais complexas do que o conjunto de dados MNIST, t√™m dimens√µes mais elevadas e h√° mais de 10 classes.

---

