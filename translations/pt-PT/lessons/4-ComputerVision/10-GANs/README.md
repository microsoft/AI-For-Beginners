# Redes Advers√°rias Generativas

Na sec√ß√£o anterior, aprendemos sobre **modelos generativos**: modelos que podem gerar novas imagens semelhantes √†s do conjunto de dados de treino. O VAE foi um bom exemplo de modelo generativo.

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ai/quiz/19)

No entanto, se tentarmos gerar algo realmente significativo, como uma pintura com resolu√ß√£o razo√°vel, usando o VAE, veremos que o treino n√£o converge bem. Para este caso, devemos aprender sobre outra arquitetura especificamente direcionada para modelos generativos - **Redes Advers√°rias Generativas**, ou GANs.

A ideia principal de uma GAN √© ter duas redes neuronais que ser√£o treinadas uma contra a outra:

<img src="../../../../../translated_images/pt-PT/gan_architecture.8f3a5ab62b8d5d69.webp" width="70%"/>

> Imagem por [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ Um pouco de vocabul√°rio:
> * **Gerador** √© uma rede que recebe um vetor aleat√≥rio e produz uma imagem como resultado.
> * **Discriminador** √© uma rede que recebe uma imagem e deve dizer se √© uma imagem real (do conjunto de dados de treino) ou se foi gerada por um gerador. Essencialmente, √© um classificador de imagens.

### Discriminador

A arquitetura do discriminador n√£o difere de uma rede de classifica√ß√£o de imagens comum. No caso mais simples, pode ser um classificador totalmente conectado, mas provavelmente ser√° uma [rede convolucional](../07-ConvNets/README.md).

> ‚úÖ Uma GAN baseada em redes convolucionais √© chamada de [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

Um discriminador CNN consiste nas seguintes camadas: v√°rias convolu√ß√µes+poolings (com tamanho espacial decrescente) e uma ou mais camadas totalmente conectadas para obter o "vetor de caracter√≠sticas", classificador bin√°rio final.

> ‚úÖ Um 'pooling' neste contexto √© uma t√©cnica que reduz o tamanho da imagem. "As camadas de pooling reduzem as dimens√µes dos dados ao combinar os resultados de clusters de neur√≥nios numa camada em um √∫nico neur√≥nio na pr√≥xima camada." - [fonte](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Gerador

Um Gerador √© um pouco mais complicado. Pode ser considerado como um discriminador invertido. Come√ßando por um vetor latente (em vez de um vetor de caracter√≠sticas), tem uma camada totalmente conectada para convert√™-lo no tamanho/forma necess√°ria, seguida por deconvolu√ß√µes+amplia√ß√£o. Isto √© semelhante √† parte de *decodificador* de um [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Como a camada de convolu√ß√£o √© implementada como um filtro linear que percorre a imagem, a deconvolu√ß√£o √© essencialmente semelhante √† convolu√ß√£o e pode ser implementada usando a mesma l√≥gica de camada.

<img src="../../../../../translated_images/pt-PT/gan_arch_detail.46b95fd366f8e543.webp" width="70%"/>

> Imagem por [Dmitry Soshnikov](http://soshnikov.com)

### Treino da GAN

As GANs s√£o chamadas de **advers√°rias** porque h√° uma competi√ß√£o constante entre o gerador e o discriminador. Durante esta competi√ß√£o, tanto o gerador quanto o discriminador melhoram, e assim a rede aprende a produzir imagens cada vez melhores.

O treino ocorre em duas etapas:

* **Treino do discriminador**. Esta tarefa √© bastante direta: geramos um lote de imagens com o gerador, rotulando-as como 0, que representa imagem falsa, e pegamos um lote de imagens do conjunto de dados de entrada (com r√≥tulo 1, imagem real). Obtemos uma *perda do discriminador* e realizamos o backprop.
* **Treino do gerador**. Isto √© um pouco mais complicado, porque n√£o sabemos diretamente o resultado esperado para o gerador. Pegamos toda a rede GAN, consistindo de um gerador seguido por um discriminador, alimentamo-la com alguns vetores aleat√≥rios e esperamos que o resultado seja 1 (correspondente a imagens reais). Em seguida, congelamos os par√¢metros do discriminador (n√£o queremos que ele seja treinado nesta etapa) e realizamos o backprop.

Durante este processo, as perdas do gerador e do discriminador n√£o diminuem significativamente. Na situa√ß√£o ideal, elas devem oscilar, correspondendo a ambos os modelos a melhorar o desempenho.

## ‚úçÔ∏è Exerc√≠cios: GANs

* [Notebook GAN em TensorFlow/Keras](GANTF.ipynb)
* [Notebook GAN em PyTorch](GANPyTorch.ipynb)

### Problemas no treino de GANs

As GANs s√£o conhecidas por serem especialmente dif√≠ceis de treinar. Aqui est√£o alguns problemas:

* **Colapso de modo**. Este termo refere-se ao fato de o gerador aprender a produzir uma √∫nica imagem bem-sucedida que engana o discriminador, em vez de uma variedade de imagens diferentes.
* **Sensibilidade aos hiperpar√¢metros**. Muitas vezes, pode-se observar que uma GAN n√£o converge de forma alguma, e ent√£o, de repente, uma diminui√ß√£o na taxa de aprendizagem leva √† converg√™ncia.
* Manter um **equil√≠brio** entre o gerador e o discriminador. Em muitos casos, a perda do discriminador pode cair para zero relativamente r√°pido, o que resulta no gerador incapaz de continuar o treino. Para superar isso, podemos tentar definir taxas de aprendizagem diferentes para o gerador e o discriminador ou ignorar o treino do discriminador se a perda j√° for muito baixa.
* Treino para **alta resolu√ß√£o**. Refletindo o mesmo problema dos autoencoders, este problema √© desencadeado porque reconstruir muitas camadas de uma rede convolucional leva a artefactos. Este problema √© geralmente resolvido com o chamado **crescimento progressivo**, onde primeiro algumas camadas s√£o treinadas em imagens de baixa resolu√ß√£o e, em seguida, as camadas s√£o "desbloqueadas" ou adicionadas. Outra solu√ß√£o seria adicionar conex√µes extras entre camadas e treinar v√°rias resolu√ß√µes ao mesmo tempo - veja este artigo [Multi-Scale Gradient GANs](https://arxiv.org/abs/1903.06048) para mais detalhes.

## Transfer√™ncia de Estilo

As GANs s√£o uma √≥tima maneira de gerar imagens art√≠sticas. Outra t√©cnica interessante √© a chamada **transfer√™ncia de estilo**, que pega uma **imagem de conte√∫do** e redesenha-a num estilo diferente, aplicando filtros de uma **imagem de estilo**.

O funcionamento √© o seguinte:
* Come√ßamos com uma imagem de ru√≠do aleat√≥rio (ou com uma imagem de conte√∫do, mas para fins de compreens√£o √© mais f√°cil come√ßar com ru√≠do aleat√≥rio).
* O nosso objetivo ser√° criar uma imagem que seja pr√≥xima tanto da imagem de conte√∫do quanto da imagem de estilo. Isto ser√° determinado por duas fun√ß√µes de perda:
   - **Perda de conte√∫do** √© calculada com base nas caracter√≠sticas extra√≠das pela CNN em algumas camadas da imagem atual e da imagem de conte√∫do.
   - **Perda de estilo** √© calculada entre a imagem atual e a imagem de estilo de uma forma inteligente usando matrizes de Gram (mais detalhes no [notebook de exemplo](StyleTransfer.ipynb)).
* Para tornar a imagem mais suave e remover o ru√≠do, tamb√©m introduzimos a **Perda de varia√ß√£o**, que calcula a dist√¢ncia m√©dia entre pixels vizinhos.
* O principal ciclo de otimiza√ß√£o ajusta a imagem atual usando descida de gradiente (ou algum outro algoritmo de otimiza√ß√£o) para minimizar a perda total, que √© uma soma ponderada de todas as tr√™s perdas.

## ‚úçÔ∏è Exemplo: [Transfer√™ncia de Estilo](StyleTransfer.ipynb)

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## Conclus√£o

Nesta li√ß√£o, aprendeste sobre GANs e como trein√°-las. Tamb√©m aprendeste sobre os desafios especiais que este tipo de rede neuronal pode enfrentar e algumas estrat√©gias para super√°-los.

## üöÄ Desafio

Experimenta o [notebook de Transfer√™ncia de Estilo](StyleTransfer.ipynb) usando as tuas pr√≥prias imagens.

## Revis√£o e Autoestudo

Para refer√™ncia, l√™ mais sobre GANs nestes recursos:

* Marco Pasini, [10 Li√ß√µes que Aprendi ao Treinar GANs por um Ano](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), uma arquitetura GAN *de facto* a considerar
* [Criando Arte Generativa usando GANs no Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Tarefa

Revisita um dos dois notebooks associados a esta li√ß√£o e treina novamente a GAN com as tuas pr√≥prias imagens. O que consegues criar?

---

