# Generative Adversarial Networks

I den forrige sektion l√¶rte vi om **generative modeller**: modeller, der kan generere nye billeder, der ligner dem i tr√¶ningsdatas√¶ttet. VAE var et godt eksempel p√• en generativ model.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/19)

Men hvis vi fors√∏ger at generere noget virkelig meningsfuldt, som et maleri i rimelig opl√∏sning, med VAE, vil vi se, at tr√¶ningen ikke konvergerer godt. Til dette form√•l b√∏r vi l√¶re om en anden arkitektur, der er specifikt rettet mod generative modeller - **Generative Adversarial Networks**, eller GANs.

Hovedideen bag en GAN er at have to neurale netv√¶rk, der tr√¶nes mod hinanden:

<img src="../../../../../translated_images/da/gan_architecture.8f3a5ab62b8d5d69.webp" width="70%"/>

> Billede af [Dmitry Soshnikov](http://soshnikov.com)

> ‚úÖ En lille ordliste:
> * **Generator** er et netv√¶rk, der tager en tilf√¶ldig vektor og producerer et billede som resultat.
> * **Discriminator** er et netv√¶rk, der tager et billede og skal afg√∏re, om det er et √¶gte billede (fra tr√¶ningsdatas√¶ttet) eller genereret af en generator. Det er i bund og grund en billedklassifikator.

### Discriminator

Discriminatorens arkitektur adskiller sig ikke fra et almindeligt billedklassifikationsnetv√¶rk. I det simpleste tilf√¶lde kan det v√¶re en fuldt forbundet klassifikator, men oftest vil det v√¶re et [konvolutionelt netv√¶rk](../07-ConvNets/README.md).

> ‚úÖ En GAN baseret p√• konvolutionelle netv√¶rk kaldes en [DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

En CNN-discriminator best√•r af f√∏lgende lag: flere konvolutioner+pooling (med faldende rumlig st√∏rrelse) og en eller flere fuldt forbundne lag for at f√• en "feature vector", samt en endelig bin√¶r klassifikator.

> ‚úÖ 'Pooling' i denne sammenh√¶ng er en teknik, der reducerer billedets st√∏rrelse. "Pooling-lag reducerer dimensionerne af data ved at kombinere output fra neuron-klynger i √©t lag til en enkelt neuron i det n√¶ste lag." - [kilde](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

En generator er lidt mere kompleks. Du kan betragte den som en omvendt discriminator. Den starter med en latent vektor (i stedet for en feature vector), har et fuldt forbundet lag til at konvertere det til den √∏nskede st√∏rrelse/form, efterfulgt af dekonvolutioner+opskalering. Dette ligner *decoder*-delen af [autoencoder](../09-Autoencoders/README.md).

> ‚úÖ Fordi konvolutionslaget implementeres som et line√¶rt filter, der bev√¶ger sig hen over billedet, er dekonvolution i bund og grund det samme som konvolution og kan implementeres med samme laglogik.

<img src="../../../../../translated_images/da/gan_arch_detail.46b95fd366f8e543.webp" width="70%"/>

> Billede af [Dmitry Soshnikov](http://soshnikov.com)

### Tr√¶ning af GAN

GANs kaldes **adversarial**, fordi der er en konstant konkurrence mellem generatoren og discriminator. Under denne konkurrence forbedres b√•de generatoren og discriminator, og netv√¶rket l√¶rer dermed at producere bedre og bedre billeder.

Tr√¶ningen sker i to trin:

* **Tr√¶ning af discriminator**. Denne opgave er ret ligetil: vi genererer en batch af billeder med generatoren, m√¶rker dem som 0, hvilket st√•r for falske billeder, og tager en batch af billeder fra inputdatas√¶ttet (med m√¶rket 1, √¶gte billeder). Vi opn√•r en *discriminator loss* og udf√∏rer backpropagation.
* **Tr√¶ning af generatoren**. Dette er lidt mere komplekst, fordi vi ikke direkte kender det forventede output for generatoren. Vi tager hele GAN-netv√¶rket, som best√•r af en generator efterfulgt af en discriminator, fodrer det med nogle tilf√¶ldige vektorer og forventer, at resultatet er 1 (svarende til √¶gte billeder). Vi fryser derefter discriminatorens parametre (vi √∏nsker ikke, at den skal tr√¶nes i dette trin) og udf√∏rer backpropagation.

Under denne proces falder b√•de generatorens og discriminatorens tab ikke markant. Ideelt set b√∏r de oscillere, hvilket svarer til, at begge netv√¶rk forbedrer deres ydeevne.

## ‚úçÔ∏è √òvelser: GANs

* [GAN Notebook i TensorFlow/Keras](GANTF.ipynb)
* [GAN Notebook i PyTorch](GANPyTorch.ipynb)

### Problemer med GAN-tr√¶ning

GANs er kendt for at v√¶re s√¶rligt sv√¶re at tr√¶ne. Her er nogle problemer:

* **Mode Collapse**. Dette betyder, at generatoren l√¶rer at producere √©t succesfuldt billede, der narrer discriminator, men ikke en r√¶kke forskellige billeder.
* **F√∏lsomhed over for hyperparametre**. Ofte kan man se, at en GAN slet ikke konvergerer, og s√• pludselig falder l√¶ringsraten, hvilket f√∏rer til konvergens.
* At holde en **balance** mellem generatoren og discriminator. I mange tilf√¶lde kan discriminatorens tab hurtigt falde til nul, hvilket resulterer i, at generatoren ikke kan tr√¶ne videre. For at overvinde dette kan vi pr√∏ve at indstille forskellige l√¶ringsrater for generatoren og discriminator eller springe discriminatorens tr√¶ning over, hvis tabet allerede er for lavt.
* Tr√¶ning for **h√∏j opl√∏sning**. Dette problem, som ogs√• ses med autoencoders, opst√•r, fordi rekonstruktion af for mange lag i et konvolutionelt netv√¶rk f√∏rer til artefakter. Problemet l√∏ses typisk med s√•kaldt **progressiv v√¶kst**, hvor de f√∏rste lag tr√¶nes p√• billeder med lav opl√∏sning, og derefter "l√•ses lagene op" eller tilf√∏jes. En anden l√∏sning er at tilf√∏je ekstra forbindelser mellem lagene og tr√¶ne flere opl√∏sninger p√• √©n gang - se denne [Multi-Scale Gradient GANs paper](https://arxiv.org/abs/1903.06048) for detaljer.

## Style Transfer

GANs er en fantastisk m√•de at generere kunstneriske billeder p√•. En anden interessant teknik er den s√•kaldte **style transfer**, som tager √©t **indholdsbillede** og tegner det i en anden stil ved at anvende filtre fra et **stilbillede**.

S√•dan fungerer det:
* Vi starter med et tilf√¶ldigt st√∏jbillede (eller med et indholdsbillede, men for forst√•elsens skyld er det lettere at starte med tilf√¶ldig st√∏j).
* Vores m√•l er at skabe et billede, der er t√¶t p√• b√•de indholdsbilledet og stilbilledet. Dette bestemmes af to tabfunktioner:
   - **Content loss** beregnes baseret p√• de features, der udtr√¶kkes af CNN p√• nogle lag fra det aktuelle billede og indholdsbilledet.
   - **Style loss** beregnes mellem det aktuelle billede og stilbilledet p√• en smart m√•de ved hj√¶lp af Gram-matricer (flere detaljer i [eksempelfilen](StyleTransfer.ipynb)).
* For at g√∏re billedet glattere og fjerne st√∏j introducerer vi ogs√• **Variation loss**, som beregner den gennemsnitlige afstand mellem nabopixels.
* Den prim√¶re optimeringssl√∏jfe justerer det aktuelle billede ved hj√¶lp af gradient descent (eller en anden optimeringsalgoritme) for at minimere det samlede tab, som er en v√¶gtet sum af alle tre tab.

## ‚úçÔ∏è Eksempel: [Style Transfer](StyleTransfer.ipynb)

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/20)

## Konklusion

I denne lektion l√¶rte du om GANs og hvordan man tr√¶ner dem. Du l√¶rte ogs√• om de s√¶rlige udfordringer, som denne type neurale netv√¶rk kan st√• overfor, og nogle strategier til at overvinde dem.

## üöÄ Udfordring

Gennemg√• [Style Transfer-notebooken](StyleTransfer.ipynb) med dine egne billeder.

## Review & Selvstudie

For reference, l√¶s mere om GANs i disse ressourcer:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), en *de facto* GAN-arkitektur at overveje
* [Creating Generative Art using GANs on Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Opgave

Gennemg√• en af de to notebooks, der er knyttet til denne lektion, og gen-tr√¶n GAN p√• dine egne billeder. Hvad kan du skabe?

---

