# Velkendte CNN-arkitekturer

### VGG-16

VGG-16 er et netv칝rk, der opn친ede 92,7% n칮jagtighed i ImageNet top-5 klassifikation i 2014. Det har f칮lgende lagstruktur:

![ImageNet Layers](../../../../../translated_images/da/vgg-16-arch1.d901a5583b3a51ba.webp)

Som du kan se, f칮lger VGG en traditionel pyramidearkitektur, som er en sekvens af konvolutions- og pooling-lag.

![ImageNet Pyramid](../../../../../translated_images/da/vgg-16-arch.64ff2137f50dd49f.webp)

> Billede fra [Researchgate](https://www.researchgate.net/figure/Vgg16-model-structure-To-get-the-VGG-NIN-model-we-replace-the-2-nd-4-th-6-th-7-th_fig2_335194493)

### ResNet

ResNet er en familie af modeller foresl친et af Microsoft Research i 2015. Hovedideen bag ResNet er brugen af **residualblokke**:

<img src="../../../../../translated_images/da/resnet-block.aba4ccbcc0944434.webp" width="300"/>

> Billede fra [denne artikel](https://arxiv.org/pdf/1512.03385.pdf)

Grunden til at bruge identitets-pass-through er, at laget skal forudsige **forskellen** mellem resultatet af et tidligere lag og outputtet fra residualblokken - deraf navnet *residual*. Disse blokke er meget lettere at tr칝ne, og man kan konstruere netv칝rk med flere hundrede af disse blokke (de mest almindelige varianter er ResNet-52, ResNet-101 og ResNet-152).

Du kan ogs친 t칝nke p친 dette netv칝rk som v칝rende i stand til at justere sin kompleksitet til datas칝ttet. I starten, n친r du begynder at tr칝ne netv칝rket, er v칝gtv칝rdierne sm친, og det meste af signalet g친r gennem identitetslagene. Efterh친nden som tr칝ningen skrider frem, og v칝gtene bliver st칮rre, vokser betydningen af netv칝rkets parametre, og netv칝rket tilpasser sig for at opn친 den n칮dvendige udtrykskraft til korrekt klassifikation af tr칝ningsbillederne.

### Google Inception

Google Inception-arkitekturen tager denne id칠 et skridt videre og bygger hvert netv칝rkslag som en kombination af flere forskellige veje:

<img src="../../../../../translated_images/da/inception.a6605b85bcbc6f52.webp" width="400"/>

> Billede fra [Researchgate](https://www.researchgate.net/figure/Inception-module-with-dimension-reductions-left-and-schema-for-Inception-ResNet-v1_fig2_355547454)

Her skal vi fremh칝ve rollen af 1x1-konvolutioner, fordi de ved f칮rste 칮jekast ikke giver mening. Hvorfor skulle vi have brug for at k칮re gennem billedet med et 1x1-filter? Men det er vigtigt at huske, at konvolutionsfiltre ogs친 arbejder med flere dybdekanaler (oprindeligt - RGB-farver, i efterf칮lgende lag - kanaler for forskellige filtre), og 1x1-konvolution bruges til at blande disse inputkanaler sammen ved hj칝lp af forskellige tr칝nbare v칝gte. Det kan ogs친 ses som en form for nedsampling (pooling) over kanaldimensionen.

Her er [en god blogpost](https://medium.com/analytics-vidhya/talented-mr-1x1-comprehensive-look-at-1x1-convolution-in-deep-learning-f6b355825578) om emnet og [den originale artikel](https://arxiv.org/pdf/1312.4400.pdf).

### MobileNet

MobileNet er en familie af modeller med reduceret st칮rrelse, der er velegnede til mobile enheder. Brug dem, hvis du har begr칝nsede ressourcer og kan acceptere en lille reduktion i n칮jagtighed. Hovedideen bag dem er den s친kaldte **depthwise separable convolution**, som g칮r det muligt at repr칝sentere konvolutionsfiltre som en sammens칝tning af rumlige konvolutioner og 1x1-konvolution over dybdekanaler. Dette reducerer antallet af parametre betydeligt, hvilket g칮r netv칝rket mindre i st칮rrelse og ogs친 lettere at tr칝ne med mindre data.

Her er [en god blogpost om MobileNet](https://medium.com/analytics-vidhya/image-classification-with-mobilenet-cc6fbb2cd470).

## Konklusion

I denne enhed har du l칝rt hovedkonceptet bag neurale netv칝rk til computer vision - konvolutionsnetv칝rk. Virkelige arkitekturer, der driver billedklassifikation, objektgenkendelse og endda billedgenereringsnetv칝rk, er alle baseret p친 CNN'er, blot med flere lag og nogle ekstra tr칝ningstricks.

## 游 Udfordring

I de medf칮lgende notebooks er der noter nederst om, hvordan man opn친r st칮rre n칮jagtighed. Lav nogle eksperimenter for at se, om du kan opn친 h칮jere n칮jagtighed.

## [Quiz efter forel칝sning](https://ff-quizzes.netlify.app/en/ai/quiz/14)

## Gennemgang & Selvstudie

Selvom CNN'er oftest bruges til opgaver inden for computer vision, er de generelt gode til at udtr칝kke m칮nstre af fast st칮rrelse. For eksempel, hvis vi arbejder med lyde, kan vi ogs친 bruge CNN'er til at finde specifikke m칮nstre i lydsignaler - i dette tilf칝lde ville filtrene v칝re 1-dimensionelle (og dette CNN ville blive kaldt 1D-CNN). Nogle gange bruges ogs친 3D-CNN til at udtr칝kke funktioner i et multidimensionelt rum, s친som visse begivenheder, der sker p친 video - CNN kan fange visse m칮nstre af funktioner, der 칝ndrer sig over tid. Lav en gennemgang og selvstudie om andre opgaver, der kan udf칮res med CNN'er.

## [Opgave](lab/README.md)

I denne lab skal du klassificere forskellige katte- og hunderacer. Disse billeder er mere komplekse end MNIST-datas칝ttet og har h칮jere dimensioner, og der er mere end 10 klasser.

---

