# Forudtr√¶nede Netv√¶rk og Transfer Learning

Tr√¶ning af CNN'er kan tage meget tid, og der kr√¶ves en stor m√¶ngde data til denne opgave. Meget af tiden bruges dog p√• at l√¶re de bedste lavniveau-filtre, som et netv√¶rk kan bruge til at udtr√¶kke m√∏nstre fra billeder. Et naturligt sp√∏rgsm√•l opst√•r: Kan vi bruge et neuralt netv√¶rk, der er tr√¶net p√• √©t datas√¶t, og tilpasse det til at klassificere andre billeder uden at skulle gennemg√• en fuld tr√¶ningsproces?

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Denne tilgang kaldes **transfer learning**, fordi vi overf√∏rer noget viden fra √©n neuralt netv√¶rksmodel til en anden. I transfer learning starter vi typisk med en forudtr√¶net model, som er blevet tr√¶net p√• et stort billeddatas√¶t, s√•som **ImageNet**. Disse modeller er allerede gode til at udtr√¶kke forskellige funktioner fra generiske billeder, og i mange tilf√¶lde kan man opn√• gode resultater blot ved at bygge en klassifikator oven p√• de udtrukne funktioner.

> ‚úÖ Transfer Learning er et begreb, der ogs√• findes i andre akademiske felter, s√•som uddannelse. Det refererer til processen med at tage viden fra √©t omr√•de og anvende det p√• et andet.

## Forudtr√¶nede Modeller som Funktionsudtr√¶kkere

De konvolutionsnetv√¶rk, vi har talt om i det foreg√•ende afsnit, indeholder en r√¶kke lag, som hver is√¶r skal udtr√¶kke nogle funktioner fra billedet. Dette starter med lavniveau-pixelkombinationer (s√•som horisontale/vertikale linjer eller streger) og g√•r op til h√∏jere niveau-kombinationer af funktioner, der svarer til ting som et √∏je p√• en flamme. Hvis vi tr√¶ner et CNN p√• et tilstr√¶kkeligt stort datas√¶t af generiske og forskellige billeder, b√∏r netv√¶rket l√¶re at udtr√¶kke disse f√¶lles funktioner.

B√•de Keras og PyTorch indeholder funktioner til nemt at indl√¶se forudtr√¶nede neurale netv√¶rksv√¶gte for nogle almindelige arkitekturer, hvoraf de fleste er tr√¶net p√• ImageNet-billeder. De mest anvendte er beskrevet p√• siden [CNN Architectures](../07-ConvNets/CNN_Architectures.md) fra den tidligere lektion. Is√¶r kan du overveje at bruge en af f√∏lgende:

* **VGG-16/VGG-19**, som er relativt simple modeller, der stadig giver god n√∏jagtighed. Ofte er det en god id√© at starte med VGG for at se, hvordan transfer learning fungerer.
* **ResNet** er en familie af modeller foresl√•et af Microsoft Research i 2015. De har flere lag og kr√¶ver derfor flere ressourcer.
* **MobileNet** er en familie af modeller med reduceret st√∏rrelse, der er velegnede til mobile enheder. Brug dem, hvis du har begr√¶nsede ressourcer og kan ofre lidt n√∏jagtighed.

Her er eksempler p√• funktioner udtrukket fra et billede af en kat ved hj√¶lp af VGG-16-netv√¶rket:

![Funktioner udtrukket af VGG-16](../../../../../translated_images/da/features.6291f9c7ba3a0b95.webp)

## Datas√¶t: Katte vs. Hunde

I dette eksempel vil vi bruge et datas√¶t med [Katte og Hunde](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), som ligger meget t√¶t p√• et realistisk scenarie for billedklassifikation.

## ‚úçÔ∏è √òvelse: Transfer Learning

Lad os se transfer learning i aktion i de tilh√∏rende notebooks:

* [Transfer Learning - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer Learning - TensorFlow](TransferLearningTF.ipynb)

## Visualisering af Adversarial Kat

Et forudtr√¶net neuralt netv√¶rk indeholder forskellige m√∏nstre i sin *hjerne*, herunder forestillinger om en **ideel kat** (samt ideel hund, ideel zebra osv.). Det kunne v√¶re interessant p√• en eller anden m√•de at **visualisere dette billede**. Det er dog ikke simpelt, fordi m√∏nstrene er spredt ud over netv√¶rkets v√¶gte og ogs√• organiseret i en hierarkisk struktur.

En tilgang, vi kan tage, er at starte med et tilf√¶ldigt billede og derefter bruge **gradient descent-optimering** til at justere billedet p√• en s√•dan m√•de, at netv√¶rket begynder at tro, at det er en kat.

![Billedoptimeringsloop](../../../../../translated_images/da/ideal-cat-loop.999fbb8ff306e044.webp)

Hvis vi g√∏r dette, vil vi dog f√• noget, der minder meget om tilf√¶ldig st√∏j. Dette skyldes, at *der er mange m√•der at f√• netv√¶rket til at tro, at inputbilledet er en kat*, herunder nogle, der ikke giver mening visuelt. Selvom disse billeder indeholder mange m√∏nstre, der er typiske for en kat, er der intet, der tvinger dem til at v√¶re visuelt genkendelige.

For at forbedre resultatet kan vi tilf√∏je et andet led til tab-funktionen, som kaldes **variationstab**. Det er en m√•ling, der viser, hvor ens nabopixels i billedet er. Ved at minimere variationstabet bliver billedet glattere og fjerner st√∏j ‚Äì hvilket afsl√∏rer mere visuelt tiltalende m√∏nstre. Her er et eksempel p√• s√•danne "ideelle" billeder, der klassificeres som henholdsvis kat og zebra med h√∏j sandsynlighed:

![Ideel Kat](../../../../../translated_images/da/ideal-cat.203dd4597643d6b0.webp) | ![Ideel Zebra](../../../../../translated_images/da/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Ideel Kat* | *Ideel Zebra*

En lignende tilgang kan bruges til at udf√∏re s√•kaldte **adversarielle angreb** p√• et neuralt netv√¶rk. Antag, at vi vil narre et neuralt netv√¶rk og f√• en hund til at ligne en kat. Hvis vi tager et billede af en hund, som netv√¶rket genkender som en hund, kan vi justere det lidt ved hj√¶lp af gradient descent-optimering, indtil netv√¶rket begynder at klassificere det som en kat:

![Billede af en Hund](../../../../../translated_images/da/original-dog.8f68a67d2fe0911f.webp) | ![Billede af en hund klassificeret som en kat](../../../../../translated_images/da/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Originalt billede af en hund* | *Billede af en hund klassificeret som en kat*

Se koden for at genskabe resultaterne ovenfor i f√∏lgende notebook:

* [Ideel og Adversarial Kat - TensorFlow](AdversarialCat_TF.ipynb)

## Konklusion

Ved hj√¶lp af transfer learning kan du hurtigt sammens√¶tte en klassifikator til en brugerdefineret objektklassifikationsopgave og opn√• h√∏j n√∏jagtighed. Du kan se, at mere komplekse opgaver, som vi l√∏ser nu, kr√¶ver h√∏jere computerkraft og ikke let kan l√∏ses p√• en CPU. I den n√¶ste enhed vil vi fors√∏ge at bruge en mere letv√¶gtsimplementering til at tr√¶ne den samme model med lavere computerressourcer, hvilket resulterer i en lidt lavere n√∏jagtighed.

## üöÄ Udfordring

I de tilh√∏rende notebooks er der noter nederst om, hvordan transfer learning fungerer bedst med nogenlunde lignende tr√¶ningsdata (m√•ske en ny type dyr). Lav nogle eksperimenter med helt nye typer billeder for at se, hvor godt eller d√•rligt dine transfer learning-modeller klarer sig.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Gennemgang & Selvstudie

L√¶s [TrainingTricks.md](TrainingTricks.md) for at uddybe din viden om andre m√•der at tr√¶ne dine modeller p√•.

## [Opgave](lab/README.md)

I dette laboratorium vil vi bruge det virkelige [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) k√¶ledyrsdatas√¶t med 35 racer af katte og hunde og bygge en transfer learning-klassifikator.

---

