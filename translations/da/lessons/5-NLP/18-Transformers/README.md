# Attention Mekanismer og Transformers

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/35)

Et af de vigtigste problemer inden for NLP er **maskinovers칝ttelse**, en essentiel opgave, der ligger til grund for v칝rkt칮jer som Google Translate. I denne sektion vil vi fokusere p친 maskinovers칝ttelse, eller mere generelt p친 enhver *sekvens-til-sekvens* opgave (som ogs친 kaldes **s칝tningsomdannelse**).

Med RNN'er implementeres sekvens-til-sekvens med to rekurrente netv칝rk, hvor det ene netv칝rk, **encoder**, komprimerer en inputsekvens til en skjult tilstand, mens det andet netv칝rk, **decoder**, udfolder denne skjulte tilstand til et oversat resultat. Der er dog nogle problemer med denne tilgang:

* Den endelige tilstand i encoder-netv칝rket har sv칝rt ved at huske begyndelsen af en s칝tning, hvilket f칮rer til d친rlig modelkvalitet for lange s칝tninger.
* Alle ord i en sekvens har samme indflydelse p친 resultatet. I virkeligheden har specifikke ord i inputsekvensen ofte st칮rre indflydelse p친 sekventielle outputs end andre.

**Attention Mekanismer** giver en metode til at v칝gte den kontekstuelle indflydelse af hver inputvektor p친 hver outputforudsigelse i RNN. Dette implementeres ved at skabe genveje mellem de mellemliggende tilstande i input-RNN og output-RNN. P친 denne m친de, n친r vi genererer outputsymbol y<sub>t</sub>, tager vi alle input skjulte tilstande h<sub>i</sub> i betragtning med forskellige v칝gtkoefficienter &alpha;<sub>t,i</sub>.

![Billede, der viser en encoder/decoder-model med et additivt attention-lag](../../../../../translated_images/da/encoder-decoder-attention.7a726296894fb567.webp)

> Encoder-decoder modellen med additiv attention mekanisme i [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf), citeret fra [denne blogpost](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

Attention-matrixen {&alpha;<sub>i,j</sub>} repr칝senterer graden af, hvor meget visse inputord spiller en rolle i genereringen af et givet ord i outputsekvensen. Nedenfor er et eksempel p친 en s친dan matrix:

![Billede, der viser en pr칮vejustering fundet af RNNsearch-50, taget fra Bahdanau - arviz.org](../../../../../translated_images/da/bahdanau-fig3.09ba2d37f202a6af.webp)

> Figur fra [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf) (Fig.3)

Attention-mekanismer er ansvarlige for meget af den nuv칝rende eller n칝sten nuv칝rende state-of-the-art inden for NLP. Tilf칮jelse af attention 칮ger dog kraftigt antallet af modelparametre, hvilket f칮rte til skaleringsproblemer med RNN'er. En vigtig begr칝nsning ved skalering af RNN'er er, at modellernes rekursive natur g칮r det udfordrende at batch- og parallelisere tr칝ning. I en RNN skal hvert element i en sekvens behandles i sekventiel r칝kkef칮lge, hvilket betyder, at det ikke nemt kan paralleliseres.

![Encoder Decoder med Attention](../../../../../lessons/5-NLP/18-Transformers/images/EncDecAttention.gif)

> Figur fra [Googles Blog](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)

Adoptionen af attention-mekanismer kombineret med denne begr칝nsning f칮rte til skabelsen af de nuv칝rende state-of-the-art Transformer-modeller, som vi kender og bruger i dag, s친som BERT og Open-GPT3.

## Transformer-modeller

En af hovedid칠erne bag transformers er at undg친 den sekventielle natur af RNN'er og skabe en model, der kan paralleliseres under tr칝ning. Dette opn친s ved at implementere to id칠er:

* positionskodning
* brug af self-attention mekanisme til at fange m칮nstre i stedet for RNN'er (eller CNN'er) (det er derfor, papiret, der introducerer transformers, hedder *[Attention is all you need](https://arxiv.org/abs/1706.03762)*)

### Positionskodning/Embedding

Id칠en med positionskodning er f칮lgende:  
1. N친r man bruger RNN'er, repr칝senteres de relative positioner af tokens af antallet af trin og beh칮ver derfor ikke at blive eksplicit repr칝senteret.  
2. N친r vi skifter til attention, skal vi dog kende de relative positioner af tokens inden for en sekvens.  
3. For at f친 positionskodning udvider vi vores sekvens af tokens med en sekvens af token-positioner i sekvensen (dvs. en sekvens af numre 0,1, ...).  
4. Vi blander derefter token-positionen med en token-embedding-vektor. For at transformere positionen (heltal) til en vektor kan vi bruge forskellige tilgange:

* Tr칝nbar embedding, svarende til token-embedding. Dette er den tilgang, vi overvejer her. Vi anvender embedding-lag oven p친 b친de tokens og deres positioner, hvilket resulterer i embedding-vektorer af samme dimensioner, som vi derefter l칝gger sammen.
* Fast positionskodningsfunktion, som foresl친et i det originale papir.

<img src="../../../../../translated_images/da/pos-embedding.e41ce9b6cf6078af.webp" width="50%"/>

> Billede af forfatteren

Resultatet, vi f친r med positionskodning, embedder b친de det originale token og dets position inden for en sekvens.

### Multi-Head Self-Attention

Dern칝st skal vi fange nogle m칮nstre inden for vores sekvens. For at g칮re dette bruger transformers en **self-attention** mekanisme, som i bund og grund er attention anvendt p친 den samme sekvens som input og output. Ved at anvende self-attention kan vi tage **kontekst** inden for s칝tningen i betragtning og se, hvilke ord der er relaterede. For eksempel giver det os mulighed for at se, hvilke ord der refereres til af coreferencer, s친som *det*, og ogs친 tage konteksten i betragtning:

![](../../../../../translated_images/da/CoreferenceResolution.861924d6d384a7d6.webp)

> Billede fra [Google Blog](https://research.googleblog.com/2017/08/transformer-novel-neural-network.html)

I transformers bruger vi **Multi-Head Attention** for at give netv칝rket evnen til at fange flere forskellige typer afh칝ngigheder, f.eks. langvarige vs. kortvarige ordrelationer, coreference vs. noget andet osv.

[TensorFlow Notebook](TransformersTF.ipynb) indeholder flere detaljer om implementeringen af transformer-lag.

### Encoder-Decoder Attention

I transformers bruges attention to steder:

* Til at fange m칮nstre inden for inputteksten ved hj칝lp af self-attention.
* Til at udf칮re sekvensovers칝ttelse - det er attention-laget mellem encoder og decoder.

Encoder-decoder attention ligner meget den attention-mekanisme, der bruges i RNN'er, som beskrevet i begyndelsen af denne sektion. Denne animerede diagram forklarer rollen af encoder-decoder attention.

![Animeret GIF, der viser, hvordan evalueringerne udf칮res i transformer-modeller.](../../../../../lessons/5-NLP/18-Transformers/images/transformer-animated-explanation.gif)

Da hver inputposition uafh칝ngigt kortl칝gges til hver outputposition, kan transformers parallelisere bedre end RNN'er, hvilket muligg칮r meget st칮rre og mere udtryksfulde sprogmodeller. Hver attention-head kan bruges til at l칝re forskellige relationer mellem ord, hvilket forbedrer nedstr칮ms Natural Language Processing-opgaver.

## BERT

**BERT** (Bidirectional Encoder Representations from Transformers) er et meget stort multi-lags transformer-netv칝rk med 12 lag for *BERT-base* og 24 for *BERT-large*. Modellen tr칝nes f칮rst p친 en stor tekstkorpus (Wikipedia + b칮ger) ved hj칝lp af usuperviseret tr칝ning (forudsige maskerede ord i en s칝tning). Under pre-tr칝ning absorberer modellen betydelige niveauer af sprogforst친else, som derefter kan udnyttes med andre datas칝t ved hj칝lp af finjustering. Denne proces kaldes **transfer learning**.

![billede fra http://jalammar.github.io/illustrated-bert/](../../../../../translated_images/da/jalammarBERT-language-modeling-masked-lm.34f113ea5fec4362.webp)

> Billede [kilde](http://jalammar.github.io/illustrated-bert/)

## 九꽲잺 칒velser: Transformers

Forts칝t din l칝ring i f칮lgende notebooks:

* [Transformers i PyTorch](TransformersPyTorch.ipynb)
* [Transformers i TensorFlow](TransformersTF.ipynb)

## Konklusion

I denne lektion l칝rte du om Transformers og Attention Mekanismer, alle essentielle v칝rkt칮jer i NLP-v칝rkt칮jskassen. Der findes mange variationer af Transformer-arkitekturer, herunder BERT, DistilBERT, BigBird, OpenGPT3 og flere, som kan finjusteres. [HuggingFace-pakken](https://github.com/huggingface/) tilbyder et repository til tr칝ning af mange af disse arkitekturer med b친de PyTorch og TensorFlow.

## 游 Udfordring

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ai/quiz/36)

## Gennemgang & Selvstudie

* [Blogpost](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/), der forklarer det klassiske [Attention is all you need](https://arxiv.org/abs/1706.03762)-papir om transformers.
* [En serie af blogposts](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452) om transformers, der forklarer arkitekturen i detaljer.

## [Opgave](assignment.md)

---

