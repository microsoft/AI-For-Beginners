# Jezikovno modeliranje

SemantiÄne vektorske predstavitve, kot sta Word2Vec in GloVe, so pravzaprav prvi korak k **jezikovnemu modeliranju** â€“ ustvarjanju modelov, ki nekako *razumejo* (ali *predstavljajo*) naravo jezika.

## [Predhodni kviz](https://ff-quizzes.netlify.app/en/ai/quiz/29)

Glavna ideja jezikovnega modeliranja je, da jih treniramo na nenalepÄenih podatkovnih nizih na nesuperviziran naÄin. To je pomembno, ker imamo na voljo ogromne koliÄine nenalepÄenega besedila, medtem ko je koliÄina nalepÄenega besedila vedno omejena z vloÅ¾enim trudom pri oznaÄevanju. Najpogosteje lahko zgradimo jezikovne modele, ki lahko **napovedujejo manjkajoÄe besede** v besedilu, saj je enostavno nakljuÄno besedo v besedilu zakriti in jo uporabiti kot uÄni vzorec.

## UÄenje vektorskih predstavitev

V prejÅ¡njih primerih smo uporabljali Å¾e vnaprej nauÄene semantiÄne vektorske predstavitve, vendar je zanimivo videti, kako lahko te predstavitve treniramo. Obstaja veÄ moÅ¾nih pristopov:

* **N-gram** jezikovno modeliranje, kjer napovedujemo token z upoÅ¡tevanjem N prejÅ¡njih tokenov (N-gram).
* **Neprekinjena vreÄa besed** (CBoW), kjer napovedujemo srednji token $W_0$ v zaporedju tokenov $W_{-N}$, ..., $W_N$.
* **Skip-gram**, kjer napovedujemo niz sosednjih tokenov {$W_{-N},\dots, W_{-1}, W_1,\dots, W_N$} iz srednjega tokena $W_0$.

![slika iz Älanka o pretvorbi besed v vektorje](../../../../../translated_images/sl/example-algorithms-for-converting-words-to-vectors.fbe9207a726922f6.webp)

> Slika iz [tega Älanka](https://arxiv.org/pdf/1301.3781.pdf)

## âœï¸ Primeri zvezkov: UÄenje CBoW modela

Nadaljujte z uÄenjem v naslednjih zvezkih:

* [UÄenje CBoW Word2Vec z TensorFlow](CBoW-TF.ipynb)
* [UÄenje CBoW Word2Vec z PyTorch](CBoW-PyTorch.ipynb)

## ZakljuÄek

V prejÅ¡nji lekciji smo videli, da vektorske predstavitve besed delujejo kot Äarovnija! Zdaj vemo, da uÄenje vektorskih predstavitev besed ni zelo zapletena naloga, in bi morali biti sposobni nauÄiti svoje vektorske predstavitve za besedila specifiÄna za doloÄeno podroÄje, Äe je to potrebno.

## [Naknadni kviz](https://ff-quizzes.netlify.app/en/ai/quiz/30)

## Pregled in samostojno uÄenje

* [Uradni PyTorch vodiÄ o jezikovnem modeliranju](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).
* [Uradni TensorFlow vodiÄ o uÄenju Word2Vec modela](https://www.TensorFlow.org/tutorials/text/word2vec).
* Uporaba ogrodja **gensim** za uÄenje najpogosteje uporabljenih vektorskih predstavitev v nekaj vrsticah kode je opisana [v tej dokumentaciji](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).

## ğŸš€ [Naloga: NauÄite Skip-Gram model](lab/README.md)

V laboratoriju vas izzivamo, da spremenite kodo iz te lekcije in nauÄite Skip-Gram model namesto CBoW. [Preberite podrobnosti](lab/README.md)

---

