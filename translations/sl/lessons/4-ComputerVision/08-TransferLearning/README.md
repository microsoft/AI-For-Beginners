# Vnaprej nauÄeni modeli in prenos uÄenja

UÄenje CNN-jev lahko zahteva veliko Äasa, poleg tega pa je za to nalogo potrebnih veliko podatkov. Velik del Äasa se porabi za uÄenje najboljÅ¡ih nizkoroÄnih filtrov, ki jih mreÅ¾a lahko uporabi za prepoznavanje vzorcev iz slik. Pojavi se naravno vpraÅ¡anje â€“ ali lahko uporabimo nevronsko mreÅ¾o, nauÄeno na enem naboru podatkov, in jo prilagodimo za razvrÅ¡Äanje drugih slik, ne da bi morali izvesti celoten proces uÄenja?

## [Predhodni kviz](https://ff-quizzes.netlify.app/en/ai/quiz/15)

Ta pristop se imenuje **prenos uÄenja**, ker prenesemo doloÄeno znanje iz enega modela nevronske mreÅ¾e na drugega. Pri prenosu uÄenja obiÄajno zaÄnemo z vnaprej nauÄenim modelom, ki je bil nauÄen na velikem naboru slik, kot je **ImageNet**. Ti modeli Å¾e dobro prepoznavajo razliÄne znaÄilnosti iz sploÅ¡nih slik, in v mnogih primerih lahko Å¾e samo z gradnjo klasifikatorja na podlagi teh znaÄilnosti doseÅ¾emo dobre rezultate.

> âœ… Prenos uÄenja je izraz, ki ga najdemo tudi v drugih akademskih podroÄjih, kot je izobraÅ¾evanje. NanaÅ¡a se na proces prenosa znanja iz enega podroÄja na drugo.

## Vnaprej nauÄeni modeli kot ekstraktorji znaÄilnosti

Konvolucijske mreÅ¾e, o katerih smo govorili v prejÅ¡njem poglavju, vsebujejo veÄ plasti, od katerih vsaka izvleÄe doloÄene znaÄilnosti iz slike, zaÄenÅ¡i z nizkoroÄnimi kombinacijami pikslov (kot so horizontalne/vertikalne Ärte ali poteze), do viÅ¡jih kombinacij znaÄilnosti, ki ustrezajo stvarem, kot je oko plamena. ÄŒe CNN nauÄimo na dovolj velikem naboru sploÅ¡nih in raznolikih slik, bi morala mreÅ¾a nauÄiti prepoznavati te skupne znaÄilnosti.

Tako Keras kot PyTorch vsebujeta funkcije za enostavno nalaganje vnaprej nauÄenih uteÅ¾i nevronske mreÅ¾e za nekatere pogoste arhitekture, veÄina katerih je bila nauÄena na slikah iz ImageNet. Najpogosteje uporabljene so opisane na strani [Arhitekture CNN](../07-ConvNets/CNN_Architectures.md) iz prejÅ¡nje lekcije. Zlasti lahko razmislite o uporabi enega od naslednjih:

* **VGG-16/VGG-19**, ki sta relativno preprosta modela, a Å¡e vedno zagotavljata dobro natanÄnost. Pogosto je uporaba VGG kot prvi poskus dobra izbira za preverjanje delovanja prenosa uÄenja.
* **ResNet** je druÅ¾ina modelov, ki jih je predlagal Microsoft Research leta 2015. Imajo veÄ plasti, zato zahtevajo veÄ virov.
* **MobileNet** je druÅ¾ina modelov z zmanjÅ¡ano velikostjo, primernih za mobilne naprave. Uporabite jih, Äe imate omejene vire in lahko Å¾rtvujete malo natanÄnosti.

Tukaj so primeri znaÄilnosti, izvleÄenih iz slike maÄke z mreÅ¾o VGG-16:

![ZnaÄilnosti, izvleÄene z VGG-16](../../../../../translated_images/sl/features.6291f9c7ba3a0b95.webp)

## Nabor podatkov MaÄke proti psom

V tem primeru bomo uporabili nabor podatkov [MaÄke in psi](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), ki je zelo blizu resniÄnemu scenariju razvrÅ¡Äanja slik.

## âœï¸ Naloga: Prenos uÄenja

Poglejmo prenos uÄenja v praksi v ustreznih zvezkih:

* [Prenos uÄenja - PyTorch](TransferLearningPyTorch.ipynb)
* [Prenos uÄenja - TensorFlow](TransferLearningTF.ipynb)

## Vizualizacija idealne maÄke

Vnaprej nauÄena nevronska mreÅ¾a vsebuje razliÄne vzorce v svojem *moÅ¾ganu*, vkljuÄno z idejami o **idealni maÄki** (pa tudi idealnem psu, idealni zebri itd.). Zanimivo bi bilo nekako **vizualizirati to sliko**. Vendar to ni preprosto, saj so vzorci razprÅ¡eni po uteÅ¾eh mreÅ¾e in organizirani v hierarhiÄno strukturo.

Eden od pristopov, ki ga lahko uporabimo, je zaÄeti z nakljuÄno sliko in nato poskusiti uporabiti tehniko **optimizacije z gradientnim spustom**, da prilagodimo to sliko tako, da mreÅ¾a zaÄne misliti, da je to maÄka.

![Zanka optimizacije slike](../../../../../translated_images/sl/ideal-cat-loop.999fbb8ff306e044.webp)

ÄŒe to storimo, bomo dobili nekaj, kar je zelo podobno nakljuÄnemu Å¡umu. To je zato, ker *obstaja veliko naÄinov, kako mreÅ¾i narediti vtis, da je vhodna slika maÄka*, vkljuÄno z nekaterimi, ki vizualno nimajo smisla. ÄŒeprav te slike vsebujejo veliko vzorcev, znaÄilnih za maÄko, ni niÄesar, kar bi jih omejevalo, da bi bile vizualno prepoznavne.

Za izboljÅ¡anje rezultata lahko v funkcijo izgube dodamo Å¡e en Älen, imenovan **izguba variacije**. To je metrika, ki kaÅ¾e, kako podobni so sosednji piksli slike. ZmanjÅ¡anje izgube variacije naredi sliko bolj gladko in odstrani Å¡um â€“ s tem razkrije bolj vizualno privlaÄne vzorce. Tukaj je primer takÅ¡nih "idealnih" slik, ki so z visoko verjetnostjo razvrÅ¡Äene kot maÄka in zebra:

![Idealna maÄka](../../../../../translated_images/sl/ideal-cat.203dd4597643d6b0.webp) | ![Idealna zebra](../../../../../translated_images/sl/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Idealna maÄka* | *Idealna zebra*

Podoben pristop lahko uporabimo za izvajanje tako imenovanih **adversarnih napadov** na nevronsko mreÅ¾o. Recimo, da Å¾elimo zavajati nevronsko mreÅ¾o in narediti, da pes izgleda kot maÄka. ÄŒe vzamemo sliko psa, ki jo mreÅ¾a prepozna kot psa, jo lahko nato nekoliko prilagodimo z optimizacijo gradientnega spusta, dokler mreÅ¾a ne zaÄne razvrÅ¡Äati slike kot maÄko:

![Slika psa](../../../../../translated_images/sl/original-dog.8f68a67d2fe0911f.webp) | ![Slika psa, razvrÅ¡Äena kot maÄka](../../../../../translated_images/sl/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Izvirna slika psa* | *Slika psa, razvrÅ¡Äena kot maÄka*

Oglejte si kodo za reprodukcijo zgornjih rezultatov v naslednjem zvezku:

* [Idealna in adversarna maÄka - TensorFlow](AdversarialCat_TF.ipynb)

## ZakljuÄek

S prenosom uÄenja lahko hitro sestavite klasifikator za nalogo razvrÅ¡Äanja prilagojenih objektov in doseÅ¾ete visoko natanÄnost. Vidite lahko, da bolj zapletene naloge, ki jih zdaj reÅ¡ujemo, zahtevajo veÄjo raÄunsko moÄ in jih ni mogoÄe enostavno reÅ¡iti na CPU. V naslednji enoti bomo poskusili uporabiti bolj lahkotno implementacijo za uÄenje istega modela z niÅ¾jimi raÄunalniÅ¡kimi viri, kar bo prineslo le nekoliko niÅ¾jo natanÄnost.

## ğŸš€ Izziv

V priloÅ¾enih zvezkih so opombe na dnu o tem, kako prenos znanja najbolje deluje s podobnimi uÄnimi podatki (morda nov tip Å¾ivali). Izvedite nekaj eksperimentov s popolnoma novimi vrstami slik, da vidite, kako dobro ali slabo delujejo vaÅ¡i modeli prenosa znanja.

## [Kviz po predavanju](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Pregled in samostojno uÄenje

Preberite [TrainingTricks.md](TrainingTricks.md), da poglobite svoje znanje o drugih naÄinih uÄenja vaÅ¡ih modelov.

## [Naloga](lab/README.md)

V tem laboratoriju bomo uporabili resniÄni nabor podatkov [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) o hiÅ¡nih ljubljenÄkih z 35 pasmami maÄk in psov ter zgradili klasifikator s prenosom uÄenja.

---

