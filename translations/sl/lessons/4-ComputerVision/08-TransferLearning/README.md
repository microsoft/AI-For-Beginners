<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "717775c4050ccbffbe0c961ad8bf7bf7",
  "translation_date": "2025-08-25T23:09:23+00:00",
  "source_file": "lessons/4-ComputerVision/08-TransferLearning/README.md",
  "language_code": "sl"
}
-->
# Vnaprej nauÄena omreÅ¾ja in prenos uÄenja

UÄenje konvolucijskih nevronskih omreÅ¾ij (CNN) lahko zahteva veliko Äasa in podatkov. Velik del Äasa se porabi za uÄenje najboljÅ¡ih nizkofrekvenÄnih filtrov, ki jih omreÅ¾je lahko uporabi za prepoznavanje vzorcev iz slik. Naravno se pojavi vpraÅ¡anje â€“ ali lahko uporabimo nevronsko omreÅ¾je, nauÄeno na enem naboru podatkov, in ga prilagodimo za razvrÅ¡Äanje drugih slik, ne da bi morali izvesti celoten proces uÄenja?

## [Predhodni kviz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/108)

Ta pristop se imenuje **prenos uÄenja**, saj prenesemo doloÄeno znanje iz enega modela nevronskega omreÅ¾ja na drugega. Pri prenosu uÄenja obiÄajno zaÄnemo z vnaprej nauÄenim modelom, ki je bil nauÄen na velikem naboru slik, kot je **ImageNet**. Ti modeli Å¾e dobro prepoznavajo razliÄne znaÄilnosti iz sploÅ¡nih slik, in v mnogih primerih lahko Å¾e samo zgraditev klasifikatorja na podlagi teh znaÄilnosti prinese dobre rezultate.

> âœ… Prenos uÄenja je izraz, ki ga najdemo tudi na drugih akademskih podroÄjih, kot je izobraÅ¾evanje. NanaÅ¡a se na proces prenosa znanja iz enega podroÄja na drugo.

## Vnaprej nauÄeni modeli kot ekstraktorji znaÄilnosti

Konvolucijska omreÅ¾ja, o katerih smo govorili v prejÅ¡njem poglavju, vsebujejo veÄ plasti, od katerih vsaka iz slike izluÅ¡Äi doloÄene znaÄilnosti â€“ od nizkofrekvenÄnih kombinacij pikslov (kot so horizontalne/vertikalne Ärte ali poteze) do viÅ¡jefrekvenÄnih kombinacij znaÄilnosti, ki ustrezajo stvarem, kot je oko plamena. ÄŒe CNN nauÄimo na dovolj velikem naboru sploÅ¡nih in raznolikih slik, bi se moralo omreÅ¾je nauÄiti prepoznavati te skupne znaÄilnosti.

Tako Keras kot PyTorch vsebujeta funkcije za enostavno nalaganje vnaprej nauÄenih uteÅ¾i nevronskih omreÅ¾ij za nekatere pogoste arhitekture, veÄina katerih je bila nauÄena na slikah iz ImageNet. Najpogosteje uporabljene so opisane na strani [Arhitekture CNN](../07-ConvNets/CNN_Architectures.md) iz prejÅ¡nje lekcije. Å e posebej lahko razmislite o uporabi enega od naslednjih:

* **VGG-16/VGG-19**, ki sta relativno preprosta modela, a Å¡e vedno zagotavljata dobro natanÄnost. Pogosto je uporaba VGG kot prvi poskus dobra izbira za preverjanje delovanja prenosa uÄenja.
* **ResNet** je druÅ¾ina modelov, ki jih je predlagal Microsoft Research leta 2015. Imajo veÄ plasti in zato zahtevajo veÄ virov.
* **MobileNet** je druÅ¾ina modelov z zmanjÅ¡ano velikostjo, primernih za mobilne naprave. Uporabite jih, Äe imate omejene vire in lahko Å¾rtvujete nekaj natanÄnosti.

Tukaj so primeri znaÄilnosti, izluÅ¡Äenih iz slike maÄke z omreÅ¾jem VGG-16:

![ZnaÄilnosti, izluÅ¡Äene z VGG-16](../../../../../translated_images/features.6291f9c7ba3a0b951af88fc9864632b9115365410765680680d30c927dd67354.sl.png)

## Nabor podatkov MaÄke proti psom

V tem primeru bomo uporabili nabor podatkov [MaÄke in psi](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), ki je zelo podoben resniÄnemu scenariju razvrÅ¡Äanja slik.

## âœï¸ Vaja: Prenos uÄenja

Poglejmo prenos uÄenja v praksi v ustreznih beleÅ¾nicah:

* [Prenos uÄenja - PyTorch](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningPyTorch.ipynb)
* [Prenos uÄenja - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/TransferLearningTF.ipynb)

## Vizualizacija nasprotne maÄke

Vnaprej nauÄeno nevronsko omreÅ¾je vsebuje razliÄne vzorce v svojem *"moÅ¾ganu"*, vkljuÄno s pojmi, kot je **idealna maÄka** (pa tudi idealen pes, idealna zebra itd.). Zanimivo bi bilo nekako **vizualizirati to sliko**. Vendar to ni preprosto, saj so vzorci razprÅ¡eni po uteÅ¾eh omreÅ¾ja in organizirani v hierarhiÄno strukturo.

Eden od pristopov, ki ga lahko uporabimo, je zaÄeti z nakljuÄno sliko in nato uporabiti tehniko **optimizacije z gradientnim spustom**, da prilagodimo to sliko tako, da omreÅ¾je zaÄne misliti, da gre za maÄko.

![Zanka optimizacije slike](../../../../../translated_images/ideal-cat-loop.999fbb8ff306e044f997032f4eef9152b453e6a990e449bbfb107de2493cc37e.sl.png)

ÄŒe to storimo, bomo dobili nekaj, kar je zelo podobno nakljuÄnemu Å¡umu. To je zato, ker *obstaja veliko naÄinov, kako omreÅ¾je prepriÄati, da je vhodna slika maÄka*, vkljuÄno z nekaterimi, ki vizualno nimajo smisla. ÄŒeprav te slike vsebujejo veliko vzorcev, znaÄilnih za maÄko, jih niÄ ne omejuje, da bi bile vizualno prepoznavne.

Za izboljÅ¡anje rezultata lahko v funkcijo izgube dodamo Å¡e en Älen, imenovan **izguba variacije**. To je metrika, ki prikazuje, kako podobni so sosednji piksli slike. ZmanjÅ¡anje izgube variacije naredi sliko bolj gladko in odstrani Å¡um â€“ s tem razkrije bolj vizualno privlaÄne vzorce. Tukaj je primer takÅ¡nih "idealnih" slik, ki so z visoko verjetnostjo razvrÅ¡Äene kot maÄka in kot zebra:

![Idealna maÄka](../../../../../translated_images/ideal-cat.203dd4597643d6b0bd73038b87f9c0464322725e3a06ab145d25d4a861c70592.sl.png) | ![Idealna zebra](../../../../../translated_images/ideal-zebra.7f70e8b54ee15a7a314000bb5df38a6cfe086ea04d60df4d3ef313d046b98a2b.sl.png)
-----|-----
*Idealna maÄka* | *Idealna zebra*

Podoben pristop lahko uporabimo za izvajanje tako imenovanih **nasprotnih napadov** na nevronsko omreÅ¾je. Recimo, da Å¾elimo prevarati nevronsko omreÅ¾je in narediti, da pes izgleda kot maÄka. ÄŒe vzamemo sliko psa, ki jo omreÅ¾je prepozna kot psa, jo lahko nato nekoliko prilagodimo z uporabo optimizacije z gradientnim spustom, dokler omreÅ¾je ne zaÄne razvrÅ¡Äati slike kot maÄko:

![Slika psa](../../../../../translated_images/original-dog.8f68a67d2fe0911f33041c0f7fce8aa4ea919f9d3917ec4b468298522aeb6356.sl.png) | ![Slika psa, razvrÅ¡Äena kot maÄka](../../../../../translated_images/adversarial-dog.d9fc7773b0142b89752539bfbf884118de845b3851c5162146ea0b8809fc820f.sl.png)
-----|-----
*Izvirna slika psa* | *Slika psa, razvrÅ¡Äena kot maÄka*

Kodo za reproduciranje zgornjih rezultatov si oglejte v naslednji beleÅ¾nici:

* [Idealna in nasprotna maÄka - TensorFlow](../../../../../lessons/4-ComputerVision/08-TransferLearning/AdversarialCat_TF.ipynb)

## ZakljuÄek

S prenosom uÄenja lahko hitro sestavite klasifikator za nalogo razvrÅ¡Äanja prilagojenih objektov in doseÅ¾ete visoko natanÄnost. Vidite lahko, da bolj zapletene naloge, ki jih zdaj reÅ¡ujemo, zahtevajo veÄjo raÄunsko moÄ in jih ni mogoÄe enostavno reÅ¡iti na CPU. V naslednji enoti bomo poskusili uporabiti laÅ¾jo implementacijo za uÄenje istega modela z niÅ¾jimi raÄunalniÅ¡kimi viri, kar bo prineslo le nekoliko niÅ¾jo natanÄnost.

## ğŸš€ Izziv

V priloÅ¾enih beleÅ¾nicah so na dnu zapiski o tem, kako prenos znanja najbolje deluje s sorodnimi uÄnimi podatki (na primer nova vrsta Å¾ivali). Naredite nekaj eksperimentov s popolnoma novimi vrstami slik, da vidite, kako dobro ali slabo delujejo vaÅ¡i modeli za prenos znanja.

## [Kviz po predavanju](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Pregled in samostojno uÄenje

Preberite [TrainingTricks.md](TrainingTricks.md), da poglobite svoje znanje o drugih naÄinih uÄenja vaÅ¡ih modelov.

## [Naloga](lab/README.md)

V tem laboratoriju bomo uporabili resniÄni nabor podatkov [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) z 35 pasmami maÄk in psov ter zgradili klasifikator s prenosom uÄenja.

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve AI za prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni ÄloveÅ¡ki prevod. Ne prevzemamo odgovornosti za morebitne nesporazume ali napaÄne razlage, ki izhajajo iz uporabe tega prevoda.