# Avtoenkoderji

Pri treniranju CNN-jev je ena od teÅ¾av, da potrebujemo veliko oznaÄenih podatkov. Pri klasifikaciji slik moramo slike razvrstiti v razliÄne razrede, kar zahteva roÄno delo.

## [Predhodni kviz](https://ff-quizzes.netlify.app/en/ai/quiz/17)

Vendar pa bi morda Å¾eleli uporabiti surove (neoznaÄene) podatke za treniranje CNN ekstraktorjev znaÄilnosti, kar imenujemo **samonadzorovano uÄenje**. Namesto oznak bomo uporabili slike za treniranje kot vhod in izhod mreÅ¾e. Glavna ideja **avtoenkoderja** je, da imamo **kodirno mreÅ¾o**, ki vhodno sliko pretvori v nek **latentni prostor** (obiÄajno je to vektor manjÅ¡ih dimenzij), nato pa **dekodirno mreÅ¾o**, katere cilj je rekonstruirati izvirno sliko.

> âœ… [Avtoenkoder](https://wikipedia.org/wiki/Autoencoder) je "vrsta umetne nevronske mreÅ¾e, ki se uporablja za uÄenje uÄinkovitih kodiranj neoznaÄenih podatkov."

Ker treniramo avtoenkoder, da zajame Äim veÄ informacij iz izvirne slike za natanÄno rekonstrukcijo, mreÅ¾a poskuÅ¡a najti najboljÅ¡o **vgradnjo** vhodnih slik, da zajame njihov pomen.

![Diagram avtoenkoderja](../../../../../translated_images/sl/autoencoder_schema.5e6fc9ad98a5eb61.webp)

> Slika iz [Keras bloga](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenariji uporabe avtoenkoderjev

ÄŒeprav se zdi rekonstrukcija izvirnih slik sama po sebi neuporabna, obstaja nekaj scenarijev, kjer so avtoenkoderji Å¡e posebej koristni:

* **ZmanjÅ¡anje dimenzije slik za vizualizacijo** ali **treniranje vgradnje slik**. ObiÄajno avtoenkoderji dajejo boljÅ¡e rezultate kot PCA, ker upoÅ¡tevajo prostorsko naravo slik in hierarhiÄne znaÄilnosti.
* **Odstranjevanje Å¡uma**, tj. odstranjevanje Å¡uma s slike. Ker Å¡um vsebuje veliko nepotrebnih informacij, avtoenkoder ne more vsega vkljuÄiti v relativno majhen latentni prostor, zato zajame le pomemben del slike. Pri treniranju odstranjevalcev Å¡uma zaÄnemo z izvirnimi slikami in uporabimo slike z umetno dodanim Å¡umom kot vhod za avtoenkoder.
* **Super-resolucija**, poveÄanje loÄljivosti slike. ZaÄnemo z visokoloÄljivostnimi slikami in uporabimo sliko z niÅ¾jo loÄljivostjo kot vhod za avtoenkoder.
* **Generativni modeli**. Ko treniramo avtoenkoder, lahko dekodirni del uporabimo za ustvarjanje novih objektov, ki izhajajo iz nakljuÄnih latentnih vektorjev.

## Variacijski avtoenkoderji (VAE)

Tradicionalni avtoenkoderji nekako zmanjÅ¡ajo dimenzijo vhodnih podatkov in ugotovijo pomembne znaÄilnosti vhodnih slik. Vendar pa latentni vektorji pogosto nimajo veliko smisla. Z drugimi besedami, Äe vzamemo MNIST podatkovno zbirko kot primer, ugotoviti, katere Å¡tevilke ustrezajo razliÄnim latentnim vektorjem, ni enostavna naloga, ker bliÅ¾nji latentni vektorji ne ustrezajo nujno istim Å¡tevilkam.

Po drugi strani pa je za treniranje *generativnih* modelov bolje imeti neko razumevanje latentnega prostora. Ta ideja nas pripelje do **variacijskega avtoenkoderja** (VAE).

VAE je avtoenkoder, ki se nauÄi napovedovati *statistiÄno porazdelitev* latentnih parametrov, tako imenovano **latentno porazdelitev**. Na primer, morda Å¾elimo, da so latentni vektorji normalno porazdeljeni z nekim povpreÄjem z<sub>mean</sub> in standardnim odklonom z<sub>sigma</sub> (obe vrednosti sta vektorja neke dimenzionalnosti d). Kodirnik v VAE se nauÄi napovedovati te parametre, nato pa dekodirnik vzame nakljuÄni vektor iz te porazdelitve za rekonstrukcijo objekta.

Povzetek:

 * Iz vhodnega vektorja napovemo `z_mean` in `z_log_sigma` (namesto napovedovanja standardnega odklona napovemo njegov logaritem)
 * Vzamemo vzorec `sample` iz porazdelitve N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
 * Dekodirnik poskuÅ¡a dekodirati izvirno sliko z uporabo `sample` kot vhodnega vektorja

 <img src="../../../../../translated_images/sl/vae.464c465a5b6a9e25.webp" width="50%">

> Slika iz [tega bloga](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) avtorja Isaaka Dykemana

Variacijski avtoenkoderji uporabljajo kompleksno funkcijo izgube, ki je sestavljena iz dveh delov:

* **Izguba rekonstrukcije** je funkcija izgube, ki prikazuje, kako blizu je rekonstruirana slika ciljni (lahko je povpreÄna kvadratna napaka ali MSE). To je ista funkcija izgube kot pri obiÄajnih avtoenkoderjih.
* **KL izguba**, ki zagotavlja, da porazdelitev latentnih spremenljivk ostane blizu normalni porazdelitvi. Temelji na konceptu [Kullback-Leiblerjeve divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - merilu za oceno podobnosti dveh statistiÄnih porazdelitev.

Ena pomembna prednost VAE-jev je, da omogoÄajo relativno enostavno generiranje novih slik, ker vemo, iz katere porazdelitve vzeti latentne vektorje. Na primer, Äe treniramo VAE z 2D latentnim vektorjem na MNIST, lahko nato spreminjamo komponente latentnega vektorja, da dobimo razliÄne Å¡tevilke:

<img alt="vaemnist" src="../../../../../translated_images/sl/vaemnist.cab9e602dc08dc50.webp" width="50%"/>

> Slika avtorja [Dmitry Soshnikov](http://soshnikov.com)

Opazite, kako se slike prelivajo ena v drugo, ko zaÄnemo pridobivati latentne vektorje iz razliÄnih delov latentnega prostora parametrov. Ta prostor lahko vizualiziramo tudi v 2D:

<img alt="vaemnist cluster" src="../../../../../translated_images/sl/vaemnist-diag.694315f775d5d666.webp" width="50%"/> 

> Slika avtorja [Dmitry Soshnikov](http://soshnikov.com)

## âœï¸ Vaje: Avtoenkoderji

VeÄ o avtoenkoderjih se nauÄite v teh ustreznih zvezkih:

* [Avtoenkoderji v TensorFlow](AutoencodersTF.ipynb)
* [Avtoenkoderji v PyTorch](AutoEncodersPyTorch.ipynb)

## Lastnosti avtoenkoderjev

* **SpecifiÄni za podatke** - dobro delujejo le s tistimi vrstami slik, na katerih so bili trenirani. Na primer, Äe treniramo mreÅ¾o za super-resolucijo na roÅ¾ah, ne bo dobro delovala na portretih. To je zato, ker mreÅ¾a lahko ustvari sliko z viÅ¡jo loÄljivostjo tako, da vzame fine podrobnosti iz znaÄilnosti, nauÄenih iz podatkovne zbirke za treniranje.
* **Izgubni** - rekonstruirana slika ni enaka izvirni sliki. Narava izgube je doloÄena z *funkcijo izgube*, uporabljeno med treniranjem.
* Deluje na **neoznaÄenih podatkih**

## [Naknadni kviz](https://ff-quizzes.netlify.app/en/ai/quiz/18)

## ZakljuÄek

V tej lekciji ste se nauÄili o razliÄnih vrstah avtoenkoderjev, ki so na voljo AI znanstveniku. NauÄili ste se, kako jih zgraditi in kako jih uporabiti za rekonstrukcijo slik. Prav tako ste se nauÄili o VAE in kako ga uporabiti za generiranje novih slik.

## ğŸš€ Izziv

V tej lekciji ste se nauÄili o uporabi avtoenkoderjev za slike. Vendar pa jih je mogoÄe uporabiti tudi za glasbo! Oglejte si projekt Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), ki uporablja avtoenkoderje za uÄenje rekonstrukcije glasbe. Izvedite nekaj [eksperimentov](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) s to knjiÅ¾nico, da vidite, kaj lahko ustvarite.

## [Naknadni kviz](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## Pregled in samostojno uÄenje

Za referenco preberite veÄ o avtoenkoderjih v teh virih:

* [Gradnja avtoenkoderjev v Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blog objava na NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Razlaga variacijskih avtoenkoderjev](https://kvfrans.com/variational-autoencoders-explained/)
* [Pogojni variacijski avtoenkoderji](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Naloga

Na koncu [tega zvezka z uporabo TensorFlow](AutoencodersTF.ipynb) boste naÅ¡li 'nalogo' - uporabite jo kot svojo nalogo.

---

