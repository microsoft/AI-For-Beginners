<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b306c04f5337b6e7430e5c0b16bb5c0",
  "translation_date": "2025-08-25T22:32:01+00:00",
  "source_file": "lessons/4-ComputerVision/09-Autoencoders/README.md",
  "language_code": "sl"
}
-->
# Avtoenkoderji

Pri treniranju CNN-jev je ena izmed teÅ¾av, da potrebujemo veliko oznaÄenih podatkov. Pri klasifikaciji slik moramo slike razvrstiti v razliÄne razrede, kar zahteva roÄno delo.

## [Pre-uÄni kviz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/109)

Vendar pa bi morda Å¾eleli uporabiti surove (neoznaÄene) podatke za treniranje CNN ekstraktorjev znaÄilnosti, kar imenujemo **samostojno uÄenje**. Namesto oznak bomo uporabili slike za treniranje kot vhod in izhod mreÅ¾e. Glavna ideja **avtoenkoderja** je, da imamo **kodirno mreÅ¾o**, ki vhodno sliko pretvori v nek **latentni prostor** (obiÄajno je to vektor manjÅ¡ih dimenzij), nato pa **dekodirno mreÅ¾o**, katere cilj je rekonstruirati izvirno sliko.

> âœ… [Avtoenkoder](https://wikipedia.org/wiki/Autoencoder) je "vrsta umetne nevronske mreÅ¾e, ki se uporablja za uÄenje uÄinkovitega kodiranja neoznaÄenih podatkov."

Ker treniramo avtoenkoder, da zajame Äim veÄ informacij iz izvirne slike za natanÄno rekonstrukcijo, mreÅ¾a poskuÅ¡a najti najboljÅ¡o **vgradnjo** vhodnih slik, da zajame njihov pomen.

![Diagram avtoenkoderja](../../../../../translated_images/autoencoder_schema.5e6fc9ad98a5eb6197f3513cf3baf4dfbe1389a6ae74daebda64de9f1c99f142.sl.jpg)

> Slika iz [Keras bloga](https://blog.keras.io/building-autoencoders-in-keras.html)

## Scenariji uporabe avtoenkoderjev

ÄŒeprav rekonstrukcija izvirnih slik sama po sebi morda ne zveni uporabno, obstaja nekaj scenarijev, kjer so avtoenkoderji Å¡e posebej koristni:

* **ZmanjÅ¡anje dimenzije slik za vizualizacijo** ali **treniranje vgradnje slik**. ObiÄajno avtoenkoderji dajejo boljÅ¡e rezultate kot PCA, ker upoÅ¡tevajo prostorsko naravo slik in hierarhiÄne znaÄilnosti.
* **Odstranjevanje Å¡uma**, tj. odstranjevanje Å¡uma s slike. Ker Å¡um vsebuje veliko nepotrebnih informacij, avtoenkoder ne more vsega vkljuÄiti v relativno majhen latentni prostor, zato zajame le pomemben del slike. Pri treniranju odstranjevalcev Å¡uma zaÄnemo z izvirnimi slikami in uporabimo slike z umetno dodanim Å¡umom kot vhod za avtoenkoder.
* **Super-resolucija**, poveÄanje loÄljivosti slike. ZaÄnemo z visokoloÄljivostnimi slikami in uporabimo sliko z niÅ¾jo loÄljivostjo kot vhod za avtoenkoder.
* **Generativni modeli**. Ko treniramo avtoenkoder, lahko dekodirni del uporabimo za ustvarjanje novih objektov, ki izhajajo iz nakljuÄnih latentnih vektorjev.

## Variacijski avtoenkoderji (VAE)

Tradicionalni avtoenkoderji nekako zmanjÅ¡ajo dimenzijo vhodnih podatkov in ugotovijo pomembne znaÄilnosti vhodnih slik. Vendar pa latentni vektorji pogosto nimajo veliko smisla. Z drugimi besedami, Äe vzamemo MNIST podatkovno zbirko kot primer, ugotoviti, katere Å¡tevilke ustrezajo razliÄnim latentnim vektorjem, ni enostavna naloga, saj bliÅ¾nji latentni vektorji ne ustrezajo nujno istim Å¡tevilkam.

Po drugi strani pa je za treniranje *generativnih* modelov bolje imeti neko razumevanje latentnega prostora. Ta ideja nas pripelje do **variacijskega avtoenkoderja** (VAE).

VAE je avtoenkoder, ki se nauÄi napovedovati *statistiÄno porazdelitev* latentnih parametrov, tako imenovano **latentno porazdelitev**. Na primer, morda Å¾elimo, da so latentni vektorji normalno porazdeljeni z nekim povpreÄjem z<sub>mean</sub> in standardnim odklonom z<sub>sigma</sub> (obe vrednosti sta vektorja neke dimenzionalnosti d). Kodirnik v VAE se nauÄi napovedovati te parametre, nato pa dekodirnik vzame nakljuÄni vektor iz te porazdelitve za rekonstrukcijo objekta.

Povzetek:

* Iz vhodnega vektorja napovemo `z_mean` in `z_log_sigma` (namesto da napovemo standardni odklon, napovemo njegov logaritem)
* Vzamemo vzorec `sample` iz porazdelitve N(z<sub>mean</sub>,exp(z<sub>log\_sigma</sub>))
* Dekodirnik poskuÅ¡a dekodirati izvirno sliko z uporabo `sample` kot vhodnega vektorja

<img src="images/vae.png" width="50%">

> Slika iz [tega bloga](https://ijdykeman.github.io/ml/2016/12/21/cvae.html) avtorja Isaaka Dykemana

Variacijski avtoenkoderji uporabljajo kompleksno funkcijo izgube, ki je sestavljena iz dveh delov:

* **Izguba rekonstrukcije** je funkcija izgube, ki prikazuje, kako blizu je rekonstruirana slika ciljni (lahko je povpreÄna kvadratna napaka ali MSE). To je ista funkcija izgube kot pri obiÄajnih avtoenkoderjih.
* **KL izguba**, ki zagotavlja, da porazdelitev latentnih spremenljivk ostane blizu normalni porazdelitvi. Temelji na konceptu [Kullback-Leiblerjeve divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) - merilu za oceno podobnosti dveh statistiÄnih porazdelitev.

Ena pomembna prednost VAE-jev je, da omogoÄajo relativno enostavno generiranje novih slik, ker vemo, iz katere porazdelitve vzeti latentne vektorje. Na primer, Äe treniramo VAE z 2D latentnim vektorjem na MNIST, lahko nato spreminjamo komponente latentnega vektorja, da dobimo razliÄne Å¡tevilke:

<img alt="vaemnist" src="images/vaemnist.png" width="50%"/>

> Slika avtorja [Dmitry Soshnikov](http://soshnikov.com)

Opazite, kako se slike prelivajo ena v drugo, ko zaÄnemo jemati latentne vektorje iz razliÄnih delov latentnega prostora parametrov. Ta prostor lahko vizualiziramo tudi v 2D:

<img alt="vaemnist cluster" src="images/vaemnist-diag.png" width="50%"/> 

> Slika avtorja [Dmitry Soshnikov](http://soshnikov.com)

## âœï¸ Vaje: Avtoenkoderji

VeÄ o avtoenkoderjih se nauÄite v teh priloÅ¾enih zvezkih:

* [Avtoenkoderji v TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb)
* [Avtoenkoderji v PyTorch](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoEncodersPyTorch.ipynb)

## Lastnosti avtoenkoderjev

* **SpecifiÄni za podatke** - dobro delujejo le s tipom slik, na katerih so bili trenirani. Na primer, Äe treniramo mreÅ¾o za super-resolucijo na roÅ¾ah, ne bo dobro delovala na portretih. To je zato, ker mreÅ¾a lahko ustvari sliko z viÅ¡jo loÄljivostjo tako, da vzame fine podrobnosti iz znaÄilnosti, nauÄenih iz podatkovne zbirke za treniranje.
* **Izgubni** - rekonstruirana slika ni enaka izvirni sliki. Narava izgube je doloÄena z *funkcijo izgube*, uporabljeno med treniranjem.
* Deluje na **neoznaÄenih podatkih**

## [Post-uÄni kviz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/209)

## ZakljuÄek

V tej lekciji ste se nauÄili o razliÄnih vrstah avtoenkoderjev, ki so na voljo AI znanstveniku. NauÄili ste se, kako jih zgraditi in kako jih uporabiti za rekonstrukcijo slik. Prav tako ste se nauÄili o VAE in kako ga uporabiti za generiranje novih slik.

## ğŸš€ Izziv

V tej lekciji ste se nauÄili o uporabi avtoenkoderjev za slike. Vendar pa jih lahko uporabimo tudi za glasbo! Oglejte si projekt Magenta [MusicVAE](https://magenta.tensorflow.org/music-vae), ki uporablja avtoenkoderje za uÄenje rekonstrukcije glasbe. Izvedite nekaj [eksperimentov](https://colab.research.google.com/github/magenta/magenta-demos/blob/master/colab-notebooks/Multitrack_MusicVAE.ipynb) s to knjiÅ¾nico, da vidite, kaj lahko ustvarite.

## [Post-uÄni kviz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/208)

## Pregled in samostojno uÄenje

Za referenco preberite veÄ o avtoenkoderjih v teh virih:

* [Gradnja avtoenkoderjev v Keras](https://blog.keras.io/building-autoencoders-in-keras.html)
* [Blog objava na NeuroHive](https://neurohive.io/ru/osnovy-data-science/variacionnyj-avtojenkoder-vae/)
* [Razlaga variacijskih avtoenkoderjev](https://kvfrans.com/variational-autoencoders-explained/)
* [Pogojni variacijski avtoenkoderji](https://ijdykeman.github.io/ml/2016/12/21/cvae.html)

## Naloga

Na koncu [tega zvezka z uporabo TensorFlow](../../../../../lessons/4-ComputerVision/09-Autoencoders/AutoencodersTF.ipynb) boste naÅ¡li 'nalogo' - uporabite jo kot svojo nalogo.

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve AI za prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni ÄloveÅ¡ki prevod. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napaÄne razlage, ki bi nastale zaradi uporabe tega prevoda.