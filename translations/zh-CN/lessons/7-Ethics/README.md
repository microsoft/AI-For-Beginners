# 伦理与负责任的人工智能

你已经快完成这门课程了，希望到现在为止，你已经清楚地了解到人工智能是基于一系列正式的数学方法，这些方法使我们能够发现数据中的关系，并训练模型以复制人类行为的某些方面。在当下，我们认为人工智能是一种非常强大的工具，可以从数据中提取模式，并将这些模式应用于解决新的问题。

## [课前测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

然而，在科幻作品中，我们经常看到人工智能对人类构成威胁的故事。这些故事通常围绕某种人工智能叛变展开，即人工智能决定与人类对抗。这暗示人工智能具有某种情感或能够做出开发者未曾预料的决定。

我们在这门课程中学习的人工智能仅仅是大型矩阵运算。它是一种非常强大的工具，可以帮助我们解决问题，但和其他任何强大的工具一样——它既可以被用于好的目的，也可以被用于坏的目的。重要的是，它可能会被*滥用*。

## 负责任人工智能的原则

为了避免人工智能的意外或故意滥用，微软提出了重要的[负责任人工智能原则](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste)。以下概念是这些原则的基础：

* **公平性**与*模型偏差*这一重要问题相关，这种偏差可能是由于使用了有偏的数据进行训练。例如，当我们试图预测一个人获得软件开发职位的概率时，模型可能会更倾向于男性——仅仅因为训练数据集可能偏向男性群体。我们需要仔细平衡训练数据并调查模型以避免偏差，并确保模型考虑到更相关的特征。
* **可靠性与安全性**。人工智能模型本质上可能会犯错。神经网络返回的是概率，我们需要在做决策时考虑到这一点。每个模型都有一定的精确度和召回率，我们需要理解这些指标，以防止错误建议可能造成的伤害。
* **隐私与安全性**具有一些人工智能特定的影响。例如，当我们使用某些数据训练模型时，这些数据会以某种方式“整合”到模型中。一方面，这提高了安全性和隐私性，另一方面，我们需要记住模型是基于哪些数据训练的。
* **包容性**意味着我们不是在构建人工智能来取代人类，而是为了增强人类的能力，使我们的工作更具创造性。这也与公平性相关，因为在处理代表性不足的群体时，我们收集的大多数数据集可能会存在偏差，我们需要确保这些群体被包括在内并被人工智能正确处理。
* **透明性**。这包括确保我们始终明确人工智能的使用。此外，在可能的情况下，我们希望使用*可解释*的人工智能系统。
* **问责性**。当人工智能模型做出某些决定时，责任归属并不总是清晰的。我们需要确保理解人工智能决策的责任归属。在大多数情况下，我们希望将人类纳入重要决策的环节，以便实际的人类承担责任。

## 负责任人工智能的工具

微软开发了[负责任人工智能工具箱](https://github.com/microsoft/responsible-ai-toolbox)，其中包含一系列工具：

* 可解释性仪表板 (InterpretML)
* 公平性仪表板 (FairLearn)
* 错误分析仪表板
* 负责任人工智能仪表板，包括：

   - EconML - 用于因果分析的工具，专注于假设性问题
   - DiCE - 用于反事实分析的工具，允许你查看需要更改哪些特征以影响模型的决策

关于人工智能伦理的更多信息，请访问机器学习课程中的[这一课](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste)，其中包括相关作业。

## 复习与自学

通过这个[学习路径](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste)了解更多关于负责任人工智能的内容。

## [课后测验](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**免责声明**：  
本文档使用AI翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。应以原文档的原始语言版本为权威来源。对于关键信息，建议使用专业人工翻译。我们对因使用此翻译而引起的任何误解或误读不承担责任。