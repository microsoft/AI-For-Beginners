# Mechanizmy uwagi i modele Transformer

## [Quiz przed wykadem](https://ff-quizzes.netlify.app/en/ai/quiz/35)

Jednym z najwa偶niejszych problem贸w w dziedzinie NLP jest **tumaczenie maszynowe**, kluczowe zadanie, kt贸re stanowi podstaw narzdzi takich jak Google Translate. W tej sekcji skupimy si na tumaczeniu maszynowym, a bardziej og贸lnie na ka偶dym zadaniu typu *sequence-to-sequence* (nazywanym r贸wnie偶 **transdukcj zda**).

W przypadku RNN, zadania sequence-to-sequence s realizowane za pomoc dw贸ch sieci rekurencyjnych, gdzie jedna sie, **enkoder**, przeksztaca sekwencj wejciow w stan ukryty, a druga sie, **dekoder**, rozwija ten stan ukryty w przetumaczony wynik. Istnieje kilka problem贸w zwizanych z tym podejciem:

* Kocowy stan sieci enkodera ma trudnoci z zapamitaniem pocztku zdania, co prowadzi do niskiej jakoci modelu dla dugich zda.
* Wszystkie sowa w sekwencji maj taki sam wpyw na wynik. W rzeczywistoci jednak konkretne sowa w sekwencji wejciowej czsto maj wikszy wpyw na sekwencyjne wyniki ni偶 inne.

**Mechanizmy uwagi** umo偶liwiaj wa偶enie kontekstowego wpywu ka偶dego wektora wejciowego na ka偶d prognoz wyjciow RNN. Implementuje si to poprzez tworzenie skr贸t贸w midzy stanami porednimi wejciowego RNN a wyjciowego RNN. W ten spos贸b, generujc symbol wyjciowy y<sub>t</sub>, uwzgldniamy wszystkie stany ukryte wejcia h<sub>i</sub>, z r贸偶nymi wsp贸czynnikami wagowymi &alpha;<sub>t,i</sub>.

![Obraz przedstawiajcy model enkoder/dekoder z warstw uwagi addytywnej](../../../../../translated_images/pl/encoder-decoder-attention.7a726296894fb567.webp)

> Model enkoder-dekoder z mechanizmem uwagi addytywnej w [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf), cytowany z [tego wpisu na blogu](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)

Macierz uwagi {&alpha;<sub>i,j</sub>} reprezentuje stopie, w jakim okrelone sowa wejciowe wpywaj na generowanie danego sowa w sekwencji wyjciowej. Poni偶ej znajduje si przykad takiej macierzy:

![Obraz przedstawiajcy przykadowe wyr贸wnanie znalezione przez RNNsearch-50, zaczerpnite z Bahdanau - arviz.org](../../../../../translated_images/pl/bahdanau-fig3.09ba2d37f202a6af.webp)

> Rysunek z [Bahdanau et al., 2015](https://arxiv.org/pdf/1409.0473.pdf) (Fig.3)

Mechanizmy uwagi s odpowiedzialne za du偶 cz obecnego lub bliskiego obecnemu stanu sztuki w NLP. Dodanie uwagi znacznie zwiksza jednak liczb parametr贸w modelu, co prowadzi do problem贸w ze skalowaniem RNN. Kluczowym ograniczeniem skalowania RNN jest to, 偶e rekurencyjny charakter modeli utrudnia grupowanie i r贸wnolege trenowanie. W RNN ka偶dy element sekwencji musi by przetwarzany w kolejnoci sekwencyjnej, co oznacza, 偶e nie mo偶na go atwo zr贸wnolegli.

![Enkoder Dekoder z Uwagi](../../../../../lessons/5-NLP/18-Transformers/images/EncDecAttention.gif)

> Rysunek z [Bloga Google](https://research.googleblog.com/2016/09/a-neural-network-for-machine.html)

Zastosowanie mechanizm贸w uwagi w poczeniu z tym ograniczeniem doprowadzio do powstania obecnych modeli Transformer, takich jak BERT czy Open-GPT3, kt贸re znamy i u偶ywamy dzisiaj.

## Modele Transformer

Jednym z g贸wnych pomys贸w stojcych za modelami Transformer jest unikanie sekwencyjnego charakteru RNN i stworzenie modelu, kt贸ry mo偶na zr贸wnolegli podczas treningu. Osiga si to poprzez wdro偶enie dw贸ch pomys贸w:

* kodowanie pozycji
* u偶ycie mechanizmu samo-uwagi do wychwytywania wzorc贸w zamiast RNN (lub CNN) (dlatego artyku wprowadzajcy modele Transformer nosi tytu *[Attention is all you need](https://arxiv.org/abs/1706.03762)*)

### Kodowanie/Osadzanie Pozycji

Pomys kodowania pozycji jest nastpujcy:  
1. W przypadku RNN wzgldna pozycja token贸w jest reprezentowana przez liczb krok贸w, wic nie musi by jawnie reprezentowana.  
2. Jednak po przejciu na mechanizm uwagi musimy zna wzgldne pozycje token贸w w sekwencji.  
3. Aby uzyska kodowanie pozycji, uzupeniamy nasz sekwencj token贸w o sekwencj pozycji token贸w w sekwencji (np. sekwencj liczb 0,1, ...).  
4. Nastpnie mieszamy pozycj tokenu z wektorem osadzania tokenu. Aby przeksztaci pozycj (liczb cakowit) w wektor, mo偶emy u偶y r贸偶nych podej:

* Osadzanie uczone, podobne do osadzania token贸w. To podejcie rozwa偶amy tutaj. Nakadamy warstwy osadzania zar贸wno na tokeny, jak i ich pozycje, uzyskujc wektory osadzania o tych samych wymiarach, kt贸re nastpnie dodajemy do siebie.
* Funkcja kodowania pozycji staej, jak zaproponowano w oryginalnym artykule.

<img src="../../../../../translated_images/pl/pos-embedding.e41ce9b6cf6078af.webp" width="50%"/>

> Obraz autorstwa autora

Wynik, kt贸ry uzyskujemy dziki osadzaniu pozycji, osadza zar贸wno oryginalny token, jak i jego pozycj w sekwencji.

### Mechanizm Samo-Uwagi z Wieloma Gowami

Nastpnie musimy wychwyci pewne wzorce w naszej sekwencji. Aby to zrobi, modele Transformer u偶ywaj mechanizmu **samo-uwagi**, kt贸ry w zasadzie jest uwag zastosowan do tej samej sekwencji jako wejcie i wyjcie. Zastosowanie samo-uwagi pozwala nam uwzgldni **kontekst** w zdaniu i zobaczy, kt贸re sowa s ze sob powizane. Na przykad pozwala nam zobaczy, kt贸re sowa s odniesieniami do innych, takich jak *to*, oraz uwzgldni kontekst:

![](../../../../../translated_images/pl/CoreferenceResolution.861924d6d384a7d6.webp)

> Obraz z [Bloga Google](https://research.googleblog.com/2017/08/transformer-novel-neural-network.html)

W modelach Transformer u偶ywamy **uwagi z wieloma gowami**, aby da sieci mo偶liwo wychwytywania r贸偶nych typ贸w zale偶noci, np. relacji midzy sowami dugoterminowych vs. kr贸tkoterminowych, wsp贸odniesie vs. czego innego itd.

[Notebook TensorFlow](TransformersTF.ipynb) zawiera wicej szczeg贸贸w na temat implementacji warstw Transformer.

### Uwagi Enkoder-Dekoder

W modelach Transformer uwaga jest u偶ywana w dw贸ch miejscach:

* Do wychwytywania wzorc贸w w tekcie wejciowym za pomoc samo-uwagi
* Do tumaczenia sekwencji - jest to warstwa uwagi midzy enkoderem a dekoderem.

Uwagi enkoder-dekoder s bardzo podobne do mechanizmu uwagi u偶ywanego w RNN, jak opisano na pocztku tej sekcji. Ten animowany diagram wyjania rol uwagi enkoder-dekoder.

![Animowany GIF pokazujcy, jak wykonywane s oceny w modelach Transformer.](../../../../../lessons/5-NLP/18-Transformers/images/transformer-animated-explanation.gif)

Poniewa偶 ka偶da pozycja wejciowa jest mapowana niezale偶nie na ka偶d pozycj wyjciow, modele Transformer mog by lepiej zr贸wnoleglone ni偶 RNN, co umo偶liwia tworzenie znacznie wikszych i bardziej ekspresyjnych modeli jzykowych. Ka偶da gowa uwagi mo偶e by u偶ywana do nauki r贸偶nych relacji midzy sowami, co poprawia zadania przetwarzania jzyka naturalnego.

## BERT

**BERT** (Bidirectional Encoder Representations from Transformers) to bardzo du偶a wielowarstwowa sie Transformer z 12 warstwami dla *BERT-base* i 24 dla *BERT-large*. Model jest najpierw wstpnie trenowany na du偶ym korpusie danych tekstowych (Wikipedia + ksi偶ki) za pomoc treningu niesuperwizowanego (przewidywanie zamaskowanych s贸w w zdaniu). Podczas wstpnego treningu model przyswaja znaczce poziomy zrozumienia jzyka, kt贸re mo偶na nastpnie wykorzysta z innymi zestawami danych za pomoc dostrajania. Ten proces nazywa si **transfer learning**.

![obrazek z http://jalammar.github.io/illustrated-bert/](../../../../../translated_images/pl/jalammarBERT-language-modeling-masked-lm.34f113ea5fec4362.webp)

> 殴r贸do obrazu [tutaj](http://jalammar.github.io/illustrated-bert/)

## 锔 wiczenia: Transformers

Kontynuuj nauk w poni偶szych notebookach:

* [Transformers w PyTorch](TransformersPyTorch.ipynb)
* [Transformers w TensorFlow](TransformersTF.ipynb)

## Podsumowanie

W tej lekcji dowiedziae si o modelach Transformer i mechanizmach uwagi, kt贸re s niezbdnymi narzdziami w zestawie narzdzi NLP. Istnieje wiele wariacji architektur Transformer, w tym BERT, DistilBERT, BigBird, OpenGPT3 i inne, kt贸re mo偶na dostraja. Pakiet [HuggingFace](https://github.com/huggingface/) zapewnia repozytorium do trenowania wielu z tych architektur zar贸wno w PyTorch, jak i TensorFlow.

##  Wyzwanie

## [Quiz po wykadzie](https://ff-quizzes.netlify.app/en/ai/quiz/36)

## Przegld i samodzielna nauka

* [Wpis na blogu](https://mchromiak.github.io/articles/2017/Sep/12/Transformer-Attention-is-all-you-need/), wyjaniajcy klasyczny artyku [Attention is all you need](https://arxiv.org/abs/1706.03762) o modelach Transformer.
* [Seria wpis贸w na blogu](https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452) o modelach Transformer, wyjaniajca szczeg贸y architektury.

## [Zadanie](assignment.md)

---

