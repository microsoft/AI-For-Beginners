# Modelowanie jzyka

Semantyczne osadzenia, takie jak Word2Vec i GloVe, s w rzeczywistoci pierwszym krokiem w kierunku **modelowania jzyka** - tworzenia modeli, kt贸re w pewien spos贸b *rozumiej* (lub *reprezentuj*) natur jzyka.

## [Quiz przed wykadem](https://ff-quizzes.netlify.app/en/ai/quiz/29)

G贸wna idea modelowania jzyka polega na trenowaniu modeli na nieoznaczonych zbiorach danych w spos贸b nienadzorowany. Jest to istotne, poniewa偶 mamy ogromne iloci nieoznaczonego tekstu, podczas gdy ilo oznaczonego tekstu zawsze bdzie ograniczona przez wysiek, jaki mo偶emy powici na jego oznaczanie. Najczciej mo偶emy budowa modele jzykowe, kt贸re potrafi **przewidywa brakujce sowa** w tekcie, poniewa偶 atwo jest zamaskowa losowe sowo w tekcie i u偶y go jako pr贸bki treningowej.

## Trenowanie osadze

W naszych wczeniejszych przykadach korzystalimy z wstpnie wytrenowanych semantycznych osadze, ale warto zobaczy, jak mo偶na je trenowa. Istnieje kilka mo偶liwych podej:

* **Modelowanie jzyka N-Gram**, gdzie przewidujemy token, patrzc na N poprzednich token贸w (N-gram).
* **Continuous Bag-of-Words** (CBoW), gdzie przewidujemy rodkowy token $W_0$ w sekwencji token贸w $W_{-N}$, ..., $W_N$.
* **Skip-gram**, gdzie przewidujemy zestaw ssiednich token贸w {$W_{-N},\dots, W_{-1}, W_1,\dots, W_N$} na podstawie rodkowego tokena $W_0$.

![obraz z artykuu o konwersji s贸w na wektory](../../../../../translated_images/pl/example-algorithms-for-converting-words-to-vectors.fbe9207a726922f6.webp)

> Obraz z [tego artykuu](https://arxiv.org/pdf/1301.3781.pdf)

## 锔 Przykadowe notatniki: Trenowanie modelu CBoW

Kontynuuj nauk w poni偶szych notatnikach:

* [Trenowanie CBoW Word2Vec z TensorFlow](CBoW-TF.ipynb)
* [Trenowanie CBoW Word2Vec z PyTorch](CBoW-PyTorch.ipynb)

## Podsumowanie

W poprzedniej lekcji zobaczylimy, 偶e osadzenia s贸w dziaaj jak magia! Teraz wiemy, 偶e trenowanie osadze s贸w nie jest bardzo skomplikowanym zadaniem i powinnimy by w stanie wytrenowa wasne osadzenia s贸w dla tekst贸w specyficznych dla danej dziedziny, jeli zajdzie taka potrzeba.

## [Quiz po wykadzie](https://ff-quizzes.netlify.app/en/ai/quiz/30)

## Przegld i samodzielna nauka

* [Oficjalny samouczek PyTorch dotyczcy modelowania jzyka](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).
* [Oficjalny samouczek TensorFlow dotyczcy trenowania modelu Word2Vec](https://www.TensorFlow.org/tutorials/text/word2vec).
* Korzystanie z frameworka **gensim** do trenowania najczciej u偶ywanych osadze w kilku liniach kodu jest opisane [w tej dokumentacji](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html).

##  [Zadanie: Wytrenuj model Skip-Gram](lab/README.md)

W laboratorium zachcamy Ci do zmodyfikowania kodu z tej lekcji, aby wytrenowa model Skip-Gram zamiast CBoW. [Przeczytaj szczeg贸y](lab/README.md)

---

