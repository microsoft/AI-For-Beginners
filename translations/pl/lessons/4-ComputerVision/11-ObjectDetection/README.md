<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "d85c8b08f6d1b48fd7f35b99f93c1138",
  "translation_date": "2025-08-24T10:28:34+00:00",
  "source_file": "lessons/4-ComputerVision/11-ObjectDetection/README.md",
  "language_code": "pl"
}
-->
# Wykrywanie ObiektÃ³w

Modele klasyfikacji obrazÃ³w, ktÃ³re omawialiÅ›my do tej pory, przyjmowaÅ‚y obraz i zwracaÅ‚y wynik kategoryczny, na przykÅ‚ad klasÄ™ 'liczba' w problemie MNIST. Jednak w wielu przypadkach nie wystarczy wiedzieÄ‡, Å¼e na zdjÄ™ciu znajdujÄ… siÄ™ obiekty â€“ chcemy rÃ³wnieÅ¼ okreÅ›liÄ‡ ich dokÅ‚adne poÅ‚oÅ¼enie. Na tym wÅ‚aÅ›nie polega **wykrywanie obiektÃ³w**.

## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ai/quiz/21)

![Wykrywanie ObiektÃ³w](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/Screen_Shot_2016-11-17_at_11.14.54_AM.png)

> Obraz z [strony YOLO v2](https://pjreddie.com/darknet/yolov2/)

## Naiwne podejÅ›cie do wykrywania obiektÃ³w

ZaÅ‚Ã³Å¼my, Å¼e chcemy znaleÅºÄ‡ kota na zdjÄ™ciu. Bardzo naiwne podejÅ›cie do wykrywania obiektÃ³w mogÅ‚oby wyglÄ…daÄ‡ nastÄ™pujÄ…co:

1. Podziel obraz na wiele kafelkÃ³w.
2. PrzeprowadÅº klasyfikacjÄ™ obrazu dla kaÅ¼dego kafelka.
3. Kafelki, ktÃ³re dajÄ… wystarczajÄ…co wysokÄ… aktywacjÄ™, moÅ¼na uznaÄ‡ za zawierajÄ…ce poszukiwany obiekt.

![Naiwne wykrywanie obiektÃ³w](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/naive-detection.png)

> *Obraz z [notatnika Ä‡wiczeniowego](../../../../../lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection-TF.ipynb)*

Jednak takie podejÅ›cie jest dalekie od ideaÅ‚u, poniewaÅ¼ pozwala algorytmowi na bardzo niedokÅ‚adne okreÅ›lenie granic obiektu. Aby uzyskaÄ‡ bardziej precyzyjne lokalizacje, musimy zastosowaÄ‡ pewien rodzaj **regresji**, aby przewidzieÄ‡ wspÃ³Å‚rzÄ™dne granic obiektÃ³w â€“ a do tego potrzebne sÄ… odpowiednie zestawy danych.

## Regresja w wykrywaniu obiektÃ³w

[Ten wpis na blogu](https://towardsdatascience.com/object-detection-with-neural-networks-a4e2c46b4491) oferuje Å›wietne wprowadzenie do wykrywania ksztaÅ‚tÃ³w.

## Zestawy danych do wykrywania obiektÃ³w

MoÅ¼esz natknÄ…Ä‡ siÄ™ na nastÄ™pujÄ…ce zestawy danych do tego zadania:

* [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/) â€“ 20 klas
* [COCO](http://cocodataset.org/#home) â€“ Common Objects in Context. 80 klas, granice obiektÃ³w i maski segmentacyjne

![COCO](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/coco-examples.jpg)

## Metryki wykrywania obiektÃ³w

### Intersection over Union

Podczas gdy w klasyfikacji obrazÃ³w Å‚atwo jest zmierzyÄ‡, jak dobrze dziaÅ‚a algorytm, w wykrywaniu obiektÃ³w musimy oceniÄ‡ zarÃ³wno poprawnoÅ›Ä‡ klasy, jak i precyzjÄ™ lokalizacji przewidzianych granic obiektÃ³w. Do tego ostatniego uÅ¼ywamy metryki zwanej **Intersection over Union** (IoU), ktÃ³ra mierzy, jak dobrze dwa obszary (lub dwie dowolne figury) siÄ™ pokrywajÄ….

![IoU](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/iou_equation.png)

> *Rysunek 2 z [tego Å›wietnego wpisu na blogu o IoU](https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/)*

Idea jest prosta â€“ dzielimy obszar przeciÄ™cia dwÃ³ch figur przez obszar ich unii. Dla dwÃ³ch identycznych obszarÃ³w IoU wynosi 1, a dla caÅ‚kowicie rozÅ‚Ä…cznych obszarÃ³w wynosi 0. W innych przypadkach wartoÅ›Ä‡ IoU mieÅ›ci siÄ™ w przedziale od 0 do 1. Zazwyczaj bierzemy pod uwagÄ™ tylko te granice obiektÃ³w, dla ktÃ³rych IoU przekracza okreÅ›lonÄ… wartoÅ›Ä‡.

### Åšrednia precyzja (Average Precision)

ZaÅ‚Ã³Å¼my, Å¼e chcemy zmierzyÄ‡, jak dobrze rozpoznawana jest dana klasa obiektÃ³w $C$. Do tego celu uÅ¼ywamy metryki **Average Precision**, ktÃ³ra jest obliczana w nastÄ™pujÄ…cy sposÃ³b:

1. RozwaÅ¼ krzywÄ… Precision-Recall, ktÃ³ra pokazuje dokÅ‚adnoÅ›Ä‡ w zaleÅ¼noÅ›ci od wartoÅ›ci progu detekcji (od 0 do 1).
2. W zaleÅ¼noÅ›ci od progu, wykryjemy wiÄ™cej lub mniej obiektÃ³w na obrazie, co da rÃ³Å¼ne wartoÅ›ci precyzji i czuÅ‚oÅ›ci.
3. Krzywa wyglÄ…da tak:

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecall.png"/>

> *Obraz z [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

Åšrednia precyzja dla danej klasy $C$ to pole pod tÄ… krzywÄ…. DokÅ‚adniej, oÅ› Recall jest zazwyczaj podzielona na 10 czÄ™Å›ci, a precyzja jest uÅ›redniana dla wszystkich tych punktÃ³w:

$$
AP = {1\over11}\sum_{i=0}^{10}\mbox{Precision}(\mbox{Recall}={i\over10})
$$

### AP i IoU

RozwaÅ¼amy tylko te detekcje, dla ktÃ³rych IoU przekracza okreÅ›lonÄ… wartoÅ›Ä‡. Na przykÅ‚ad w zestawie danych PASCAL VOC zazwyczaj $\mbox{IoU Threshold} = 0.5$, podczas gdy w COCO AP jest mierzony dla rÃ³Å¼nych wartoÅ›ci $\mbox{IoU Threshold}$.

<img src="https://github.com/shwars/NeuroWorkshop/raw/master/images/ObjDetectionPrecisionRecallIoU.png"/>

> *Obraz z [NeuroWorkshop](http://github.com/shwars/NeuroWorkshop)*

### Åšrednia Å›rednia precyzja â€“ mAP

GÅ‚Ã³wna metryka dla wykrywania obiektÃ³w nazywa siÄ™ **Mean Average Precision**, czyli **mAP**. Jest to wartoÅ›Ä‡ Average Precision, uÅ›redniona dla wszystkich klas obiektÃ³w, a czasami takÅ¼e dla rÃ³Å¼nych wartoÅ›ci $\mbox{IoU Threshold}$. SzczegÃ³Å‚owy opis procesu obliczania **mAP** znajdziesz
[w tym wpisie na blogu](https://medium.com/@timothycarlen/understanding-the-map-evaluation-metric-for-object-detection-a07fe6962cf3)), a takÅ¼e [tutaj z przykÅ‚adami kodu](https://gist.github.com/tarlen5/008809c3decf19313de216b9208f3734).

## RÃ³Å¼ne podejÅ›cia do wykrywania obiektÃ³w

IstniejÄ… dwie gÅ‚Ã³wne klasy algorytmÃ³w wykrywania obiektÃ³w:

* **Sieci propozycji regionÃ³w** (R-CNN, Fast R-CNN, Faster R-CNN). GÅ‚Ã³wna idea polega na generowaniu **RegionÃ³w Zainteresowania** (ROI) i uruchamianiu CNN na nich, szukajÄ…c maksymalnej aktywacji. Jest to trochÄ™ podobne do naiwnego podejÅ›cia, z wyjÄ…tkiem tego, Å¼e ROI sÄ… generowane w bardziej inteligentny sposÃ³b. Jednym z gÅ‚Ã³wnych minusÃ³w takich metod jest ich wolne dziaÅ‚anie, poniewaÅ¼ wymagajÄ… wielu przejÅ›Ä‡ klasyfikatora CNN przez obraz.
* Metody **jednoprzebiegowe** (YOLO, SSD, RetinaNet). W tych architekturach projektujemy sieÄ‡ tak, aby przewidywaÅ‚a zarÃ³wno klasy, jak i ROI w jednym przebiegu.

### R-CNN: Region-Based CNN

[R-CNN](http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf) uÅ¼ywa [Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) do generowania hierarchicznej struktury regionÃ³w ROI, ktÃ³re nastÄ™pnie sÄ… przepuszczane przez ekstraktory cech CNN i klasyfikatory SVM, aby okreÅ›liÄ‡ klasÄ™ obiektu, oraz regresjÄ™ liniowÄ…, aby okreÅ›liÄ‡ wspÃ³Å‚rzÄ™dne *granicy obiektu*. [Oficjalny artykuÅ‚](https://arxiv.org/pdf/1506.01497v1.pdf)

![RCNN](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/rcnn1.png)

> *Obraz z van de Sande et al. ICCVâ€™11*

![RCNN-1](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/rcnn2.png)

> *Obrazy z [tego bloga](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e)*

### F-RCNN - Fast R-CNN

To podejÅ›cie jest podobne do R-CNN, ale regiony sÄ… definiowane po zastosowaniu warstw konwolucyjnych.

![FRCNN](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/f-rcnn.png)

> Obraz z [oficjalnego artykuÅ‚u](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf), [arXiv](https://arxiv.org/pdf/1504.08083.pdf), 2015

### Faster R-CNN

GÅ‚Ã³wna idea tego podejÅ›cia polega na uÅ¼yciu sieci neuronowej do przewidywania ROI â€“ tak zwanej *Region Proposal Network*. [ArtykuÅ‚](https://arxiv.org/pdf/1506.01497.pdf), 2016

![FasterRCNN](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/faster-rcnn.png)

> Obraz z [oficjalnego artykuÅ‚u](https://arxiv.org/pdf/1506.01497.pdf)

### R-FCN: Region-Based Fully Convolutional Network

Ten algorytm jest jeszcze szybszy niÅ¼ Faster R-CNN. GÅ‚Ã³wna idea jest nastÄ™pujÄ…ca:

1. WyciÄ…gamy cechy za pomocÄ… ResNet-101.
2. Cechy sÄ… przetwarzane przez **Position-Sensitive Score Map**. KaÅ¼dy obiekt z $C$ klas jest podzielony na $k\times k$ regiony, a sieÄ‡ uczy siÄ™ przewidywaÄ‡ czÄ™Å›ci obiektÃ³w.
3. Dla kaÅ¼dej czÄ™Å›ci z $k\times k$ regionÃ³w wszystkie sieci gÅ‚osujÄ… na klasy obiektÃ³w, a klasa obiektu z najwiÄ™kszÄ… liczbÄ… gÅ‚osÃ³w jest wybierana.

![r-fcn image](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/r-fcn.png)

> Obraz z [oficjalnego artykuÅ‚u](https://arxiv.org/abs/1605.06409)

### YOLO - You Only Look Once

YOLO to algorytm jednoprzebiegowy w czasie rzeczywistym. GÅ‚Ã³wna idea jest nastÄ™pujÄ…ca:

 * Obraz jest podzielony na $S\times S$ regiony.
 * Dla kaÅ¼dego regionu **CNN** przewiduje $n$ moÅ¼liwych obiektÃ³w, wspÃ³Å‚rzÄ™dne *granicy obiektu* oraz *pewnoÅ›Ä‡*=*prawdopodobieÅ„stwo* * IoU.

 ![YOLO](../../../../../lessons/4-ComputerVision/11-ObjectDetection/images/yolo.png)

> Obraz z [oficjalnego artykuÅ‚u](https://arxiv.org/abs/1506.02640)

### Inne algorytmy

* RetinaNet: [oficjalny artykuÅ‚](https://arxiv.org/abs/1708.02002)
   - [Implementacja w PyTorch w Torchvision](https://pytorch.org/vision/stable/_modules/torchvision/models/detection/retinanet.html)
   - [Implementacja w Keras](https://github.com/fizyr/keras-retinanet)
   - [Wykrywanie obiektÃ³w za pomocÄ… RetinaNet](https://keras.io/examples/vision/retinanet/) w przykÅ‚adach Keras
* SSD (Single Shot Detector): [oficjalny artykuÅ‚](https://arxiv.org/abs/1512.02325)

## âœï¸ Ä†wiczenia: Wykrywanie ObiektÃ³w

Kontynuuj naukÄ™ w nastÄ™pujÄ…cym notatniku:

[ObjectDetection.ipynb](../../../../../lessons/4-ComputerVision/11-ObjectDetection/ObjectDetection.ipynb)

## Podsumowanie

W tej lekcji odbyÅ‚eÅ› szybki przeglÄ…d rÃ³Å¼nych sposobÃ³w, w jakie moÅ¼na realizowaÄ‡ wykrywanie obiektÃ³w!

## ğŸš€ Wyzwanie

Przeczytaj te artykuÅ‚y i notatniki o YOLO i sprÃ³buj je samodzielnie:

* [Dobry wpis na blogu](https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/) opisujÄ…cy YOLO
 * [Oficjalna strona](https://pjreddie.com/darknet/yolo/)
 * YOLO: [Implementacja w Keras](https://github.com/experiencor/keras-yolo2), [notatnik krok po kroku](https://github.com/experiencor/basic-yolo-keras/blob/master/Yolo%20Step-by-Step.ipynb)
 * YOLO v2: [Implementacja w Keras](https://github.com/experiencor/keras-yolo2), [notatnik krok po kroku](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb)

## [Quiz po wykÅ‚adzie](https://ff-quizzes.netlify.app/en/ai/quiz/22)

## PrzeglÄ…d i samodzielna nauka

* [Wykrywanie ObiektÃ³w](https://tjmachinelearning.com/lectures/1718/obj/) autorstwa Nikhila Sardany
* [Dobry przeglÄ…d algorytmÃ³w wykrywania obiektÃ³w](https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html)
* [PrzeglÄ…d algorytmÃ³w gÅ‚Ä™bokiego uczenia do wykrywania obiektÃ³w](https://medium.com/comet-app/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852)
* [Wprowadzenie krok po kroku do podstawowych algorytmÃ³w wykrywania obiektÃ³w](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/)
* [Implementacja Faster R-CNN w Pythonie do wykrywania obiektÃ³w](https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/)

## [Zadanie: Wykrywanie ObiektÃ³w](lab/README.md)

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ staramy siÄ™ zapewniÄ‡ dokÅ‚adnoÅ›Ä‡, prosimy mieÄ‡ na uwadze, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z uÅ¼ycia tego tÅ‚umaczenia.