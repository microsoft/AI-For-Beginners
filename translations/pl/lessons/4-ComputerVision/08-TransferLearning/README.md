# WstÄ™pnie wytrenowane sieci i transfer uczenia

Trenowanie CNN moÅ¼e zajÄ…Ä‡ duÅ¼o czasu, a do tego zadania potrzebne sÄ… duÅ¼e iloÅ›ci danych. Jednak wiÄ™kszoÅ›Ä‡ czasu poÅ›wiÄ™ca siÄ™ na naukÄ™ najlepszych filtrÃ³w niskiego poziomu, ktÃ³re sieÄ‡ moÅ¼e wykorzystaÄ‡ do wyodrÄ™bniania wzorcÃ³w z obrazÃ³w. Pojawia siÄ™ naturalne pytanie - czy moÅ¼emy uÅ¼yÄ‡ sieci neuronowej wytrenowanej na jednym zbiorze danych i dostosowaÄ‡ jÄ… do klasyfikacji innych obrazÃ³w bez koniecznoÅ›ci peÅ‚nego procesu trenowania?

## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ai/quiz/15)

To podejÅ›cie nazywa siÄ™ **transferem uczenia**, poniewaÅ¼ przenosimy pewnÄ… wiedzÄ™ z jednego modelu sieci neuronowej do innego. W transferze uczenia zazwyczaj zaczynamy od modelu wstÄ™pnie wytrenowanego, ktÃ³ry zostaÅ‚ wytrenowany na duÅ¼ym zbiorze obrazÃ³w, takim jak **ImageNet**. Te modele potrafiÄ… juÅ¼ dobrze wyodrÄ™bniaÄ‡ rÃ³Å¼ne cechy z ogÃ³lnych obrazÃ³w, a w wielu przypadkach samo zbudowanie klasyfikatora na podstawie tych wyodrÄ™bnionych cech moÅ¼e daÄ‡ dobre rezultaty.

> âœ… Transfer uczenia to termin, ktÃ³ry moÅ¼na znaleÅºÄ‡ w innych dziedzinach akademickich, takich jak edukacja. Odnosi siÄ™ do procesu przenoszenia wiedzy z jednej dziedziny i stosowania jej w innej.

## WstÄ™pnie wytrenowane modele jako ekstraktory cech

Sieci konwolucyjne, o ktÃ³rych mÃ³wiliÅ›my w poprzedniej sekcji, zawierajÄ… wiele warstw, z ktÃ³rych kaÅ¼da ma za zadanie wyodrÄ™bniaÄ‡ pewne cechy z obrazu, zaczynajÄ…c od kombinacji pikseli niskiego poziomu (takich jak linie poziome/pionowe czy kreski), aÅ¼ po kombinacje cech wyÅ¼szego poziomu, odpowiadajÄ…ce np. oku pÅ‚omienia. JeÅ›li wytrenujemy CNN na wystarczajÄ…co duÅ¼ym zbiorze ogÃ³lnych i zrÃ³Å¼nicowanych obrazÃ³w, sieÄ‡ powinna nauczyÄ‡ siÄ™ wyodrÄ™bniaÄ‡ te wspÃ³lne cechy.

ZarÃ³wno Keras, jak i PyTorch zawierajÄ… funkcje umoÅ¼liwiajÄ…ce Å‚atwe Å‚adowanie wstÄ™pnie wytrenowanych wag sieci neuronowych dla niektÃ³rych popularnych architektur, z ktÃ³rych wiÄ™kszoÅ›Ä‡ zostaÅ‚a wytrenowana na obrazach z ImageNet. NajczÄ™Å›ciej uÅ¼ywane z nich sÄ… opisane na stronie [Architektury CNN](../07-ConvNets/CNN_Architectures.md) z poprzedniej lekcji. W szczegÃ³lnoÅ›ci warto rozwaÅ¼yÄ‡ uÅ¼ycie jednej z poniÅ¼szych:

* **VGG-16/VGG-19**, ktÃ³re sÄ… stosunkowo prostymi modelami, ale nadal dajÄ… dobrÄ… dokÅ‚adnoÅ›Ä‡. CzÄ™sto uÅ¼ycie VGG jako pierwszej prÃ³by jest dobrym wyborem, aby zobaczyÄ‡, jak dziaÅ‚a transfer uczenia.
* **ResNet** to rodzina modeli zaproponowanych przez Microsoft Research w 2015 roku. MajÄ… wiÄ™cej warstw, a zatem wymagajÄ… wiÄ™cej zasobÃ³w.
* **MobileNet** to rodzina modeli o zmniejszonym rozmiarze, odpowiednia dla urzÄ…dzeÅ„ mobilnych. UÅ¼ywaj ich, jeÅ›li masz ograniczone zasoby i moÅ¼esz poÅ›wiÄ™ciÄ‡ trochÄ™ dokÅ‚adnoÅ›ci.

Oto przykÅ‚adowe cechy wyodrÄ™bnione z obrazu kota przez sieÄ‡ VGG-16:

![Cechy wyodrÄ™bnione przez VGG-16](../../../../../translated_images/pl/features.6291f9c7ba3a0b95.webp)

## ZbiÃ³r danych Koty vs. Psy

W tym przykÅ‚adzie uÅ¼yjemy zbioru danych [Koty i Psy](https://www.microsoft.com/download/details.aspx?id=54765&WT.mc_id=academic-77998-cacaste), ktÃ³ry jest bardzo zbliÅ¼ony do scenariusza klasyfikacji obrazÃ³w w rzeczywistych warunkach.

## âœï¸ Ä†wiczenie: Transfer uczenia

Zobaczmy transfer uczenia w praktyce w odpowiednich notebookach:

* [Transfer uczenia - PyTorch](TransferLearningPyTorch.ipynb)
* [Transfer uczenia - TensorFlow](TransferLearningTF.ipynb)

## Wizualizacja idealnego kota

WstÄ™pnie wytrenowana sieÄ‡ neuronowa zawiera rÃ³Å¼ne wzorce w swoim *mÃ³zgu*, w tym pojÄ™cia **idealnego kota** (jak rÃ³wnieÅ¼ idealnego psa, idealnej zebry itd.). ByÅ‚oby interesujÄ…ce jakoÅ› **zwizualizowaÄ‡ ten obraz**. Jednak nie jest to proste, poniewaÅ¼ wzorce sÄ… rozproszone po wagach sieci i zorganizowane w hierarchicznÄ… strukturÄ™.

Jednym z podejÅ›Ä‡, ktÃ³re moÅ¼emy zastosowaÄ‡, jest rozpoczÄ™cie od losowego obrazu, a nastÄ™pnie prÃ³ba uÅ¼ycia techniki **optymalizacji metodÄ… gradientu** w celu dostosowania tego obrazu w taki sposÃ³b, aby sieÄ‡ zaczÄ™Å‚a myÅ›leÄ‡, Å¼e to kot.

![PÄ™tla optymalizacji obrazu](../../../../../translated_images/pl/ideal-cat-loop.999fbb8ff306e044.webp)

Jednak jeÅ›li to zrobimy, otrzymamy coÅ› bardzo podobnego do losowego szumu. Dzieje siÄ™ tak, poniewaÅ¼ *istnieje wiele sposobÃ³w, aby sieÄ‡ myÅ›laÅ‚a, Å¼e obraz wejÅ›ciowy to kot*, w tym takie, ktÃ³re nie majÄ… sensu wizualnie. ChociaÅ¼ te obrazy zawierajÄ… wiele wzorcÃ³w typowych dla kota, nic nie zmusza ich do bycia wizualnie wyraÅºnymi.

Aby poprawiÄ‡ wynik, moÅ¼emy dodaÄ‡ kolejny skÅ‚adnik do funkcji straty, ktÃ³ry nazywa siÄ™ **stratÄ… wariacji**. Jest to metryka pokazujÄ…ca, jak podobne sÄ… sÄ…siadujÄ…ce piksele obrazu. Minimalizowanie straty wariacji sprawia, Å¼e obraz staje siÄ™ bardziej gÅ‚adki i pozbywa siÄ™ szumu - ujawniajÄ…c bardziej atrakcyjne wizualnie wzorce. Oto przykÅ‚ad takich "idealnych" obrazÃ³w, ktÃ³re sÄ… klasyfikowane jako kot i jako zebra z duÅ¼ym prawdopodobieÅ„stwem:

![Idealny kot](../../../../../translated_images/pl/ideal-cat.203dd4597643d6b0.webp) | ![Idealna zebra](../../../../../translated_images/pl/ideal-zebra.7f70e8b54ee15a7a.webp)
-----|-----
 *Idealny kot* | *Idealna zebra*

Podobne podejÅ›cie moÅ¼na zastosowaÄ‡ do przeprowadzania tzw. **atakÃ³w adversarialnych** na sieÄ‡ neuronowÄ…. ZaÅ‚Ã³Å¼my, Å¼e chcemy oszukaÄ‡ sieÄ‡ neuronowÄ… i sprawiÄ‡, by pies wyglÄ…daÅ‚ jak kot. JeÅ›li weÅºmiemy obraz psa, ktÃ³ry jest rozpoznawany przez sieÄ‡ jako pies, moÅ¼emy go nieco zmodyfikowaÄ‡ za pomocÄ… optymalizacji metodÄ… gradientu, aÅ¼ sieÄ‡ zacznie klasyfikowaÄ‡ go jako kota:

![Obraz psa](../../../../../translated_images/pl/original-dog.8f68a67d2fe0911f.webp) | ![Obraz psa klasyfikowany jako kot](../../../../../translated_images/pl/adversarial-dog.d9fc7773b0142b89.webp)
-----|-----
*Oryginalny obraz psa* | *Obraz psa klasyfikowany jako kot*

Zobacz kod, aby odtworzyÄ‡ powyÅ¼sze wyniki w nastÄ™pujÄ…cym notebooku:

* [Idealny i adversarialny kot - TensorFlow](AdversarialCat_TF.ipynb)

## Podsumowanie

DziÄ™ki transferowi uczenia moÅ¼esz szybko stworzyÄ‡ klasyfikator do zadania klasyfikacji niestandardowych obiektÃ³w i osiÄ…gnÄ…Ä‡ wysokÄ… dokÅ‚adnoÅ›Ä‡. WidaÄ‡, Å¼e bardziej zÅ‚oÅ¼one zadania, ktÃ³re teraz rozwiÄ…zujemy, wymagajÄ… wiÄ™kszej mocy obliczeniowej i nie mogÄ… byÄ‡ Å‚atwo rozwiÄ…zane na CPU. W nastÄ™pnej jednostce sprÃ³bujemy uÅ¼yÄ‡ bardziej lekkiej implementacji, aby wytrenowaÄ‡ ten sam model przy uÅ¼yciu mniejszych zasobÃ³w obliczeniowych, co skutkuje tylko nieznacznie niÅ¼szÄ… dokÅ‚adnoÅ›ciÄ….

## ğŸš€ Wyzwanie

W towarzyszÄ…cych notebookach znajdujÄ… siÄ™ notatki na dole dotyczÄ…ce tego, jak transfer wiedzy dziaÅ‚a najlepiej z nieco podobnymi danymi treningowymi (na przykÅ‚ad nowy typ zwierzÄ™cia). PrzeprowadÅº eksperymenty z zupeÅ‚nie nowymi typami obrazÃ³w, aby zobaczyÄ‡, jak dobrze lub Åºle dziaÅ‚ajÄ… Twoje modele transferu wiedzy.

## [Quiz po wykÅ‚adzie](https://ff-quizzes.netlify.app/en/ai/quiz/16)

## PrzeglÄ…d i samodzielna nauka

Przeczytaj [TrainingTricks.md](TrainingTricks.md), aby pogÅ‚Ä™biÄ‡ swojÄ… wiedzÄ™ na temat innych sposobÃ³w trenowania modeli.

## [Zadanie](lab/README.md)

W tym laboratorium uÅ¼yjemy rzeczywistego zbioru danych [Oxford-IIIT](https://www.robots.ox.ac.uk/~vgg/data/pets/) zawierajÄ…cego 35 ras kotÃ³w i psÃ³w, i zbudujemy klasyfikator transferu uczenia.

---

