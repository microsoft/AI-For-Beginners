# 倫理與負責任的人工智慧

你即將完成這門課程，希望到目前為止，你已經清楚了解到人工智慧是基於一系列正式的數學方法，這些方法讓我們能夠在數據中找到關聯，並訓練模型來模仿人類行為的某些方面。在這個歷史時刻，我們認為人工智慧是一個非常強大的工具，可以從數據中提取模式，並將這些模式應用於解決新問題。

## [課前測驗](https://white-water-09ec41f0f.azurestaticapps.net/quiz/5/)

然而，在科幻小說中，我們經常看到人工智慧對人類構成威脅的故事。這些故事通常圍繞某種人工智慧的反叛展開，當人工智慧決定與人類對抗時，這暗示人工智慧具有某種情感或能做出開發者無法預見的決策。

在這門課程中，我們學到的人工智慧無非是大型矩陣運算。它是一個非常強大的工具，可以幫助我們解決問題，但就像任何其他強大的工具一樣——它既可以被用於好的目的，也可以被用於壞的目的。重要的是，它可能會被*濫用*。

## 負責任的人工智慧原則

為了避免人工智慧的意外或故意濫用，微軟提出了重要的[負責任的人工智慧原則](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-77998-cacaste)。以下概念是這些原則的基礎：

* **公平性**與*模型偏差*這一重要問題相關，偏差可能是由於使用了有偏差的數據進行訓練。例如，當我們試圖預測某人獲得軟體開發工作機會的可能性時，模型可能會更偏向男性，這只是因為訓練數據集可能偏向於男性受眾。我們需要仔細平衡訓練數據並調查模型，以避免偏差，並確保模型考慮到更多相關特徵。
* **可靠性與安全性**。由於其本質，人工智慧模型可能會犯錯。神經網絡返回的是概率，我們在做決策時需要考慮到這一點。每個模型都有一定的精確度和召回率，我們需要理解這些指標，以防止錯誤建議可能帶來的傷害。
* **隱私與安全性**具有一些人工智慧特有的影響。例如，當我們使用某些數據來訓練模型時，這些數據會以某種方式“整合”到模型中。一方面，這提高了安全性和隱私性；另一方面，我們需要記住模型是基於哪些數據進行訓練的。
* **包容性**意味著我們不是在構建人工智慧來取代人類，而是為了增強人類的能力，使我們的工作更具創造性。這也與公平性相關，因為在處理代表性不足的社群時，我們收集的大多數數據集可能存在偏差，我們需要確保這些社群被納入考量並得到人工智慧的正確處理。
* **透明性**。這包括確保我們始終清楚地表明人工智慧正在被使用。此外，在可能的情況下，我們希望使用*可解釋*的人工智慧系統。
* **問責性**。當人工智慧模型做出某些決策時，並不總是清楚誰應該對這些決策負責。我們需要確保我們理解人工智慧決策的責任所在。在大多數情況下，我們希望將人類納入重要決策的過程中，確保實際的人對決策負責。

## 負責任的人工智慧工具

微軟開發了[負責任的人工智慧工具箱](https://github.com/microsoft/responsible-ai-toolbox)，其中包含一系列工具：

* 解釋性儀表板 (InterpretML)
* 公平性儀表板 (FairLearn)
* 錯誤分析儀表板
* 負責任的人工智慧儀表板，包括：

   - EconML - 用於因果分析的工具，專注於假設性問題
   - DiCE - 用於反事實分析的工具，讓你了解需要改變哪些特徵才能影響模型的決策

想了解更多關於人工智慧倫理的資訊，請參考[這一課程](https://github.com/microsoft/ML-For-Beginners/tree/main/1-Introduction/3-fairness?WT.mc_id=academic-77998-cacaste)，該課程屬於機器學習課程大綱，並包含作業。

## 回顧與自學

參加這個[學習路徑](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77998-cacaste)，深入了解負責任的人工智慧。

## [課後測驗](https://white-water-09ec41f0f.azurestaticapps.net/quiz/6/)

**免責聲明**：  
本文件已使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。儘管我們努力確保翻譯的準確性，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應被視為權威來源。對於關鍵信息，建議使用專業人工翻譯。我們對因使用此翻譯而引起的任何誤解或誤釋不承擔責任。